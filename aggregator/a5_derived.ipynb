{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Aggregator 4: Derived__\n",
        "\n",
        "This tutorial describes how to estimate derived quantities from a model-fit, where a derived quantity is one which may\n",
        "be used for the analysis and interpreation of results but is not explicitly a free parameter in the non-linear search.\n",
        "\n",
        "An example is the total luminosity of the lens or source galaxy, or total mass of the lens galaxy. These quantities\n",
        "are estimated by a PyAutoLens model-fit, but are estimated from a combination of lens model parameters.\n",
        "\"\"\"\n",
        "\n",
        "from autoconf import conf\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we set up the aggregator as we did in the previous tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "workspace_path = \"/home/jammy/PycharmProjects/PyAuto/autolens_workspace\"\n",
        "output_path = f\"{workspace_path}/output\"\n",
        "agg_results_path = f\"{output_path}/aggregator\"\n",
        "\n",
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\", output_path=output_path\n",
        ")\n",
        "\n",
        "agg = af.Aggregator(directory=str(agg_results_path))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "name = \"phase__aggregator\"\n",
        "agg_phase3 = agg.filter(agg.phase == name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, lets compute the axis ratio of a lens model, including the errors on the axis ratio. In the previous tutorials, \n",
        "we saw that the errors on a quantity like the elliptical_comps is simple, because it was sampled by the non-linear \n",
        "search. Thus, to get their we can uses the Samples object to simply marginalize over all over parameters via the 1D \n",
        "Probability Density Function (PDF).\n",
        "\n",
        "But what if we want the errors on the axis-ratio? This wasn`t a free parameter in our model so we can`t just \n",
        "marginalize over all other parameters.\n",
        "\n",
        "Instead, we need to compute the axis-ratio of every lens model sampled by the `NonLinearSearch` and from this determine \n",
        "the PDF of the axis-ratio. When combining the different axis-ratios we weight each value by its `weight`. For Dynesty,\n",
        "the nested sampler we fitted our aggregator sample with, this downweights the model which gave lower likelihood fits.\n",
        "For other `NonLinearSearch` methods (e.g. MCMC) the weights can take on a different meaning but can still be used for\n",
        "combining different model results.\n",
        "\n",
        "Below, we get an instance of every Dynesty sample using the `Samples`, compute that models axis-ratio, store them in a \n",
        "list and find the weighted median value with errors.\n",
        "\n",
        "This function takes the list of axis-ratio values with their sample weights and computes the weighted mean and \n",
        "standard deviation of these values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def weighted_mean_and_standard_deviation(values, weights):\n",
        "    \"\"\"\n",
        "    Return the weighted average and standard deviation.\n",
        "    values, weights -- Numpy ndarrays with the same shape.\n",
        "    \"\"\"\n",
        "    values = np.asarray(values)\n",
        "    weights = np.asarray(weights)\n",
        "    average = np.average(values, weights=weights)\n",
        "    # Fast and numerically precise:\n",
        "    variance = np.average((values - average) ** 2, weights=weights)\n",
        "    return (average, np.sqrt(variance))\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we iterate over each Samples object, using every model instance to compute its axis-ratio. We combine these \n",
        "axis-ratios with the samples weights to give us the weighted mean axis-ratio and error.\n",
        "\n",
        "To do this, we again use a generator. Whislt the axis-ratio is a fairly light-weight value, and this could be\n",
        "performed using a list without crippling your comptuer`s memory, for other quantities this is not the case. Thus, for\n",
        "computing derived quantities it is good practise to always use a generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def axis_ratio_error_from_agg_obj(agg_obj):\n",
        "\n",
        "    samples = agg_obj.samples\n",
        "\n",
        "    axis_ratios = []\n",
        "\n",
        "    for sample_index in range(samples.total_accepted_samples):\n",
        "\n",
        "        instance = samples.instance_from_sample_index(sample_index=sample_index)\n",
        "\n",
        "        axis_ratio = al.convert.axis_ratio_from(\n",
        "            elliptical_comps=instance.galaxies.mass.elliptical_comps\n",
        "        )\n",
        "\n",
        "        axis_ratios.append(axis_ratio)\n",
        "\n",
        "    return weighted_mean_and_standard_deviation(\n",
        "        values=axis_ratios, weights=samples.weights\n",
        "    )\n",
        "\n",
        "\n",
        "axis_ratio, axis_ratio_error = agg_phase3.map(func=axis_ratio_error_from_agg_obj)\n",
        "\n",
        "print(\"Axis Ratio:\\n\")\n",
        "print(axis_ratio)\n",
        "print(\"Axis Ratio Error\\n\")\n",
        "print(axis_ratio_error())\n",
        "stop\n",
        "\n",
        "\n",
        "def axis_ratio_error(agg_obj):\n",
        "\n",
        "    samples = agg_obj.samples\n",
        "\n",
        "    sample_masses = []\n",
        "\n",
        "    for sample_index in range(samples.total_accepted_samples):\n",
        "\n",
        "        if samples.weights[sample_index] > 1.0e-4:\n",
        "\n",
        "            instance = samples.instance_from_sample_index(sample_index=sample_index)\n",
        "\n",
        "            einstein_mass = instance.galaxies.lens.einstein_mass_in_units(\n",
        "                redshift_object=instance.galaxies.lens.redshift,\n",
        "                redshift_source=instance.galaxies.source.redshift,\n",
        "            )\n",
        "\n",
        "            sample_masses.append(einstein_mass)\n",
        "\n",
        "    return weighted_mean_and_standard_deviation(\n",
        "        values=sample_masses, weights=samples.weights\n",
        "    )\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also iterate over every Fit of our results, to extracting derived information on the fit. Below, we reperform\n",
        "every source reconstruction of the fit and ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_gen = al.agg.FitImaging(aggregator=agg_phase[3])\n",
        "\n",
        "for fit in fit_gen:\n",
        "\n",
        "    print(fit.inversion)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}