{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lens Models__\n",
    "\n",
    "This tutorial builds on tutorial_1 of the aggregator autolens_workspace. Here, we use the aggregator to load models from a non-linear search and visualize and interpret results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autofit as af\n",
    "import autolens as al\n",
    "import autolens.plot as aplt\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frist, we set up the aggregator as we did in the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = \"/home/jammy/PycharmProjects/PyAuto/autolens_workspace/\"\n",
    "output_path = workspace_path + \"output\"\n",
    "aggregator_results_path = output_path + \"/aggregator_sample_beginner\"\n",
    "\n",
    "af.conf.instance = af.conf.Config(\n",
    "    config_path=str(workspace_path + \"/config\"), output_path=str(output_path)\n",
    ")\n",
    "\n",
    "aggregator = af.Aggregator(directory=str(aggregator_results_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets create a list of instances of the most-likely models of the final phase of each fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"pipeline__lens_sie__source_inversion\"\n",
    "phase_name = \"phase_3__source_inversion\"\n",
    "\n",
    "outputs = aggregator.filter(phase=phase_name).output\n",
    "\n",
    "instances = [out.most_likely_instance for out in outputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model instance is a Galaxy instance of the pipeline's GalaxyModel. So, its just a list of galaxies which we can pass to functions in PyAutoLens. Lets create the most-likely tracer of every fit..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracers = [\n",
    "    al.Tracer.from_galaxies(galaxies=instance.galaxies) for instance in instances\n",
    "]\n",
    "\n",
    "print(\"Most Likely Tracers: \\n\")\n",
    "print(tracers, \"\\n\")\n",
    "print(\"Total Tracers = \", len(tracers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and then plot their convergences.\n",
    "\n",
    "We'll just use a grid of 100 x 100 pixels for now, and cover later how we use the actual grid of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = al.grid.uniform(shape_2d=(100, 100), pixel_scales=0.1)\n",
    "\n",
    "[aplt.tracer.convergence(tracer=tracer, grid=grid) for tracer in tracers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because instances are just lists of galaxies we can directly extract attributes of the Galaxy class. Lets print  the Einstein mass of each of our most-likely lens galaxies.\n",
    "\n",
    "The model instance uses the model defined by a pipeline. In this pipeline, we called the lens galaxy 'lens'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Most Likely Lens Einstein Masses:\")\n",
    "print(\n",
    "    [\n",
    "        instance.galaxies.lens.einstein_mass_in_units(\n",
    "            redshift_object=instance.galaxies.lens.redshift, \n",
    "            redshift_source=instance.galaxies.source.redshift\n",
    "        )\n",
    "        for instance in instances\n",
    "    ]\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets next do something a bit more ambitious. Lets create a plot of the einstein_radius vs axis_ratio of each SIE mass profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_instances = [out.most_probable_instance for out in outputs]\n",
    "einstein_radii = [\n",
    "    instance.galaxies.lens.mass.einstein_radius\n",
    "    for instance in mp_instances\n",
    "]\n",
    "axis_ratios = [\n",
    "    instance.galaxies.lens.mass.axis_ratio for instance in mp_instances\n",
    "]\n",
    "\n",
    "print(einstein_radii)\n",
    "print(axis_ratios)\n",
    "\n",
    "plt.scatter(\n",
    "    einstein_radii, axis_ratios, marker=\"x\" \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets also include error bars at 3 sigma confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bugged until Friday.\n",
    "\n",
    "upper_error_instances = [\n",
    "    out.error_instance_at_upper_sigma(sigma=3.0)\n",
    "    for out in outputs\n",
    "]\n",
    "lower_error_instances = [\n",
    "    out.error_instance_at_lower_sigma(sigma=3.0)\n",
    "    for out in outputs\n",
    "]\n",
    "\n",
    "einstein_radii_upper = [\n",
    "    instance.galaxies.lens.mass.einstein_radius for instance in upper_error_instances\n",
    "]\n",
    "einstein_radii_lower = [\n",
    "    instance.galaxies.lens.mass.einstein_radius for instance in lower_error_instances\n",
    "]\n",
    "axis_ratios_upper = [\n",
    "    instance.galaxies.lens.mass.axis_ratio for instance in upper_error_instances\n",
    "]\n",
    "axis_ratios_lower = [\n",
    "    instance.galaxies.lens.mass.axis_ratio for instance in lower_error_instances\n",
    "]\n",
    "\n",
    "plt.errorbar(\n",
    "    x=einstein_radii, y=axis_ratios, \n",
    "    xerr=[einstein_radii_upper, einstein_radii_lower], \n",
    "    yerr=[axis_ratios_upper, axis_ratios_lower]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets compute the errors on an attribute that wasn't a free parameter in our model fit. For example, getting the errors on an axis_ratio is simple, because it was sampled by MultiNest during the fit. Thus, to get errors on the axis ratio we simply marginalizes over all over parameters to produce the 1D Probability Density Function (PDF).\n",
    "\n",
    "But what if we want the errors on the Einstein Mass? This wasn't a free parameter in our model so we can't just marginalize over all other parameters.\n",
    "\n",
    "Instead, we need to compute the Einstein mass of every lens model sampled by MultiNest and from this determine the PDF of the Einstein mass. When combining the different Einstein mass we weight each value by its MultiNest sampling probablity. This means that models which gave a poor fit to the data are downweighted appropriately.\n",
    "\n",
    "Below, we get an instance of every MultiNest sample using the MultiNestOutput, compute that models einstein mass, store them in a list and find the weighted median value with errors.\n",
    "\n",
    "This function takes the list of Einstein mass values with their sample weights and computed the weighted mean and standard deviation of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean_and_standard_deviation(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "    values, weights -- Numpy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    values = np.asarray(values)\n",
    "    weights = np.asarray(weights)\n",
    "    average = np.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.average((values - average) ** 2, weights=weights)\n",
    "    return (average, np.sqrt(variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we iterate over each MultiNestOutput, extracting all samples and computing ther masses and weights and compute the weighted mean of these samples.\n",
    "\n",
    "Computing an Einstein mass takes a bit of time, so be warned this cell could run for a few minutes! To speed things up, you'll notice that we only perform the loop on samples whose probably is above 1.0e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight_threshold = 1.0e-4\n",
    "\n",
    "einstein_masses = []\n",
    "einstein_mass_errors = []\n",
    "\n",
    "for output in outputs:\n",
    "\n",
    "    sample_masses = []\n",
    "    sample_weights = []\n",
    "\n",
    "    for sample_index in range(output.total_samples):\n",
    "\n",
    "        sample_weight = output.weight_from_sample_index(sample_index=sample_index)\n",
    "\n",
    "        if sample_weight > sample_weight_threshold:\n",
    "\n",
    "            instance = output.instance_from_sample_index(sample_index=sample_index)\n",
    "\n",
    "            einstein_mass = instance.galaxies.lens.einstein_mass_in_units(\n",
    "                redshift_object=instance.galaxies.lens.redshift,\n",
    "                redshift_source=instance.galaxies.source.redshift,\n",
    "            )\n",
    "\n",
    "            sample_masses.append(einstein_mass)\n",
    "            sample_weights.append(sample_weight)\n",
    "\n",
    "    value, error = weighted_mean_and_standard_deviation(\n",
    "        values=sample_masses, weights=sample_weights\n",
    "    )\n",
    "    einstein_masses.append(value)\n",
    "    einstein_mass_errors.append(value)\n",
    "    \n",
    "print(\"Einstein Masses:\\n\")\n",
    "print(einstein_masses)\n",
    "print(\"Einstein Mass Errors\\n\")\n",
    "print(einstein_mass_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
