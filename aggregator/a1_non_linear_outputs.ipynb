{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Aggregato 1: Non Linear Outputs__\n",
        "\n",
        "After fitting a large suite of data with the same pipeline, the aggregator allows us to load the results and manipulate\n",
        "/ plot them using a Python script or Jupyter notebook.\n",
        "\n",
        "This script uses the results generated by the script '/autolens_workspace/aggregator/beginner_runner.py',\n",
        "which fitted 3 simulated strong lenses. We fitted each image with the pipeline:\n",
        "\n",
        "'autolens_workspace/pipelines/beginner/no_lens_light/lens_sie__source_inversion.py'\n",
        "\n",
        "This pipeline is composed of 3 phases.\n",
        "\n",
        "__File Output__\n",
        "\n",
        "The results of this fit are in the '/output/aggregator_sample_beginner' folder. First, take a look in this folder.\n",
        "Provided you haven't rerun the runner, you'll notice that all the results (e.g. optimizer, optimizer_backup,\n",
        "model.results, images, etc.) are in .zip files as opposed to folders that can be instantly accessed.\n",
        "\n",
        "This is because when the pipeline was run, the 'remove_files' option in the 'config/general.ini' was set to True.\n",
        "This means all results (other than the .zip file) were removed. This feature is implemented because super-computers\n",
        "often have a limit on the number of files allowed per user.\n",
        "\n",
        "Bare in mind the fact that all results are in .zip files - we'll come back to this point in a second.\n",
        "\n",
        "__Aggregator__\n",
        "\n",
        "We can load the results of each pipeline's analysis of each of the 3 images using the aggregator. This will allow us to\n",
        "manipulate the results in this Python script (or a Jupyter notebook) to plot figures, interpret results, check specific\n",
        "values, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, we setup the path to the output path we want to load results from, which in this case is the folder \n",
        "'autolens_workspace/output/aggregator_sample_beginner'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "workspace_path = \"/home/jammy/PycharmProjects/PyAuto/autolens_workspace/\"\n",
        "output_path = workspace_path + \"output\"\n",
        "agg_results_path = output_path + \"/aggregator_sample_beginner\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll use this path to explicitly set the config path and output path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "af.conf.instance = af.conf.Config(\n",
        "    config_path=str(workspace_path + \"/config\"), output_path=str(output_path)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To set up the aggregator we simply pass it the folder of the results we want to load."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg = af.Aggregator(directory=str(agg_results_path))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we continue, take another look at the output folder. The .zip files containing results have now all been \n",
        "unzipped, such that the results are accessible on your laptop for navigation. This means you can run fits to many \n",
        "lenses on a super computer and easily unzip all the results on your computer afterwards via the aggregator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, let me quickly explain what a generator is in Python, for those unaware. A generator is an object that \n",
        "iterates over a function when it is called. The aggregator creates all objects as generators, rather than lists, or \n",
        "dictionaries, or whatever.\n",
        "\n",
        "Why? Because lists store every entry in memory simultaneously. If you fit many lenses, you'll have lots of results and \n",
        "therefore use a lot of memory. This will crash your laptop! On the other hand, a generator only stores the object in \n",
        "memory when it runs the function; it is free to overwrite it afterwards. This, your laptop won't crash!\n",
        "\n",
        "There are two things to bare in mind with generators:\n",
        "\n",
        "1) A generator has no length, thus to determine how many entries of data it corresponds to you first must turn it to a \n",
        "list.\n",
        "\n",
        "2) Once we use a generator, we cannot use it again - we'll need to remake it.\n",
        "\n",
        "We can now create a 'non-linear outputs' generator of every fit. An instance of the NonLinearOutput class acts as an \n",
        "interface between the results of the non-linear fit on your hard-disk and Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "output_gen = agg.values(\"output\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we print this the length of this generator converted to a list of outputs we see 9 different MultiNestOutput \n",
        "instances. These correspond to all 3 phases of each pipeline's fit to all 3 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"MultiNest Outputs: \\n\")\n",
        "print(output_gen)\n",
        "print()\n",
        "print(\"Total Outputs = \", len(list(output_gen)), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we want to remove the fits of the first 2 phases and just keep the MultiNestOutputs of the 3rd and final phase of \n",
        "the pipeline we can do so by filtering for the phase's name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "phase_name = \"phase_3__source_inversion\"\n",
        "agg_filter = agg.filter(agg.phase == phase_name)\n",
        "output_gen = agg_filter.values(\"output\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, this list now has only 3 MultiNestOutputs, one for each image we fitted (note how in the bottom print\n",
        "statement we remake the generator using the aggregator)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Phase Name Filtered MultiNest Outputs: \\n\")\n",
        "print(list(output_gen))\n",
        "print()\n",
        "print(\"Total Outputs = \", len(list(agg_filter.values(\"output\"))), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example, we only fitted the 3 images using one pipeline. But suppose we used multiple pipelines, like we do in \n",
        "the advanced pipelines. In this case, the aggregator would load the MultiNestOutputs of all fits of all phases of all \n",
        "pipelines!\n",
        "\n",
        "In such circumstances, we can filter by phase name and pipeline name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pipeline_name = \"pipeline__lens_sie__source_inversion\"\n",
        "agg_filter = agg.filter(agg.phase == phase_name, agg.pipeline == pipeline_name)\n",
        "output_gen = agg_filter.values(\"output\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, this list again has 3 MultiNestOutputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Pipeline Name Filtered MultiNest Outputs: \\n\")\n",
        "print(output_gen)\n",
        "print()\n",
        "print(\"Total Outputs = \", len(list(agg_filter.values(\"output\"))), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use the outputs to create a list of the most-likely (e.g. highest likelihood) model of each fit to our three \n",
        "images (in this case in phase 3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_vector = [out.most_likely_vector for out in agg_filter.values(\"output\")]\n",
        "\n",
        "print(\"Most Likely Model Parameter Lists: \\n\")\n",
        "print(ml_vector, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This provides us with lists of all model parameters. However, this isn't that much use - which values correspond to \n",
        "which parameters?\n",
        "\n",
        "Its more useful to create the model instance of every fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_instances = [out.most_likely_instance for out in agg_filter.values(\"output\")]\n",
        "print(\"Most Likely Model Instances: \\n\")\n",
        "print(ml_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A model instance contains all the model components of our fit - most importantly the list of galaxies we specified in the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies)\n",
        "print(ml_instances[1].galaxies)\n",
        "print(ml_instances[2].galaxies)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These galaxies will be named according to the pipeline (in this case, 'lens' and 'source')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies.lens)\n",
        "print()\n",
        "print(ml_instances[1].galaxies.source)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Their light and mass profiles are also named according to the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies.lens.mass)\n",
        "print()\n",
        "print(ml_instances[0].galaxies.lens.shear)\n",
        "print()\n",
        "print(ml_instances[1].galaxies.source.pixelization)\n",
        "print()\n",
        "print(ml_instances[1].galaxies.source.regularization)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also access the 'most probable' model, which is the model computed by marginalizing over the MultiNest samples \n",
        "of every parameter in 1D and taking the median of this PDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mp_vector = [out.most_probable_vector for out in agg_filter.values(\"output\")]\n",
        "mp_instances = [out.most_probable_instance for out in agg_filter.values(\"output\")]\n",
        "\n",
        "print(\"Most Probable Model Parameter Lists: \\n\")\n",
        "print(mp_vector, \"\\n\")\n",
        "print(\"Most probable Model Instances: \\n\")\n",
        "print(mp_instances, \"\\n\")\n",
        "print(mp_instances[0].galaxies.lens.mass)\n",
        "print(mp_instances[0].galaxies.lens.shear)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute the model parameters at a given sigma value (e.g. at 3.0 sigma limits).\n",
        "\n",
        "These parameter values do not account for covariance between the model. For example if two parameters are degenerate \n",
        "this will find their values from the degeneracy in the 'same direction' (e.g. both will be positive). \n",
        "\n",
        "# Here, I use \"uv3\" to signify this is an upper value at 3 sigma confidence,, and \"lv3\" for the lower value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "uv3_vectors = [\n",
        "    out.vector_at_upper_sigma(sigma=3.0) for out in agg_filter.values(\"output\")\n",
        "]\n",
        "\n",
        "uv3_instances = [\n",
        "    out.instance_at_upper_sigma(sigma=3.0) for out in agg_filter.values(\"output\")\n",
        "]\n",
        "\n",
        "lv3_vectors = [\n",
        "    out.vector_at_lower_sigma(sigma=3.0) for out in agg_filter.values(\"output\")\n",
        "]\n",
        "\n",
        "lv3_instances = [\n",
        "    out.instance_at_lower_sigma(sigma=3.0) for out in agg_filter.values(\"output\")\n",
        "]\n",
        "\n",
        "print(\"Errors Lists: \\n\")\n",
        "print(uv3_vectors, \"\\n\")\n",
        "print(lv3_vectors, \"\\n\")\n",
        "print(\"Errors Instances: \\n\")\n",
        "print(uv3_instances, \"\\n\")\n",
        "print(lv3_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute the upper and lower errors on each parameter at a given sigma limit.\n",
        "\n",
        "Here, \"ue3\" signifies the upper error at 3 sigma. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# These do not currently work due to a bug which will be fixed on Friday\n",
        "\n",
        "ue3_vectors = [\n",
        "    out.error_vector_at_upper_sigma(sigma=3.0) for out in agg_filter.values(\"output\")\n",
        "]\n",
        "ue3_instances = [\n",
        "    out.error_instance_at_upper_sigma(sigma=3.0) for out in agg_filter.values(\"output\")\n",
        "]\n",
        "le3_vectors = [\n",
        "    out.error_vector_at_lower_sigma(sigma=3.0) for out in agg_filter.values(\"output\")\n",
        "]\n",
        "le3_instances = [\n",
        "    out.error_instance_at_lower_sigma(sigma=3.0) for out in agg_filter.values(\"output\")\n",
        "]\n",
        "\n",
        "print(\"Errors Lists: \\n\")\n",
        "print(ue3_vectors, \"\\n\")\n",
        "print(le3_vectors, \"\\n\")\n",
        "print(\"Errors Instances: \\n\")\n",
        "print(ue3_instances, \"\\n\")\n",
        "print(le3_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The maximum likelihood of each model fit and its Bayesian evidence (estimated via MultiNest) are also available.\n",
        "\n",
        "Given each fit is to a different image, these are not very useful. However, in tutorial 5 we'll look at using the \n",
        "aggregator for images that we fit with many different models and many different pipelines, in which case comparing \n",
        "the evidences allows us to perform Bayesian model comparison!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Likelihoods: \\n\")\n",
        "print([out.maximum_log_likelihood for out in agg_filter.values(\"output\")])\n",
        "print([out.evidence for out in agg_filter.values(\"output\")])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also print the \"model_results\" of all phases, which is string that summarizes every fit's lens model providing \n",
        "quick inspection of all results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = agg_filter.model_results\n",
        "print(\"Model Results Summary: \\n\")\n",
        "print(results, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}