{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Fitting__\n",
    "\n",
    "In this tutorial, we use the aggregator to load models and data from a non-linear search and use them to reperform fits to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autofit as af\n",
    "import autolens as al\n",
    "import autolens.plot as aplt\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we set up the aggregator as we did in the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = \"/home/jammy/PycharmProjects/PyAuto/autolens_workspace/\"\n",
    "output_path = workspace_path + \"output\"\n",
    "aggregator_results_path = output_path + \"/aggregator_sample_beginner\"\n",
    "\n",
    "af.conf.instance = af.conf.Config(\n",
    "    config_path=str(workspace_path + \"/config\"), output_path=str(output_path)\n",
    ")\n",
    "\n",
    "aggregator = af.Aggregator(directory=str(aggregator_results_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we create a list of the MultiNestOutputs of each phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"pipeline__lens_sie__source_inversion\"\n",
    "phase_name = \"phase_3__source_inversion\"\n",
    "\n",
    "outputs = aggregator.filter(phase=phase_name).output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the aggregator to load the dataset of every lens our pipeline fitted. This returns the dataset as the \"Imaging\" objects we passed to the pipeline when we ran them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = aggregator.filter(phase=phase_name).dataset\n",
    "\n",
    "# There is a BUG where the pixel scale of a dataset is lost. Below is a hot-fix but this will be\n",
    "# fixed in general soon.\n",
    "\n",
    "pixel_scale = 0.1\n",
    "\n",
    "for dataset in datasets:\n",
    "\n",
    "    dataset.image.mask.pixel_scales = (pixel_scale, pixel_scale)\n",
    "    dataset.noise_map.mask.pixel_scales = (pixel_scale, pixel_scale)\n",
    "    dataset.psf.mask.pixel_scales = (pixel_scale, pixel_scale)\n",
    "\n",
    "print(\"Datasets:\")\n",
    "print(datasets, \"\\n\")\n",
    "print(datasets[0].image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot each dataset's subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[aplt.imaging.subplot_imaging(imaging=dataset) for dataset in datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need the masks we used to fit the lenses, which the aggregator also provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bugged until Friday :(\n",
    "\n",
    "# masks = aggregator.filter(phase=phase_name).mask\n",
    "# print(\"Masks:\")\n",
    "# print(masks, \"\\n\")\n",
    "\n",
    "# For now lets just use manual masks\n",
    "\n",
    "masks = [al.mask.circular(\n",
    "    shape_2d=datasets[0].shape, pixel_scales=0.1, sub_size=1, radius=3.0\n",
    ") for _ in range(len(datasets))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot each dataset's again now with its mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[aplt.imaging.subplot_imaging(imaging=dataset, mask=mask) for dataset, mask in zip(datasets, masks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reperform the fit of each most-likely lens model we'll need the masked imaging used by that phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_imagings = [\n",
    "    al.masked.imaging(imaging=dataset, mask=mask)\n",
    "    for dataset, mask in zip(datasets, masks)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we're good to go! Lets use each most likely instance to create the most-likely tracer, and fit the masked imaging using this tracer for every lens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [\n",
    "    out.most_likely_instance for out in outputs\n",
    "]\n",
    "\n",
    "tracers = [\n",
    "    al.Tracer.from_galaxies(galaxies=instance.galaxies)\n",
    "    for instance in instances\n",
    "]\n",
    "\n",
    "fits = [\n",
    "    al.fit(masked_dataset=masked_imaging, tracer=tracer)\n",
    "    for masked_imaging, tracer in zip(masked_imagings, tracers)\n",
    "]\n",
    "\n",
    "[aplt.fit_imaging.subplot_fit_imaging(fit=fit) for fit in fits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit of inspecting fits using the aggregator, rather than the files outputs to the hard-disk, is that we can customize the plots using the PyAutoLens plotters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = aplt.Plotter(\n",
    "    figure=aplt.Figure(figsize=(12, 12)),\n",
    "    labels=aplt.Labels(title=\"Custom Image\", titlesize=24, ysize=24, xsize=24),\n",
    "    ticks=aplt.Ticks(ysize=24, xsize=24),\n",
    "    cmap=aplt.ColorMap(norm=\"log\", norm_max=1.0, norm_min=1.0),\n",
    "    cb=aplt.ColorBar(ticksize=20),\n",
    "    units=aplt.Units(in_kpc=True)\n",
    ")\n",
    "\n",
    "[aplt.fit_imaging.normalized_residual_map(fit=fit, plotter=plotter) for fit in fits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making this plot for a paper? You can output it to hard disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = aplt.Plotter(\n",
    "    output=aplt.Output(\n",
    "        path=workspace_path + \"/output/path/of/file/\", filename=\"publication\", format=\"png\"\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
