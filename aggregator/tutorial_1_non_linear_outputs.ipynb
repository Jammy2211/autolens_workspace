{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Non Linear Outputs__\n",
    "\n",
    "After fitting a large suite of data with the same pipeline, the aggregator allows us to load the results and manipulate / plot them using a Python script or Jupyter notebook.\n",
    "\n",
    "This script uses the results generated by the script '/autolens_workspace/aggregator/beginner_runner.py', which fitted 3 simulated strong lenses. We fitted each image with the pipeline:\n",
    "\n",
    "'autolens_workspace/pipelines/beginner/no_lens_light/lens_sie__source_inversion.py'\n",
    "\n",
    "This pipeline is composed of 3 phases.\n",
    "\n",
    "__File Output__\n",
    "\n",
    "The results of this fit are in the '/output/aggregator_sample_beginner' folder. First, take a look in this folder. Provided you haven't rerun the runner, you'll notice that all the results (e.g. optimizer, optimizer_backup, model.results, images, etc.) are in .zip files as opposed to folders that can be instantly accessed.\n",
    "\n",
    "This is because when the pipeline was run, the 'remove_files' option in the 'config/general.ini' was set to True. This means all results (other than the .zip file) were removed. This feature is implemented because super-computer often have a limit on the number of files allowed per user.\n",
    "\n",
    "Bare in mind the fact that all results are in .zip files - we'll come back to this point in a second.\n",
    "\n",
    "__Aggregator__\n",
    "\n",
    "We can load the results of each pipeline's analysis of each of the 3 images using the aggregator. This will allow us to manipulate the results in this Python script (or a Jupyter notebook) to plot figures, interpret results, check specific values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autofit as af"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, we setup the path to the output path we want to load results from, which in this case is the folder 'autolens_workspace/output/aggregator_sample_beginner'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_path = \"/home/jammy/PycharmProjects/PyAuto/autolens_workspace/\"\n",
    "output_path = workspace_path + \"output\"\n",
    "aggregator_results_path = output_path + \"/aggregator_sample_beginner\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use this path to explicitly set the config path and output path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.conf.instance = af.conf.Config(\n",
    "    config_path=str(workspace_path + \"/config\"), output_path=str(output_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up the aggregator we simply pass it the folder of the results we want to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = af.Aggregator(directory=str(aggregator_results_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, take another look at the output folder. The .zip files containing results have now all been unzipped, such that the results are accessible on your laptop for navigation. This means you can run fits to many lenses on a super computer and easily unzip all the results on your computer afterwards via the aggregator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a list of the 'non-linear outputs' of every fit. An instance of the NonLinearOutput class acts as an interface between the results of the non-linear fit on your hard-disk and Python.\n",
    "\n",
    "The fits to each lens used MultiNest, so below we create a list of instances of the MultiNestOutput class (the non-linear output class will change dependent on the non-linear optimizer used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = aggregator.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we print this list of outputs we see 9 different MultiNestOutput instances. These correspond to all 3 phases of each pipeline's fit to all 3 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MultiNest Outputs: \\n\")\n",
    "print(outputs)\n",
    "print()\n",
    "print(\"Total Outputs = \", len(outputs), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to remove the fits of the first 2 phases and just keep the MultiNestOutputs of the 3rd and final phase of the pipeline we can do so by filtering for the phase's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_name = \"phase_3__source_inversion\"\n",
    "outputs = aggregator.filter(phase=phase_name).output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, this list now has only 3 MultiNestOutputs, one for each image we fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Phase Name Filtered MultiNest Outputs: \\n\")\n",
    "print(outputs)\n",
    "print()\n",
    "print(\"Total Outputs = \", len(outputs), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we only fitted the 3 images using one pipeline. But suppose we used multiple pipelines, like we do in the advanced pipelines. In this case, the aggregator would load the MultiNestOutputs of all fits of all phases of all pipelines!\n",
    "\n",
    "In such circumstances, we can filter by pipeline name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"pipeline__lens_sie__source_inversion\"\n",
    "outputs = aggregator.filter(pipeline=pipeline_name, phase=phase_name).output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, this list again has 3 MultiNestOutputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline Name Filtered MultiNest Outputs: \\n\")\n",
    "print(outputs)\n",
    "print()\n",
    "print(\"Total Outputs = \", len(outputs), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the outputs to create a list of the most-likely (e.g. highest likelihood) model of each fit to our three images (in this case in phase 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_likely_vector = [\n",
    "    out.most_probable_vector for out in outputs\n",
    "]\n",
    "print(\"Most Likely Model Parameter Lists: \\n\")\n",
    "print(most_likely_vector, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides us with lists of all model parameters. However, this isn't that much use - which values correspond to which parameters?\n",
    "\n",
    "Its more useful to create the model instance of every fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [out.most_likely_instance for out in outputs]\n",
    "print(\"Most Likely Model Instances: \\n\")\n",
    "print(instances, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model instance contains all the model components of our fit - most importantly the list of galaxies we specified in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instances[0].galaxies)\n",
    "print(instances[1].galaxies)\n",
    "print(instances[2].galaxies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These galaxies will be named according to the pipeline (in this case, 'lens' and 'source')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instances[0].galaxies.lens)\n",
    "print()\n",
    "print(instances[1].galaxies.source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their light and mass profiles are also named according to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(instances[0].galaxies.lens.mass)\n",
    "print()\n",
    "print(instances[0].galaxies.lens.shear)\n",
    "print()\n",
    "print(instances[1].galaxies.source.pixelization)\n",
    "print()\n",
    "print(instances[1].galaxies.source.regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the 'most probable' model, which is the model computed by marginalizing over the MultiNest samples of every parameter in 1D and taking the median of this PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_vector = [out.most_probable_vector for out in outputs]\n",
    "mp_instances = [out.most_probable_instance for out in outputs]\n",
    "\n",
    "print(\"Most Probable Model Parameter Lists: \\n\")\n",
    "print(mp_vector, \"\\n\")\n",
    "print(\"Most probable Model Instances: \\n\")\n",
    "print(mp_instances, \"\\n\")\n",
    "print(mp_instances[0].galaxies.lens.mass)\n",
    "print(mp_instances[0].galaxies.lens.shear)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the model parameters at a given sigma value (e.g. at 3.0 sigma limits).\n",
    "\n",
    "These parameter values do not account for covariance between the model. For example if two parameters are degenerate this will find their values from the degeneracy in the 'same direction' (e.g. both will be positive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_vectors = [out.vector_at_upper_sigma(sigma=3.0) for out in outputs]\n",
    "\n",
    "upper_instances = [out.instance_at_upper_sigma(sigma=3.0) for out in outputs]\n",
    "                                               \n",
    "lower_vectors = [out.vector_at_lower_sigma(sigma=3.0) for out in outputs]\n",
    "                                               \n",
    "lower_instances = [out.instance_at_lower_sigma(sigma=3.0) for out in outputs]\n",
    "\n",
    "print(\"Errors Lists: \\n\")\n",
    "print(upper_vectors, \"\\n\")\n",
    "print(lower_vectors, \"\\n\")\n",
    "print(\"Errors Instances: \\n\")\n",
    "print(upper_instances, \"\\n\")\n",
    "print(lower_instances, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the upper and lower errors on each parameter at a given sigma limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These do not currently work due to a bug which will be fixed on Friday\n",
    "\n",
    "upper_errors = [out.error_vector_at_upper_sigma(sigma=3.0) for out in outputs]\n",
    "upper_error_instances = [\n",
    "    out.error_instance_at_upper_sigma(sigma=3.0) for out in outputs\n",
    "]\n",
    "lower_errors = [out.error_vector_at_lower_sigma(sigma=3.0) for out in outputs]\n",
    "lower_error_instances = [\n",
    "    out.error_instance_at_lower_sigma(sigma=3.0) for out in outputs\n",
    "]\n",
    "\n",
    "print(\"Errors Lists: \\n\")\n",
    "print(upper_errors, \"\\n\")\n",
    "print(lower_errors, \"\\n\")\n",
    "print(\"Errors Instances: \\n\")\n",
    "print(upper_error_instances, \"\\n\")\n",
    "print(lower_error_instances, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum likelihood of each model fit and its Bayesian evidence (estimated via MultiNest) are also available.\n",
    "\n",
    "Given each fit is to a different image, these are not very useful. However, in tutorial 5 we'll look at using the aggregator for images that we fit with many different models and many different pipelines, in which case comparing the evidences allows us to perform Bayesian model comparison!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Likelihoods: \\n\")\n",
    "print([out.maximum_log_likelihood for out in outputs])\n",
    "print([out.evidence for out in outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print the \"model_results\" of all phases, which is string that summarizes every fit's lens model providing quick inspection of all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = aggregator.filter(pipeline=pipeline_name).model_results\n",
    "print(\"Model Results Summary: \\n\")\n",
    "print(results, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
