{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Preprocess 6: - Info (Optional)__\n",
        "\n",
        "Here, we include auxiliary information about our dataset or the strong lens system that one may want to use during\n",
        "an analysis or when interpreting the results after the analysis.\n",
        "\n",
        "The most obvious example of such information is the redshifts of the source and lens galaxy. By storing these as an\n",
        "'info' file in the lens's dataset folder, it is straight forward to load the redshifts in a runner and pass them to a\n",
        "pipeline, such that PyAutoLens can then output results in physical units (e.g. kpc instead of arc-seconds, solMass\n",
        "instead of angular units).\n",
        "\n",
        "The info file may also be loaded by the aggregator after a model-fit has completed, such that when one is interpreting\n",
        "the results of a model fit additional data on a lens can be used to, for example to plot the model-results against\n",
        "other measurements of a lens not made by PyAutoLens. Examples of such data might be:\n",
        "\n",
        "- The velocity dispersion of the lens galaxy.\n",
        "- The stellar mass of the lens galaxy.\n",
        "- The results of previous strong lens models to the lens performed in previous papers.\n",
        "\"\"\"\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup the path to the autolens_workspace, using the correct path name below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "workspace_path = \"path/to/AutoLens/autolens_workspace/\"\n",
        "workspace_path = \"/home/jammy/PycharmProjects/PyAuto/autolens_workspace\"\n",
        "\n",
        "preprocess_path = f\"{workspace_path}//preprocess/imaging/\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The 'dataset label' is the name of the dataset folder and 'dataset_name' the folder the info file is stored in e.g,\n",
        "the info will be output as '/autolens_workspace/dataset/dataset_label/dataset_name/info.json'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_label = \"imaging\"\n",
        "dataset_name = \"lens_sie__source_sersic\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the path where the info will be output, which in this case is\n",
        "'/autolens_workspace/dataset/imaging/lens_sie__source_sersic/'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = af.util.create_path(\n",
        "    path=workspace_path, folder_names=[\"dataset\", dataset_label, dataset_name]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The info is written as a Python dictionary and can have as many entires as desired added to it. Any information you\n",
        "want to include int he interpretation of your lens models should be included here.\n",
        "\"\"\"\n",
        "\n",
        "info = {\n",
        "    \"redshihft_lens\": 0.5,\n",
        "    \"redshift_source\": 1.0,\n",
        "    \"velocity_dispersion\": 250000,\n",
        "    \"stellar mass\": 1e11,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The info is stored in the dataset folder as a .json file. \n",
        "\n",
        "We cannot 'dump' a .json file using a string which contains a directory, so we dump it to the location of this\n",
        "script and move it to the appropriate dataset folder. We first delete existing info file in the dataset folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "info_file = \"info.json\"\n",
        "\n",
        "with open(info_file, \"w+\") as f:\n",
        "    json.dump(info, f, indent=4)\n",
        "\n",
        "\n",
        "if os.path.exists(dataset_path + \"info.json\"):\n",
        "    os.remove(dataset_path + \"info.json\")\n",
        "\n",
        "shutil.move(\"info.json\", dataset_path + \"info.json\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the info to be available to the results of a model-fit, the runner must load the info file from the .json and \n",
        "pass it to the pipeline.run() function."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}