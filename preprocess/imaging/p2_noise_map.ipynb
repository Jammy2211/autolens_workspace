{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Preprocess 2: Noise-map__\n",
        "\n",
        "The noise-map defines the uncertainty in every pixel of your strong lens image. Values are defined as the RMS standard\n",
        "deviation in every pixel (not the variances, HST WHT-map values, etc.). You MUST be certain that the noise-map is\n",
        "the RMS standard deviations or else your analysis will be incorrect!\n",
        "\n",
        "This tutorial describes preprocessing your dataset`s noise-map to adhere too the units and formats required by PyAutoLens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets begin by importing PyAutoFit, PyAutoLens and its plotting module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, lets setup the path to our current working directory. I recommend you use the `autolens_workspace` directory \n",
        "and place your dataset in the `autolens_workspace/dataset` directory.\n",
        "\n",
        "For this tutorial, we'll use the `autolens_workspace/preprocess/imaging/data_raw` directory. The folder `data_raw` \n",
        "contains example data we'll use in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "workspace_path = os.environ[\"WORKSPACE\"]\n",
        "print(\"Workspace Path: \", workspace_path)\n",
        "\n",
        "dataset_path = f\"{workspace_path}/preprocess/imaging/data_raw\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This populates the `data_raw` path with example simulated `Imaging` data-sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autolens_workspace.preprocess.imaging.data_raw import simulators\n",
        "\n",
        "simulators.simulate_all_imaging(dataset_path=dataset_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Loading Data From Individual Fits Files__\n",
        "\n",
        "First, lets load a noise-map as an Array. This noise-map represents a good data-reduction that conforms to the \n",
        "formatting standards I describe in this tutorial!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imaging_path = f\"{dataset_path}/imaging\"\n",
        "\n",
        "noise_map = al.Array.from_fits(\n",
        "    file_path=f\"{imaging_path}/noise_map.fits\", pixel_scales=0.1\n",
        ")\n",
        "\n",
        "aplt.Array(array=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__1) Converting Noise-Map Like The Image__\n",
        "\n",
        "If in the previous preprocessing script you did any of the following to the image:\n",
        "\n",
        "1) Converted it from counts / ADUs / other units to electrons per second.\n",
        "2) Trimmed / padded the image.\n",
        "3) Recentered the image.\n",
        "\n",
        "You must perform identical operations on your noise-map (assuming it is in the same units and has the dimensions as the\n",
        "image. You can simply cut and paste the appropriate functions in below - I`ve commented out the appropriate functions\n",
        "you might of used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# exposure_time_map = al.Array.full(fill_value=1000.0, shape_2d=noise_map.shape_2d)\n",
        "#\n",
        "# noise_map_processed = al.preprocess.array_from_counts_to_electrons_per_second(\n",
        "#     array=noise_map, exposure_time_map=exposure_time_map\n",
        "# )\n",
        "#\n",
        "# noise_map_processed = al.preprocess.array_from_adus_to_electrons_per_second(\n",
        "#     array=noise_map, exposure_time_map=exposure_time_map, gain=4.0\n",
        "# )\n",
        "\n",
        "# noise_map_processed = al.preprocess.array_with_new_shape(array=noise_map_large_stamp, new_shape=(130, 130))\n",
        "\n",
        "# noise_map_processed = al.Array.from_fits(\n",
        "#     file_path=f\"{imaging_path}/noise_map.fits\", pixel_scales=0.1\n",
        "# )\n",
        "\n",
        "# aplt.Array(array=noise_map_processed)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Noise Conversions__\n",
        "There are many different ways the noise-map can be reduced. We are aiming to include conversion functions for all \n",
        "common data-reductions. For example, the noise-map may be a HST WHT map, where RMS SD = 1.0/ sqrt(WHT). Note how \n",
        "the values of the noise-map go to very large values in excess of 10000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imaging_path = f\"{dataset_path}/imaging_noise_map_wht\"\n",
        "\n",
        "weight_map = al.Array.from_fits(\n",
        "    file_path=f\"{imaging_path}/noise_map.fits\", pixel_scales=0.1\n",
        ")\n",
        "\n",
        "aplt.Array(array=weight_map)\n",
        "\n",
        "\"\"\"\n",
        "This can be converted to a noise-map using the preprocess module.\n",
        "\"\"\"\n",
        "\n",
        "noise_map = al.preprocess.noise_map_from_weight_map(weight_map=weight_map)\n",
        "\n",
        "aplt.Array(array=noise_map)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}