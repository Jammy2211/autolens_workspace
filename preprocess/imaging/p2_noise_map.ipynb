{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Preprocess 2: Noise-map__\n",
        "\n",
        "The noise-map defines the uncertainty in every pixel of your strong lens image. Values are defined as the RMS standard\n",
        "deviation in every pixel (not the variances, HST WHT-map values, etc.). You MUST be certain that the noise-map is\n",
        "the RMS standard deviations or else your analysis will be incorrect!\n",
        "\n",
        "This tutorial describes preprocessing your dataset's noise-map to adhere too the units and formats required by PyAutoLens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "\n",
        "from preprocess.imaging.data_raw import simulators"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, lets setup the path to our current working directory. I recommend you use the 'autolens_workspace' directory \n",
        "and place your dataset in the 'autolens_workspace/dataset' directory.\n",
        "\n",
        "For this tutorial, we'll use the 'autolens_workspace/preprocess/imaging/data_raw' directory. The folder 'data_raw' \n",
        "contains example data we'll use in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path = (\n",
        "    \"path/to/AutoLens/autolens_workspace/preprocess/imaging/\"\n",
        ")  # <----- You must include this slash on the end\n",
        "path = \"/home/jammy/PycharmProjects/PyAuto/autolens_workspace/preprocess/imaging/\"\n",
        "\n",
        "dataset_path = af.path_util.make_and_return_path_from_path_and_folder_names(\n",
        "    path=path, folder_names=[\"data_raw\"]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This populates the 'data_raw' path with example simulated imaging data-sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "simulators.simulate_all_imaging(dataset_path=dataset_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Loading Data From Individual Fits Files__\n",
        "\n",
        "First, lets load a noise-map as an Array. This noise-map represents a good data-reduction that conforms to the \n",
        "formatting standards I describe in this tutorial!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imaging_path = af.path_util.make_and_return_path_from_path_and_folder_names(\n",
        "    path=dataset_path, folder_names=[\"imaging\"]\n",
        ")\n",
        "\n",
        "noise_map = al.Array.from_fits(\n",
        "    file_path=imaging_path + \"noise_map.fits\", pixel_scales=0.1\n",
        ")\n",
        "\n",
        "aplt.Array(array=noise_map)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__1) Converting Noise-Map Like The Image__\n",
        "\n",
        "If in the previous preprocessing script you did any of the following to the image:\n",
        "\n",
        "1) Converted it from counts / ADUs / other units to electrons per second.\n",
        "2) Trimmed / padded the image.\n",
        "3) Recentered the image.\n",
        "\n",
        "You must perform identical operations on your noise-map (assuming it is in the same units and has the dimensions as the\n",
        "image. You can simply cut and paste the appropriate functions in below - I've commented out the appropriate functions\n",
        "you might of used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# exposure_time_map = al.Array.full(fill_value=1000.0, shape_2d=noise_map.shape_2d)\n",
        "#\n",
        "# noise_map_processed = al.preprocess.array_from_counts_to_electrons_per_second(\n",
        "#     array=noise_map, exposure_time_map=exposure_time_map\n",
        "# )\n",
        "#\n",
        "# noise_map_processed = al.preprocess.array_from_adus_to_electrons_per_second(\n",
        "#     array=noise_map, exposure_time_map=exposure_time_map, gain=4.0\n",
        "# )\n",
        "\n",
        "# noise_map_processed = al.preprocess.array_with_new_shape(array=noise_map_large_stamp, new_shape=(130, 130))\n",
        "\n",
        "# noise_map_processed = al.Array.from_fits(\n",
        "#     file_path=imaging_path + \"noise_map.fits\", pixel_scales=0.1\n",
        "# )\n",
        "\n",
        "# aplt.Array(array=noise_map_processed)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Noise Conversions__\n",
        "There are many different ways the noise-map can be reduced. We are aiming to include conversion functions for all \n",
        "common data-reductions. For example, the noise-map may be a HST WHT map, where RMS SD = 1.0/ sqrt(WHT). Note how \n",
        "the values of the noise-map go to very large values in excess of 10000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "imaging_path = af.path_util.make_and_return_path_from_path_and_folder_names(\n",
        "    path=dataset_path, folder_names=[\"imaging_noise_map_wht\"]\n",
        ")\n",
        "\n",
        "weight_map = al.Array.from_fits(\n",
        "    file_path=imaging_path + \"noise_map.fits\", pixel_scales=0.1\n",
        ")\n",
        "\n",
        "aplt.Array(array=weight_map)\n",
        "\n",
        "\"\"\"\n",
        "This can be converted to a noise-map using the preprocess module.\n",
        "\"\"\"\n",
        "\n",
        "noise_map = al.preprocess.noise_map_from_weight_map(weight_map=weight_map)\n",
        "\n",
        "aplt.Array(array=noise_map)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}