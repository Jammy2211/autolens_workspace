{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 7: Adaptive Pixelization\n",
        "=================================\n",
        "\n",
        "In this tutorial we'll use a new _Pixelization_, called the VoronoiMagnification _Pixelization_. This pixelization\n",
        "doesn't use a uniform _Grid_ of rectangular pixels, but instead uses an irregular 'Voronoi' pixels. So, why do we\n",
        "want to do that? Lets take another quick look at the rectangular grid.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "import os\n",
        "workspace_path = os.environ[\"WORKSPACE\"]\n",
        "print(\"Workspace Path: \", workspace_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll use the same strong lensing data as the previous tutorial, where:\n",
        "\n",
        " - The lens galaxy's light is omitted.\n",
        " - The lens galaxy's _MassProfile_ is an _EllipticalIsothermal_.\n",
        " - The source galaxy's _LightProfile_ is an _EllipticalSersic_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autolens_workspace.howtolens.simulators.chapter_4 import mass_sie__source_sersic\n",
        "\n",
        "dataset_type = \"chapter_4\"\n",
        "dataset_name = \"mass_sie__source_sersic\"\n",
        "dataset_path = f\"{workspace_path}/howtolens/dataset/{dataset_type}/{dataset_name}\"\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=f\"{dataset_path}/image.fits\",\n",
        "    noise_map_path=f\"{dataset_path}/noise_map.fits\",\n",
        "    psf_path=f\"{dataset_path}/psf.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask.circular(\n",
        "    shape_2d=imaging.shape_2d, pixel_scales=imaging.pixel_scales, sub_size=2, radius=3.0\n",
        ")\n",
        "\n",
        "aplt.Imaging.subplot_imaging(imaging=imaging, mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The lines of code below do everything we're used to, that is, setup an image, mask it, trace it via a tracer, \n",
        "setup the rectangular mapper, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.EllipticalIsothermal(\n",
        "        centre=(0.0, 0.0), elliptical_comps=(0.111111, 0.0), einstein_radius=1.6\n",
        "    ),\n",
        ")\n",
        "\n",
        "masked_imaging = al.MaskedImaging(\n",
        "    imaging=imaging, mask=mask, settings=al.SettingsMaskedImaging(sub_size=2)\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.Rectangular(shape=(40, 40)),\n",
        "    regularization=al.reg.Constant(coefficient=0.5),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "fit = al.FitImaging(masked_imaging=masked_imaging, tracer=tracer)\n",
        "\n",
        "aplt.FitImaging.subplot_fit_imaging(fit=fit, include=aplt.Include(mask=True))\n",
        "aplt.FitImaging.subplot_of_plane(\n",
        "    fit=fit, plane_index=1, include=aplt.Include(mask=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay, so lets think about the _Rectangular_ _Pixelization_. Is this the optimal way to reconstruct our source? Are \n",
        "there features in the source-plane that arn't ideal? How do you think we could do a better job?\n",
        "\n",
        "Well, given we're doing a whole tutorial on using a different _Pixelization_to this grid, you've probably guessed that\n",
        "it isn't optimal. Infact, its pretty rubbish, and not a _Pixelization_we should actually want to model any lenses with!\n",
        "\n",
        "So what is wrong with the grid? Well, lets think about the source reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.Inversion.reconstruction(\n",
        "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is one clear problem, we are using a small number of the total source pixels to reconstruct the source. The \n",
        "majority of source pixels are located away from the source. By my estimate, we're using just 16 pixels (the central \n",
        "4x4 grid) out of the 1600 pixels to actually fit the data! The remaining ~1500 pixels are doing *nothing* but fit noise.\n",
        "\n",
        "This is a waste and our analysis will take longer to run because of it. However, more importantly, it means that our \n",
        "Bayesian _Regularization_ scheme is sub-optimal. In tutorial 4, we discussed how the Bayesian log evidence of the \n",
        "regularization wants to obtain the *simplest* source solution possible. That is the solution which fits the data \n",
        "well using the fewest source pixels. Clearly, if we dedicating a huge number of source pixels to doing *nothing*, our \n",
        "source reconstruction will be unecessarily complex (and therefore lower log_evidence).\n",
        "\n",
        "If our _Pixelization_ could 'focus' its pixels where we actually have more data, e.g. the highly magnified regions of \n",
        "the source-plane, we could reconstruct the source using far fewer pixels. That'd be great both for computational \n",
        "efficiency and increasing the Bayesian log evidence. This is what the Voronoi _Pixelization_ does.\n",
        "\n",
        "To achieve this, we first compute an 'image-plane sparse grid', which is a set of sparse coordinates in the image-plane \n",
        "that will be ray-traced to the source-plane and define the centres of our source-pixel grid. We compute this _Grid_ \n",
        "directly from a _Pixelization_, by passing it a grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "adaptive = al.pix.VoronoiMagnification(shape=(20, 20))\n",
        "\n",
        "image_plane_sparse_grid = adaptive.sparse_grid_from_grid(grid=masked_imaging.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot this _Grid_ over the image, to see that it is a coarse _Grid_ over-laying the image itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.Imaging.image(imaging=imaging, grid=image_plane_sparse_grid, mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we pass a _Tracer_ a source galaxy with this _Pixelization_ it automatically computes the ray-traced source-plane \n",
        "Voronoi _Pixelization_ using the _Grid_ above. Thus, our Voronoi _Pixelization_is used by the tracer's fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0, pixelization=adaptive, regularization=al.reg.Constant(coefficient=1.0)\n",
        ")\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look at the lens fit, we'll see that our source-plane no longer uses rectangular pixels, but Voronoi pixels!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = al.FitImaging(masked_imaging=masked_imaging, tracer=tracer)\n",
        "\n",
        "aplt.FitImaging.subplot_fit_imaging(\n",
        "    fit=fit,\n",
        "    include=aplt.Include(\n",
        "        mask=True,\n",
        "        inversion_image_pixelization_grid=True,\n",
        "        inversion_pixelization_grid=True,\n",
        "    ),\n",
        ")\n",
        "aplt.FitImaging.subplot_of_plane(\n",
        "    fit=fit, plane_index=1, include=aplt.Include(mask=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can take a closer inspection of the _Inversion_ itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.Inversion.reconstruction(\n",
        "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clearly, this is an improvement. We're using fewer pixels than the rectangular _Grid_ (400, instead of 1600), but \n",
        "reconstructing our source is far greater detail. A win all around? It sure is.\n",
        "\n",
        "On our rectangular grid, we regularized each source pixel with its 4 neighbors. We compared their fluxes, summed \n",
        "the differences, and penalized solutions where the differences were large. For a Voronoi _Pixelization_, we do the same \n",
        "thing, now comparing each source-pixel with all other source-pixels with which it shares a direct vertex. This means that \n",
        "different source-pixels may be regularized with different numbers of source-pixels, depending on how many neighbors \n",
        "are formed.\n",
        "\n",
        "However, this _VoronoiMagnification_ _Pixelization_ is still far from optimal. There are lots of source-pixels \n",
        "effectively fitting just noise. We may achieve even better solutions if the central regions of the source were \n",
        "reconstructed using even more pixels. So, how do we improve on this? Well, you'll have to wait until chapter 5, \n",
        "when we introduce __PyAutoLens__'s adaptive functionality, or 'hyper-mode'.\n",
        "\n",
        "In the mean time, you may wish to experiment with using both Rectangular and VoronoiMagnification _Grid_'s to fit \n",
        "lenses which can be easily achieve by changing the input pixeliation given to a pipeline."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}