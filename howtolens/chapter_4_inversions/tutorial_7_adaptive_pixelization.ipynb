{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 7: Adaptive Pixelization\n",
        "=================================\n",
        "\n",
        "In this tutorial we'll use a new `Pixelization`, called the VoronoiMagnification `Pixelization`. This pixelization\n",
        "doesn`t use a uniform `Grid` of rectangular pixels, but instead uses an irregular `Voronoi` pixels. So, why do we\n",
        "want to do that? Lets take another quick look at the rectangular grid.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from pyprojroot import here\n",
        "\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we'll use the same strong lensing data as the previous tutorial, where:\n",
        "\n",
        " - The lens `Galaxy`'s light is omitted.\n",
        " - The lens `Galaxy`'s total mass distribution is an `EllipticalIsothermal`.\n",
        " - The source `Galaxy`'s `LightProfile` is an `EllipticalSersic`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"mass_sie__source_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"howtolens\", \"chapter_4\", dataset_name)\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=path.join(dataset_path, \"image.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_2d=imaging.shape_2d, pixel_scales=imaging.pixel_scales, sub_size=2, radius=3.0\n",
        ")\n",
        "\n",
        "aplt.Imaging.subplot_imaging(imaging=imaging, mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The lines of code below do everything we're used to, that is, setup an image, mask it, trace it via a tracer, \n",
        "setup the rectangular mapper, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.EllipticalIsothermal(\n",
        "        centre=(0.0, 0.0), elliptical_comps=(0.111111, 0.0), einstein_radius=1.6\n",
        "    ),\n",
        ")\n",
        "\n",
        "masked_imaging = al.MaskedImaging(\n",
        "    imaging=imaging, mask=mask, settings=al.SettingsMaskedImaging(sub_size=2)\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.Rectangular(shape=(40, 40)),\n",
        "    regularization=al.reg.Constant(coefficient=0.5),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "fit = al.FitImaging(masked_imaging=masked_imaging, tracer=tracer)\n",
        "\n",
        "aplt.FitImaging.subplot_fit_imaging(fit=fit, include=aplt.Include(mask=True))\n",
        "aplt.FitImaging.subplot_of_plane(\n",
        "    fit=fit, plane_index=1, include=aplt.Include(mask=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay, so lets think about the `Rectangular` `Pixelization`. Is this the optimal way to reconstruct our source? Are \n",
        "there features in the source-plane that arn`t ideal? How do you think we could do a better job?\n",
        "\n",
        "Well, given we're doing a whole tutorial on using a different `Pixelization`.o this grid, you`ve probably guessed that\n",
        "it isn't optimal. Infact, its pretty rubbish, and not a `Pixelization`.e should actually want to model any lenses with!\n",
        "\n",
        "So what is wrong with the grid? Well, lets think about the source reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.Inversion.reconstruction(\n",
        "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is one clear problem, we are using a small number of the total source pixels to reconstruct the source. The \n",
        "majority of source pixels are located away from the source. By my estimate, we're using just 16 pixels (the central \n",
        "4x4 grid) out of the 1600 pixels to actually fit the data! The remaining ~1500 pixels are doing *nothing* but fit noise.\n",
        "\n",
        "This is a waste and our analysis will take longer to run because of it. However, more importantly, it means that our \n",
        "Bayesian `Regularization` scheme is sub-optimal. In tutorial 4, we discussed how the Bayesian log evidence of the \n",
        "regularization wants to obtain the *simplest* source solution possible. That is the solution which fits the data \n",
        "well using the fewest source pixels. Clearly, if we dedicating a huge number of source pixels to doing *nothing*, our \n",
        "source reconstruction will be unecessarily complex (and therefore lower log_evidence).\n",
        "\n",
        "If our `Pixelization` could `focus` its pixels where we actually have more data, e.g. the highly magnified regions of \n",
        "the source-plane, we could reconstruct the source using far fewer pixels. That`d be great both for computational \n",
        "efficiency and increasing the Bayesian log evidence. This is what the Voronoi `Pixelization` does.\n",
        "\n",
        "To achieve this, we first compute an `image-plane sparse grid`, which is a set of sparse coordinates in the image-plane \n",
        "that will be ray-traced to the source-plane and define the centres of our source-pixel grid. We compute this `Grid` \n",
        "directly from a `Pixelization`, by passing it a grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "adaptive = al.pix.VoronoiMagnification(shape=(20, 20))\n",
        "\n",
        "image_plane_sparse_grid = adaptive.sparse_grid_from_grid(grid=masked_imaging.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot this `Grid` over the image, to see that it is a coarse `Grid` over-laying the image itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.Imaging.image(imaging=imaging, grid=image_plane_sparse_grid, mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we pass a `Tracer` a source galaxy with this `Pixelization` it automatically computes the ray-traced source-plane \n",
        "Voronoi `Pixelization` using the `Grid` above. Thus, our Voronoi `Pixelization`.s used by the tracer`s fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0, pixelization=adaptive, regularization=al.reg.Constant(coefficient=1.0)\n",
        ")\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look at the lens fit, we'll see that our source-plane no longer uses rectangular pixels, but Voronoi pixels!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = al.FitImaging(masked_imaging=masked_imaging, tracer=tracer)\n",
        "\n",
        "aplt.FitImaging.subplot_fit_imaging(\n",
        "    fit=fit,\n",
        "    include=aplt.Include(\n",
        "        mask=True,\n",
        "        inversion_image_pixelization_grid=True,\n",
        "        inversion_pixelization_grid=True,\n",
        "    ),\n",
        ")\n",
        "aplt.FitImaging.subplot_of_plane(\n",
        "    fit=fit, plane_index=1, include=aplt.Include(mask=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can take a closer inspection of the `Inversion` itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.Inversion.reconstruction(\n",
        "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Clearly, this is an improvement. we're using fewer pixels than the rectangular `Grid` (400, instead of 1600), but \n",
        "reconstructing our source is far greater detail. A win all around? It sure is.\n",
        "\n",
        "On our rectangular grid, we regularized each source pixel with its 4 neighbors. We compared their fluxes, summed \n",
        "the differences, and penalized solutions where the differences were large. For a Voronoi `Pixelization`, we do the same \n",
        "thing, now comparing each source-pixel with all other source-pixels with which it shares a direct vertex. This means that \n",
        "different source-pixels may be regularized with different numbers of source-pixels, depending on how many neighbors \n",
        "are formed.\n",
        "\n",
        "However, this `VoronoiMagnification` `Pixelization`.is still far from optimal. There are lots of source-pixels \n",
        "effectively fitting just noise. We may achieve even better solutions if the central regions of the source were \n",
        "reconstructed using even more pixels. So, how do we improve on this? Well, you'll have to wait until chapter 5, \n",
        "when we introduce **PyAutoLens**`s adaptive functionality, or `hyper-mode`.\n",
        "\n",
        "In the mean time, you may wish to experiment with using both Rectangular and VoronoiMagnification `Grid`'s to fit \n",
        "lenses which can be easily achieve by changing the input pixeliation given to a pipeline."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}