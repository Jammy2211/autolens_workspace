{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 3: Inversions\n",
        "======================\n",
        "\n",
        "We've covered `Mapper``., which, if I haven`t emphasised it enough yet, map things. Now, we're going to look at how we\n",
        "can use these `Mapper`'s (which map things) to reconstruct the source galaxy - I hope you're excited!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from pyprojroot import here\n",
        "\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we'll use the same strong lensing data as the previous tutorial, where:\n",
        "\n",
        " - The lens `Galaxy`'s light is omitted.\n",
        " - The lens `Galaxy`'s total mass distribution is an `EllipticalIsothermal`.\n",
        " - The source `Galaxy`'s `LightProfile` is an `EllipticalSersic`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"mass_sie__source_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"howtolens\", \"chapter_4\", dataset_name)\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=path.join(dataset_path, \"image.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets create an annular `Mask2D` which traces the stongly lensed source ring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular_annular(\n",
        "    shape_2d=imaging.shape_2d,\n",
        "    pixel_scales=imaging.pixel_scales,\n",
        "    sub_size=1,\n",
        "    inner_radius=0.5,\n",
        "    outer_radius=2.8,\n",
        ")\n",
        "\n",
        "aplt.Imaging.image(imaging=imaging, mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, lets set the `Imaging` and `Mask2D` up as a `MaskedImaging` object and setup a `Tracer` using the input lens \n",
        "galaxy model (we don't need to provide the source's `LightProfile`, as we're using a `Mapper` to reconstruct it)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "masked_imaging = al.MaskedImaging(\n",
        "    imaging=imaging, mask=mask, settings=al.SettingsMaskedImaging(sub_size=2)\n",
        ")\n",
        "\n",
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.EllipticalIsothermal(\n",
        "        centre=(0.0, 0.0), elliptical_comps=(0.1, 0.0), einstein_radius=1.6\n",
        "    ),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, al.Galaxy(redshift=1.0)])\n",
        "\n",
        "source_plane_grid = tracer.traced_grids_of_planes_from_grid(grid=masked_imaging.grid)[1]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we'll use another rectangular `Pixelization` and `Mapper` to perform the reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rectangular = al.pix.Rectangular(shape=(25, 25))\n",
        "\n",
        "mapper = rectangular.mapper_from_grid_and_sparse_grid(grid=source_plane_grid)\n",
        "\n",
        "aplt.Mapper.subplot_image_and_mapper(\n",
        "    image=imaging.image,\n",
        "    mapper=mapper,\n",
        "    include=aplt.Include(mask=True, inversion_grid=True),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now, finally, we're going to use our `Mapper` to invert the image using an `Inversion`. I'll explain how this \n",
        "works in a second - but lets just go ahead and use the `Inversion` first. (Ignore the `regularization` input below for \n",
        "now, we'll cover this in the next tutorial)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion = al.Inversion(\n",
        "    masked_dataset=masked_imaging,\n",
        "    mapper=mapper,\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our `Inversion` has a reconstructed image and `Pixeilzation`, whcih we can plot using an `Inversion` plotter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.Inversion.reconstructed_image(inversion=inversion, include=aplt.Include(mask=True))\n",
        "\n",
        "aplt.Inversion.reconstruction(\n",
        "    inversion=inversion, include=aplt.Include(inversion_grid=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And there we have it, we've successfully reconstructed, or, *inverted*, our source using the mapper`s rectangular \n",
        "grid. Whilst this source was simple (a blob of light in the centre of the source-plane), `Inversion`'s come into their \n",
        "own when fitting sources with complex morphologies. Infact, given we're having so much fun inverting things, lets \n",
        "invert a really complex source!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"mass_sie__source_sersic_x5\"\n",
        "dataset_path = path.join(\"dataset\", \"howtolens\", \"chapter_4\", dataset_name)\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=path.join(dataset_path, \"image.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "aplt.Imaging.image(imaging=imaging)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code is doing all the the same as above (setup the `Mask2D`, `Galaxy`'s `Tracer`, `Mapper`, ec.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "mask = al.Mask2D.circular_annular(\n",
        "    shape_2d=imaging.shape_2d,\n",
        "    pixel_scales=imaging.pixel_scales,\n",
        "    sub_size=1,\n",
        "    inner_radius=0.1,\n",
        "    outer_radius=3.2,\n",
        ")\n",
        "\n",
        "aplt.Imaging.image(imaging=imaging, mask=mask)\n",
        "\n",
        "masked_imaging = al.MaskedImaging(imaging=imaging, mask=mask)\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, al.Galaxy(redshift=1.0)])\n",
        "\n",
        "source_plane_grid = tracer.traced_grids_of_planes_from_grid(grid=masked_imaging.grid)[1]\n",
        "\n",
        "mapper = rectangular.mapper_from_grid_and_sparse_grid(grid=source_plane_grid)\n",
        "\n",
        "inversion = al.Inversion(\n",
        "    masked_dataset=masked_imaging,\n",
        "    mapper=mapper,\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets inspect the complex source reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.Inversion.reconstructed_image(inversion=inversion, include=aplt.Include(mask=True))\n",
        "\n",
        "aplt.Inversion.reconstruction(\n",
        "    inversion=inversion, include=aplt.Include(inversion_grid=True)\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pretty great, huh? If you ran the complex source pipeline, you'll remember that getting a model image that looked that \n",
        "good simply *was not possible*. With an `Inversion`, we can do it with ease and without fitting 30+ parameters!\n",
        "\n",
        "Lets discuss how an `Inversion` actually works. The explanation I give below is overly-simplified. I'm avoiding the \n",
        "technical details of how an `Inversion` *actually* works. To be good at lens modeling you don't need to understand the \n",
        "nitty-gritty details of linear inversions, you just need an instinct for how to use them as a tool to model lenses.\n",
        "\n",
        "Nevertheless, I know a lot of you hate `black-boxes`, or have an interest in linear algrebra. If you're that way \n",
        "inclined, then checkout the documentation of the autolens source code for more information. In particular, you should \n",
        "look at the following functions in the project PyAutoArray:\n",
        "\n",
        "autoarray.inversions.mappers.mapping_matrix\n",
        "autoarray.opterators.convolution.convolve_mapping_matrix\n",
        "autoarray.opterators.inversions.regularization.Regularization\n",
        "autoarray.opterators.inversions.inversions.Inversion\n",
        "\n",
        "To begin, lets consider some random mappings between our mapper`s source-pixels and the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.Mapper.subplot_image_and_mapper(\n",
        "    image=masked_imaging.image,\n",
        "    mapper=mapper,\n",
        "    include=aplt.Include(mask=True, inversion_grid=True),\n",
        "    source_pixel_indexes=[[445], [285], [313], [132], [11]],\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These mappings are known before the `Inversion`, which means pre-inversion we know two key pieces of information:\n",
        "\n",
        " 1) The mappings between every source-pixel and sets of image-pixels.\n",
        " 2) The flux values in every observed image-pixel, which are the values we want to fit successfully.\n",
        "\n",
        "It turns out that with these two pieces of information we can linearly solve for the set of source-pixel fluxes that \n",
        "best-fit (e.g. maximize the log likelihood of) our observed image. Essentially, we set up the mapping between source and \n",
        "image pixels as a large matrix and solve for the source-pixel fluxes in an analogous fashion to how you would solve a \n",
        "set of simultaneous linear equations. This process is called a `linear inversion`.\n",
        "\n",
        "There are three more things about a linear `Inversion` that are worth knowing:\n",
        "\n",
        " 1) We've discussed the image sub-grid before, which splits each image-pixel into a sub-pixel. If a sub-grid is \n",
        " used, it is the mapping between every sub-pixel and source-pixel that is computed and used to perform the \n",
        " `Inversion`. This prevents aliasing effects degrading the image reconstruction, and, as a rule of thumb, I \n",
        " would suggest you use sub-gridding of degree 2x2.\n",
        "\n",
        " 2) When fitting using `LightProfile`'s we discussed how a `model_image` was generated by blurring them with the \n",
        " data's PSF. A similar blurring operation is incorporated into the `Inversion`, such that the reconstructed \n",
        " image and source fully account for the telescope optics and effect of the PSF.\n",
        "\n",
        " 3) The inversion`s solution is regularized. But wait, that`s what we'll cover in the next tutorial!\n",
        "\n",
        "Finally, let me show you how easy it is to fit an image with an `Inversion` using a `FitImaging` oboject. Instead of \n",
        "giving the source galaxy a `LightProfile`, we give it a `Pixelization`.nd `Regularization`, and pass it to a `Tracer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.Rectangular(shape=(40, 40)),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, like before, we pass the `MaskedImaging` and `Tracer` to a `FitImaging` object. Indeed, we see some \n",
        "pretty good looking residuals - we're certainly fitting the lensed source accurately!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = al.FitImaging(masked_imaging=masked_imaging, tracer=tracer)\n",
        "\n",
        "aplt.FitImaging.subplot_fit_imaging(fit=fit, include=aplt.Include(mask=True))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And, we're done, here are a few questions to get you thinking about `Inversion``.:\n",
        "\n",
        " 1) The `Inversion` provides the maximum log likelihood solution to the observed image. Is there a problem with seeking \n",
        " the `best-fit`? Is there a risk that we're going to fit other things in the image than just the lensed source \n",
        " galaxy? What happens if you reduce the `regularization_coefficient` above to zero?\n",
        "\n",
        " 2) The exterior pixels in the `Rectangular` `Grid`.have no image-pixels in them. However, they are still given a \n",
        " reconstructed flux. If this value isn't` coming from a util to an image-pixel, where is it be coming from?"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}