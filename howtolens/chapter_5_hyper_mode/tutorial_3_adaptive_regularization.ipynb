{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 3: Adaptive Regularization\n",
        "===================================\n",
        "\n",
        "In tutorial 1, we considered why our _Constant_ _Regularization_scheme was sub-optimal. Diffferent regions of the\n",
        "source demand different levels of regularization, motivating a _Regularization_scheme which adapts to the reconstructed\n",
        "source's surface brightness.\n",
        "\n",
        "This raises the same question as before, how do we adapt our _Regularization_scheme to the source before we've\n",
        "reconstructed it? Just like in the last tutorial, we'll use a model image of a strongly lensed source from a previous\n",
        "phase of the pipeline that we've begun calling the 'hyper-galaxy-image'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "from pyprojroot import here\n",
        "\n",
        "workspace_path = str(here())\n",
        "print(\"Workspace Path: \", workspace_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll use the same strong lensing data as the previous tutorial, where:\n",
        "\n",
        " - The lens galaxy's light is omitted.\n",
        " - The lens galaxy's _MassProfile_ is an _EllipticalIsothermal_.\n",
        " - The source galaxy's _LightProfile_ is an _EllipticalSersic_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from howtolens.simulators.chapter_5 import lens_sie__source_sersic\n",
        "\n",
        "dataset_type = \"chapter_5\"\n",
        "dataset_name = \"lens_sie__source_sersic\"\n",
        "dataset_path = f\"{workspace_path}/howtolens/dataset/{dataset_type}/{dataset_name}\"\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=f\"{dataset_path}/image.fits\",\n",
        "    noise_map_path=f\"{dataset_path}/noise_map.fits\",\n",
        "    psf_path=f\"{dataset_path}/psf.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask.circular(\n",
        "    shape_2d=imaging.shape_2d, pixel_scales=imaging.pixel_scales, sub_size=2, radius=3.0\n",
        ")\n",
        "\n",
        "masked_imaging = al.MaskedImaging(\n",
        "    imaging=imaging,\n",
        "    mask=mask,\n",
        "    settings=al.SettingsMaskedImaging(grid_class=al.Grid, sub_size=2),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we're going to fit the image using our magnification based grid. To perform the fits, we'll use a convenience \n",
        "function to fit the lens data we simulated above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fit_masked_imaging_with_source_galaxy(masked_imaging, source_galaxy):\n",
        "\n",
        "    lens_galaxy = al.Galaxy(\n",
        "        redshift=0.5,\n",
        "        mass=al.mp.EllipticalIsothermal(\n",
        "            centre=(0.0, 0.0), elliptical_comps=(0.111111, 0.0), einstein_radius=1.6\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "    return al.FitImaging(masked_imaging=masked_imaging, tracer=tracer)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we'll use the magnification based source to fit this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_magnification = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.VoronoiMagnification(shape=(30, 30)),\n",
        "    regularization=al.reg.Constant(coefficient=3.3),\n",
        ")\n",
        "\n",
        "fit = fit_masked_imaging_with_source_galaxy(\n",
        "    masked_imaging=masked_imaging, source_galaxy=source_magnification\n",
        ")\n",
        "\n",
        "aplt.FitImaging.subplot_fit_imaging(\n",
        "    fit=fit, include=aplt.Include(inversion_image_pixelization_grid=True, mask=True)\n",
        ")\n",
        "\n",
        "aplt.Inversion.reconstruction(\n",
        "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Okay, so the inversion's fit looks just like it did in the previous tutorials. Lets quickly remind ourselves that \n",
        "the effective regularization_coefficient of each source pixel is our input coefficient value of 3.3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.Inversion.regularization_weights(\n",
        "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets now look at adaptive _Regularization_in action, by setting up a hyper-galaxy-image and using the \n",
        "'AdaptiveBrightness' _Regularization_scheme. This introduces additional hyper-galaxy-parameters, that I'll explain next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "hyper_image = fit.model_image.in_1d_binned\n",
        "\n",
        "source_adaptive_regularization = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.VoronoiMagnification(shape=(30, 30)),\n",
        "    regularization=al.reg.AdaptiveBrightness(\n",
        "        inner_coefficient=0.005, outer_coefficient=1.9, signal_scale=3.0\n",
        "    ),\n",
        "    hyper_galaxy_image=hyper_image,\n",
        ")\n",
        "\n",
        "fit = fit_masked_imaging_with_source_galaxy(\n",
        "    masked_imaging=masked_imaging, source_galaxy=source_adaptive_regularization\n",
        ")\n",
        "\n",
        "aplt.Inversion.reconstruction(\n",
        "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
        ")\n",
        "\n",
        "aplt.Inversion.regularization_weights(\n",
        "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, as expected, we now have a variable _Regularization_ scheme. The _Regularization_of the source's brightest regions \n",
        "is much lower than that of its outer regions. As discussed before, this is what we want. Lets quickly check that this \n",
        "does, indeed, increase the Bayesian log evidence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Evidence using constant _Regularization_= \", 4216)\n",
        "print(\"Evidence using adaptive _Regularization_= \", fit.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Yep! Of course, combining the adaptive _Pixelization_and _Regularization_will only further benefit our lens modeling!\n",
        "\n",
        "However, as shown below, we don't fit the source as well as the morphology based _Pixelization_ did in the last chapter. \n",
        "This is because although the adaptive _Regularization_ scheme improves the fit, the magnification based \n",
        "_Pixelization_ simply *does not*  have sufficient resolution to resolve the source's cuspy central _LightProfile_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "aplt.FitImaging.subplot_fit_imaging(\n",
        "    fit=fit, include=aplt.Include(inversion_image_pixelization_grid=True, mask=True)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__How does adaptive regularization work?__\n",
        "\n",
        "For every source-pixel, we have a mapping between that pixel and a set of pixels in the hyper-galaxy-image. Therefore, \n",
        "for every source-pixel, if we sum the values of all hyper-galaxy-image pixels that map to it we get an estimate of \n",
        "how much of the lensed source's signal we expect will be reconstructed. We call this each pixel's 'pixel signal'.\n",
        "\n",
        "If a source-pixel has a higher pixel-signal, we anticipate that it'll reconstruct more flux and we use this information \n",
        "to regularize it less. Conversely, if the pixel-signal is close to zero, the source pixel will reconstruct near-zero \n",
        "flux and _Regularization_will smooth over these pixels by using a high regularization_coefficient.\n",
        "\n",
        "This works as follows:\n",
        "\n",
        " 1) For every source pixel, compute its pixel-signal, the summed flux of all corresponding image-pixels in the \n",
        " hyper-galaxy-image.\n",
        "    \n",
        " 2) Divide every pixel-signal by the number of image-pixels that map directly to that source-pixel. In doing so, all \n",
        " pixel-signals are 'relative'. This means that source-pixels which by chance map to more image-pixels than their \n",
        " neighbors will not have a higher pixel-signal, and visa versa. This ensures the specific _Pixelization_\n",
        " does impact the adaptive _Regularization_ pattern.\n",
        "    \n",
        " 3) Divide the pixel-signals by the maximum pixel signal so that they range between 0.0 and 1.0.\n",
        "    \n",
        " 4) Raise these values to the power of the hyper-galaxy-parameter *signal_scale*. For a *signal_scale* of 0.0, all \n",
        " pixels will therefore have the same final pixel-scale. As the *signal_scale* increases, a sharper transition of \n",
        " pixel-signal values arises between regions with high and low pixel-signals.\n",
        "    \n",
        " 5) Compute every source pixel's effective regularization_coefficient as:\n",
        "    \n",
        " (inner_coefficient * pixel_signals + outer_coefficient * (1.0 - pixel_signals)) ** 2.0\n",
        "    \n",
        " This uses two regularization_coefficients, one which is applied to pixels with high pixel-signals and one to \n",
        " pixels with low pixel-signals. Thus, pixels in the inner regions of the source may be given a lower level of \n",
        " _Regularization_than pixels further away, as desired.\n",
        "\n",
        "Thus, we now adapt our _Regularization_ scheme to the source's surface brightness. Where its brighter (and therefore \n",
        "has a steeper flux gradient) we apply a lower level of _Regularization_ than further out. Furthermore, in the edges of \n",
        "the source-plane where no source-flux is present we will assume a high regularization_coefficients that smooth over \n",
        "all source-pixels.\n",
        "\n",
        "Try looking at a couple of extra solutions which use with different inner and outer regularization_coefficients or \n",
        "signal scales. I doubt you'll notice a lot change visually, but the log evidence certainly has a lot of room for \n",
        "manoveur with different values.\n",
        "\n",
        "You may find solutions that raise an 'InversionException'. These solutions mean that the matrix used during the \n",
        "linear algebra calculation was ill-defined, and could not be inverted. These solutions are removed by __PyAutoLens__ \n",
        "during lens modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_adaptive_regularization = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=al.pix.VoronoiMagnification(shape=(30, 30)),\n",
        "    regularization=al.reg.AdaptiveBrightness(\n",
        "        inner_coefficient=0.001, outer_coefficient=0.2, signal_scale=2.0\n",
        "    ),\n",
        "    hyper_galaxy_image=hyper_image,\n",
        ")\n",
        "\n",
        "fit = fit_masked_imaging_with_source_galaxy(\n",
        "    masked_imaging=masked_imaging, source_galaxy=source_adaptive_regularization\n",
        ")\n",
        "\n",
        "aplt.Inversion.reconstruction(\n",
        "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
        ")\n",
        "\n",
        "aplt.Inversion.regularization_weights(\n",
        "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
        ")\n",
        "\n",
        "aplt.FitImaging.subplot_fit_imaging(\n",
        "    fit=fit, include=aplt.Include(inversion_image_pixelization_grid=True, mask=True)\n",
        ")\n",
        "\n",
        "print(\"Evidence using adaptive _Regularization_= \", fit.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To end, lets consider what this adaptive _Regularization_scheme means in the context of maximizing the Bayesian\n",
        "log_evidence. In the previous tutorial, we noted that by using a brightness-based adaptive _Pixelization_ we increased \n",
        "the Bayesian log evidence by allowing for new solutions which fit the data user fewer source pixels; the key criteria \n",
        "in making a source reconstruction 'more simple' and 'less complex'.\n",
        "\n",
        "As you might of guessed, adaptive _Regularization_again increases the Bayesian log evidence by making the source \n",
        "reconstruction simpler:\n",
        "\n",
        " 1) Reducing _Regularization_ in the source's brightest regions produces a 'simpler' solution in that we are not \n",
        " over-smoothing our reconstruction of its brightest regions.\n",
        "    \n",
        " 2) Increasing _Regularization_ in the outskirts produces a simpler solution by correlating more source-pixels, \n",
        " effectively reducing the number of pixels used by the reconstruction.\n",
        "\n",
        "Together, brightness based _Pixelization_'s and _Regularization_ allow us to find the objectively 'simplest' source \n",
        "solution possible and therefore ensure that our Bayesian log evidence's have a well defined maximum value they are \n",
        "seeking. This was not the case for magnification based _Pixelization_'s and constant _Regularization_ schemes."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}