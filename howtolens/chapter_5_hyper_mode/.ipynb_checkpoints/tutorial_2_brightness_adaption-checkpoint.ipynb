{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Brightness Adaption__\n",
    "\n",
    "In the previous tutorial we motivated a need to adapt our pixelization to the source's morphology, such that source  pixels congregates in the source's brightest regions regardless of where it is located in the source-plane. This raises an interesting question; how do we adapt our source pixelization to the reconstructed source, before we've actually reconstructed the source and therefore know what to adapt it too?\n",
    "\n",
    "To do this, we define a 'hyper-galaxy-image' of the lensed source galaxy. This is a model image of the source computed using a previous lens model fit to the image (e.g. in an earlier phase of a pipeline). This image tells us where in the image our source is located, thus telling us where we need to adapt our source pixelization!\n",
    "\n",
    "So, lets go into the details of how this works. We'll use the same compact source galaxy as the previous tutorial and we'll begin by fitting it with a magnification based pixelization. Why? So we can use its model image to set up the hyper-galaxy-image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import autolens as al\n",
    "import autolens.plot as aplt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the usual simulate function, using the compact source of the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "\n",
    "    psf = al.kernel.from_gaussian(shape_2d=(11, 11), sigma=0.05, pixel_scales=0.05)\n",
    "\n",
    "    lens_galaxy = al.Galaxy(\n",
    "        redshift=0.5,\n",
    "        mass=al.mp.EllipticalIsothermal(\n",
    "            centre=(0.0, 0.0), axis_ratio=0.8, phi=45.0, einstein_radius=1.6\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    source_galaxy = al.Galaxy(\n",
    "        redshift=1.0,\n",
    "        light=al.lp.EllipticalSersic(\n",
    "            centre=(0.0, 0.0),\n",
    "            axis_ratio=0.7,\n",
    "            phi=135.0,\n",
    "            intensity=0.2,\n",
    "            effective_radius=0.2,\n",
    "            sersic_index=2.5,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy])\n",
    "\n",
    "    simulator = al.simulator.imaging(\n",
    "        shape_2d=(150, 150),\n",
    "        pixel_scales=0.05,\n",
    "        exposure_time=300.0,\n",
    "        sub_size=2,\n",
    "        psf=psf,\n",
    "        background_level=1.0,\n",
    "        add_noise=True,\n",
    "        noise_seed=1,\n",
    "    )\n",
    "\n",
    "    return simulator.from_tracer(tracer=tracer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets simulate the data, draw a 3.0\" mask and set up the lens data that we'll fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging = simulate()\n",
    "\n",
    "mask = al.mask.circular(\n",
    "    shape_2d=(150, 150), \n",
    "    pixel_scales=0.05, \n",
    "    sub_size=2, \n",
    "    radius=3.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform brightness adaption, we use a 'binned grid' in our masked_imaging aongide binned_hyper_galaxy_images. For now, ignore these 'binned' quantities - I'll explain what they do at the end of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_imaging = al.masked.imaging(\n",
    "    imaging=imaging, mask=mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to fit the image using our magnification based grid. The code below does all the usual steps required to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_galaxy = al.Galaxy(\n",
    "    redshift=0.5,\n",
    "    mass=al.mp.EllipticalIsothermal(\n",
    "        centre=(0.0, 0.0), axis_ratio=0.8, phi=45.0, einstein_radius=1.6\n",
    "    ),\n",
    ")\n",
    "\n",
    "source_galaxy_magnification = al.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=al.pix.VoronoiMagnification(shape=(30, 30)),\n",
    "    regularization=al.reg.Constant(coefficient=3.3),\n",
    ")\n",
    "\n",
    "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy_magnification])\n",
    "\n",
    "fit = al.fit(masked_dataset=masked_imaging, tracer=tracer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a quick look to make sure it has the same residuals we saw in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aplt.fit_imaging.subplot_fit_imaging(\n",
    "    fit=fit,\n",
    "    include=aplt.Include(inversion_image_pixelization_grid=True, mask=True)\n",
    ")\n",
    "\n",
    "aplt.inversion.reconstruction(\n",
    "    inversion=fit.inversion,\n",
    "    include=aplt.Include(inversion_pixelization_grid=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use this fit to set up our hyper-galaxy-image. This hyper-galaxy-image isn't perfect,  as there are residuals in the central regions of the reconstructed source. But it's *okay* and it'll certainly give us enough information on where the lensed source is located to adapt our pixelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_image = fit.model_image.in_1d_binned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at brightness based adaption in action! Below, we define a source-galaxy using our new 'VoronoiBrightnessImage' pixelization and use this to fit the lens-data. One should note that we also attach the hyper-galaxy-image to this galaxy because its pixelization uses this hyper-galaxy-image for adaption, thus the galaxy needs to know what hyper-galaxy-image it should use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_galaxy_brightness = al.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=al.pix.VoronoiBrightnessImage(\n",
    "        pixels=500, weight_floor=0.0, weight_power=10.0\n",
    "    ),\n",
    "    regularization=al.reg.Constant(coefficient=0.5),\n",
    "    hyper_galaxy_image=hyper_image,\n",
    "    binned_hyper_galaxy_image=hyper_image,\n",
    ")\n",
    "\n",
    "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy_brightness])\n",
    "\n",
    "fit = al.fit(masked_dataset=masked_imaging, tracer=tracer)\n",
    "\n",
    "aplt.fit_imaging.subplot_fit_imaging(\n",
    "    fit=fit,\n",
    "    include=aplt.Include(inversion_image_pixelization_grid=True, mask=True)\n",
    ")\n",
    "\n",
    "aplt.inversion.reconstruction(\n",
    "    inversion=fit.inversion,\n",
    "    include=aplt.Include(inversion_pixelization_grid=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you look at that! Our reconstruction of the image no longer has residuals! By congregating more source pixels in the brightest regions of the source reconstruction we get a better fit. Furthermore, we can check that this provides an increase in Bayesian evidence, noting that the evidence of the compact source when using a VoronoiMagnification pixelization was 14236:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evidence using magnification based pixelization = \", 14236.292117135737)\n",
    "\n",
    "print(\"Evidence using brightness based pixelization = \", fit.evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It increases! By over 200, which, for a Bayesian evidence, is pretty damn large! By any measure, this pixelization is a huge success. It turns out that we should have been adapting to the source's brightness all along! In doing so, we will *always* reconstruct the detailed structure of the source's brightest regions with a sufficiently high resolution. Hurrah!\n",
    "\n",
    "So, we are now able to adapt our pixelization to the morphology of our lensed source galaxy. To my knowledge, this is the *best* approach one can take in lens modeling. Its more tricky to implement (as I'll explain next) and introduces extra hyper-galaxy-parametersr. But the pay-off is more than worth it, as we fit our image data better and (typically) end up using far fewer source pixels to fit the data because we don't 'waste' pixels reconstructing regions of the source-plane where there is no signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so how does the hyper_image actually adapt our pixelization to the source's brightness? It uses a 'weighted KMeans clustering algorithm', which is a standard algorithm for partioning data in statistics.\n",
    "\n",
    "In simple terms, this algorithm works as follows:\n",
    "\n",
    "1) Give the KMeans algorithm a set of weighted data (e.g. determined from the hyper-galaxy image).\n",
    "\n",
    "2) For a given number of K-clusters, this algorithm will find a set of (y,x) coordinates that equally partition the weighted data-set. Wherever the data has higher weighting, more clusters congregate and visa versa.\n",
    "\n",
    "3) The returned (y,x) 'clusters' then make up our source-pixel centres, where the brightest (e.g. higher weighted regions of the hyper-galaxy-image will have more clusters! Like we did for the magnification based pixelization, we can then trace these coordinates to the source-plane to define our source-pixel pixelization.\n",
    "\n",
    "This is a fairly simplistic description of a KMeans algorithm. Feel free to check out the links below for a more in-depth view:\n",
    "\n",
    "https://en.wikipedia.org/wiki/K-means_clustering\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "\n",
    "Okay, so we now have a sense of how our VoronoiBrightnessImage pixelization is computed. Now, lets look at how we create the weighted data the KMeans algorithm uses.\n",
    "\n",
    "This image, called the 'cluster_weight_map' is generated using the 'weight_floor' and 'weight_power' parameters of the VoronoiBrightness pixelization. The cluster weight map is generated following 4 steps:\n",
    "\n",
    "1) Increase all values of the hyper-galaxy-image that are < 0.02 to 0.02. This is necessary because negative values and zeros break the KMeans clustering algorithm.\n",
    "\n",
    "2) Divide all values of this image by its maximum value, such that the hyper-galaxy-image now only contains values between 0.0 and 1.0 (where the values of 1.0 were the maximum values of the hyper-galaxy-image).\n",
    "\n",
    "3) Add the weight_floor to all values (a weight_floor of 0.0 therefore does not change the cluster weight map).\n",
    "\n",
    "4) Raise all values to the power of weight_power (a weight_power of 1.0 therefore does not change the cluster weight map, whereas a value of 0.0 means all values 1.0 and therefore weighted equally).\n",
    "\n",
    "Lets look at this in action. We'll inspect 3 cluster_weight_maps, using a weight_power of 0.0, 5.0 and 10.0, setting the weight_floor to 0.0 such that it does not change the cluster weight map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_weight_power_0 = al.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=al.pix.VoronoiBrightnessImage(\n",
    "        pixels=500, weight_floor=0.0, weight_power=0.0\n",
    "    ),\n",
    "    regularization=al.reg.Constant(coefficient=1.0),\n",
    "    hyper_galaxy_image=hyper_image,\n",
    "    binned_hyper_galaxy_image=hyper_image,\n",
    ")\n",
    "\n",
    "cluster_weight_power_0 = source_weight_power_0.pixelization.weight_map_from_hyper_image(\n",
    "    hyper_image=source_weight_power_0.hyper_galaxy_image\n",
    ")\n",
    "\n",
    "aplt.array(array=cluster_weight_power_0, mask=mask)\n",
    "\n",
    "source_weight_power_5 = al.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=al.pix.VoronoiBrightnessImage(\n",
    "        pixels=500, weight_floor=0.0, weight_power=5.0\n",
    "    ),\n",
    "    regularization=al.reg.Constant(coefficient=1.0),\n",
    "    hyper_galaxy_image=hyper_image,\n",
    "    binned_hyper_galaxy_image=hyper_image,\n",
    ")\n",
    "\n",
    "cluster_weight_power_5 = source_weight_power_5.pixelization.weight_map_from_hyper_image(\n",
    "    hyper_image=source_weight_power_5.hyper_galaxy_image\n",
    ")\n",
    "\n",
    "aplt.array(array=cluster_weight_power_5, mask=mask)\n",
    "\n",
    "source_weight_power_10 = al.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=al.pix.VoronoiBrightnessImage(\n",
    "        pixels=500, weight_floor=0.0, weight_power=10.0\n",
    "    ),\n",
    "    regularization=al.reg.Constant(coefficient=1.0),\n",
    "    hyper_galaxy_image=hyper_image,\n",
    "    binned_hyper_galaxy_image=hyper_image,\n",
    ")\n",
    "\n",
    "cluster_weight_power_10 = source_weight_power_10.pixelization.weight_map_from_hyper_image(\n",
    "    hyper_image=source_weight_power_10.hyper_galaxy_image\n",
    ")\n",
    "\n",
    "aplt.array(array=cluster_weight_power_10, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we increase the weight-power the brightest regions of the hyper-galaxy-image become weighted higher relative to the fainter regions. This means that t e KMeans algorithm will adapt its pixelization to the brightest regions of the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_weight_power_0])\n",
    "\n",
    "fit = al.fit(masked_dataset=masked_imaging, tracer=tracer)\n",
    "\n",
    "aplt.inversion.reconstruction(\n",
    "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
    ")\n",
    "\n",
    "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_weight_power_5])\n",
    "\n",
    "fit = al.fit(masked_dataset=masked_imaging, tracer=tracer)\n",
    "\n",
    "aplt.inversion.reconstruction(\n",
    "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
    ")\n",
    "\n",
    "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_weight_power_10])\n",
    "\n",
    "fit = al.fit(masked_dataset=masked_imaging, tracer=tracer)\n",
    "\n",
    "aplt.inversion.reconstruction(\n",
    "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what does the weight_floor do? Increasing the weight-power congregates pixels around the source. However, there is a risk that by congregating too many source pixels in its brightest regions we lose resolution further out, where the source is bright, but not its brightest!\n",
    "\n",
    "The noise-floor allows these regions to maintain a higher weighting whilst the noise_power increases. This means that the pixelization can fully adapt to the source's brightest and faintest regions simultaneously.\n",
    "\n",
    "Lets look at once example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_weight_floor = al.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=al.pix.VoronoiBrightnessImage(\n",
    "        pixels=500, weight_floor=0.5, weight_power=10.0\n",
    "    ),\n",
    "    regularization=al.reg.Constant(coefficient=1.0),\n",
    "    hyper_galaxy_image=hyper_image\n",
    ")\n",
    "\n",
    "cluster_weight_floor = source_weight_floor.pixelization.weight_map_from_hyper_image(\n",
    "    hyper_image=source_weight_floor.hyper_galaxy_image\n",
    ")\n",
    "\n",
    "aplt.array(array=cluster_weight_floor, mask=mask)\n",
    "\n",
    "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_weight_floor])\n",
    "\n",
    "fit = al.fit(masked_dataset=masked_imaging, tracer=tracer)\n",
    "\n",
    "aplt.inversion.reconstruction(\n",
    "    inversion=fit.inversion, include=aplt.Include(inversion_pixelization_grid=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To end, lets think about the Bayesian evidence which goes to significantly higher values than a magnification-based gird. At this point, it might be worth reminding yourself how the Bayesian evidence works by going back to the 'introduction' text file.\n",
    "\n",
    "So, why do you think why adapting to the source's brightness increases the evidence?\n",
    "\n",
    "It is because by adapting to the source's morphology we can now access solutions that fit the data really well (e.g. to the Gaussian noise-limit) but use significantly fewer source-pixels than other al. For instance, a typical magnification based grid uses resolutions of 40 x 40, or 1600 pixels. In contrast, a morphology based grid typically uses just 300-800 pixels (depending on the source itself). Clearly, the easiest way to make our source solution simpler is to use fewer pixels overall!\n",
    "\n",
    "This provides a second benefit. If the best solutions in our fit want to use the fewest source-pixels possible and PyAutoLens can now access those solutions, this means that hyper-galaxy-mode will run much faster than the magnification based grid! Put simply, fewer source-pixels means lower computational overheads. YAY!\n",
    "\n",
    "Tutorial 2 done, next up, adaptive regularization!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
