{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So, in the previous tutorial, we motivated a need to adapt our pixelization to the source's morphology, that is where it congregates pixels in the source's brightest regions, regardless of where it is located in the source-plane. This raises an interesting question; how do we adapt our source pixelization to the reconstructed source, before we've actually reconstructed the source and therefore know what to adapt it too?\n",
    "\n",
    "To do this, we define a 'hyper-image' of the lensed source galaxy, which is a model image of the source computed using a previous lens model fit to the image (e.g. in an earlier phase of a pipeline). Because this image tells us where in the image our source is located, it means that by tracing these pixels to the source-plane we can use them to tell us where we need to adapt our source pixelization!\n",
    "\n",
    "So, lets go into the details of how this works. We'll use the same compact source galaxy as the previous tutorial and we'll begin by fitting it with a magnification based pixelizationo. Why? So we can use its model image to set up the hyper-image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolens.data.instrument import abstract_data
from autolens.data.instrument import ccd\n",
    "from autolens.data.array import mask as msk\n",
    "from autolens.model.profiles import light_profiles as lp\n",
    "from autolens.model.profiles import mass_profiles as mp\n",
    "from autolens.model.galaxy import galaxy as g\n",
    "from autolens.lens import ray_tracing\n",
    "from autolens.lens import lens_fit\n",
    "from autolens.lens import lens_data as ld\n",
    "from autolens.model.inversion import pixelizations as pix\n",
    "from autolens.model.inversion import regularization as reg\n",
    "from autolens.model.inversion.plotters import inversion_plotters\n",
    "from autolens.lens.plotters import lens_fit_plotters\n",
    "from autolens.plotters import array_plotters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the usual simulate function, using the compact source of the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate():\n",
    "\n",
    "    from autolens.data.array import grids\n",
    "    from autolens.model.galaxy import galaxy as g\n",
    "    from autolens.lens import ray_tracing\n",
    "\n",
    "    psf = abstract_data.PSF.from_gaussian(shape=(11, 11), sigma=0.05, pixel_scale=0.05)\n",
    "\n",
    "    image_plane_grid_stack = grids.GridStack.from_shape_pixel_scale_and_sub_grid_size(\n",
    "        shape=(150, 150), pixel_scale=0.05, sub_grid_size=2\n",
    "    )\n",
    "\n",
    "    lens_galaxy = g.Galaxy(\n",
    "        redshift=0.5,\n",
    "        mass=mp.EllipticalIsothermal(\n",
    "            centre=(0.0, 0.0), axis_ratio=0.8, phi=45.0, einstein_radius=1.6\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    source_galaxy = g.Galaxy(\n",
    "        redshift=1.0,\n",
    "        light=lp.EllipticalSersic(\n",
    "            centre=(0.0, 0.0),\n",
    "            axis_ratio=0.7,\n",
    "            phi=135.0,\n",
    "            intensity=0.2,\n",
    "            effective_radius=0.2,\n",
    "            sersic_index=2.5,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    tracer = ray_tracing.Tracer.from_galaxies_and_image_plane_grid_stack(\n",
    "        galaxies=[lens_galaxy, source_galaxy],\n",
    "        image_plane_grid_stack=image_plane_grid_stack,\n",
    "    )\n",
    "\n",
    "    return ccd.SimulatedCCDData.from_tracer_and_exposure_arrays(\n",
    "        tracer=tracer,\n",
    "        pixel_scale=0.05,\n",
    "        exposure_time=300.0,\n",
    "        psf=psf,\n",
    "        background_sky_level=1.0,\n",
    "        add_noise=True,\n",
    "        noise_seed=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets simulate the data, draw a 3.0\" mask and set up the lens data that we'll fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccd_data = simulate()\n",
    "mask = msk.Mask.circular(shape=(150, 150), pixel_scale=0.05, radius_arcsec=3.0)\n",
    "lens_data = ld.LensData(ccd_data=ccd_data, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to fit the image using our magnification based grid. The code below does all the usual steps required to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_galaxy = g.Galaxy(\n",
    "    redshift=0.5,\n",
    "    mass=mp.EllipticalIsothermal(\n",
    "        centre=(0.0, 0.0), axis_ratio=0.8, phi=45.0, einstein_radius=1.6\n",
    "    ),\n",
    ")\n",
    "\n",
    "source_magnification = g.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=pix.VoronoiMagnification(shape=(30, 30)),\n",
    "    regularization=reg.Constant(coefficient=3.3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This convenience function fits the image using a source-galaxy (which may have a hyper-image attatched to it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lens_data_with_source_galaxy(lens_data, source_galaxy):\n",
    "\n",
    "    pixelization_grid = source_galaxy.pixelization.pixelization_grid_from_grid_stack(\n",
    "        grid_stack=lens_data.grid_stack,\n",
    "        hyper_image=source_galaxy.hyper_galaxy_image_1d,\n",
    "        cluster=lens_data.cluster,\n",
    "    )\n",
    "\n",
    "    grid_stack_with_pixelization_grid = lens_data.grid_stack.new_grid_stack_with_grids_added(\n",
    "        pixelization=pixelization_grid\n",
    "    )\n",
    "\n",
    "    tracer = ray_tracing.Tracer.from_galaxies_and_image_plane_grid_stack(\n",
    "        galaxies=[lens_galaxy, source_galaxy],\n",
    "        image_plane_grid_stack=grid_stack_with_pixelization_grid,\n",
    "        border=lens_data.border,\n",
    "    )\n",
    "\n",
    "    return lens_fit.LensDataFit.for_data_and_tracer(lens_data=lens_data, tracer=tracer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so now lets fit the data using our magnification based pixelizatioin and have a quick look to make sure it has the same residuals we saw in tutorial 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = fit_lens_data_with_source_galaxy(\n",
    "    lens_data=lens_data, source_galaxy=source_magnification\n",
    ")\n",
    "\n",
    "lens_fit_plotters.plot_fit_subplot(\n",
    "    fit=fit,\n",
    "    should_plot_image_plane_pix=True,\n",
    "    should_plot_mask=True,\n",
    "    extract_array_from_mask=True,\n",
    "    zoom_around_mask=True,\n",
    ")\n",
    "\n",
    "inversion_plotters.plot_pixelization_values(\n",
    "    inversion=fit.inversion, should_plot_centres=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use this fit to set up our hyper-image. Sure, the hyper-image isn't perfect, after all the were clear residuals in the central regions of the reconstructed source. But it's *okay*, it'll certainly gives us enough information on where the lensed source is located to adapt our pixelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_image_1d = fit.model_image(return_in_2d=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now lets take a look at our brightness based adaption in action! Below, we define a source-galaxy using our new 'VoronoiBrightnessImage' pixelization and use this to fit the lens-data. One should note that we also attach the hyper-image to this galaxy. This is because it's pixelization uses this hyper-image to adapt, thus the galaxy needs to know what hyper-image it should use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_brightness = g.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=pix.VoronoiBrightnessImage(\n",
    "        pixels=500, weight_floor=0.0, weight_power=10.0\n",
    "    ),\n",
    "    regularization=reg.Constant(coefficient=0.5),\n",
    "    hyper_galaxy_image_1d=hyper_image_1d,\n",
    ")\n",
    "\n",
    "fit = fit_lens_data_with_source_galaxy(\n",
    "    lens_data=lens_data, source_galaxy=source_brightness\n",
    ")\n",
    "\n",
    "lens_fit_plotters.plot_fit_subplot(\n",
    "    fit=fit,\n",
    "    should_plot_image_plane_pix=True,\n",
    "    should_plot_mask=True,\n",
    "    extract_array_from_mask=True,\n",
    "    zoom_around_mask=True,\n",
    ")\n",
    "\n",
    "inversion_plotters.plot_pixelization_values(\n",
    "    inversion=fit.inversion, should_plot_centres=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you look at that! Our reconstruction of the image no longer has residuals! By congregating more source pixels in the brightest regions of the source reconstruction, we got a better fit. Furthermore, we can check that this indeed corresponds to an increase in Bayesian evidence, noting that the evidence of the compact source when using a VoronoiMagnification pixelization was 14236:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evidence using magnification based pixelization = \", 14236.292117135737)\n",
    "\n",
    "print(\"Evidence using brightness based pixelization = \", fit.evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It increases! By over 200, which, for a Bayesian evidence, is pretty damn large! Clearly, By any measure, this pixelization is a huge success. It turns out that, all along, we should have been adapting to the source's brightness! In doing so, we will *always* reconstruct the detailed structure of the source's brightest regions with a sufficiently high resolution. Hurrah!\n",
    "\n",
    "Okay, so we can now adapt our pixelization to the morphology of our lensed source galaxy. To my knowledge, this is the *best* approach one can take the lens modeling. Its more tricky to implement (as I'll explain next) and introduces a few extra hyper-parameters that we'll fit for. But, the pay-off is more than worth it, as we fit our imaging data better and (typically) end up using far fewer source pixels to fit the data, as we don't 'waste' pixels reconstructing regions of the source-plane where there is no signal.\n",
    "\n",
    "\n",
    "Okay, so how does the hyper_image actually adapt our pixelization to the source's brightness? We derive the pixelization using a 'weighted KMeans clustering algorithm', which is a standard algorithm for partioning data in statistics.\n",
    "\n",
    "In simple terms, this algorithm works as follows:\n",
    "\n",
    "1) Give the KMeans algorithm a set of weighted data (e.g. determined from the hyper image).\n",
    "\n",
    "2) For a given number of clusters, this algorithm will find a set of (y,x) coordinates or 'clusters' that are equally distributed over the weighted data. Where the data is weighted higher, more clusters will congregate, and visa versa.\n",
    "\n",
    "3) The returned (y,x) 'clusters' then make up our source-pixel centres and, as described, there will be more wherever our hyper-image is brighter! Like we did for the magnification based pixelization, we can then trace these coordinates to the source-plane to define our source-pixel grid.\n",
    "\n",
    "This is a fairly simplistic description of a KMeans algorithm. Feel free to check out the links below for a more in-depth view:\n",
    "\n",
    "https://en.wikipedia.org/wiki/K-means_clustering\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "\n",
    "Okay, so we now have a sense of how our VoronoiBrightnessImage pixelization is computed. Now, lets look at how we create the weighted data the KMeans algorithm clusters.\n",
    "\n",
    "This image, called the 'cluster_weight_map'  is generated using the 'weight_floor' and 'weight_power' parameters of the VoronoiBrightness pixelization. The cluster weight map is generated following 4 steps:\n",
    "\n",
    "1) Increase all values of the hyper-image that are < 0.02 to 0.02. This is necessary because negative values and zeros break the KMeans clustering algorithm.\n",
    "\n",
    "2) Divide all values of this image by its maximum value, such that the hyper-image now only contains values between 0.0 and 1.0 (where the values of 1.0 were the maximum values of the hyper-image)\n",
    "\n",
    "3) Add the weight_floor to all values (a weight_floor of 0.0 therefore does not change the cluster weight map)\n",
    "\n",
    "4) Raise all values to the power of weight_power (a weight_power of 1.0 therefore does not change the cluster weight map, whereas a value of 0.0 means all values 1.0 and therefore weighted equally).\n",
    "\n",
    "Lets look at this in action. We'll inspect 3 cluster_weight_maps, using a weight_power of 0.0, 5.0 and 10.0, setting the weight_floor to 0.0 such that it does not change the cluster weight map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_weight_power_0 = g.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=pix.VoronoiBrightnessImage(\n",
    "        pixels=500, weight_floor=0.0, weight_power=0.0\n",
    "    ),\n",
    "    regularization=reg.Constant(coefficient=1.0),\n",
    "    hyper_galaxy_image_1d=hyper_image_1d,\n",
    ")\n",
    "\n",
    "cluster_weight_power_0 = source_weight_power_0.pixelization.cluster_weight_map_from_hyper_image(\n",
    "    hyper_image=source_weight_power_0.hyper_galaxy_image_1d\n",
    ")\n",
    "cluster_weight_power_0 = mask.scaled_array_2d_from_array_1d(\n",
    "    array_1d=cluster_weight_power_0\n",
    ")\n",
    "array_plotters.plot_array(\n",
    "    array=cluster_weight_power_0,\n",
    "    mask=mask,\n",
    "    extract_array_from_mask=True,\n",
    "    zoom_around_mask=True,\n",
    ")\n",
    "\n",
    "source_weight_power_5 = g.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=pix.VoronoiBrightnessImage(\n",
    "        pixels=500, weight_floor=0.0, weight_power=5.0\n",
    "    ),\n",
    "    regularization=reg.Constant(coefficient=1.0),\n",
    "    hyper_galaxy_image_1d=hyper_image_1d,\n",
    ")\n",
    "\n",
    "cluster_weight_power_5 = source_weight_power_5.pixelization.cluster_weight_map_from_hyper_image(\n",
    "    hyper_image=source_weight_power_5.hyper_galaxy_image_1d\n",
    ")\n",
    "cluster_weight_power_5 = mask.scaled_array_2d_from_array_1d(\n",
    "    array_1d=cluster_weight_power_5\n",
    ")\n",
    "array_plotters.plot_array(\n",
    "    array=cluster_weight_power_5,\n",
    "    mask=mask,\n",
    "    extract_array_from_mask=True,\n",
    "    zoom_around_mask=True,\n",
    ")\n",
    "\n",
    "source_weight_power_10 = g.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=pix.VoronoiBrightnessImage(\n",
    "        pixels=500, weight_floor=0.0, weight_power=10.0\n",
    "    ),\n",
    "    regularization=reg.Constant(coefficient=1.0),\n",
    "    hyper_galaxy_image_1d=hyper_image_1d,\n",
    ")\n",
    "\n",
    "cluster_weight_power_10 = source_weight_power_10.pixelization.cluster_weight_map_from_hyper_image(\n",
    "    hyper_image=source_weight_power_10.hyper_galaxy_image_1d\n",
    ")\n",
    "cluster_weight_power_10 = mask.scaled_array_2d_from_array_1d(\n",
    "    array_1d=cluster_weight_power_10\n",
    ")\n",
    "array_plotters.plot_array(\n",
    "    array=cluster_weight_power_10,\n",
    "    mask=mask,\n",
    "    extract_array_from_mask=True,\n",
    "    zoom_around_mask=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as expected, when we increased the weight-power the brightest regions of the hyper-image become weighted higher relative to the fainter regions. This is exactly what we want, as it means the KMeans algorithm will adapt its pixelization to the brightest regions of the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fit = fit_lens_data_with_source_galaxy(\n",
    "    lens_data=lens_data, source_galaxy=source_weight_power_0\n",
    ")\n",
    "\n",
    "inversion_plotters.plot_pixelization_values(\n",
    "    inversion=fit.inversion, should_plot_centres=True\n",
    ")\n",
    "\n",
    "fit = fit_lens_data_with_source_galaxy(\n",
    "    lens_data=lens_data, source_galaxy=source_weight_power_5\n",
    ")\n",
    "\n",
    "inversion_plotters.plot_pixelization_values(\n",
    "    inversion=fit.inversion, should_plot_centres=True\n",
    ")\n",
    "\n",
    "fit = fit_lens_data_with_source_galaxy(\n",
    "    lens_data=lens_data, source_galaxy=source_weight_power_10\n",
    ")\n",
    "\n",
    "inversion_plotters.plot_pixelization_values(\n",
    "    inversion=fit.inversion, should_plot_centres=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so this is why our pixelization can adapt to the source's brightness.\n",
    "\n",
    "So, what does the weight_floor do? Increasing the weight-power congregates pixels around the source. However, there is a risk that by congregating too many source pixels in its brightest regions, we lose resolution further out, where the source is bright, but not its brightest!\n",
    "\n",
    "The noise-floor allows these regions to maintain a higher weighting whilst the noise_power increases. This means that the pixelization can fully adapt to the source's brightest and faintest regions simultaneously.\n",
    "\n",
    "Lets look at once example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_weight_floor = g.Galaxy(\n",
    "    redshift=1.0,\n",
    "    pixelization=pix.VoronoiBrightnessImage(\n",
    "        pixels=500, weight_floor=0.5, weight_power=10.0\n",
    "    ),\n",
    "    regularization=reg.Constant(coefficient=1.0),\n",
    "    hyper_galaxy_image_1d=hyper_image_1d,\n",
    ")\n",
    "\n",
    "cluster_weight_floor = source_weight_floor.pixelization.cluster_weight_map_from_hyper_image(\n",
    "    hyper_image=source_weight_floor.hyper_galaxy_image_1d\n",
    ")\n",
    "cluster_weight_floor = mask.scaled_array_2d_from_array_1d(array_1d=cluster_weight_floor)\n",
    "\n",
    "array_plotters.plot_array(\n",
    "    array=cluster_weight_floor,\n",
    "    mask=mask,\n",
    "    extract_array_from_mask=True,\n",
    "    zoom_around_mask=True,\n",
    ")\n",
    "\n",
    "fit = fit_lens_data_with_source_galaxy(\n",
    "    lens_data=lens_data, source_galaxy=source_weight_floor\n",
    ")\n",
    "\n",
    "inversion_plotters.plot_pixelization_values(\n",
    "    inversion=fit.inversion, should_plot_centres=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is how the first feature in hyper-mode works.\n",
    "\n",
    "Finally, lets think about the Bayesian evidence, which we have noted went to significantly higher values than the magnification-based gird. At this point, it might be worth reminding yourself how the Bayesian evidence works, by going back to the 'introduction_bayesian_evidence' text file.\n",
    "\n",
    "So, why do you think why adapting to the source's brightness increases the evidence?\n",
    "\n",
    "Its because, by adapting to the source's morphology, we can now access solutions that fit the data really well (e.g. to the Gaussian noise-limit) but use significantly fewer source-pixels than other grids. For instance, a typical magnification based grid uses resolutions of 40 x 40, or 1600 pixels. In contrast, a morphology based grid typically uses just 300-800 pixels (depending on the source itself). Clearly, the easiest way to make our source solution simpler is to use fewer pixels overall!\n",
    "\n",
    "This provides a second benefit. If the best solutions in our fit want to use the fewest source-pixels possible, and PyAutoLens can now access those solutions, this means that hyper-mode will run much faster than the magnification based grid! Put simply, fewer source-pixels means lower computational overheads. YAY!\n",
    "\n",
    "Tutorial 2 done, next up, adaptive regularization!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
