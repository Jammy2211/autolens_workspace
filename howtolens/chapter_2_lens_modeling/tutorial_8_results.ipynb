{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 8: Results\n",
        "===================\n",
        "\n",
        "Once a phase has completed running, it results a `Result` object, which in the previous tutorials we used to plot\n",
        "the maximum log likelihood fit of the modoel-fits. Lets take a more detailed look at what else the results contains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from pyprojroot import here\n",
        "\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets reperform the model-fit from tutorial 1 to get a results object, provided you didn`t delete the results on\n",
        "your hard-disk this should simply reload them into this Pythons script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"mass_sis__source_exp\"\n",
        "dataset_path = path.join(\"dataset\", \"howtolens\", \"chapter_2\", dataset_name)\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    image_path=path.join(dataset_path, \"image.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_2d=imaging.shape_2d, pixel_scales=imaging.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "phase = al.PhaseImaging(\n",
        "    search=af.DynestyStatic(\n",
        "        path_prefix=\"howtolens\", name=\"phase_t1_non_linear_search\", n_live_points=40\n",
        "    ),\n",
        "    settings=al.SettingsPhaseImaging(\n",
        "        settings_masked_imaging=al.SettingsMaskedImaging(grid_class=al.Grid, sub_size=2)\n",
        "    ),\n",
        "    galaxies=dict(\n",
        "        lens_galaxy=al.GalaxyModel(redshift=0.5, mass=al.mp.SphericalIsothermal),\n",
        "        source_galaxy=al.GalaxyModel(redshift=1.0, bulge=al.lp.SphericalExponential),\n",
        "    ),\n",
        ")\n",
        "\n",
        "result = phase.run(dataset=imaging, mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the previous tutorials, we saw that this result contains the maximum log likelihood tracer and fit, which provide\n",
        "a fast way to visualize the result.\n",
        "\n",
        "(Uncomment the line below to pllot the tracer).\n",
        "\"\"\"\n",
        "aplt.Tracer.subplot_tracer(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=mask.geometry.unmasked_grid\n",
        ")\n",
        "aplt.FitImaging.subplot_fit_imaging(fit=result.max_log_likelihood_fit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result contains a lot more information about the model-fit. For example, its `Samples` object contains the complete\n",
        "set of `NonLinearSearch` samples, for example every set of parameters evaluated, their log likelihoods and so on,\n",
        "which are used for computing information about the model-fit such as the error on every parameter.\n",
        "\"\"\"\n",
        "print(result.samples)\n",
        "print(result.samples.parameters)\n",
        "print(result.samples.log_likelihoods)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, we are not going into any more detail on the result variable in this tutorial, or in the **HowToLens** lectures.\n",
        "\n",
        "A comprehensive description of the results can be found at the following script:\n",
        "\n",
        " `autolens_workspace/examples/model/result.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Aggregator__\n",
        "\n",
        "Once a phase has completed running, we have a set of results on our hard disk we manually inspect and analyse. \n",
        "Alternatively, we can return the results from the phase.run() method and manipulate them in a Python script.  \n",
        "\n",
        "However, imagine your dataset is large and consists of many images of strong lenses. You analyse each image \n",
        "individually using the same phase, producing a large set of results on your hard disk corresponding to the full sample.\n",
        "That will be a lot of paths and directories to navigate! At some point, there`ll be too many results for it to be\n",
        "a sensible use of your time to analyse the results by sifting through the outputs on your hard disk.\n",
        "\n",
        "PyAutoFit`s aggregator tool allows us to load results in a Python script or, more impotantly, a Jupyter notebook.\n",
        "All we have to do is point the aggregator to the output directory from which we want to load results, which in this c\n",
        "ase will be the results of the first `NonLinearSearch` of this chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To set up the aggregator we simply pass it the folder of the results we want to load."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg = af.Aggregator(directory=\"output\")\n",
        "agg = agg.filter(agg.phase == \"phase_t1_non_linear_search\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get the output of the results of the model-fit performed in tutorial 1, given that is the directory we point too. \n",
        "This gives us a list with 1 entry, the list would have more entries if there were more results in the path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = list(agg.values(\"samples\"))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From here, we can inspect results as we please, for example printing the maximum log likelihood model of the phase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(samples[0].max_log_likelihood_vector)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, we won't go into any more detail on the aggregator in this tutorial. For those of you modeling large samples of\n",
        "lenses for who the tool will prove useful, checkout the full set of aggregator tutorials which can be found at the \n",
        "location `autolens_workspace/advanced`aggregator`. Here, you'll learn how to:\n",
        "\n",
        " - Use the aggregator to filter out results given a phase name or input string.\n",
        " - Use the Samples to produce many different results from the fit, including error estimates on parameters and \n",
        "      plots of the probability density function of parameters in 1D and 2D.\n",
        " - Reproduce visualizations of results, such as a tracer`s images or the fit to a lens dataset.\n",
        "\n",
        "Even if you are only modeling a small sample of lenses, if you anticipate using **PyAutoLens** for the long-term I \n",
        "strongly recommend you begin using the aggregator to inspect and analyse your result. This is because it makes it \n",
        "simple to perform all analyse in a Jupyter notebook, which as you already know is a flexible and versatile way to check \n",
        "results and make figures.\n",
        "\n",
        "In HowToLelens, the main purpose of this tutorial was to make sure that you are aware of the aggregator`s existance, \n",
        "and now you are!"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}