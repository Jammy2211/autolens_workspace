{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Aggregator 1: Samples__\n",
        "\n",
        "After fitting a large suite of strong lens data, we can use the aggregator to load the results and manipulate,\n",
        "interpret and visualize them using a Python script or Jupyter notebook.\n",
        "\n",
        "This script uses the results generated by the script `/autolens_workspace/aggregator/phaserunner.py`, which fitted 3\n",
        "simulated strong lenses with:\n",
        "\n",
        " - An `EllipticalIsothermal` `MassProfile`.for the lens `Galaxy`'s mass.\n",
        " - An `EllipticalSersic` `LightProfile`.for the source `Galaxy`'s light.\n",
        "\n",
        "This fit was performed using one `PhaseImaging` object, and the first four tutorials (a1-a4) cover how to use the\n",
        "aggregator on the results of `Phase`'s (as opposed to `Pipeline`'s). However, the aggregator API is extremely similar\n",
        "across both and learning to use the aggregator with phases can be easily applied to the results of pipelines.\n",
        "\n",
        "__Samples__\n",
        "\n",
        "If you are familiar with the  `Samples`  object returned from a *PyAutoLens* model-fit (e.g. via a *Phase* or *Pipeline*)\n",
        "You will be familiar with most of the content in this script. Nevertheless, the script also describes how to use\n",
        "the aggregator, so will be useful for you too!\n",
        "\n",
        "__File Output__\n",
        "\n",
        "The results of this fit are in the `autolens_workspace//output/aggregato` folder. First, take a look in this folder.\n",
        "Provided you haven`t rerun the runner, you`ll notice that all the results (e.g. samples, samples_backup,\n",
        "model.results, images, etc.) are in .zip files as opposed to folders that can be instantly accessed.\n",
        "\n",
        "This is because when the pipeline was run, the `remove_files` option in the `config/general.ini` was set to True.\n",
        "This means all results (other than the .zip file) were removed. This feature is implemented because super-computers\n",
        "often have a limit on the number of files allowed per user.\n",
        "\n",
        "Bare in mind the fact that all results are in .zip files, we'll come back to this point in a second."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf import conf\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, we setup the path to the output path we want to load results from, which in this case is the folder \n",
        "`autolens_workspace/output/aggregator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "workspace_path = \"/home/jammy/PycharmProjects/PyAuto/autolens_workspace\"\n",
        "output_path = f\"{workspace_path}/output\"\n",
        "agg_results_path = f\"{output_path}/aggregator\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we'll use this path to explicitly set the config path and output path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "conf.instance = conf.Config(\n",
        "    config_path=f\"{workspace_path}/config\", output_path=output_path\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To set up the aggregator we simply pass it the folder of the results we want to load."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg = af.Aggregator(directory=str(agg_results_path))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before we continue, take another look at the output folder. The .zip files containing results have now all been \n",
        "unzipped, such that the results are accessible on your laptop for navigation. This means you can run fits to many \n",
        "lenses on a super computer and easily unzip all the results on your computer afterwards via the aggregator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To begin, let me quickly explain what a generator is in Python, for those unaware. A generator is an object that \n",
        "iterates over a function when it is called. The aggregator creates all objects as generators, rather than lists, or \n",
        "dictionaries, or whatever.\n",
        "\n",
        "Why? Because lists store every entry in memory simultaneously. If you fit many lenses, you`ll have lots of results and \n",
        "therefore use a lot of memory. This will crash your laptop! On the other hand, a generator only stores the object in \n",
        "memory when it runs the function; it is free to overwrite it afterwards. Thus, your laptop won`t crash!\n",
        "\n",
        "There are two things to bare in mind with generators:\n",
        "\n",
        "    1) A generator has no length, thus to determine how many entries of data it corresponds to you first must convert \n",
        "       it to a list.\n",
        "    \n",
        "    2) Once we use a generator, we cannot use it again and we'll need to remake it.\n",
        "\n",
        "We can now create a `samples` generator of every fit, which creates `Sample`'s objects of our results. This object \n",
        "contains information on the result of the non-linear search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples_gen = agg.values(\"samples\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we print this the length of this generator converted to a list of outputs we see 3 different NestSamples \n",
        "instances. These correspond to each fit of each phase to each of our 3 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"NestedSampler Samples: \\n\")\n",
        "print(samples_gen)\n",
        "print()\n",
        "print(\"Total Samples Objects = \", len(list(samples_gen)), \"\\n\")\n",
        "\n",
        "# %%/\n",
        "\"\"\"\n",
        "The `Samples` class contains all the parameter samples, which is a list of lists where:\n",
        " \n",
        " - The outer list is the size of the total number of samples.\n",
        " - The inner list is the size of the number of free parameters in the fit.\n",
        "\"\"\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "\n",
        "    print(\"All parameters of the very first sample\")\n",
        "    print(samples.parameters[0])\n",
        "    print(\"The third parameter of the tenth sample\")\n",
        "    print(samples.parameters[9][2])\n",
        "\n",
        "\n",
        "print(\"Samples: \\n\")\n",
        "print(agg.values(\"samples\"))\n",
        "print()\n",
        "print(\"Total Samples Objects = \", len(list(agg.values(\"samples\"))), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Samples` class contains the log likelihood, log prior, log posterior and weights of every sample, where:\n",
        "\n",
        "   - The log likelihood is the value evaluated from the likelihood function (e.g. -0.5 * chi_squared + the noise \n",
        "     normalization).\n",
        "    \n",
        "   - The log prior encodes information on how the priors on the parameters maps the log likelihood value to the log\n",
        "     posterior value.\n",
        "      \n",
        "   - The log posterior is log_likelihood + log_prior.\n",
        "    \n",
        "   - The weight gives information on how samples should be combined to estimate the posterior. The weight values \n",
        "     depend on the sampler used, for example for MCMC they will all be 1`s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    print(\"log(likelihood), log(prior), log(posterior) and weight of the tenth sample.\")\n",
        "    print(samples.log_likelihoods[9])\n",
        "    print(samples.log_priors[9])\n",
        "    print(samples.log_posteriors[9])\n",
        "    print(samples.weights[9])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use the outputs to create a list of the maximum log likelihood model of each fit to our three images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_vector = [samps.max_log_likelihood_vector for samps in agg.values(\"samples\")]\n",
        "\n",
        "print(\"Max Log Likelihood Model Parameter Lists: \\n\")\n",
        "print(ml_vector, \"\\n\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This provides us with lists of all model parameters. However, this isn't that much use, which values correspond to \n",
        "which parameters?\n",
        "\n",
        "The list of parameter names are available as a property of the `Model` included with the `Samples`, as are labels \n",
        "which can be used for labeling figures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    model = samples.model\n",
        "    print(model)\n",
        "    print(model.parameter_names)\n",
        "    print(model.parameter_labels)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These lists will be used later for visualization, how it is often more useful to create the model instance of every fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_instances = [samps.max_log_likelihood_instance for samps in agg.values(\"samples\")]\n",
        "print(\"Maximum Log Likelihood Model Instances: \\n\")\n",
        "print(ml_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A model instance contains all the model components of our fit, most importantly the list of galaxies we specified in \n",
        "the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies)\n",
        "print(ml_instances[1].galaxies)\n",
        "print(ml_instances[2].galaxies)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These galaxies will be named according to the phase (in this case, `lens` and `source`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies.lens)\n",
        "print()\n",
        "print(ml_instances[1].galaxies.source)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Their `LightProfile`'s and `MassProfile`'s are also named according to the phase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies.lens.mass)\n",
        "print(ml_instances[1].galaxies.source.light)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also access the `median pdf` model, which is the model computed by marginalizing over the samples of every \n",
        "parameter in 1D and taking the median of this PDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mp_vector = [samps.median_pdf_vector for samps in agg.values(\"samples\")]\n",
        "mp_instances = [samps.median_pdf_instance for samps in agg.values(\"samples\")]\n",
        "\n",
        "print(\"Median PDF Model Parameter Lists: \\n\")\n",
        "print(mp_vector, \"\\n\")\n",
        "print(\"Most probable Model Instances: \\n\")\n",
        "print(mp_instances, \"\\n\")\n",
        "print(mp_instances[0].galaxies.lens.mass)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute the model parameters at a given sigma value (e.g. at 3.0 sigma limits).\n",
        "\n",
        "These parameter values do not account for covariance between the model. For example if two parameters are degenerate \n",
        "this will find their values from the degeneracy in the `same direction` (e.g. both will be positive). we'll cover\n",
        "how to handle covariance in a later tutorial.\n",
        "\n",
        "Here, I use \"uv3\" to signify this is an upper value at 3 sigma confidence,, and \"lv3\" for the lower value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "uv3_vectors = [\n",
        "    samps.vector_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "uv3_instances = [\n",
        "    samps.instance_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "lv3_vectors = [\n",
        "    samps.vector_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "lv3_instances = [\n",
        "    samps.instance_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "print(\"Errors Lists: \\n\")\n",
        "print(uv3_vectors, \"\\n\")\n",
        "print(lv3_vectors, \"\\n\")\n",
        "print(\"Errors Instances: \\n\")\n",
        "print(uv3_instances, \"\\n\")\n",
        "print(lv3_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute the upper and lower errors on each parameter at a given sigma limit.\n",
        "\n",
        "Here, \"ue3\" signifies the upper error at 3 sigma. \n",
        "\n",
        "( Need to fix bug, sigh)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ue3_vectors = [\n",
        "#     samps.error_vector_at_upper_sigma(sigma=3.0)\n",
        "#     for samps in agg.values(\"samples\")\n",
        "# ]\n",
        "#\n",
        "# ue3_instances = [\n",
        "#     samps.error_instance_at_upper_sigma(sigma=3.0)\n",
        "#     for samps in agg.values(\"samples\")\n",
        "# ]\n",
        "#\n",
        "# le3_vectors = [\n",
        "#     samps.error_vector_at_lower_sigma(sigma=3.0)\n",
        "#     for samps in agg.values(\"samples\")\n",
        "# ]\n",
        "# le3_instances = [\n",
        "#     samps.error_instance_at_lower_sigma(sigma=3.0)\n",
        "#     for samps in agg.values(\"samples\")\n",
        "# ]\n",
        "#\n",
        "# print(\"Errors Lists: \\n\")\n",
        "# print(ue3_vectors, \"\\n\")\n",
        "# print(le3_vectors, \"\\n\")\n",
        "# print(\"Errors Instances: \\n\")\n",
        "# print(ue3_instances, \"\\n\")\n",
        "# print(le3_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The maximum log likelihood of each model fit and its Bayesian log evidence (estimated via the nested sampling \n",
        "algorithm) are also available.\n",
        "\n",
        "Given each fit is to a different image, these are not very useful. However, in a later tutorial we'll look at using \n",
        "the aggregator for images that we fit with many different models and many different pipelines, in which case comparing \n",
        "the evidences allows us to perform Bayesian model comparison!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Maximum Log Likelihoods and Log Evidences: \\n\")\n",
        "print([max(samps.log_likelihoods) for samps in agg.values(\"samples\")])\n",
        "print([samps.log_evidence for samps in agg.values(\"samples\")])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also print the \"model_results\" of all phases, which is string that summarizes every fit`s lens model providing \n",
        "quick inspection of all results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = agg.model_results\n",
        "print(\"Model Results Summary: \\n\")\n",
        "print(results, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Probability Density Functions (PDF`s) of the results can be plotted using the library:\n",
        "\n",
        " corner.py: https://corner.readthedocs.io/en/latest/\n",
        "\n",
        "(In built visualization for PDF`s and non-linear searches is a future feature of PyAutoFit, but for now you`ll have to \n",
        "use the libraries yourself!).\n",
        "\"\"\"\n",
        "\n",
        "import corner\n",
        "\n",
        "for samples in agg.values(\"samples\"):\n",
        "    corner.corner(xs=samples.parameters, weights=samples.weights)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}