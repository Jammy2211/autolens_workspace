{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start Here: Imaging\n",
        "===================\n",
        "\n",
        "Strong gravitational lenses often have point sources (e.g. quasars) that are being lensed, appearing as two or\n",
        "four distinct point-like images. These lenses are particularly useful for measuring cosmological parameters\n",
        "like the Hubble constant, and for studying the small-scale properties of dark matter.\n",
        "\n",
        "This script shows you how to model such a lens system using **PyAutoLens** with as little setup\n",
        "as possible. In about 15 minutes you\u2019ll be able to point the code at your own data and\n",
        "fit your first lens.\n",
        "\n",
        "We focus on a *galaxy-scale* lens (a single lens galaxy). If you have multiple lens galaxies,\n",
        "see the `start_here_group.ipynb` and `start_here_cluster.ipynb` examples.\n",
        "\n",
        "Point source modeling uses the positions of the lensed source in the image-plane, and optionally may also\n",
        "use their fluxes and time delays. However, it is common for lensed quasar overall to be observed by CCD\n",
        "imaging data, which is used to measure the positions of the point sources precisions and produes visuals\n",
        "of the strong lens which aid its interpretation.\n",
        "\n",
        "This script therefore also shows how to plot the CCD imaging of a point source lens, but does not use the\n",
        "imaging data to constrain the lens model itself.\n",
        "\n",
        "PyAutoLens uses JAX under the hood for fast GPU/CPU acceleration. If JAX is installed with GPU\n",
        "support, your fits will run much faster (a few minutes instead of an hour). If you don\u2019t have\n",
        "a GPU locally, consider Google Colab which provides free GPUs, so your modeling runs are much faster.\n",
        "\n",
        "We also show how to simulate strong lens point sources. This is useful for building machine learning\n",
        "training datasets, or for investigating lensing effects in a controlled way.\n",
        "\n",
        "__Google Colab Setup__\n",
        "\n",
        "The introduction `start_here` examples are available on Google Colab, which allows you to run them in a web browser\n",
        "without manual local PyAutoLens installation.\n",
        "\n",
        "The code below sets up your environment if you are using Google Colab, including installing autolens and downloading\n",
        "files required to run the notebook. If you are running this script not in Colab (e.g. locally on your own computer), \n",
        "running the code below state you are not in a Colab environment and skip the setup."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf import setup_colab\n",
        "\n",
        "try:\n",
        "    setup_colab.setup_colab_autolens()\n",
        "except ModuleNotFoundError:\n",
        "    pass"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Imports__\n",
        "\n",
        "Lets first import autolens, its plotting module and the other libraries we'll need.\n",
        "\n",
        "You'll see these imports in the majority of workspace examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "We begin by Creating the point source dataset, which for now contains only: \n",
        "\n",
        "1. The positions of the lensed images in the image-plane.\n",
        "2. Their RMS noise-map values, corresponding to the uncertainty on their position measurements.\n",
        "3. The PSF (Point Spread Function).\n",
        "\n",
        "We print and plot the dataset to show these properties but also see that the dataset has a name,\n",
        "this will be import later when we perform lens modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = al.Grid2DIrregular(\n",
        "    [(-1.039, -1.038), (0.442, 1.608), (1.609, 0.442), (1.179, 1.179)]\n",
        ")\n",
        "noise_map = al.ArrayIrregular([0.05, 0.05, 0.05, 0.05])\n",
        "\n",
        "dataset = al.PointDataset(\n",
        "    name=\"point_0\", positions=positions, positions_noise_map=noise_map\n",
        ")\n",
        "\n",
        "print(\"Point Dataset Info:\")\n",
        "print(dataset.info)\n",
        "\n",
        "dataset_plotter = aplt.PointDatasetPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also load the dataset from the workspace `datasset` folder, which means the image we\n",
        "load below is also available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = Path(\"dataset\") / \"point_source\" / dataset_name\n",
        "\n",
        "dataset = al.from_json(\n",
        "    file_path=dataset_path / \"point_dataset_positions_only.json\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We next load an image of the dataset. \n",
        "\n",
        "Although we are performing point-source modeling and do not use this data in the actual modeling, it is useful to \n",
        "load it for visualization, for example to see where the multiple images of the point source are located relative to the \n",
        "lens galaxy.\n",
        "\n",
        "The image will also be passed to the analysis further down, meaning that visualization of the point-source model\n",
        "overlaid over the image will be output making interpretation of the results straight forward.\n",
        "\n",
        "Loading and inputting the image of the dataset in this way is entirely optional, and if you are only interested in\n",
        "performing point-source modeling you do not need to do this.\n",
        "\n",
        "We also plot the dataset's multiple image positions over the observed image, to ensure they overlap the\n",
        "lensed source's multiple images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = al.Array2D.from_fits(file_path=dataset_path / \"data.fits\", pixel_scales=0.05)\n",
        "\n",
        "visuals = aplt.Visuals2D(positions=dataset.positions)\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data, visuals_2d=visuals)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Solver__\n",
        "\n",
        "For point-source modeling we require a `PointSolver`, which determines the multiple-images of the mass model for a \n",
        "point source at location (y,x) in the source plane. \n",
        "\n",
        "It does this by ray tracing triangles from the image-plane to the source-plane and calculating if the \n",
        "source-plane (y,x) centre is inside the triangle. The method gradually ray-traces smaller and smaller triangles so \n",
        "that the multiple images can be determine with sub-pixel precision.\n",
        "\n",
        "The solver has various settings which are set below to ensure for lens modeling the multiple images are computed\n",
        "accurately, precisely and efficiently. These are described elsewhere in the workspace documentation.\n",
        "\n",
        "The triangle ray-tracing method is fully compatible wit JAX and is significantly accelerated on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(100, 100),\n",
        "    pixel_scales=0.2,  # <- The pixel-scale describes the conversion from pixel units to arc-seconds.\n",
        ")\n",
        "\n",
        "solver = al.PointSolver.for_grid(\n",
        "    grid=grid, pixel_scale_precision=0.001, magnification_threshold=0.1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "To perform lens modeling we must define a lens model, describing the mass profile of the lens \n",
        "galaxy and point source model of the source galaxy.\n",
        "\n",
        "A brilliant lens model to start with is one which uses aSingular Isothermal \n",
        "Ellipsoid (SIE) plus shear to model the lens mass and simply assumes the source is\n",
        "a point source, with a `centre` (y,x) position that is a free parameter of the model.\n",
        "\n",
        "__Name Pairing__\n",
        "\n",
        "The `PointDataset` above had a name, `point_0`. This `name` pairs  the dataset to the `Point` in \n",
        "the model below, which is called `point_0`. \n",
        "\n",
        "If there is no point-source in the model that has the same name as a `PointDataset`, that data \n",
        "is not used in the model-fit. \n",
        "\n",
        "For galaxy scale lenses, where there is just one source galaxy, name pairing is unnecessary. \n",
        "However, cluster-scale strong lenses use the point source modeling API. These systems can have\n",
        "over 100 source galaxies, and name pairing is necessary to ensure every point source in \n",
        "the lens model is fitted to its particular lensed images in the `PointDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=al.mp.Isothermal)\n",
        "\n",
        "# Source:\n",
        "\n",
        "point_0 = af.Model(al.ps.Point)\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, point_0=point_0)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can print the model to show the parameters that the model is composed of."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__\n",
        "\n",
        "We now fit the data with the lens model using the non-linear fitting method and nested sampling algorithm Nautilus.\n",
        "\n",
        "This requires an `AnalysisPoint` object, which defines the `log_likelihood_function` used by Nautilus to fit\n",
        "the model to the point source data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"point_source\"),  # The path where results and output are stored.\n",
        "    name=\"start_here\",  # The name of the fit and folder results are output to.\n",
        "    unique_tag=dataset_name,  # A unique tag which also defines the folder.\n",
        "    n_live=75,  # The number of Nautilus \"live\" points, increase for more complex models.\n",
        "    n_batch=50,  # For fast GPU fitting lens model fits are batched and run simultaneously.\n",
        "    iterations_per_quick_update=2500,  # Every N iterations the max likelihood model is visualized and written to output folder.\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisPoint(dataset=dataset, solver=solver)\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "Now this is running you should checkout the `autolens_workspace/output` folder, where many results of the fit\n",
        "are written in a human readable format (e.g. .json files) and .fits and .png images of the fit are stored.\n",
        "\n",
        "When the fit is complex, we can print the results by printing `result.info`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result also contains the maximum likelihood lens model which can be used to plot the best-fit lensing information\n",
        "and fit to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=result.grids.lp\n",
        ")\n",
        "tracer_plotter.subplot_tracer()\n",
        "\n",
        "fit_plotter = aplt.FitPointDatasetPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result object contains pretty much everything you need to do science with your own strong lens, but details\n",
        "of all the information it contains are beyond the scope of this introductory script. The `guides` and `result` \n",
        "packages of the workspace contains all the information you need to analyze your results yourself.\n",
        "\n",
        "__Model Your Own Lens__\n",
        "\n",
        "If you have your own strong lens point source data, you are now ready to model it yourself by adapting the code above\n",
        "and simply writing your own `PointSourceDataset`, or loading one from .json if you have already created it.\n",
        "\n",
        "A few things to note, with full details on data preparation provided in the main workspace documentation:\n",
        "\n",
        "- PyAutoLens uses (y,x) conventions, so the positions below are y = 1.0\", y = 2.0\", x = 0.0\" and x = 0.0\".\n",
        "- Supply your own CCD image for the lensed quasar for visualization.\n",
        "- Ensure the lens galaxy is roughly centered in the image.\n",
        "- Double-check `pixel_scales` for your telescope/detector.\n",
        "- Start with the default model \u2014 it works very well for pretty much all galaxy scale lenses!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = al.Grid2DIrregular(\n",
        "    [(-1.039, -1.038), (0.442, 1.608), (1.609, 0.442), (1.179, 1.179)]\n",
        ")\n",
        "noise_map = al.ArrayIrregular([0.05, 0.05, 0.05, 0.05])\n",
        "\n",
        "dataset = al.PointDataset(\n",
        "    name=\"point_0\", positions=positions, positions_noise_map=noise_map\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fluxes and Time Delays__\n",
        "\n",
        "If you have measured the fluxes and/or time delays of the lensed point sources, these can also be included in\n",
        "the `PointDataset` above and fitted by the lens model.\n",
        "\n",
        "We first add fluxes, time delays and their RMS noise-map values to the dataset. Note that ordering is used across\n",
        "quantities, so the first flux and time delay corresponds to the first position (1.0, 0.0) and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = al.Grid2DIrregular(\n",
        "    [(-1.039, -1.038), (0.442, 1.608), (1.609, 0.442), (1.179, 1.179)]\n",
        ")\n",
        "fluxes = al.ArrayIrregular(values=[6.82, 55.16, 53.63, 100.62])\n",
        "time_delays = al.ArrayIrregular(values=[-136.99, -176.85, -177.02, -176.74])\n",
        "\n",
        "positions_noise_map = al.ArrayIrregular([0.05, 0.05, 0.05, 0.05])\n",
        "fluxes_noise_map = al.ArrayIrregular(values=[1.0, 1.0, 1.0, 1.0])\n",
        "time_delays_noise_map = al.ArrayIrregular(values=[-34.25, -44.21, -44.26, -44.19])\n",
        "\n",
        "dataset = al.PointDataset(\n",
        "    name=\"point_0\",\n",
        "    positions=positions,\n",
        "    positions_noise_map=positions_noise_map,\n",
        "    fluxes=fluxes,\n",
        "    fluxes_noise_map=fluxes_noise_map,\n",
        "    time_delays=time_delays,\n",
        "    time_delays_noise_map=time_delays_noise_map,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "When we add fluxes to the point dataset, we also need to updatre our model such that our point source\n",
        "objects have their `flux` as a free parameter we fit for. The model API below does this, using the `PointFlux` \n",
        "component instead of the `Point` component. \n",
        "\n",
        "Time delays do not need the model to be updated, as they are computed from the mass model and the \n",
        "point source (y,x) position.\n",
        "\n",
        "You should think very carefully if including fluxes in your modeling is a sensible idea, even if you have\n",
        "the data available. For real lenses, they are often affected by microlensing, dust extinction, and\n",
        "intrinsic variability of the source, all of which are difficult to model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=al.mp.Isothermal)\n",
        "\n",
        "# Source:\n",
        "\n",
        "point_0 = af.Model(al.ps.PointFlux)\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, point_0=point_0)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__\n",
        "\n",
        "We now fit the model to the data using Nautilus, as before, but including\n",
        "the fluxes and time delays in the `AnalysisPoint` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"point_source\"),  # The path where results and output are stored.\n",
        "    name=\"start_here_flux_time_delay\",  # The name of the fit and folder results are output to.\n",
        "    unique_tag=\"example_point\",  # A unique tag which also defines the folder.\n",
        "    n_live=75,  # The number of Nautilus \"live\" points, increase for more complex models.\n",
        "    n_batch=50,  # For fast GPU fitting lens model fits are batched and run simultaneously.\n",
        "    iterations_per_full_update=20000,  # Every N iterations the results are written to hard-disk for inspection.\n",
        ")\n",
        "analysis = al.AnalysisPoint(dataset=dataset)\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Simulator__\n",
        "\n",
        "Let\u2019s now switch gears and simulate our own strong lens point sources. This is a great way to:\n",
        "\n",
        "- Practice lens modeling before using real data.\n",
        "- Build large training sets (e.g. for machine learning).\n",
        "- Test lensing theory in a controlled environment.\n",
        "\n",
        "With each point source we'll also output CCD imaging of the source which is useful for visually\n",
        "showing the lensing configuration.\n",
        "\n",
        "To do this we need to define a 2D grid of (y,x) coordinates in the image-plane. This grid is\n",
        "where we\u2019ll evaluate the light from the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(100, 100),\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now define a `Tracer` \u2014 this is the key object that combines all galaxies in the system\n",
        "and computes how light rays are deflected.\n",
        "\n",
        "- The lens galaxy has both light (a Sersic bulge) and mass (an isothermal profile + shear).\n",
        "- The source galaxy has its own light (a SersicCore profile).\n",
        "\n",
        "Together they define a strong lens system. The tracer will \u201cray-trace\u201d our grid through\n",
        "this mass distribution and generate a lensed image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_centre = (0.0, 0.0)\n",
        "\n",
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.0, 0.0),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        "    shear=al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp.SersicCore(\n",
        "        centre=source_centre,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.8, angle=60.0),\n",
        "        intensity=4.0,\n",
        "        effective_radius=0.1,\n",
        "        sersic_index=1.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the tracer\u2019s image gives us a \u201cperfect\u201d view of the strong lens system, before\n",
        "adding telescope effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid)\n",
        "tracer_plotter.figures_2d(image=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The image cna be saved to .fits for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image = tracer.image_2d_from(grid=grid)\n",
        "\n",
        "dataset_type = \"point_source\"\n",
        "dataset_name = \"start_here_example\"\n",
        "dataset_path = Path(\"dataset\") / dataset_type / dataset_name\n",
        "\n",
        "al.output_to_fits(\n",
        "    values=image.native,\n",
        "    file_path=dataset_path / \"image.fits\",\n",
        "    overwrite=True,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Simulator__\n",
        "\n",
        "We now compute: \n",
        "\n",
        " - The point source positions, reusing the `PointSolver` above.\n",
        " - The RMS noise map of the positions, which uses the `pixel_scale` of the CCD imaging data the quasar is observed on.\n",
        " - The point source fluxes, by computing the magnificaiton from the tracer and applying it to an input source flux.\n",
        " - The RMS noise map of the fluxes, which is the square root of the observed counts of each image.\n",
        " - The time delays, which comes from the tracer's mass model.\n",
        " - The RMS noise of the time delays, which is assumed to be 0.25 * their values but in real data uses the time delay estimate process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = solver.solve(\n",
        "    tracer=tracer, source_plane_coordinate=source_galaxy.point_0.centre\n",
        ")\n",
        "\n",
        "magnifications = tracer.magnification_2d_via_hessian_from(grid=positions)\n",
        "\n",
        "time_delays = tracer.time_delays_from(grid=positions)\n",
        "\n",
        "flux = 1.0\n",
        "fluxes = [flux * np.abs(magnification) for magnification in magnifications]\n",
        "fluxes = al.ArrayIrregular(values=fluxes)\n",
        "\n",
        "positions_noise_map = al.ArrayIrregular([0.05, 0.05, 0.05, 0.05])\n",
        "\n",
        "fluxes_noise_map = al.ArrayIrregular(values=[np.sqrt(flux) for _ in range(len(fluxes))])\n",
        "\n",
        "time_delays_noise_map = al.ArrayIrregular(values=time_delays * 0.25)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can pass these to a `PointDataset` and output to hard disk as a .json file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.PointDataset(\n",
        "    name=\"point_0\",\n",
        "    positions=positions,\n",
        "    positions_noise_map=grid.pixel_scale,\n",
        "    fluxes=fluxes,\n",
        "    fluxes_noise_map=fluxes_noise_map,\n",
        "    time_delays=time_delays,\n",
        "    time_delays_noise_map=time_delays_noise_map,\n",
        ")\n",
        "\n",
        "point_dataset_plotter = aplt.PointDatasetPlotter(\n",
        "    dataset=dataset,\n",
        ")\n",
        "point_dataset_plotter.subplot_dataset()\n",
        "\n",
        "dataset_path = Path(\"dataset\") / \"point_source\" / \"simulated_lens\"\n",
        "\n",
        "\n",
        "al.output_to_json(\n",
        "    obj=dataset,\n",
        "    file_path=dataset_path / \"point_dataset.json\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Sample__\n",
        "\n",
        "Often we want to simulate *many* strong lenses \u2014 for example, to train a neural network\n",
        "or to explore population-level statistics.\n",
        "\n",
        "This uses the model composition API to define the distribution of the light and mass profiles\n",
        "of the lens and source galaxies we draw from. The model composition is a little too complex for\n",
        "the first example, thus we use a helper function to create a simple lens and source model.\n",
        "\n",
        "We then generate 3 lenses for speed, and plot their images so you can see the variety of lenses\n",
        "we create.\n",
        "\n",
        "Each lens is simulated as if it were observed with CD imaging, therefore with a PSF and noise-map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_model, source_model = al.model_util.simulator_start_here_model_from(\n",
        "    include_lens_light=False, use_point_source=True\n",
        ")\n",
        "\n",
        "print(lens_model.info)\n",
        "print(source_model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now simulate a sample of strong lens, we just do 3 for efficiency here but you can increase this to any number."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "total_datasets = 3\n",
        "\n",
        "for sample_index in range(total_datasets):\n",
        "\n",
        "    lens_galaxy = lens_model.random_instance()\n",
        "    source_galaxy = source_model.random_instance()\n",
        "\n",
        "    tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "    positions = solver.solve(\n",
        "        tracer=tracer, source_plane_coordinate=source_galaxy.point_0.centre\n",
        "    )\n",
        "    magnifications = tracer.magnification_2d_via_hessian_from(grid=positions)\n",
        "    time_delays = tracer.time_delays_from(grid=positions)\n",
        "\n",
        "    flux = 1.0\n",
        "    fluxes = [flux * np.abs(magnification) for magnification in magnifications]\n",
        "    fluxes = al.ArrayIrregular(values=fluxes)\n",
        "\n",
        "    positions_noise_map = al.ArrayIrregular([0.05, 0.05, 0.05, 0.05])\n",
        "    fluxes_noise_map = al.ArrayIrregular(\n",
        "        values=[np.sqrt(flux) for _ in range(len(fluxes))]\n",
        "    )\n",
        "    time_delays_noise_map = al.ArrayIrregular(values=time_delays * 0.25)\n",
        "\n",
        "    dataset = al.PointDataset(\n",
        "        positions=positions,\n",
        "        fluxes=fluxes,\n",
        "        time_delays=time_delays,\n",
        "        positions_noise_map=positions_noise_map,\n",
        "        fluxes_noise_map=fluxes_noise_map,\n",
        "        time_delays_noise_map=time_delays_noise_map,\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "This script has shown how to model point source data of strong lenses, and simulate your own strong lenses.\n",
        "\n",
        "Details of the **PyAutoLens** API and how lens modeling and simulations actually work were omitted for simplicity,\n",
        "but everything you need to know is described throughout the main workspace documentation. You should check it out,\n",
        "but maybe you want to try and model your own lens first!\n",
        "\n",
        "The following locations of the workspace are good places to checkout next:\n",
        "\n",
        "- `autolens_workspace/*/modeling/point_source`: A full description of the lens modeling API and how to customize your model-fits.\n",
        "- `autolens_workspace/*/simulators/point_source`: A full description of the lens simulation API and how to customize your simulations.\n",
        "- `autolens_workspace/*/data_preparation/point_source`: How to load and prepare your own imaging data for lens modeling.\n",
        "- `autolens_workspace/results`: How to load and analyze the results of your lens model fits, including tools for large samples.\n",
        "- `autolens_workspace/guides`: A complete description of the API and information on lensing calculations and units.\n",
        "- `autolens_workspace/feature`: A description of advanced features for lens modeling, for example pixelized source reconstructions, read this once you're confident with the basics!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}