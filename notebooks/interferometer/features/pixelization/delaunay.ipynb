{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Log Likelihood Function: Pixelization__\n",
        "\n",
        "This script provides a step-by-step guide of the **PyAutoLens** `log_likelihood_function` which is used to fit\n",
        "`Interferometer` data with an inversion (specifically a `Delaunay` mesh and `Constant` regularization scheme`).\n",
        "\n",
        "This script has the following aims:\n",
        "\n",
        " - To provide a resource that authors can include in papers using **PyAutoLens**, so that readers can understand the\n",
        " likelihood function (including references to the previous literature from which it is defined) without having to\n",
        " write large quantities of text and equations.\n",
        "\n",
        " - To make inversions in **PyAutoLens** less of a \"black-box\" to users.\n",
        "\n",
        "Accompanying this script is the `contributor_guide.py` which provides URL's to every part of the source-code that\n",
        "is illustrated in this guide. This gives contributors a sequential run through of what source-code functions, modules and\n",
        "packages are called when the likelihood is evaluated.\n",
        "\n",
        "__Prerequisites__\n",
        "\n",
        "The likelihood function of pixelizations is the most complicated likelihood function.\n",
        "\n",
        "It is advised you read through the following two simpler likelihood functions first, which break down a number of the\n",
        "concepts used in this script:\n",
        "\n",
        " - `interferometer/light_profile/log_likelihood_function.py` the likelihood function for a light profile.\n",
        " - `imaging/linear_light_profile/log_likelihood_function.py` the likelihood function for a linear light profile, which\n",
        " introduces the linear algebra used for a pixelization but with a simpler use case.\n",
        "\n",
        "This script repeats all text and code examples in the above likelihood function examples. It therefore can be used to\n",
        "learn about the linear light profile likelihood function without reading other likelihood scripts.\n",
        "\n",
        "__Likelihood Function__\n",
        "\n",
        "The example `imaging/interferometer/pixelization/likelihood_function.py` provides a step-by-step description of how\n",
        "a likelihood evaluation is performed for interferometer data using a pixelized source reconstruction with a rectangular\n",
        "mesh.\n",
        "\n",
        "We now give the same step-by-step description for a pixelized source reconstruction using a Delaunay mesh and\n",
        "adaptive features.\n",
        "\n",
        "We only describe code which is specific to Delaunay meshes and adaptive features -- for all other aspects of the likelihood\n",
        "evaluation, refer to rectangular mesh example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "real_space_mask = al.Mask2D.circular(\n",
        "    shape_native=(80, 80), pixel_scales=0.05, radius=4.0\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = Path(\"dataset\") / \"interferometer\" / dataset_name\n",
        "\n",
        "dataset = al.Interferometer.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    uv_wavelengths_path=Path(dataset_path, \"uv_wavelengths.fits\"),\n",
        "    real_space_mask=real_space_mask,\n",
        "    transformer_class=al.TransformerDFT,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.InterferometerPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "dataset_plotter.subplot_dirty_images()\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=dataset.grids.pixelization)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "mass = al.mp.Isothermal(\n",
        "    centre=(0.0, 0.0),\n",
        "    einstein_radius=1.6,\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        ")\n",
        "\n",
        "shear = al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05)\n",
        "\n",
        "lens_galaxy = al.Galaxy(redshift=0.5, mass=mass, shear=shear)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Source Galaxy Pixelization and Regularization__\n",
        "\n",
        "We combine the pixelization into a single `Galaxy` object.\n",
        "\n",
        "The galaxy includes the Delaunay mesh and constant regularization scheme, which will ultimately be used\n",
        "to reconstruct its star forming clumps.\n",
        "\n",
        "One of the biggest differences between a Delaunay mesh and rectangular mesh is how the centres of the mesh pixels\n",
        "in the source-plane are computed. \n",
        "\n",
        "For the rectangular mesh, the pixel centres are computed by overlaying a uniform grid over the source-plane.\n",
        "\n",
        "For a Delaunay mesh, the uniform grid is instead laid over the image-plane to create a course grid of (y,x) coordinates.\n",
        "These are then ray-traced to the source-plane and are used as the vertexes of the Delaunay triangles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    image_mesh=al.image_mesh.Overlay(shape=(30, 30)),  # Specific to Delaunay\n",
        "    mesh=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(redshift=1.0, pixelization=pixelization)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Source Pixel Centre Calculation__\n",
        "\n",
        "In order to reconstruct the source galaxy using a Delaunay mesh, we need to determine the centres of the Delaunay\n",
        "source pixels.\n",
        "\n",
        "The image-mesh `Overlay` object computes the source-pixel centres in the image-plane (which are ray-traced to the\n",
        "source-plane below). The source pixelization therefore adapts to the lens model magnification, because more\n",
        "source pixels will congregate in higher magnification regions.\n",
        "\n",
        "This calculation is performed by overlaying a uniform regular grid with an `pixelization_shape_2d` over the image\n",
        "mask and retaining all pixels that fall within the mask. This uses a `Grid2DSparse` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_plane_mesh_grid = pixelization.image_mesh.image_plane_mesh_grid_from(\n",
        "    mask=dataset.mask,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting this grid shows a sparse grid of (y,x) coordinates within the mask, which will form our source pixel centres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(grid=image_plane_mesh_grid)\n",
        "dataset_plotter = aplt.InterferometerPlotter(dataset=dataset, visuals_2d=visuals)\n",
        "dataset_plotter.figures_2d(dirty_image=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Ray Tracing__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The source code gets quite complex when handling grids for a pixelization, but it is all handled in\n",
        "the `TracerToInversion` objects.\n",
        "\n",
        "The plots at the bottom of this cell show the traced grids used by the source pixelization, showing\n",
        "how the Delaunay mesh and traced image pixels are constructed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_to_inversion = al.TracerToInversion(tracer=tracer, dataset=dataset)\n",
        "\n",
        "# A list of every grid (e.g. image-plane, source-plane) however we only need the source plane grid with index -1.\n",
        "traced_grid_pixelization = tracer.traced_grid_2d_list_from(\n",
        "    grid=dataset.grids.pixelization\n",
        ")[-1]\n",
        "\n",
        "# This functions a bit weird - it returns a list of lists of ndarrays. Best not to worry about it for now!\n",
        "traced_mesh_grid = tracer_to_inversion.traced_mesh_grid_pg_list[-1][-1]\n",
        "\n",
        "mat_plot = aplt.MatPlot2D(axis=aplt.Axis(extent=[-1.5, 1.5, -1.5, 1.5]))\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=traced_grid_pixelization, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=traced_mesh_grid, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Border Relocation__\n",
        "\n",
        "Coordinates that are ray-traced near the mass profile centres are heavily demagnified and may trace to far outskirts of\n",
        "the source-plane. \n",
        "\n",
        "Border relocation is performed on both the traced image-pixel grid and traced mesh pixels, therefore ensuring that\n",
        "the vertexes of the Delaunay triangles are not at the extreme outskirts of the source-plane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoarray.inversion.pixelization.border_relocator import BorderRelocator\n",
        "\n",
        "border_relocator = BorderRelocator(mask=dataset.mask, sub_size=1)\n",
        "\n",
        "relocated_grid = border_relocator.relocated_grid_from(grid=traced_grid_pixelization)\n",
        "\n",
        "relocated_mesh_grid = border_relocator.relocated_mesh_grid_from(\n",
        "    grid=traced_mesh_grid, mesh_grid=traced_mesh_grid\n",
        ")\n",
        "\n",
        "mat_plot = aplt.MatPlot2D(axis=aplt.Axis(extent=[-1.5, 1.5, -1.5, 1.5]))\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=relocated_grid, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=relocated_mesh_grid, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Delaunay Mesh__\n",
        "\n",
        "The relocated mesh grid is used to create the `Pixelization`'s Delaunay mesh using the `scipy.spatial` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_rectangular = al.Mesh2DDelaunay(\n",
        "    values=relocated_mesh_grid,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the Delaunay mesh shows that the source-plane and been discretized into a grid of irregular Delaunay pixels.\n",
        "\n",
        "(To plot the Delaunay mesh, we have to convert it to a `Mapper` object, which is described in the next likelihood step).\n",
        "\n",
        "Below, we plot the Delaunay mesh without the traced image-grid pixels (for clarity) and with them as black dots in order\n",
        "to show how each set of image-pixels fall within a Delaunay pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_grids = al.MapperGrids(\n",
        "    mask=real_space_mask,\n",
        "    source_plane_data_grid=relocated_grid,\n",
        "    source_plane_mesh_grid=grid_rectangular,\n",
        "    image_plane_mesh_grid=image_plane_mesh_grid,\n",
        ")\n",
        "\n",
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "mapper_plotter.figure_2d(interpolate_to_uniform=False)\n",
        "\n",
        "visuals = aplt.Visuals2D(\n",
        "    grid=mapper_grids.source_plane_data_grid,\n",
        ")\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper, visuals_2d=visuals)\n",
        "mapper_plotter.figure_2d(interpolate_to_uniform=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Image-Source Mapping__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "pix_indexes_for_sub_slim_index = mapper.pix_indexes_for_sub_slim_index\n",
        "\n",
        "print(pix_indexes_for_sub_slim_index[0:9])\n",
        "\n",
        "visuals = aplt.Visuals2D(indexes=[list(range(2050, 2090))])\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(\n",
        "    mapper=mapper,\n",
        "    visuals_2d=visuals,\n",
        ")\n",
        "mapper_plotter.subplot_image_and_mapper(\n",
        "    image=dataset.dirty_image, interpolate_to_uniform=False\n",
        ")\n",
        "\n",
        "pix_indexes = [[200]]\n",
        "\n",
        "indexes = mapper.slim_indexes_for_pix_indexes(pix_indexes=pix_indexes)\n",
        "\n",
        "visuals = aplt.Visuals2D(indexes=indexes)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(\n",
        "    mapper=mapper,\n",
        "    visuals_2d=visuals,\n",
        ")\n",
        "\n",
        "mapper_plotter.subplot_image_and_mapper(\n",
        "    image=dataset.dirty_image, interpolate_to_uniform=False\n",
        ")\n",
        "\n",
        "mapping_matrix = al.util.mapper.mapping_matrix_from(\n",
        "    pix_indexes_for_sub_slim_index=pix_indexes_for_sub_slim_index,\n",
        "    pix_size_for_sub_slim_index=mapper.pix_sizes_for_sub_slim_index,  # unused for Delaunay\n",
        "    pix_weights_for_sub_slim_index=mapper.pix_weights_for_sub_slim_index,  # unused for Delaunay\n",
        "    pixels=mapper.pixels,\n",
        "    total_mask_pixels=mapper.source_plane_data_grid.mask.pixels_in_mask,\n",
        "    slim_index_for_sub_slim_index=mapper.slim_index_for_sub_slim_index,\n",
        "    sub_fraction=np.array(mapper.over_sampler.sub_fraction),\n",
        ")\n",
        "\n",
        "plt.imshow(mapping_matrix, aspect=(mapping_matrix.shape[1] / mapping_matrix.shape[0]))\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "indexes_source_pix_200 = np.nonzero(mapping_matrix[:, 200])\n",
        "\n",
        "print(indexes_source_pix_200[0])\n",
        "\n",
        "array_2d = al.Array2D(values=mapping_matrix[:, 200], mask=dataset.mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "transformed_mapping_matrix = dataset.transformer.transform_mapping_matrix(\n",
        "    mapping_matrix=mapping_matrix\n",
        ")\n",
        "\n",
        "plt.imshow(\n",
        "    transformed_mapping_matrix.real,\n",
        "    aspect=(transformed_mapping_matrix.shape[1] / transformed_mapping_matrix.shape[0]),\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "plt.imshow(\n",
        "    transformed_mapping_matrix.imag,\n",
        "    aspect=(transformed_mapping_matrix.shape[1] / transformed_mapping_matrix.shape[0]),\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "indexes_pix_200 = np.nonzero(transformed_mapping_matrix[:, 200])\n",
        "\n",
        "print(indexes_pix_200[0])\n",
        "\n",
        "visibilities = al.Visibilities(visibilities=transformed_mapping_matrix[:, 200])\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=visibilities.in_grid)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "print(f\"Mapping between visibility 0 and Delaunay pixel 2 = {mapping_matrix[0, 2]}\")\n",
        "\n",
        "data_vector = (\n",
        "    al.util.inversion_interferometer.data_vector_via_transformed_mapping_matrix_from(\n",
        "        transformed_mapping_matrix=transformed_mapping_matrix,\n",
        "        visibilities=np.array(dataset.data),\n",
        "        noise_map=np.array(dataset.noise_map),\n",
        "    )\n",
        ")\n",
        "\n",
        "plt.imshow(\n",
        "    data_vector.reshape(data_vector.shape[0], 1), aspect=10.0 / data_vector.shape[0]\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(\"Data Vector:\")\n",
        "print(data_vector)\n",
        "print(data_vector.shape)\n",
        "\n",
        "real_curvature_matrix = al.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=transformed_mapping_matrix.real,\n",
        "    noise_map=dataset.noise_map.real,\n",
        ")\n",
        "\n",
        "imag_curvature_matrix = al.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=transformed_mapping_matrix.imag,\n",
        "    noise_map=dataset.noise_map.imag,\n",
        ")\n",
        "\n",
        "curvature_matrix = np.add(real_curvature_matrix, imag_curvature_matrix)\n",
        "\n",
        "plt.imshow(curvature_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "source_pixel_0 = 0\n",
        "source_pixel_1 = 1\n",
        "\n",
        "print(curvature_matrix[source_pixel_0, source_pixel_1])\n",
        "\n",
        "visibilities = al.Visibilities(\n",
        "    visibilities=transformed_mapping_matrix[:, source_pixel_0],\n",
        ")\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=visibilities.in_grid)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "visibilities = al.Visibilities(\n",
        "    visibilities=transformed_mapping_matrix[:, source_pixel_1],\n",
        ")\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=visibilities.in_grid)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "regularization_matrix = al.util.regularization.constant_regularization_matrix_from(\n",
        "    coefficient=source_galaxy.pixelization.regularization.coefficient,\n",
        "    neighbors=mapper.source_plane_mesh_grid.neighbors,\n",
        "    neighbors_sizes=mapper.source_plane_mesh_grid.neighbors.sizes,\n",
        ")\n",
        "\n",
        "plt.imshow(regularization_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "curvature_reg_matrix = np.add(curvature_matrix, regularization_matrix)\n",
        "\n",
        "reconstruction = np.linalg.solve(curvature_reg_matrix, data_vector)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "\n",
        "mapper_plotter.figure_2d(solution_vector=reconstruction, interpolate_to_uniform=False)\n",
        "\n",
        "mapped_reconstructed_visibilities = (\n",
        "    al.util.inversion_interferometer.mapped_reconstructed_visibilities_from(\n",
        "        transformed_mapping_matrix=transformed_mapping_matrix,\n",
        "        reconstruction=reconstruction,\n",
        "    )\n",
        ")\n",
        "\n",
        "mapped_reconstructed_visibilities = al.Visibilities(\n",
        "    visibilities=mapped_reconstructed_visibilities\n",
        ")\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=mapped_reconstructed_visibilities.in_grid)\n",
        "grid_plotter.figure_2d()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Function__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_visibilities = mapped_reconstructed_visibilities\n",
        "\n",
        "residual_map = dataset.data - model_visibilities\n",
        "\n",
        "\n",
        "normalized_residual_map_real = (residual_map.real / dataset.noise_map.real).astype(\n",
        "    \"complex128\"\n",
        ")\n",
        "normalized_residual_map_imag = (residual_map.imag / dataset.noise_map.imag).astype(\n",
        "    \"complex128\"\n",
        ")\n",
        "normalized_residual_map = (\n",
        "    normalized_residual_map_real + 1j * normalized_residual_map_imag\n",
        ")\n",
        "\n",
        "\n",
        "chi_squared_map_real = (residual_map.real / dataset.noise_map.real) ** 2\n",
        "chi_squared_map_imag = (residual_map.imag / dataset.noise_map.imag) ** 2\n",
        "chi_squared_map = chi_squared_map_real + 1j * chi_squared_map_imag\n",
        "\n",
        "\n",
        "chi_squared_real = np.sum(chi_squared_map.real)\n",
        "chi_squared_imag = np.sum(chi_squared_map.imag)\n",
        "chi_squared = chi_squared_real + chi_squared_imag\n",
        "\n",
        "print(chi_squared)\n",
        "\n",
        "chi_squared_map = al.Visibilities(visibilities=chi_squared_map)\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=chi_squared_map.in_grid)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "regularization_term = np.matmul(\n",
        "    reconstruction.T, np.matmul(regularization_matrix, reconstruction)\n",
        ")\n",
        "\n",
        "print(regularization_term)\n",
        "\n",
        "log_curvature_reg_matrix_term = np.linalg.slogdet(curvature_reg_matrix)[1]\n",
        "log_regularization_matrix_term = np.linalg.slogdet(regularization_matrix)[1]\n",
        "\n",
        "print(log_curvature_reg_matrix_term)\n",
        "print(log_regularization_matrix_term)\n",
        "\n",
        "noise_normalization_real = np.sum(np.log(2 * np.pi * dataset.noise_map.real**2.0))\n",
        "noise_normalization_imag = np.sum(np.log(2 * np.pi * dataset.noise_map.imag**2.0))\n",
        "noise_normalization = noise_normalization_real + noise_normalization_imag\n",
        "\n",
        "log_evidence = float(\n",
        "    -0.5\n",
        "    * (\n",
        "        chi_squared\n",
        "        + regularization_term\n",
        "        + log_curvature_reg_matrix_term\n",
        "        - log_regularization_matrix_term\n",
        "        + noise_normalization\n",
        "    )\n",
        ")\n",
        "\n",
        "print(log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "This process to perform a likelihood function evaluation performed via the `FitInterferometer` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "fit = al.FitInterferometer(\n",
        "    dataset=dataset,\n",
        "    tracer=tracer,\n",
        "    preloads=preloads,\n",
        "    settings_inversion=al.SettingsInversion(use_border_relocator=True),\n",
        ")\n",
        "fit_log_evidence = fit.log_evidence\n",
        "print(fit_log_evidence)\n",
        "\n",
        "fit_plotter = aplt.FitInterferometerPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Lens Modeling__\n",
        "\n",
        "To fit a lens model to data, the likelihood function illustrated in this tutorial is sampled using a\n",
        "non-linear search algorithm.\n",
        "\n",
        "The default sampler is the nested sampling algorithm `nautilus` (https://github.com/joshspeagle/nautilus)\n",
        "but **PyAutoLens** supports multiple MCMC and optimization algorithms. \n",
        "\n",
        "__Log Likelihood Function: Fast Chi Squared__\n",
        "\n",
        "This script describes how the `chi_squared` of an interferometer pixelization can be computed without using a\n",
        "`transformed_mapping_matrix` or an NUFFT algorithm at all.\n",
        "\n",
        "This means the likelihood function can be computed without ever performing an NUFFT, which for datasets of 10^6\n",
        "visibilities or more can be extremely computationally expensive.\n",
        "\n",
        "This can make the likelihood function significantly faster, for example with speed ups of hundreds of times or more\n",
        "for tens or millions of visibilities. In fact, the run time does not scale with the number of visibilities at all,\n",
        "meaning datasets of any size can be fitted in seconds.\n",
        "\n",
        "It directly follows on from the `pixelization/log_likelihood_function.py` and ``pixelization/w_tilde.py` notebooks and\n",
        "you should read through those examples before reading this script.\n",
        "\n",
        "__Prerequisites__\n",
        "\n",
        "You must read through the following likelihood functions first:\n",
        "\n",
        " - `pixelization/log_likelihood_function.py` the likelihood function for a pixelization.\n",
        " - `pixelization/w_tilde.py` the w-tilde formalism used to compute the likelihood function without an NUFFT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__JAX & Preloads__\n",
        "\n",
        "The `autolens_workspace/*/imaging/features/pixelization/modeling` example describes how JAX required preloads in\n",
        "advance so it knows the shape of arrays it must compile functions for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_mesh = None\n",
        "mesh_shape = (20, 20)\n",
        "total_mapper_pixels = mesh_shape[0] * mesh_shape[1]\n",
        "\n",
        "total_linear_light_profiles = 0\n",
        "\n",
        "preloads = al.Preloads(\n",
        "    mapper_indices=al.mapper_indices_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        total_mapper_pixels=total_mapper_pixels,\n",
        "    ),\n",
        "    source_pixel_zeroed_indices=al.util.mesh.rectangular_edge_pixel_list_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        shape_native=mesh_shape,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Following the `pixelization/log_likelihood_function.py` script, we load and mask an `Imaging` dataset and\n",
        "set oversampling to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "real_space_mask = al.Mask2D.circular(\n",
        "    shape_native=(80, 80), pixel_scales=0.05, radius=4.0\n",
        ")\n",
        "\n",
        "dataset_name = \"simple\"\n",
        "dataset_path = Path(\"dataset\") / \"interferometer\" / dataset_name\n",
        "\n",
        "dataset = al.Interferometer.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    uv_wavelengths_path=Path(dataset_path, \"uv_wavelengths.fits\"),\n",
        "    real_space_mask=real_space_mask,\n",
        "    transformer_class=al.TransformerDFT,\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__W Tilde__\n",
        "\n",
        "The fast chi-squared method uses the w-tilde matrix, which we compute now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoarray import numba_util\n",
        "\n",
        "\n",
        "@numba_util.jit()\n",
        "def w_tilde_curvature_interferometer_from(\n",
        "    noise_map_real: np.ndarray,\n",
        "    uv_wavelengths: np.ndarray,\n",
        "    grid_radians_slim: np.ndarray,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    The matrix w_tilde is a matrix of dimensions [image_pixels, image_pixels] that encodes the NUFFT of every pair of\n",
        "    image pixels given the noise map. This can be used to efficiently compute the curvature matrix via the mappings\n",
        "    between image and source pixels, in a way that omits having to perform the NUFFT on every individual source pixel.\n",
        "    This provides a significant speed up for inversions of interferometer datasets with large number of visibilities.\n",
        "\n",
        "    The limitation of this matrix is that the dimensions of [image_pixels, image_pixels] can exceed many 10s of GB's,\n",
        "    making it impossible to store in memory and its use in linear algebra calculations extremely. The method\n",
        "    `w_tilde_preload_interferometer_from` describes a compressed representation that overcomes this hurdles. It is\n",
        "    advised `w_tilde` and this method are only used for testing.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    noise_map_real\n",
        "        The real noise-map values of the interferometer data.\n",
        "    uv_wavelengths\n",
        "        The wavelengths of the coordinates in the uv-plane for the interferometer dataset that is to be Fourier\n",
        "        transformed.\n",
        "    grid_radians_slim\n",
        "        The 1D (y,x) grid of coordinates in radians corresponding to real-space mask within which the image that is\n",
        "        Fourier transformed is computed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray\n",
        "        A matrix that encodes the NUFFT values between the noise map that enables efficient calculation of the curvature\n",
        "        matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    w_tilde = np.zeros((grid_radians_slim.shape[0], grid_radians_slim.shape[0]))\n",
        "\n",
        "    for i in range(w_tilde.shape[0]):\n",
        "        for j in range(i, w_tilde.shape[1]):\n",
        "            y_offset = grid_radians_slim[i, 1] - grid_radians_slim[j, 1]\n",
        "            x_offset = grid_radians_slim[i, 0] - grid_radians_slim[j, 0]\n",
        "\n",
        "            for vis_1d_index in range(uv_wavelengths.shape[0]):\n",
        "                w_tilde[i, j] += noise_map_real[vis_1d_index] ** -2.0 * np.cos(\n",
        "                    2.0\n",
        "                    * np.pi\n",
        "                    * (\n",
        "                        y_offset * uv_wavelengths[vis_1d_index, 0]\n",
        "                        + x_offset * uv_wavelengths[vis_1d_index, 1]\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    for i in range(w_tilde.shape[0]):\n",
        "        for j in range(i, w_tilde.shape[1]):\n",
        "            w_tilde[j, i] = w_tilde[i, j]\n",
        "\n",
        "    return w_tilde\n",
        "\n",
        "\n",
        "w_tilde = w_tilde_curvature_interferometer_from(\n",
        "    noise_map_real=np.array(dataset.noise_map.real),\n",
        "    uv_wavelengths=np.array(dataset.uv_wavelengths),\n",
        "    grid_radians_slim=np.array(dataset.grid.in_radians),\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapping Matrix__\n",
        "\n",
        "It also uses the `mapping_matrix` which we compute now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    mesh=al.mesh.Delaunay(shape=(30, 30)),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "galaxy = al.Galaxy(redshift=0.5, pixelization=pixelization)\n",
        "\n",
        "grid_rectangular = al.Mesh2DRectangular.overlay_grid(\n",
        "    shape_native=galaxy.pixelization.mesh.shape, grid=dataset.grids.pixelization\n",
        ")\n",
        "\n",
        "mapper_grids = al.MapperGrids(\n",
        "    mask=real_space_mask,\n",
        "    source_plane_data_grid=dataset.grids.pixelization,\n",
        "    source_plane_mesh_grid=grid_rectangular,\n",
        ")\n",
        "\n",
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "mapping_matrix = al.util.mapper.mapping_matrix_from(\n",
        "    pix_indexes_for_sub_slim_index=mapper.pix_indexes_for_sub_slim_index,\n",
        "    pix_size_for_sub_slim_index=mapper.pix_sizes_for_sub_slim_index,  # unused for rectangular\n",
        "    pix_weights_for_sub_slim_index=mapper.pix_weights_for_sub_slim_index,  # unused for rectangular\n",
        "    pixels=mapper.pixels,\n",
        "    total_mask_pixels=mapper.source_plane_data_grid.mask.pixels_in_mask,\n",
        "    slim_index_for_sub_slim_index=mapper.slim_index_for_sub_slim_index,\n",
        "    sub_fraction=np.array(mapper.over_sampler.sub_fraction),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Log Likelihood Function: W Tilde__\n",
        "\n",
        "This script describes how a pixelization can be computed using a different linear algebra calculation, but\n",
        "one which produces an identical likelihood at the end.\n",
        "\n",
        "This is called the `w_tilde` formalism, and for interferometer datasets it avoids storing the `operated_mapping_matrix`\n",
        "in memory, meaning that in the regime of 1e6 or more visibilities this extremely large matrix does not need to be\n",
        "stored in memory.\n",
        "\n",
        "This can make the likelihood function significantly faster, for example with speed ups of hundreds of times or more\n",
        "for tens or millions of visibilities. In fact, the run time does not scale with the number of visibilities at all,\n",
        "meaning datasets of any size can be fitted in seconds.\n",
        "\n",
        "It directly follows on from the `pixelization/log_likelihood_function.py` notebook and you should read through that\n",
        "script before reading this script.\n",
        "\n",
        "__Prerequisites__\n",
        "\n",
        "You must read through the following likelihood functions first:\n",
        "\n",
        " - `pixelization/log_likelihood_function.py` the likelihood function for a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Following the `pixelization/log_likelihood_function.py` script, we load and mask an `Imaging` dataset and\n",
        "set oversampling to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "real_space_mask = al.Mask2D.circular(shape_native=(8, 8), pixel_scales=0.05, radius=4.0)\n",
        "\n",
        "dataset_name = \"simple\"\n",
        "dataset_path = Path(\"dataset\") / \"interferometer\" / dataset_name\n",
        "\n",
        "dataset = al.Interferometer.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    uv_wavelengths_path=Path(dataset_path, \"uv_wavelengths.fits\"),\n",
        "    real_space_mask=real_space_mask,\n",
        "    transformer_class=al.TransformerDFT,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__W Tilde__\n",
        "\n",
        "We now compute the `w_tilde` matrix.\n",
        "\n",
        "The `w_tilde` matrix is applied to the `curvature_matrix`, and allows us to efficiently compute the curvature matrix\n",
        "without computing the `transformed_mapping_matrix` matrix. \n",
        "\n",
        "The functions used to do this has been copy and pasted from the `inversion` module of PyAutoArray source code below,\n",
        "so you can see the calculation in full detail.\n",
        "\n",
        "REMINDER: for the `real_space_mask` above with shape (800, 800) the `w_tilde` matrix will TAKE A LONG\n",
        "TIME TO COMPUTE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoarray import numba_util\n",
        "\n",
        "\n",
        "@numba_util.jit()\n",
        "def w_tilde_curvature_interferometer_from(\n",
        "    noise_map_real: np.ndarray,\n",
        "    uv_wavelengths: np.ndarray,\n",
        "    grid_radians_slim: np.ndarray,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    The matrix w_tilde is a matrix of dimensions [image_pixels, image_pixels] that encodes the NUFFT of every pair of\n",
        "    image pixels given the noise map. This can be used to efficiently compute the curvature matrix via the mappings\n",
        "    between image and source pixels, in a way that omits having to perform the NUFFT on every individual source pixel.\n",
        "    This provides a significant speed up for inversions of interferometer datasets with large number of visibilities.\n",
        "\n",
        "    The limitation of this matrix is that the dimensions of [image_pixels, image_pixels] can exceed many 10s of GB's,\n",
        "    making it impossible to store in memory and its use in linear algebra calculations extremely. The method\n",
        "    `w_tilde_preload_interferometer_from` describes a compressed representation that overcomes this hurdles. It is\n",
        "    advised `w_tilde` and this method are only used for testing.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    noise_map_real\n",
        "        The real noise-map values of the interferometer data.\n",
        "    uv_wavelengths\n",
        "        The wavelengths of the coordinates in the uv-plane for the interferometer dataset that is to be Fourier\n",
        "        transformed.\n",
        "    grid_radians_slim\n",
        "        The 1D (y,x) grid of coordinates in radians corresponding to real-space mask within which the image that is\n",
        "        Fourier transformed is computed.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray\n",
        "        A matrix that encodes the NUFFT values between the noise map that enables efficient calculation of the curvature\n",
        "        matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    w_tilde = np.zeros((grid_radians_slim.shape[0], grid_radians_slim.shape[0]))\n",
        "\n",
        "    for i in range(w_tilde.shape[0]):\n",
        "        for j in range(i, w_tilde.shape[1]):\n",
        "            y_offset = grid_radians_slim[i, 1] - grid_radians_slim[j, 1]\n",
        "            x_offset = grid_radians_slim[i, 0] - grid_radians_slim[j, 0]\n",
        "\n",
        "            for vis_1d_index in range(uv_wavelengths.shape[0]):\n",
        "                w_tilde[i, j] += noise_map_real[vis_1d_index] ** -2.0 * np.cos(\n",
        "                    2.0\n",
        "                    * np.pi\n",
        "                    * (\n",
        "                        y_offset * uv_wavelengths[vis_1d_index, 0]\n",
        "                        + x_offset * uv_wavelengths[vis_1d_index, 1]\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    for i in range(w_tilde.shape[0]):\n",
        "        for j in range(i, w_tilde.shape[1]):\n",
        "            w_tilde[j, i] = w_tilde[i, j]\n",
        "\n",
        "    return w_tilde\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now compute the `w_tilde` matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "w_tilde = w_tilde_curvature_interferometer_from(\n",
        "    noise_map_real=np.array(dataset.noise_map.real),\n",
        "    uv_wavelengths=np.array(dataset.uv_wavelengths),\n",
        "    grid_radians_slim=np.array(dataset.grid.in_radians),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapping Matrix__\n",
        "\n",
        "The `w_tilde` matrix is applied directly to the `mapping_matrix` to compute the `curvature_matrix`.\n",
        "\n",
        "Below, we perform the likelihood function steps described in the `pixelization/log_likelihood_function.py` script,\n",
        "to create the `mapping_matrix` we will apply the `w_tilde` matrix to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    mesh=al.mesh.Delaunay(shape=(30, 30)),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "galaxy = al.Galaxy(redshift=0.5, pixelization=pixelization)\n",
        "\n",
        "grid_rectangular = al.Mesh2DRectangular.overlay_grid(\n",
        "    shape_native=galaxy.pixelization.mesh.shape, grid=dataset.grids.pixelization\n",
        ")\n",
        "\n",
        "mapper_grids = al.MapperGrids(\n",
        "    mask=real_space_mask,\n",
        "    source_plane_data_grid=dataset.grids.pixelization,\n",
        "    source_plane_mesh_grid=grid_rectangular,\n",
        ")\n",
        "\n",
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "mapping_matrix = al.util.mapper.mapping_matrix_from(\n",
        "    pix_indexes_for_sub_slim_index=mapper.pix_indexes_for_sub_slim_index,\n",
        "    pix_size_for_sub_slim_index=mapper.pix_sizes_for_sub_slim_index,  # unused for rectangular\n",
        "    pix_weights_for_sub_slim_index=mapper.pix_weights_for_sub_slim_index,  # unused for rectangular\n",
        "    pixels=mapper.pixels,\n",
        "    total_mask_pixels=mapper.source_plane_data_grid.mask.pixels_in_mask,\n",
        "    slim_index_for_sub_slim_index=mapper.slim_index_for_sub_slim_index,\n",
        "    sub_fraction=np.array(mapper.over_sampler.sub_fraction),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Curvature Matrix__\n",
        "\n",
        "We can now compute the `curvature_matrix` using the `w_tilde` matrix and `mapping_matrix`, which amazingly uses\n",
        "simple matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def curvature_matrix_via_w_tilde_from(\n",
        "    w_tilde: np.ndarray, mapping_matrix: np.ndarray\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns the curvature matrix `F` (see Warren & Dye 2003) from `w_tilde`.\n",
        "\n",
        "    The dimensions of `w_tilde` are [image_pixels, image_pixels], meaning that for datasets with many image pixels\n",
        "    this matrix can take up 10's of GB of memory. The calculation of the `curvature_matrix` via this function will\n",
        "    therefore be very slow, and the method `curvature_matrix_via_w_tilde_curvature_preload_imaging_from` should be used\n",
        "    instead.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    w_tilde\n",
        "        A matrix of dimensions [image_pixels, image_pixels] that encodes the convolution or NUFFT of every image pixel\n",
        "        pair on the noise map.\n",
        "    mapping_matrix\n",
        "        The matrix representing the mappings between sub-grid pixels and pixelization pixels.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray\n",
        "        The curvature matrix `F` (see Warren & Dye 2003).\n",
        "    \"\"\"\n",
        "\n",
        "    return np.dot(mapping_matrix.T, np.dot(w_tilde, mapping_matrix))\n",
        "\n",
        "\n",
        "curvature_matrix = curvature_matrix_via_w_tilde_from(\n",
        "    w_tilde=w_tilde, mapping_matrix=mapping_matrix\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you compare the `curvature_matrix` computed using the `w_tilde` matrix to the `curvature_matrix` computed using the\n",
        "`operated_mapping_matrix` matrix in the other example scripts, you'll see they are identical.\n",
        "\n",
        "__Data Vector__\n",
        "\n",
        "The `data_vector` was computed in the `pixelization/log_likelihood_function.py` script using \n",
        "the `transformed_mapping_matrix`.\n",
        "\n",
        "Fortunately, there is also an easy way to compute the `data_vector` which bypasses the need to compute the\n",
        "`transformed_mapping_matrix` matrix, again using simple matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_vector = np.dot(mapping_matrix.T, dataset.w_tilde.dirty_image)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction__\n",
        "\n",
        "The `reconstruction` is computed using the `curvature_matrix` and `data_vector` as per usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "regularization_matrix = al.util.regularization.constant_regularization_matrix_from(\n",
        "    coefficient=galaxy.pixelization.regularization.coefficient,\n",
        "    neighbors=mapper.source_plane_mesh_grid.neighbors,\n",
        "    neighbors_sizes=mapper.source_plane_mesh_grid.neighbors.sizes,\n",
        ")\n",
        "\n",
        "curvature_reg_matrix = np.add(curvature_matrix, regularization_matrix)\n",
        "\n",
        "reconstruction = np.linalg.solve(curvature_reg_matrix, data_vector)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fast Chi Squared__\n",
        "\n",
        "In the `pixelization/log_likelihood_function.py` example the mapped reconstructed visibilities were another quantity \n",
        "computed which used the `transformed_mapping_matrix` matrix, which is another step that must skip computing this matrix.\n",
        "\n",
        "The w-tilde matrix again provides a trick which skips the need to compute the `transformed_mapping_matrix` matrix,\n",
        "with the code for this shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(mapping_matrix.shape)\n",
        "print(w_tilde.shape)\n",
        "\n",
        "chi_squared_term_1 = np.linalg.multi_dot(\n",
        "    [\n",
        "        reconstruction.T,  # NOTE: shape = (M, )\n",
        "        curvature_matrix,  # NOTE: shape = (M, M)\n",
        "        reconstruction,  # NOTE: shape = (M, )\n",
        "    ]\n",
        ")\n",
        "chi_squared_term_2 = -2.0 * np.linalg.multi_dot(\n",
        "    [reconstruction.T, data_vector]  # NOTE: shape = (M, )  # NOTE: i.e. dirty_image\n",
        ")\n",
        "chi_squared_term_3 = np.add(  # NOTE: i.e. noise_normalization\n",
        "    np.sum(dataset.data.real**2.0 / dataset.noise_map.real**2.0),\n",
        "    np.sum(dataset.data.imag**2.0 / dataset.noise_map.imag**2.0),\n",
        ")\n",
        "\n",
        "chi_squared = chi_squared_term_1 + chi_squared_term_2 + chi_squared_term_3\n",
        "\n",
        "print(chi_squared)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Log Likelihood__\n",
        "\n",
        "Finally, we verify that the log likelihood computed using the `curvature_matrix` and `data_vector` computed using the\n",
        "`w_tilde` matrix is identical to the log likelihood computed using the `operated_mapping_matrix` matrix in the\n",
        "other example scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "regularization_term = np.matmul(\n",
        "    reconstruction.T, np.matmul(regularization_matrix, reconstruction)\n",
        ")\n",
        "\n",
        "log_curvature_reg_matrix_term = np.linalg.slogdet(curvature_reg_matrix)[1]\n",
        "log_regularization_matrix_term = np.linalg.slogdet(regularization_matrix)[1]\n",
        "\n",
        "\n",
        "noise_normalization_real = np.sum(np.log(2 * np.pi * dataset.noise_map.real**2.0))\n",
        "noise_normalization_imag = np.sum(np.log(2 * np.pi * dataset.noise_map.imag**2.0))\n",
        "noise_normalization = noise_normalization_real + noise_normalization_imag\n",
        "\n",
        "log_evidence = float(\n",
        "    -0.5\n",
        "    * (\n",
        "        chi_squared\n",
        "        + regularization_term\n",
        "        + log_curvature_reg_matrix_term\n",
        "        - log_regularization_matrix_term\n",
        "        + noise_normalization\n",
        "    )\n",
        ")\n",
        "\n",
        "print(log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Repeated Pattern in W_Tilde__\n",
        "\n",
        "The `w_tilde` matrix has a repeated pattern, which can be used to perform the above calculations using far less\n",
        "memory, at the expense of code complexity. \n",
        "\n",
        "First, let us consider the pattern of the `w_tilde` matrix, which is seen in the following 7 values: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(w_tilde[0, 1])\n",
        "print(w_tilde[1, 2])\n",
        "print(w_tilde[2, 3])\n",
        "print(w_tilde[3, 4])\n",
        "print(w_tilde[4, 5])\n",
        "print(w_tilde[5, 6])\n",
        "print(w_tilde[6, 7])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "However, the pattern breaks for the next value, which is:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(w_tilde[7, 8])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What do the first 7 values have in common?\n",
        "\n",
        "Let us think about the `real_space_mask` of the interferometer dataset, which I have made a really basic cartoon of\n",
        "below:\n",
        "\n",
        "![w_tilde](https://github.com/Jammy2211/autogalaxy_workspace/blob/main/scripts/advanced/log_likelihood_function/interferometer/pixelization/w_tilde_cartoon.png?raw=true)\n",
        "\n",
        "What elements 0 -> 6 of the `w_tilde` matrix have in common is that they are next to one another in the real-space,\n",
        "to the right, in the mask.\n",
        "\n",
        "The element 6 -> 7 breaks this pattern, as it is at the end of the mask and there is no pixel to the right of it,\n",
        "so it \"jumps\" to the next row.\n",
        "\n",
        "We can now reinspect how the `w_tilde` matrix is computed, and see that the pattern of the `w_tilde` matrix is\n",
        "determined by the real-space mask:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "@numba_util.jit()\n",
        "def w_tilde_curvature_interferometer_from(\n",
        "    noise_map_real: np.ndarray,\n",
        "    uv_wavelengths: np.ndarray,\n",
        "    grid_radians_slim: np.ndarray,\n",
        ") -> np.ndarray:\n",
        "    w_tilde = np.zeros((grid_radians_slim.shape[0], grid_radians_slim.shape[0]))\n",
        "\n",
        "    for i in range(w_tilde.shape[0]):\n",
        "        for j in range(i, w_tilde.shape[1]):\n",
        "            \"\"\"\n",
        "\n",
        "            !!!LOOK HERE!!!!\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "            y_offset = (\n",
        "                grid_radians_slim[i, 1] - grid_radians_slim[j, 1]\n",
        "            )  # The y-offset is 0 for pixels 0 -> 6, but becomes non-zero for 6 -> 7\n",
        "            x_offset = (\n",
        "                grid_radians_slim[i, 0] - grid_radians_slim[j, 0]\n",
        "            )  # The x-offset is the same for pixels 0 -> 6 and 6 -> 7\n",
        "\n",
        "            for vis_1d_index in range(uv_wavelengths.shape[0]):\n",
        "                w_tilde[i, j] += noise_map_real[vis_1d_index] ** -2.0 * np.cos(\n",
        "                    2.0\n",
        "                    * np.pi\n",
        "                    * (\n",
        "                        y_offset * uv_wavelengths[vis_1d_index, 0]\n",
        "                        + x_offset * uv_wavelengths[vis_1d_index, 1]\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    for i in range(w_tilde.shape[0]):\n",
        "        for j in range(i, w_tilde.shape[1]):\n",
        "            w_tilde[j, i] = w_tilde[i, j]\n",
        "\n",
        "    return w_tilde\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `y_offset` and `x_offset` values are what determine the repeated pattern of the `w_tilde` matrix, and therefore\n",
        "mean it has far fewer unique values than the number of pixels in the real-space mask.\n",
        "\n",
        "This could make our calculation way more efficient: as if we can exploit it we would not store [image_pixels, image_pixels]\n",
        "values (where image_pixels is the number of pixels in the real-space mask and can easily reach 100,000, or 100GB+ memory),\n",
        "but instead far fewer values.\n",
        "\n",
        "This could also, maybe, speed up the matrix multiplication calculation, as we would be performing far fewer operations.\n",
        "\n",
        "__W Tilde 1D__\n",
        "\n",
        "The function below shows how we compute `w_tilde_curvature_preload`, which is a 2D array of dimensions\n",
        "[2*shape_masked_pixels_y, 2*shape_masked_pixels_x, 2], where `shape_masked_pixels` is the (y,x) size corresponding to the\n",
        "extent of unmasked pixels that go vertically and horizontally across the mask.\n",
        "\n",
        "print(real_space_mask.shape_native_masked_pixels)\n",
        "\n",
        "The idea behind this is we don't need to store all [image_pixels, image_pixels] values of the `w_tilde` matrix, but\n",
        "instead only the unique values of the `w_tilde` matrix that are computed for each unique (y,x) offset between pairs of\n",
        "pixels in the real-space mask.\n",
        "\n",
        "Another complication is that the `y_offset` and `x_offset` values can be negative, for example if we pair a pixel\n",
        "to its neighbor to the left.\n",
        "\n",
        "That is why it has shape [2*shape_masked_pixels_y, 2*shape_masked_pixels_x, 2], with a factor of 2* in front of the\n",
        "shape of the real-space mask. This is so that negative offsets can be stored in the negative half of the 2D array.\n",
        "\n",
        "The function also has four inner four loops, which store the values of the `w_tilde` matrix for each unique (y,x) offset\n",
        "between pairs of pixels in the real-space mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from typing import Tuple\n",
        "\n",
        "\n",
        "@numba_util.jit()\n",
        "def w_tilde_curvature_preload_interferometer_from(\n",
        "    noise_map_real: np.ndarray,\n",
        "    uv_wavelengths: np.ndarray,\n",
        "    shape_masked_pixels_2d: Tuple[int, int],\n",
        "    grid_radians_2d: np.ndarray,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    The matrix w_tilde is a matrix of dimensions [unmasked_image_pixels, unmasked_image_pixels] that encodes the\n",
        "    NUFFT of every pair of image pixels given the noise map. This can be used to efficiently compute the curvature\n",
        "    matrix via the mapping matrix, in a way that omits having to perform the NUFFT on every individual source pixel.\n",
        "    This provides a significant speed up for inversions of interferometer datasets with large number of visibilities.\n",
        "    The limitation of this matrix is that the dimensions of [image_pixels, image_pixels] can exceed many 10s of GB's,\n",
        "    making it impossible to store in memory and its use in linear algebra calculations extremely. This methods creates\n",
        "    a preload matrix that can compute the matrix w_tilde via an efficient preloading scheme which exploits the\n",
        "    symmetries in the NUFFT.\n",
        "    To compute w_tilde, one first defines a real space mask where every False entry is an unmasked pixel which is\n",
        "    used in the calculation, for example:\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI     This is an imaging.Mask2D, where:\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI     x = `True` (Pixel is masked and excluded from lens)\n",
        "        IxIxIxIoIoIoIxIxIxIxI     o = `False` (Pixel is not masked and included in lens)\n",
        "        IxIxIxIoIoIoIxIxIxIxI\n",
        "        IxIxIxIoIoIoIxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "    Here, there are 9 unmasked pixels. Indexing of each unmasked pixel goes from the top-left corner right and\n",
        "    downwards, therefore:\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "        IxIxIxI0I1I2IxIxIxIxI\n",
        "        IxIxIxI3I4I5IxIxIxIxI\n",
        "        IxIxIxI6I7I8IxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "        IxIxIxIxIxIxIxIxIxIxI\n",
        "    In the standard calculation of `w_tilde` it is a matrix of\n",
        "    dimensions [unmasked_image_pixels, unmasked_pixel_images], therefore for the example mask above it would be\n",
        "    dimensions [9, 9]. One performs a double for loop over `unmasked_image_pixels`, using the (y,x) spatial offset\n",
        "    between every possible pair of unmasked image pixels to precompute values that depend on the properties of the NUFFT.\n",
        "    This calculation has a lot of redundancy, because it uses the (y,x) *spatial offset* between the image pixels. For\n",
        "    example, if two image pixel are next to one another by the same spacing the same value will be computed via the\n",
        "    NUFFT. For the example mask above:\n",
        "\n",
        "    - The value precomputed for pixel pair [0,1] is the same as pixel pairs [1,2], [3,4], [4,5], [6,7] and [7,9].\n",
        "\n",
        "    - The value precomputed for pixel pair [0,3] is the same as pixel pairs [1,4], [2,5], [3,6], [4,7] and [5,8].\n",
        "\n",
        "    - The values of pixels paired with themselves are also computed repeatedly for the standard calculation (e.g. 9\n",
        "      times using the mask above).\n",
        "\n",
        "    The `w_tilde_preload` method instead only computes each value once. To do this, it stores the preload values in a\n",
        "    matrix of dimensions [shape_masked_pixels_y, shape_masked_pixels_x, 2], where `shape_masked_pixels` is the (y,x)\n",
        "    size of the vertical and horizontal extent of unmasked pixels, e.g. the spatial extent over which the real space\n",
        "    grid extends.\n",
        "    Each entry in the matrix `w_tilde_preload[:,:,0]` provides the precomputed NUFFT value mapping an image pixel\n",
        "    to a pixel offset by that much in the y and x directions, for example:\n",
        "\n",
        "    - w_tilde_preload[0,0,0] gives the precomputed values of image pixels that are offset in the y direction by 0 and\n",
        "      in the x direction by 0 - the values of pixels paired with themselves.\n",
        "\n",
        "    - w_tilde_preload[1,0,0] gives the precomputed values of image pixels that are offset in the y direction by 1 and\n",
        "      in the x direction by 0 - the values of pixel pairs [0,3], [1,4], [2,5], [3,6], [4,7] and [5,8]\n",
        "\n",
        "    - w_tilde_preload[0,1,0] gives the precomputed values of image pixels that are offset in the y direction by 0 and\n",
        "      in the x direction by 1 - the values of pixel pairs [0,1], [1,2], [3,4], [4,5], [6,7] and [7,9].\n",
        "\n",
        "    Flipped pairs:\n",
        "\n",
        "    The above preloaded values pair all image pixel NUFFT values when a pixel is to the right and / or down of the\n",
        "    first image pixel. However, one must also precompute pairs where the paired pixel is to the left of the host\n",
        "    pixels. These pairings are stored in `w_tilde_preload[:,:,1]`, and the ordering of these pairings is flipped in the\n",
        "    x direction to make it straight forward to use this matrix when computing w_tilde.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    noise_map_real\n",
        "        The real noise-map values of the interferometer data\n",
        "    uv_wavelengths\n",
        "        The wavelengths of the coordinates in the uv-plane for the interferometer dataset that is to be Fourier\n",
        "        transformed.\n",
        "    shape_masked_pixels_2d\n",
        "        The (y,x) shape corresponding to the extent of unmasked pixels that go vertically and horizontally across the\n",
        "        mask.\n",
        "    grid_radians_2d\n",
        "        The 2D (y,x) grid of coordinates in radians corresponding to real-space mask within which the image that is\n",
        "        Fourier transformed is computed.\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray\n",
        "        A matrix that precomputes the values for fast computation of w_tilde.\n",
        "    \"\"\"\n",
        "\n",
        "    y_shape = shape_masked_pixels_2d[0]\n",
        "    x_shape = shape_masked_pixels_2d[1]\n",
        "\n",
        "    curvature_preload = np.zeros((y_shape * 2, x_shape * 2))\n",
        "\n",
        "    #  For the second preload to index backwards correctly we have to extracted the 2D grid to its shape.\n",
        "    grid_radians_2d = grid_radians_2d[0:y_shape, 0:x_shape]\n",
        "\n",
        "    grid_y_shape = grid_radians_2d.shape[0]\n",
        "    grid_x_shape = grid_radians_2d.shape[1]\n",
        "\n",
        "    for i in range(y_shape):\n",
        "        for j in range(x_shape):\n",
        "            y_offset = grid_radians_2d[0, 0, 0] - grid_radians_2d[i, j, 0]\n",
        "            x_offset = grid_radians_2d[0, 0, 1] - grid_radians_2d[i, j, 1]\n",
        "\n",
        "            for vis_1d_index in range(uv_wavelengths.shape[0]):\n",
        "                curvature_preload[i, j] += noise_map_real[\n",
        "                    vis_1d_index\n",
        "                ] ** -2.0 * np.cos(\n",
        "                    2.0\n",
        "                    * np.pi\n",
        "                    * (\n",
        "                        x_offset * uv_wavelengths[vis_1d_index, 0]\n",
        "                        + y_offset * uv_wavelengths[vis_1d_index, 1]\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    for i in range(y_shape):\n",
        "        for j in range(x_shape):\n",
        "            if j > 0:\n",
        "                y_offset = (\n",
        "                    grid_radians_2d[0, -1, 0]\n",
        "                    - grid_radians_2d[i, grid_x_shape - j - 1, 0]\n",
        "                )\n",
        "                x_offset = (\n",
        "                    grid_radians_2d[0, -1, 1]\n",
        "                    - grid_radians_2d[i, grid_x_shape - j - 1, 1]\n",
        "                )\n",
        "\n",
        "                for vis_1d_index in range(uv_wavelengths.shape[0]):\n",
        "                    curvature_preload[i, -j] += noise_map_real[\n",
        "                        vis_1d_index\n",
        "                    ] ** -2.0 * np.cos(\n",
        "                        2.0\n",
        "                        * np.pi\n",
        "                        * (\n",
        "                            x_offset * uv_wavelengths[vis_1d_index, 0]\n",
        "                            + y_offset * uv_wavelengths[vis_1d_index, 1]\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "    for i in range(y_shape):\n",
        "        for j in range(x_shape):\n",
        "            if i > 0:\n",
        "                y_offset = (\n",
        "                    grid_radians_2d[-1, 0, 0]\n",
        "                    - grid_radians_2d[grid_y_shape - i - 1, j, 0]\n",
        "                )\n",
        "                x_offset = (\n",
        "                    grid_radians_2d[-1, 0, 1]\n",
        "                    - grid_radians_2d[grid_y_shape - i - 1, j, 1]\n",
        "                )\n",
        "\n",
        "                for vis_1d_index in range(uv_wavelengths.shape[0]):\n",
        "                    curvature_preload[-i, j] += noise_map_real[\n",
        "                        vis_1d_index\n",
        "                    ] ** -2.0 * np.cos(\n",
        "                        2.0\n",
        "                        * np.pi\n",
        "                        * (\n",
        "                            x_offset * uv_wavelengths[vis_1d_index, 0]\n",
        "                            + y_offset * uv_wavelengths[vis_1d_index, 1]\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "    for i in range(y_shape):\n",
        "        for j in range(x_shape):\n",
        "            if i > 0 and j > 0:\n",
        "                y_offset = (\n",
        "                    grid_radians_2d[-1, -1, 0]\n",
        "                    - grid_radians_2d[grid_y_shape - i - 1, grid_x_shape - j - 1, 0]\n",
        "                )\n",
        "                x_offset = (\n",
        "                    grid_radians_2d[-1, -1, 1]\n",
        "                    - grid_radians_2d[grid_y_shape - i - 1, grid_x_shape - j - 1, 1]\n",
        "                )\n",
        "\n",
        "                for vis_1d_index in range(uv_wavelengths.shape[0]):\n",
        "                    curvature_preload[-i, -j] += noise_map_real[\n",
        "                        vis_1d_index\n",
        "                    ] ** -2.0 * np.cos(\n",
        "                        2.0\n",
        "                        * np.pi\n",
        "                        * (\n",
        "                            x_offset * uv_wavelengths[vis_1d_index, 0]\n",
        "                            + y_offset * uv_wavelengths[vis_1d_index, 1]\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "    return curvature_preload\n",
        "\n",
        "\n",
        "curvature_preload = w_tilde_curvature_preload_interferometer_from(\n",
        "    noise_map_real=np.array(dataset.noise_map.real),\n",
        "    uv_wavelengths=np.array(dataset.uv_wavelengths),\n",
        "    shape_masked_pixels_2d=np.array(\n",
        "        dataset.transformer.grid.mask.shape_native_masked_pixels\n",
        "    ),\n",
        "    grid_radians_2d=np.array(\n",
        "        dataset.transformer.grid.mask.derive_grid.all_false.in_radians.native\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now use the `curvature_preload` matrix to compute the `w_tilde` matrix with its original dimensions\n",
        "of [image_pixels, image_pixels] using the function below.\n",
        "\n",
        "This is a lot faster than the original calculation, as we are only storing the unique values of the `w_tilde` matrix\n",
        "and avoid repeating the same calculation for every pair of pixels in the real-space mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "@numba_util.jit()\n",
        "def w_tilde_via_preload_from(w_tilde_preload, native_index_for_slim_index):\n",
        "    \"\"\"\n",
        "    Use the preloaded w_tilde matrix (see `w_tilde_preload_interferometer_from`) to compute\n",
        "    w_tilde (see `w_tilde_interferometer_from`) efficiently.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    w_tilde_preload\n",
        "        The preloaded values of the NUFFT that enable efficient computation of w_tilde.\n",
        "    native_index_for_slim_index\n",
        "        An array of shape [total_unmasked_pixels*sub_size] that maps every unmasked sub-pixel to its corresponding\n",
        "        native 2D pixel using its (y,x) pixel indexes.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray\n",
        "        A matrix that encodes the NUFFT values between the noise map that enables efficient calculation of the curvature\n",
        "        matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    slim_size = len(native_index_for_slim_index)\n",
        "\n",
        "    w_tilde_via_preload = np.zeros((slim_size, slim_size))\n",
        "\n",
        "    for i in range(slim_size):\n",
        "        i_y, i_x = native_index_for_slim_index[i]\n",
        "\n",
        "        for j in range(i, slim_size):\n",
        "            j_y, j_x = native_index_for_slim_index[j]\n",
        "\n",
        "            y_diff = j_y - i_y\n",
        "            x_diff = j_x - i_x\n",
        "\n",
        "            w_tilde_via_preload[i, j] = w_tilde_preload[y_diff, x_diff]\n",
        "\n",
        "    for i in range(slim_size):\n",
        "        for j in range(i, slim_size):\n",
        "            w_tilde_via_preload[j, i] = w_tilde_via_preload[i, j]\n",
        "\n",
        "    return w_tilde_via_preload\n",
        "\n",
        "\n",
        "w_matrix = w_tilde_via_preload_from(\n",
        "    w_tilde_preload=curvature_preload,\n",
        "    native_index_for_slim_index=real_space_mask.derive_indexes.native_for_slim,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following function is how we compute `curvature_matrix` using the `w_tilde` matrix computed using the preload\n",
        "method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "@numba_util.jit()\n",
        "def curvature_matrix_via_w_tilde_curvature_preload_interferometer_from(\n",
        "    curvature_preload: np.ndarray,\n",
        "    pix_indexes_for_sub_slim_index: np.ndarray,\n",
        "    pix_size_for_sub_slim_index: np.ndarray,\n",
        "    pix_weights_for_sub_slim_index: np.ndarray,\n",
        "    native_index_for_slim_index: np.ndarray,\n",
        "    pix_pixels: int,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns the curvature matrix `F` (see Warren & Dye 2003) by computing it using `w_tilde_preload`\n",
        "    (see `w_tilde_preload_interferometer_from`) for an interferometer inversion.\n",
        "\n",
        "    To compute the curvature matrix via w_tilde the following matrix multiplication is normally performed:\n",
        "\n",
        "    curvature_matrix = mapping_matrix.T * w_tilde * mapping matrix\n",
        "\n",
        "    This function speeds this calculation up in two ways:\n",
        "\n",
        "    1) Instead of using `w_tilde` (dimensions [image_pixels, image_pixels] it uses `w_tilde_preload` (dimensions\n",
        "    [image_pixels, 2]). The massive reduction in the size of this matrix in memory allows for much fast computation.\n",
        "\n",
        "    2) It omits the `mapping_matrix` and instead uses directly the 1D vector that maps every image pixel to a source\n",
        "    pixel `native_index_for_slim_index`. This exploits the sparsity in the `mapping_matrix` to directly\n",
        "    compute the `curvature_matrix` (e.g. it condenses the triple matrix multiplication into a double for loop!).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    curvature_preload\n",
        "        A matrix that precomputes the values for fast computation of w_tilde, which in this function is used to bypass\n",
        "        the creation of w_tilde altogether and go directly to the `curvature_matrix`.\n",
        "    pix_indexes_for_sub_slim_index\n",
        "        The mappings from a data sub-pixel index to a pixelization pixel index.\n",
        "    pix_size_for_sub_slim_index\n",
        "        The number of mappings between each data sub pixel and pixelization pixel.\n",
        "    pix_weights_for_sub_slim_index\n",
        "        The weights of the mappings of every data sub pixel and pixelization pixel.\n",
        "    native_index_for_slim_index\n",
        "        An array of shape [total_unmasked_pixels*sub_size] that maps every unmasked sub-pixel to its corresponding\n",
        "        native 2D pixel using its (y,x) pixel indexes.\n",
        "    pix_pixels\n",
        "        The total number of pixels in the pixelization that reconstructs the data.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ndarray\n",
        "        The curvature matrix `F` (see Warren & Dye 2003).\n",
        "    \"\"\"\n",
        "\n",
        "    curvature_matrix = np.zeros((pix_pixels, pix_pixels))\n",
        "\n",
        "    image_pixels = len(native_index_for_slim_index)\n",
        "\n",
        "    for ip0 in range(image_pixels):\n",
        "        ip0_y, ip0_x = native_index_for_slim_index[ip0]\n",
        "\n",
        "        for ip0_pix in range(pix_size_for_sub_slim_index[ip0]):\n",
        "            sp0 = pix_indexes_for_sub_slim_index[ip0, ip0_pix]\n",
        "\n",
        "            ip0_weight = pix_weights_for_sub_slim_index[ip0, ip0_pix]\n",
        "\n",
        "            for ip1 in range(image_pixels):\n",
        "                ip1_y, ip1_x = native_index_for_slim_index[ip1]\n",
        "\n",
        "                for ip1_pix in range(pix_size_for_sub_slim_index[ip1]):\n",
        "                    sp1 = pix_indexes_for_sub_slim_index[ip1, ip1_pix]\n",
        "\n",
        "                    # This is where the magic happens.\n",
        "\n",
        "                    # Basically, `curvature_preload` stores the unique values of the w_tilde matrix in a structure\n",
        "                    # where each combination of index differences are the dimensions of the arrays.\n",
        "\n",
        "                    # So, if y_diff=0 and x_diff=1, it goes to the 0,1 index of the `curvature_preload` array,\n",
        "                    # which by definition is the unique value of the w_tilde matrix for pixels that are offset by\n",
        "                    # 0 in the y direction and 1 in the x direction in pixel units.\n",
        "\n",
        "                    ip1_weight = pix_weights_for_sub_slim_index[ip1, ip1_pix]\n",
        "\n",
        "                    y_diff = ip1_y - ip0_y\n",
        "                    x_diff = ip1_x - ip0_x\n",
        "\n",
        "                    curvature_matrix[sp0, sp1] += (\n",
        "                        curvature_preload[y_diff, x_diff] * ip0_weight * ip1_weight\n",
        "                    )\n",
        "\n",
        "    return curvature_matrix\n",
        "\n",
        "\n",
        "curvature_matrix_fast = curvature_matrix_via_w_tilde_curvature_preload_interferometer_from(\n",
        "    curvature_preload=dataset.w_tilde.curvature_preload,\n",
        "    pix_indexes_for_sub_slim_index=mapper.pix_indexes_for_sub_slim_index,\n",
        "    pix_size_for_sub_slim_index=mapper.pix_sizes_for_sub_slim_index,\n",
        "    pix_weights_for_sub_slim_index=mapper.pix_weights_for_sub_slim_index,\n",
        "    native_index_for_slim_index=dataset.transformer.real_space_mask.derive_indexes.native_for_slim,\n",
        "    pix_pixels=mapper.pixels,\n",
        ")\n",
        "\n",
        "print(curvature_matrix_fast - curvature_matrix)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "We have presented a visual step-by-step guide to the pixelization likelihood function.\n",
        "\n",
        "There are a number of other inputs features which slightly change the behaviour of this likelihood function, which\n",
        "are described in additional notebooks found in this package. In brief, these describe:\n",
        "\n",
        " - **Over Sampling**: Oversampling the image grid into a finer grid of sub-pixels, which are all individually \n",
        " paired fractionally with each Delaunay pixel.\n",
        "\n",
        " - **Source-plane Interpolation**: Using bilinear interpolation on the Delaunay pixelization to pair each \n",
        " image (sub-)pixel to multiple Delaunay pixels with interpolation weights.\n",
        "\n",
        " - **Luminosity Weighted Regularization**: Using an adaptive regularization coefficient which adapts the level of \n",
        " regularization applied to the source galaxy based on its luminosity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}