{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pixelization: CPU Fast Modeling Preparation\n",
        "===========================================\n",
        "\n",
        "The example `many_visibility_modeling` demonstrates how to achieve **fast pixelization performance** for\n",
        "datasets exceeding millions, or hundreds of millions, of visibilities, using a CPU or GPU.\n",
        "\n",
        "To perform many visibility modeling, a matrix called `curvature_preload` is created and used, which encodes information\n",
        "and symmetries into the Fourier transform operation performed when modeling interferometer datasets, in a way that\n",
        "exploits the sparsity of the pixelized source reconstructions and means a very small amount of memory or VRAM is used.\n",
        "\n",
        "The details can be found in the source code, but you do not need to know them to do science with the code,\n",
        "nevertheless this ultimately means datasets exceeding millions of visibilities can be modeled in under an hour on a GPU.\n",
        "\n",
        "The time to compute this matrix can vary between seconds and hours, depending on the number of visibilities in the\n",
        "dataset and image pixels in the real space mask. If this matrix is not saved and loaded from hard disk, this\n",
        "recalculation would need to be performed before every model-fit.\n",
        "\n",
        "This example therefore creates the `curvature_preload` matrix using independent Python code and saves it to hard-disk\n",
        "for modeling. The `cpu_fast_modeling` example loads this w_tilde matrix from hard-disk if it is available,\n",
        "and computes it from scratch if not.\n",
        "\n",
        "__High Resolution Dataset__\n",
        "\n",
        "A high-resolution `uv_wavelengths` file for ALMA is available in a separate repository that hosts large files which\n",
        "are too big to include in the main `autolens_workspace` repository:\n",
        "\n",
        "https://github.com/Jammy2211/autolens_workspace_large_files\n",
        "\n",
        "After downloading the file, place it in the directory:\n",
        "\n",
        "`autolens_workspace/dataset/interferometer/alma`\n",
        "\n",
        "You can then compute the `curvature_preload` matrix for this dataset by uncommenting\n",
        "the line `dataset_name = \"alma\"` below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import autolens as al"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset + Masking__ \n",
        "\n",
        "Load the `Interferometer` data, define the visibility and real-space masks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_radius = 3.0\n",
        "\n",
        "real_space_mask = al.Mask2D.circular(\n",
        "    shape_native=(256, 256), pixel_scales=0.1, radius=mask_radius\n",
        ")\n",
        "\n",
        "dataset_name = \"simple\"\n",
        "# dataset_name = \"alma\"\n",
        "dataset_path = Path(\"dataset\") / \"interferometer\" / dataset_name\n",
        "\n",
        "dataset = al.Interferometer.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    uv_wavelengths_path=dataset_path / \"uv_wavelengths.fits\",\n",
        "    real_space_mask=real_space_mask,\n",
        "    transformer_class=al.TransformerNUFFT,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Profiling Dataset__\n",
        "\n",
        "The code above loads a dataset with very few visibilities and a low resolution real space mask, so the \n",
        "`curvature_preload` computation is fast.\n",
        "\n",
        "Real datasets often have 100,000+ visibilities, and a high resolution real space mask, which makes the \n",
        "`curvature_preload` computation much slower.\n",
        "\n",
        "It may therefore be useful to profile the run times for different dataset sizes using the code below, which overwrites \n",
        "the dataset above. This will allow you to plan ahead how long the `curvature_preload` computation will take for your \n",
        "dataset, and whether doing it on a HPC is necessary.\n",
        "\n",
        "This code is commented out by default, so your dataset is used instead, but you can uncomment it to run the profiling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ### Key run time parameters ###\n",
        "#\n",
        "# mask_radius = 3.0\n",
        "# total_visibilities = 1000000\n",
        "#\n",
        "# ### Setup Data ###\n",
        "#\n",
        "# real_space_mask = al.Mask2D.circular(\n",
        "#     shape_native=(800, 800), pixel_scales=0.05, radius=mask_radius\n",
        "# )\n",
        "#\n",
        "# data = al.Visibilities(np.random.normal(loc=0.0, scale=1.0, size=total_visibilities) + 1j * np.random.normal(\n",
        "#     loc=0.0, scale=1.0, size=total_visibilities\n",
        "# ))\n",
        "#\n",
        "# noise_map = al.VisibilitiesNoiseMap(np.ones(total_visibilities) + 1j * np.ones(total_visibilities))\n",
        "#\n",
        "# uv_wavelengths = np.random.uniform(\n",
        "#     low=-300.0, high=300.0, size=(total_visibilities, 2)\n",
        "# )\n",
        "#\n",
        "# dataset = al.Interferometer(\n",
        "#     data=data,\n",
        "#     noise_map=noise_map,\n",
        "#     uv_wavelengths=uv_wavelengths,\n",
        "#     real_space_mask=real_space_mask,\n",
        "#     transformer_class=al.TransformerNUFFT,\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__W_Tilde__\n",
        "\n",
        "Pixelized source modeling requires heavy linear algebra operations. These calculations are greatly accelerated\n",
        "using an alternative mathematical approach called the **w_tilde formalism**.\n",
        "\n",
        "You do not need to understand the full details of the method, but the key point is:\n",
        "\n",
        "- `w_tilde` exploits the **sparsity** of the matrices used in pixelized source reconstruction.\n",
        "- This leads to a **significant speed-up on GPU or CPU**, using JAX to perform the linear algebra calculations.\n",
        "\n",
        "To enable this feature, we call `apply_w_tilde()` on the dataset. This computes and stores a `w_tilde_preload` matrix,\n",
        "which reused in all subsequent pixelized source fits.\n",
        "\n",
        "For datasets with over 100000 visibilities and many pixels in their real-space mask, this computation\n",
        "can take 10 minutes or hours. Computing it once, in this script, saving it to hard-disk, and loading it\n",
        "for modeling is therefore recommended. The `show_progress` input outputs a progress bar to the terminal\n",
        "so you can monitor the computation.\n",
        "\n",
        "We comment out the w_tilde calculation below as we are going to illustrate how you can compute it on CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# dataset = dataset.apply_w_tilde(show_progress=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__CPU__\n",
        "\n",
        "The code below computes the w_tilde matrix on a CPU using a pure numpy implementation, including inputs:\n",
        "\n",
        "- `chunk_k`: The chunk size of visibilities to process at a time. Decreasing this value decreases the memory\n",
        "  requirements of the computation, but increases the run time. You should set this as high as your system's\n",
        "  memory allows.\n",
        "  \n",
        "- `show_progress`: Whether to output a progress bar to the terminal, which is on here as for runs which take over\n",
        "  an hour this is useful to monitor.\n",
        "\n",
        "- `show_memory`: Whether to output memory usage to the terminal, which is useful to ensure your system has enough\n",
        "  memory to complete the computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "curvature_preload = (\n",
        "    al.util.inversion_interferometer.w_tilde_curvature_preload_interferometer_from(\n",
        "        noise_map_real=dataset.noise_map.array.real,\n",
        "        uv_wavelengths=dataset.uv_wavelengths,\n",
        "        shape_masked_pixels_2d=dataset.grid.mask.shape_native_masked_pixels,\n",
        "        grid_radians_2d=dataset.grid.mask.derive_grid.all_false.in_radians.native.array,\n",
        "        chunk_k=2048,\n",
        "        show_progress=True,\n",
        "        show_memory=True,\n",
        "    )\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__W Tilde Preload Output__\n",
        "\n",
        "We now output the `curvature_preload` object to hard-disk, so it can be loaded quickly in the \n",
        "`cpu_fast_modeling` example.\n",
        "\n",
        "We save it using a numpy `npz` file, which compresses the data to save hard-disk space, and put it in the \n",
        "dataset folder so it can be easily found."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "np.save(file=dataset_path / \"curvature_preload\", arr=curvature_preload)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Curvature Matrix Time__\n",
        "\n",
        "The main bottleneck the w-tilde method speeds up is the calculation of the curvature matrix in the source\n",
        "reconstruction, which is performed for every likelihood evaluation.\n",
        "\n",
        "If this takes a long time, then lens modeling the dataset will be slow. We therefore time how long it takes\n",
        "to compute the curvature matrix using the `w_tilde` method on the CPU with numba, you need this to be \n",
        "under a second to get reasonable performance.\n",
        "\n",
        "The **time the curvature matrix calculation takes is independent of the number of visibilities in the dataset**. \n",
        "This is because the w-tilde method compresses all the visibility information into the `curvature_preload` matrix, \n",
        "whose size depends only on the number of pixels in the real-space mask.\n",
        "\n",
        "Therefore, the main driver of the curvature matrix calculation time is the number of pixels in the real-space mask,\n",
        "not the number of visibilities in the dataset. The calculation also runs the same speed irrespective of whether\n",
        "the real space mask is circular, or irregularly shaped, therefore using a circlular mask is recommended as it is\n",
        "simpler to set up.\n",
        "\n",
        "Here are some estimated run times for different mask sizes, where the GPU is a 2021 laptop GPU with 4GB VRAM and \n",
        "therefore not too modern\n",
        "\n",
        "- Mask Radius 3.0\", pixel_scale=0.05 (e.g. high resolution ALMA): 1.7 seconds on CPU, < 0.2 seconds on GPU.\n",
        "- Mask Radius 3.0\", pixel_scale=0.025 (e.g. highest resolution ALMA):\n",
        "- Mask Radius 3.0\", pixel_scale=0.01 (e.g. JVLA extreme resolution):\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "This example has demonstrated how to set up the linear algebra to perform fast pixelized source modeling on\n",
        "interferometer datasets with many visibilities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}