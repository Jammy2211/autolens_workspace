{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Preparation: Run Times\n",
        "===========================\n",
        "\n",
        "The run times of an interferometer analysis depend significantly on how many visibilities are in the dataset. The\n",
        "settings of an interferometer analysis must therefore be chosen based on the dataset being fitted.\n",
        "\n",
        "Analyses which perform an interferometer pixelization reconstruction (called an `Inversion`) also depend on the number\n",
        "of visibilities, with additional settings that can be chosen to improve the run time.\n",
        "\n",
        "This script allows you to load an interferometer dataset, define the `real_space_mask` and fit it with different\n",
        "settings to determine which give the fastest results for your dataset.\n",
        "\n",
        "To fit the dataset a lens mass model is omitted, because we have not modeled the dataset yet. Whilst the solution we use\n",
        "is therefore a poor fit, it wills till give representaitive run times.\n",
        "\n",
        "Some settings may use extremely large amounts of memory (e.g. > 100GB), if your datasset have many visibilities\n",
        "(e.g. > 1 000 000). This may crash your computer.\n",
        "\n",
        "To prevent this, functions which provide run times are commented out below, and you will need to uncomment them\n",
        "depending on whether they are suitable for your data (e.g. they typically give the best performance for datasets\n",
        "with less visibilitlies, around < 100 000).\n",
        "\n",
        "__Preloading Time__\n",
        "\n",
        "Some functionality takes longer the first time it is run, as it is preloading in memory certain quantities that are\n",
        "reused many times when lens modeling is performed.\n",
        "\n",
        "This means that when profiling settings below it may appear that the function is very slow, but actually it is\n",
        "performing this preloading. The run times provided by the functions below do not include this preloading time (as\n",
        "this is representative of the run time of a lens model analysis).\n",
        "\n",
        "You therefore should not cancel the script if it appears to be running slowly, as it could be this preloading time\n",
        "that is the cause."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import time\n",
        "\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Transformer Time__\n",
        "\n",
        "This function is used to time how long a transformer takes to map the real-space image of a strong lens to its\n",
        "visibilities. This is used to determine which transformer is optimal for your dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def print_transformer_time_from(dataset, transformer_class, repeats=1):\n",
        "    \"\"\"\n",
        "    __Numba Caching__\n",
        "\n",
        "    Perform a single transformer call to ensure all numba functions are initialized.\n",
        "    \"\"\"\n",
        "    image = tracer.image_2d_from(grid=dataset.grid)\n",
        "\n",
        "    dataset.transformer.visibilities_from(image=image)\n",
        "\n",
        "    \"\"\"\n",
        "    __Fit Time__\n",
        "\n",
        "    Now profile the overall run-time of the transformer.\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    dataset.transformer.visibilities_from(image=image)\n",
        "\n",
        "    transformer_time = (time.time() - start) / repeats\n",
        "    print(f\"Transformer Time = {transformer_time} \\n\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit Time__\n",
        "\n",
        "This function is used throughout this script to time how long a fit takes for each combination of settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def print_fit_time_from(dataset, transformer_class, use_linear_operators, repeats=1):\n",
        "    \"\"\"\n",
        "    __Numba Caching__\n",
        "\n",
        "    Call FitImaging once to get all numba functions initialized.\n",
        "    \"\"\"\n",
        "    fit = al.FitInterferometer(\n",
        "        dataset=dataset,\n",
        "        tracer=tracer,\n",
        "        settings_inversion=al.SettingsInversion(\n",
        "            use_linear_operators=use_linear_operators\n",
        "        ),\n",
        "    )\n",
        "    print(fit.figure_of_merit)\n",
        "\n",
        "    \"\"\"\n",
        "    __Fit Time__\n",
        "\n",
        "    Time FitImaging by itself, to compare to run_times dict call.\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    for i in range(repeats):\n",
        "        fit = al.FitInterferometer(\n",
        "            dataset=dataset,\n",
        "            tracer=tracer,\n",
        "            settings_inversion=al.SettingsInversion(\n",
        "                use_linear_operators=use_linear_operators\n",
        "            ),\n",
        "        )\n",
        "        fit.figure_of_merit\n",
        "\n",
        "    fit_time = (time.time() - start) / repeats\n",
        "    print(f\"Fit Time = {fit_time} \\n\")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We define the \u2018real_space_mask\u2019 which defines the grid the image the strong lens is evaluated using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "real_space_mask = al.Mask2D.circular(\n",
        "    shape_native=(800, 800),\n",
        "    pixel_scales=0.2,\n",
        "    radius=3.0,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the strong lens `Interferometer` dataset `simple` from .fits files , which we will fit \n",
        "with the lens model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"interferometer\", dataset_name)\n",
        "\n",
        "dataset = al.Interferometer.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    uv_wavelengths_path=path.join(dataset_path, \"uv_wavelengths.fits\"),\n",
        "    real_space_mask=real_space_mask,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.InterferometerPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "dataset_plotter.subplot_dirty_images()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Tracer__\n",
        "\n",
        "Set up the `Tracer` used to profile each method, which:\n",
        " \n",
        " - Does not implement mass or light profiles for the lens galaxy.\n",
        " - Uses an `Overlay` image-mesh, `Delaunay` mesh with `Constant` regularization to fit the data and thus profile the \n",
        "  pixelized source reconstruction `Inversion` run time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(redshift=0.5)\n",
        "\n",
        "pixelization = al.Pixelization(\n",
        "    image_mesh=al.image_mesh.Overlay(shape=(30, 30)),\n",
        "    mesh=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Transformer__\n",
        "\n",
        "The transformer maps the inversion's image from real-space to Fourier space, with two options available that have\n",
        "optimal run-times depending on the number of visibilities in the dataset:\n",
        "\n",
        "- `TransformerDFT`: A discrete Fourier transform which is most efficient for < ~100 000 visibilities.\n",
        "\n",
        "- `TransformerNUFFT`: A non-uniform fast Fourier transform which is most efficient for > ~100 000 visibilities.\n",
        "\n",
        "If your dataset has < ~100 000 visibilities, you should confirm whether the DFT is faster than the NUFFT for your\n",
        "specific dataset and use that setting in your modeling scripts.\n",
        "\n",
        "For datasets with > ~100 000 visibilities, the DFT uses a lot of memory and has very long run times. You may still \n",
        "wish to profile it below, but it can use a lot of memory so proceed with caution!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.Interferometer.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    uv_wavelengths_path=path.join(dataset_path, \"uv_wavelengths.fits\"),\n",
        "    real_space_mask=real_space_mask,\n",
        "    transformer_class=al.TransformerDFT,\n",
        ")\n",
        "\n",
        "print_transformer_time_from(\n",
        "    dataset=dataset, transformer_class=al.TransformerDFT, repeats=1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Linear Algebra__\n",
        "\n",
        "The linear algebra describes how the linear system of equations used to reconstruct a source via a pixelization is\n",
        "solved. \n",
        "\n",
        "The optimal transformer does not depend on the linear algebra settings, thus because we have found the optimal\n",
        "transformer above we can now easily choose the optimal linear algebra settings.\n",
        "\n",
        "There are with three options available that again have run-times that are optimal for datasets of different sizes \n",
        "(do not worry if you do not understand how the linear algebra works, all you need to do is ensure you choose the\n",
        "setting most appropriate for the size of your dataset):\n",
        "\n",
        "- `use_linear_operators`:  If `False`, the matrices in the linear system are computed via a `mapping_matrix`, which \n",
        "  is optimal for datasets with < ~10 000 visibilities.\n",
        "  \n",
        "- `use_linear_operators`: If `True`, a different formalism is used entirely where matrices are not computed and \n",
        "   linear operators  are used instead. This is optimal for datasets with > ~1 000 000 visibilities. Note that \n",
        "   the `TransformerNUFFT` must be used with this setting.\n",
        "\n",
        "If your dataset has > 1 000 000 visibilities, you should be cautious that using `use_linear_operations=False` \n",
        " will use significant amounts of memory and take a long time to run. \n",
        "\n",
        "You should now vary the settings below to determine the optimal settings for your dataset, making sure to use the\n",
        "optimal transformer determined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.Interferometer.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    uv_wavelengths_path=path.join(dataset_path, \"uv_wavelengths.fits\"),\n",
        "    real_space_mask=real_space_mask,\n",
        "    transformer_class=al.TransformerNUFFT,\n",
        ")\n",
        "\n",
        "print_fit_time_from(\n",
        "    dataset=dataset,\n",
        "    transformer_class=al.TransformerNUFFT,\n",
        "    use_linear_operators=False,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fin."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}