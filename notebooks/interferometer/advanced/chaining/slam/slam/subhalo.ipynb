{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "from autofit.non_linear.grid import sensitivity as s\n",
        "\n",
        "\n",
        "import json\n",
        "import os\n",
        "from typing import Union, Tuple, ClassVar\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def detection(\n",
        "    settings_autofit: af.SettingsSearch,\n",
        "    analysis: Union[al.AnalysisImaging, al.AnalysisInterferometer],\n",
        "    mass_results: af.ResultsCollection,\n",
        "    subhalo_mass: af.Model = af.Model(al.mp.NFWMCRLudlowSph),\n",
        "    free_redshift: bool = False,\n",
        "    grid_dimension_arcsec: float = 3.0,\n",
        "    number_of_steps: Union[Tuple[int], int] = 5,\n",
        ") -> af.ResultsCollection:\n",
        "    \"\"\"\n",
        "    The SLaM SUBHALO PIPELINE for fitting lens mass models which include a dark matter subhalo.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    analysis\n",
        "        The analysis class which includes the `log_likelihood_function` and can be customized for the SLaM model-fit.\n",
        "    setup_adapt\n",
        "        The setup of the adapt fit.\n",
        "    mass_results\n",
        "        The results of the SLaM MASS PIPELINE which ran before this pipeline.\n",
        "    subhalo_mass\n",
        "        The `MassProfile` used to fit the subhalo in this pipeline.\n",
        "    grid_dimension_arcsec\n",
        "        the arc-second dimensions of the grid in the y and x directions. An input value of 3.0\" means the grid in\n",
        "        all four directions extends to 3.0\" giving it dimensions 6.0\" x 6.0\".\n",
        "    free_redshift\n",
        "        If `True` the redshift of the subhalo is a free parameter in the second and third searches.\n",
        "    number_of_steps\n",
        "        The 2D dimensions of the grid (e.g. number_of_steps x number_of_steps) that the subhalo search is performed for.\n",
        "    number_of_cores\n",
        "        The number of cores used to perform the non-linear search grid search. If 1, each model-fit on the grid is\n",
        "        performed in serial, if > 1 fits are distributed in parallel using the Python multiprocessing module.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    __Model + Search + Analysis + Model-Fit (Search 1)__\n",
        "\n",
        "    Search 1 of the SUBHALO PIPELINE fits a lens model where:\n",
        "\n",
        "     - The lens galaxy mass is modeled using MASS PIPELINE's mass distribution [Priors initialized from MASS PIPELINE].\n",
        "     - The source galaxy's light is parametric or a pixelization depending on the previous MASS PIPELINE [Model and \n",
        "     priors initialized from MASS PIPELINE].\n",
        "\n",
        "    This search aims to accurately estimate the lens mass model, using the improved mass model priors and source model \n",
        "    of the MASS PIPELINE. \n",
        "    \n",
        "    This model will be used to perform Bayesian model comparison with models that include a subhalo, to determine if \n",
        "    a subhalo is detected.\n",
        "    \"\"\"\n",
        "\n",
        "    source = al.util.chaining.source_from(\n",
        "        result=mass_results.last,\n",
        "    )\n",
        "\n",
        "    lens = mass_results.last.model.galaxies.lens\n",
        "\n",
        "    model = af.Collection(\n",
        "        galaxies=af.Collection(lens=lens, source=source),\n",
        "        clumps=al.util.chaining.clumps_from(\n",
        "            result=mass_results.last, mass_as_model=True\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    search_no_subhalo = af.Nautilus(\n",
        "        name=\"subhalo[1]_mass[total_refine]\",\n",
        "        **settings_autofit.search_dict,\n",
        "        n_live=200,\n",
        "    )\n",
        "\n",
        "    result_1 = search_no_subhalo.fit(\n",
        "        model=model, analysis=analysis, **settings_autofit.fit_dict\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    __Model + Search + Analysis + Model-Fit (Search 2)__\n",
        "\n",
        "    Search 2 of the SUBHALO PIPELINE we perform a [number_of_steps x number_of_steps] grid search of non-linear\n",
        "    searches where:\n",
        "\n",
        "     - The lens galaxy mass is modeled using MASS PIPELINE's mass distribution [Priors initialized from MASS PIPELINE].\n",
        "     - The source galaxy's light is parametric or a pixelization depending on the previous MASS PIPELINE [Model and \n",
        "     priors initialized from MASS PIPELINE].\n",
        "     - The subhalo redshift is fixed to that of the lens galaxy.\n",
        "     - Each grid search varies the subhalo (y,x) coordinates and mass as free parameters.\n",
        "     - The priors on these (y,x) coordinates are UniformPriors, with limits corresponding to the grid-cells.\n",
        "\n",
        "    This search aims to detect a dark matter subhalo.\n",
        "    \"\"\"\n",
        "\n",
        "    subhalo = af.Model(al.Galaxy, mass=subhalo_mass)\n",
        "\n",
        "    subhalo.mass.mass_at_200 = af.LogUniformPrior(lower_limit=1.0e6, upper_limit=1.0e11)\n",
        "    subhalo.mass.centre_0 = af.UniformPrior(\n",
        "        lower_limit=-grid_dimension_arcsec, upper_limit=grid_dimension_arcsec\n",
        "    )\n",
        "    subhalo.mass.centre_1 = af.UniformPrior(\n",
        "        lower_limit=-grid_dimension_arcsec, upper_limit=grid_dimension_arcsec\n",
        "    )\n",
        "\n",
        "    if not free_redshift:\n",
        "        subhalo.redshift = result_1.instance.galaxies.lens.redshift\n",
        "        subhalo.mass.redshift_object = result_1.instance.galaxies.lens.redshift\n",
        "        search_tag = \"search_lens_plane\"\n",
        "        refine_tag = \"single_plane_refine\"\n",
        "    else:\n",
        "        subhalo.redshift = af.UniformPrior(\n",
        "            lower_limit=0.0, upper_limit=result_1.instance.galaxies.source.redshift\n",
        "        )\n",
        "        subhalo.mass.redshift_object = subhalo.redshift\n",
        "        search_tag = \"search_multi_plane\"\n",
        "        refine_tag = \"multi_plane_refine\"\n",
        "\n",
        "    subhalo.mass.redshift_source = result_1.instance.galaxies.source.redshift\n",
        "\n",
        "    source = al.util.chaining.source_from(\n",
        "        result=mass_results.last,\n",
        "    )\n",
        "\n",
        "    model = af.Collection(\n",
        "        galaxies=af.Collection(lens=lens, subhalo=subhalo, source=source),\n",
        "        clumps=al.util.chaining.clumps_from(result=result_1, mass_as_model=True),\n",
        "    )\n",
        "\n",
        "    search = af.Nautilus(\n",
        "        name=f\"subhalo[2]_mass[total]_source_subhalo[{search_tag}]\",\n",
        "        **settings_autofit.search_dict_x1_core,\n",
        "        n_live=150,\n",
        "        force_x1_cpu=True,  # ensures parallelizing over grid search works.\n",
        "    )\n",
        "\n",
        "    subhalo_grid_search = af.SearchGridSearch(\n",
        "        search=search,\n",
        "        number_of_steps=number_of_steps,\n",
        "        number_of_cores=settings_autofit.number_of_cores,\n",
        "    )\n",
        "\n",
        "    subhalo_result = subhalo_grid_search.fit(\n",
        "        model=model,\n",
        "        analysis=analysis,\n",
        "        grid_priors=[\n",
        "            model.galaxies.subhalo.mass.centre_1,\n",
        "            model.galaxies.subhalo.mass.centre_0,\n",
        "        ],\n",
        "        info=settings_autofit.info,\n",
        "        parent=search_no_subhalo,\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    __Model + Search + Analysis + Model-Fit (Search 3)__\n",
        "\n",
        "    Search 3 of the SUBHALO PIPELINE we refit the lens and source models above but now including a subhalo, where \n",
        "    the subhalo model is initialized from the highest evidence model of the subhalo grid search.\n",
        "\n",
        "     - The lens galaxy mass is modeled using MASS PIPELINE's mass distribution [Priors initialized from MASS PIPELINE].\n",
        "     - The source galaxy's light is parametric or a pixelization depending on the previous MASS PIPELINE [Model and \n",
        "     priors initialized from MASS PIPELINE].\n",
        "     - The subhalo redshift is fixed to that of the lens galaxy.\n",
        "     - Each grid search varies the subhalo (y,x) coordinates and mass as free parameters.\n",
        "     - The priors on these (y,x) coordinates are UniformPriors, with limits corresponding to the grid-cells.\n",
        "\n",
        "    This search aims to refine the parameter estimates and errors of a dark matter subhalo detected in the grid search\n",
        "    above.\n",
        "    \"\"\"\n",
        "\n",
        "    subhalo = af.Model(\n",
        "        al.Galaxy, redshift=result_1.instance.galaxies.lens.redshift, mass=subhalo_mass\n",
        "    )\n",
        "\n",
        "    subhalo.mass.mass_at_200 = af.LogUniformPrior(lower_limit=1.0e6, upper_limit=1.0e11)\n",
        "    subhalo.mass.centre = subhalo_result.model_absolute(\n",
        "        a=1.0\n",
        "    ).galaxies.subhalo.mass.centre\n",
        "\n",
        "    subhalo.redshift = subhalo_result.model.galaxies.subhalo.redshift\n",
        "    subhalo.mass.redshift_object = subhalo.redshift\n",
        "\n",
        "    model = af.Collection(\n",
        "        galaxies=af.Collection(\n",
        "            lens=subhalo_result.model.galaxies.lens,\n",
        "            subhalo=subhalo,\n",
        "            source=subhalo_result.model.galaxies.source,\n",
        "        ),\n",
        "        clumps=al.util.chaining.clumps_from(result=subhalo_result, mass_as_model=True),\n",
        "    )\n",
        "\n",
        "    search = af.Nautilus(\n",
        "        name=f\"subhalo[3]_subhalo[{refine_tag}]\",\n",
        "        **settings_autofit.search_dict,\n",
        "        n_live=1000,\n",
        "    )\n",
        "\n",
        "    result_3 = search.fit(model=model, analysis=analysis, **settings_autofit.fit_dict)\n",
        "\n",
        "    return af.ResultsCollection([result_1, subhalo_result, result_3])\n",
        "\n",
        "\n",
        "class SimulateImaging:\n",
        "    def __init__(self, mask, psf):\n",
        "        self.mask = mask\n",
        "        self.psf = psf\n",
        "\n",
        "    def __call__(self, instance, simulate_path):\n",
        "        \"\"\"\n",
        "        Set up the `Tracer` which is used to simulate the strong lens imaging, which may include the subhalo in\n",
        "        addition to the lens and source galaxy.\n",
        "        \"\"\"\n",
        "        tracer = al.Tracer.from_galaxies(\n",
        "            galaxies=[\n",
        "                instance.galaxies.lens,\n",
        "                instance.perturbation,\n",
        "                instance.galaxies.source,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "        Set up the grid, PSF and simulator settings used to simulate imaging of the strong lens. These should be tuned to\n",
        "        match the S/N and noise properties of the observed data you are performing sensitivity mapping on.\n",
        "        \"\"\"\n",
        "        grid = al.Grid2DIterate.uniform(\n",
        "            shape_native=self.mask.shape_native,\n",
        "            pixel_scales=self.mask.pixel_scales,\n",
        "            fractional_accuracy=0.9999,\n",
        "            sub_steps=[2, 4, 8, 16, 24],\n",
        "        )\n",
        "\n",
        "        simulator = al.SimulatorImaging(\n",
        "            exposure_time=300.0,\n",
        "            psf=self.psf,\n",
        "            background_sky_level=0.1,\n",
        "            add_poisson_noise=True,\n",
        "        )\n",
        "\n",
        "        dataset = simulator.via_tracer_from(tracer=tracer, grid=grid)\n",
        "        dataset.apply_mask(mask=self.mask)\n",
        "\n",
        "        self.output_info(simulate_path=simulate_path, dataset=dataset, tracer=tracer)\n",
        "\n",
        "        \"\"\"\n",
        "        The data generated by the simulate function is that which is fitted, so we should apply the mask for \n",
        "        the analysis here before we return the simulated data.\n",
        "        \"\"\"\n",
        "        return dataset\n",
        "\n",
        "    def output_info(self, simulate_path, dataset, tracer):\n",
        "        mat_plot = aplt.MatPlot2D(output=aplt.Output(path=simulate_path, format=\"png\"))\n",
        "\n",
        "        dataset_plotter = aplt.ImagingPlotter(dataset=dataset, mat_plot_2d=mat_plot)\n",
        "        dataset_plotter.subplot_dataset()\n",
        "\n",
        "        tracer_plotter = aplt.TracerPlotter(\n",
        "            tracer=tracer, grid=dataset.grid, mat_plot_2d=mat_plot\n",
        "        )\n",
        "        tracer_plotter.subplot_lensed_images()\n",
        "\n",
        "        with open(os.path.join(simulate_path, \"tracer.json\"), \"w+\") as f:\n",
        "            json.dump(tracer.dict(), f, indent=4)\n",
        "\n",
        "\n",
        "def sensitivity_mapping_imaging(\n",
        "    settings_autofit: af.SettingsSearch,\n",
        "    mask: al.Mask2D,\n",
        "    psf: al.Kernel2D,\n",
        "    mass_results: af.ResultsCollection,\n",
        "    analysis_cls: ClassVar[al.AnalysisImaging],\n",
        "    subhalo_mass: af.Model = af.Model(al.mp.NFWMCRLudlowSph),\n",
        "    grid_dimension_arcsec: float = 3.0,\n",
        "    number_of_steps: Union[Tuple[int], int] = 5,\n",
        "):\n",
        "    \"\"\"\n",
        "    The SLaM SUBHALO PIPELINE for performing sensitivity mapping, which determines what mass dark matter subhalos\n",
        "    can be detected where in the dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mask\n",
        "        The Mask2D that is applied to the imaging data for model-fitting.\n",
        "    psf\n",
        "        The Point Spread Function (PSF) used when simulating every image of the strong lens that is fitted by\n",
        "        sensitivity mapping.\n",
        "    mass_results\n",
        "        The results of the SLaM MASS PIPELINE which ran before this pipeline.\n",
        "    analysis_cls\n",
        "        The analysis class which includes the `log_likelihood_function` and can be customized for the SLaM model-fit. A\n",
        "        new instance of this class is created for every model-fit.\n",
        "    subhalo_mass\n",
        "        The `MassProfile` used to fit the subhalo in this pipeline.\n",
        "    grid_dimension_arcsec\n",
        "        the arc-second dimensions of the grid in the y and x directions. An input value of 3.0\" means the grid in\n",
        "        all four directions extends to 3.0\" giving it dimensions 6.0\" x 6.0\".\n",
        "    number_of_steps\n",
        "        The 2D dimensions of the grid (e.g. number_of_steps x number_of_steps) that the subhalo search is performed for.\n",
        "    number_of_cores\n",
        "        The number of cores used to perform the non-linear search grid search. If 1, each model-fit on the grid is\n",
        "        performed in serial, if > 1 fits are distributed in parallel using the Python multiprocessing module.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    To begin, we define the `base_model` that we use to perform sensitivity mapping. This is the lens model that is f\n",
        "    itted to every simulated strong lens without a subhalo, giving us the Bayesian evidence which we compare to the model\n",
        "    which includes one!).\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    We now define the `base_model` that we use to perform sensitivity mapping. This is the lens model that is fitted to \n",
        "    every simulated strong lens without a subhalo, giving us the Bayesian evidence which we compare to the model which \n",
        "    includes one!). \n",
        "\n",
        "    For this model, we can use the result of fitting this model to the dataset before sensitivity mapping via the \n",
        "    mass pipeline. This ensures the priors associated with each parameter are initialized so as to speed up\n",
        "    each non-linear search performed during sensitivity mapping.\n",
        "    \"\"\"\n",
        "    base_model = mass_results.last.model\n",
        "\n",
        "    \"\"\"\n",
        "    We now define the `perturbation_model`, which is the model component whose parameters we iterate over to perform \n",
        "    sensitivity mapping. In this case, this model is a `NFWMCRLudlowSph` model and we will iterate over its\n",
        "    `centre` and `mass_at_200`. We set it up as a `Model` so it has an associated redshift and can be directly\n",
        "    passed to the tracer in the simulate function below.\n",
        "\n",
        "    Many instances of the `perturbation_model` are created and used to simulate the many strong lens datasets that we fit. \n",
        "    However, it is only included in half of the model-fits; corresponding to the lens models which include a dark matter \n",
        "    subhalo and whose Bayesian evidence we compare to the simpler model-fits consisting of just the `base_model` to \n",
        "    determine if the subhalo was detectable.\n",
        "\n",
        "    By fitting both models to every simulated lens, we therefore infer the Bayesian evidence of every model to every \n",
        "    dataset. Sensitivity mapping therefore maps out for what values of `centre` and `mass_at_200` in the dark mattter \n",
        "    subhalo the model-fit including a subhalo provide higher values of Bayesian evidence than the simpler model-fit (and\n",
        "    therefore when it is detectable!).\n",
        "    \"\"\"\n",
        "    perturbation_model = af.Model(al.Galaxy, redshift=0.5, mass=subhalo_mass)\n",
        "\n",
        "    \"\"\"\n",
        "    Sensitivity mapping is typically performed over a large range of parameters. However, to make this demonstration quick\n",
        "    and clear we are going to fix the `centre` of the subhalo to a value near the Einstein ring of (1.6, 0.0). We will \n",
        "    iterate over just two `mass_at_200` values corresponding to subhalos of mass 1e6 and 1e11, of which only the latter\n",
        "    will be shown to be detectable.\n",
        "    \"\"\"\n",
        "    # perturbation_model.mass.mass_at_200 = af.UniformPrior(\n",
        "    #     lower_limit=1e6, upper_limit=1e11\n",
        "    # )\n",
        "    perturbation_model.mass.mass_at_200 = 1e10\n",
        "    perturbation_model.mass.centre.centre_0 = af.UniformPrior(\n",
        "        lower_limit=-grid_dimension_arcsec, upper_limit=grid_dimension_arcsec\n",
        "    )\n",
        "    perturbation_model.mass.centre.centre_1 = af.UniformPrior(\n",
        "        lower_limit=-grid_dimension_arcsec, upper_limit=grid_dimension_arcsec\n",
        "    )\n",
        "    perturbation_model.mass.redshift_object = (\n",
        "        mass_results.last.model.galaxies.lens.redshift\n",
        "    )\n",
        "    perturbation_model.mass.redshift_source = (\n",
        "        mass_results.last.model.galaxies.source.redshift\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    We are performing sensitivity mapping to determine when a subhalo is detectable. Eery simulated dataset must \n",
        "    be simulated with a lens model, called the `simulation_instance`. We use the maximum likelihood model of the mass pipeline\n",
        "    for this.\n",
        "\n",
        "    This includes the lens light and mass and source galaxy light.\n",
        "    \"\"\"\n",
        "    simulation_instance = mass_results.last.instance\n",
        "\n",
        "    fit = mass_results.last.max_log_likelihood_fit\n",
        "\n",
        "    simulation_instance.galaxies.lens.bulge = (\n",
        "        fit.model_obj_linear_light_profiles_to_light_profiles.galaxies[0].bulge\n",
        "    )\n",
        "    simulation_instance.galaxies.lens.disk = (\n",
        "        fit.model_obj_linear_light_profiles_to_light_profiles.galaxies[0].disk\n",
        "    )\n",
        "    simulation_instance.galaxies.source.bulge = (\n",
        "        fit.model_obj_linear_light_profiles_to_light_profiles.galaxies[-1].bulge\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    We now write the `simulate_function`, which takes the `simulation_instance` of our model (defined above) and uses it to \n",
        "    simulate a dataset which is subsequently fitted.\n",
        "\n",
        "    Note that when this dataset is simulated, the quantity `instance.perturbation` is used in the `simulate_function`.\n",
        "    This is an instance of the `NFWMCRLudlowSph`, and it is different every time the `simulate_function` is called\n",
        "    based on the value of sensitivity being computed. \n",
        "\n",
        "    In this example, this `instance.perturbation` corresponds to two different subhalos with values of `mass_at_200` of \n",
        "    1e6 MSun and 1e11 MSun.\n",
        "    \"\"\"\n",
        "    simulate_function = SimulateImaging(mask=mask, psf=psf)\n",
        "\n",
        "    \"\"\"\n",
        "    We next specify the search used to perform each model fit by the sensitivity mapper.\n",
        "    \"\"\"\n",
        "    search = af.Nautilus(\n",
        "        name=\"subhalo__sensitivity\", **settings_autofit.search_dict, n_live=100\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    We can now combine all of the objects created above and perform sensitivity mapping. The inputs to the `Sensitivity`\n",
        "    object below are:\n",
        "\n",
        "    - `simulation_instance`: This is an instance of the model used to simulate every dataset that is fitted. In this \n",
        "    example it is a lens model that does not include a subhalo, which was inferred by fitting the dataset we perform \n",
        "    sensitivity mapping on.\n",
        "\n",
        "    - `base_model`: This is the lens model that is fitted to every simulated dataset, which does not include a subhalo. \n",
        "    In this example is composed of an `Isothermal` lens and `Sersic` source.\n",
        "\n",
        "    - `perturbation_model`: This is the extra model component that alongside the `base_model` is fitted to every \n",
        "    simulated dataset. In this example it is a `NFWMCRLudlowSph` dark matter subhalo.\n",
        "\n",
        "    - `simulate_function`: This is the function that uses the `simulation_instance` and many instances of the \n",
        "    `perturbation_model` to simulate many datasets that are fitted with the `base_model` \n",
        "    and `base_model` + `perturbation_model`.\n",
        "\n",
        "    - `analysis_class`: The wrapper `Analysis` class that passes each simulated dataset to the `Analysis` class that \n",
        "    fits the data.\n",
        "\n",
        "    - `number_of_steps`: The number of steps over which the parameters in the `perturbation_model` are iterated. In \n",
        "    this example, `mass_at_200` has a `LogUniformPrior` with lower limit 1e6 and upper limit 1e11, therefore \n",
        "    the `number_of_steps` of 2 will simulate and fit just 2 datasets where the `mass_at_200` is between 1e6 and 1e11.\n",
        "\n",
        "    - `number_of_cores`: The number of cores over which the sensitivity mapping is performed, enabling parallel \n",
        "    processing if set above 1.\n",
        "    \"\"\"\n",
        "    sensitivity_mapper = s.Sensitivity(\n",
        "        base_model=base_model,\n",
        "        perturbation_model=perturbation_model,\n",
        "        simulation_instance=simulation_instance,\n",
        "        simulate_function=simulate_function,\n",
        "        analysis_class=analysis_cls,\n",
        "        search=search,\n",
        "        number_of_steps=number_of_steps,\n",
        "        number_of_cores=settings_autofit.number_of_cores,\n",
        "    )\n",
        "\n",
        "    return sensitivity_mapper.run()\n",
        "\n",
        "\n",
        "def sensitivity_mapping_interferometer(\n",
        "    settings_autofit: af.SettingsSearch,\n",
        "    uv_wavelengths: np.ndarray,\n",
        "    real_space_mask: al.Mask2D,\n",
        "    mass_results: af.ResultsCollection,\n",
        "    analysis_cls: ClassVar[al.AnalysisInterferometer],\n",
        "    subhalo_mass: af.Model = af.Model(al.mp.NFWMCRLudlowSph),\n",
        "    grid_dimension_arcsec: float = 3.0,\n",
        "    number_of_steps: Union[Tuple[int], int] = 5,\n",
        "):\n",
        "    \"\"\"\n",
        "    The SLaM SUBHALO PIPELINE for performing sensitivity mapping, which determines what mass dark matter subhalos\n",
        "    can be detected where in the dataset.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path_prefix\n",
        "        The prefix of folders between the output path and the search folders.\n",
        "    uv_wavelengths\n",
        "        The wavelengths of the interferometer baselines used for mapping to Fourier space.\n",
        "    real_space_mask\n",
        "        The mask in real space which defines how lensed images are computed.\n",
        "    mass_results\n",
        "        The results of the SLaM MASS PIPELINE which ran before this pipeline.\n",
        "    analysis_cls\n",
        "        The analysis class which includes the `log_likelihood_function` and can be customized for the SLaM model-fit. A\n",
        "        new instance of this class is created for every model-fit.\n",
        "    subhalo_mass\n",
        "        The `MassProfile` used to fit the subhalo in this pipeline.\n",
        "    grid_dimension_arcsec\n",
        "        the arc-second dimensions of the grid in the y and x directions. An input value of 3.0\" means the grid in\n",
        "        all four directions extends to 3.0\" giving it dimensions 6.0\" x 6.0\".\n",
        "    number_of_steps\n",
        "        The 2D dimensions of the grid (e.g. number_of_steps x number_of_steps) that the subhalo search is performed for.\n",
        "    number_of_cores\n",
        "        The number of cores used to perform the non-linear search grid search. If 1, each model-fit on the grid is\n",
        "        performed in serial, if > 1 fits are distributed in parallel using the Python multiprocessing module.\n",
        "    unique_tag\n",
        "        The unique tag for this model-fit, which will be given a unique entry in the sqlite database and also acts as\n",
        "        the folder after the path prefix and before the search name. This is typically the name of the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    To begin, we define the `base_model` that we use to perform sensitivity mapping. This is the lens model that is f\n",
        "    itted to every simulated strong lens without a subhalo, giving us the Bayesian evidence which we compare to the model\n",
        "    which includes one!).\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    We now define the `base_model` that we use to perform sensitivity mapping. This is the lens model that is fitted to \n",
        "    every simulated strong lens without a subhalo, giving us the Bayesian evidence which we compare to the model which \n",
        "    includes one!). \n",
        "\n",
        "    For this model, we can use the result of fitting this model to the dataset before sensitivity mapping via the \n",
        "    mass pipeline. This ensures the priors associated with each parameter are initialized so as to speed up\n",
        "    each non-linear search performed during sensitivity mapping.\n",
        "    \"\"\"\n",
        "    base_model = mass_results.last.model\n",
        "\n",
        "    \"\"\"\n",
        "    We now define the `perturbation_model`, which is the model component whose parameters we iterate over to perform \n",
        "    sensitivity mapping. In this case, this model is a `NFWMCRLudlowSph` model and we will iterate over its\n",
        "    `centre` and `mass_at_200`. We set it up as a `Model` so it has an associated redshift and can be directly\n",
        "    passed to the tracer in the simulate function below.\n",
        "\n",
        "    Many instances of the `perturbation_model` are created and used to simulate the many strong lens datasets that we fit. \n",
        "    However, it is only included in half of the model-fits; corresponding to the lens models which include a dark matter \n",
        "    subhalo and whose Bayesian evidence we compare to the simpler model-fits consisting of just the `base_model` to \n",
        "    determine if the subhalo was detectable.\n",
        "\n",
        "    By fitting both models to every simulated lens, we therefore infer the Bayesian evidence of every model to every \n",
        "    dataset. Sensitivity mapping therefore maps out for what values of `centre` and `mass_at_200` in the dark mattter \n",
        "    subhalo the model-fit including a subhalo provide higher values of Bayesian evidence than the simpler model-fit (and\n",
        "    therefore when it is detectable!).\n",
        "    \"\"\"\n",
        "    perturbation_model = af.Model(al.Galaxy, redshift=0.5, mass=subhalo_mass)\n",
        "\n",
        "    \"\"\"\n",
        "    Sensitivity mapping is typically performed over a large range of parameters. However, to make this demonstration quick\n",
        "    and clear we are going to fix the `centre` of the subhalo to a value near the Einstein ring of (1.6, 0.0). We will \n",
        "    iterate over just two `mass_at_200` values corresponding to subhalos of mass 1e6 and 1e11, of which only the latter\n",
        "    will be shown to be detectable.\n",
        "    \"\"\"\n",
        "    perturbation_model.mass.mass_at_200 = af.LogUniformPrior(\n",
        "        lower_limit=1e6, upper_limit=1e11\n",
        "    )\n",
        "    perturbation_model.mass.centre.centre_0 = af.UniformPrior(\n",
        "        lower_limit=-grid_dimension_arcsec, upper_limit=grid_dimension_arcsec\n",
        "    )\n",
        "    perturbation_model.mass.centre.centre_1 = af.UniformPrior(\n",
        "        lower_limit=-grid_dimension_arcsec, upper_limit=grid_dimension_arcsec\n",
        "    )\n",
        "    perturbation_model.mass.redshift_object = (\n",
        "        mass_results.last.model.galaxies.lens.redshift\n",
        "    )\n",
        "    perturbation_model.mass.redshift_source = (\n",
        "        mass_results.last.model.galaxies.source.redshift\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    We are performing sensitivity mapping to determine when a subhalo is detectable. Eery simulated dataset must \n",
        "    be simulated with a lens model, called the `simulation_instance`. We use the maximum likelihood model of the mass pipeline\n",
        "    for this.\n",
        "\n",
        "    This includes the lens light and mass and source galaxy light.\n",
        "    \"\"\"\n",
        "    simulation_instance = mass_results.last.instance\n",
        "\n",
        "    \"\"\"\n",
        "    We now write the `simulate_function`, which takes the `simulation_instance` of our model (defined above) and uses it to \n",
        "    simulate a dataset which is subsequently fitted.\n",
        "\n",
        "    Note that when this dataset is simulated, the quantity `instance.perturbation` is used in the `simulate_function`.\n",
        "    This is an instance of the `NFWMCRLudlowSph`, and it is different every time the `simulate_function` is called\n",
        "    based on the value of sensitivity being computed. \n",
        "\n",
        "    In this example, this `instance.perturbation` corresponds to two different subhalos with values of `mass_at_200` of \n",
        "    1e6 MSun and 1e11 MSun.\n",
        "    \"\"\"\n",
        "\n",
        "    def simulate_function(instance, simulate_path):\n",
        "        \"\"\"\n",
        "        Set up the `Tracer` which is used to simulate the strong lens imaging, which may include the subhalo in\n",
        "        addition to the lens and source galaxy.\n",
        "        \"\"\"\n",
        "        tracer = al.Tracer.from_galaxies(\n",
        "            galaxies=[\n",
        "                instance.galaxies.lens,\n",
        "                instance.perturbation,\n",
        "                instance.galaxies.source,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "        Set up the grid, PSF and simulator settings used to simulate imaging of the strong lens. These should be tuned to\n",
        "        match the S/N and noise properties of the observed data you are performing sensitivity mapping on.\n",
        "        \"\"\"\n",
        "        grid = al.Grid2DIterate.uniform(\n",
        "            shape_native=real_space_mask.shape_native,\n",
        "            pixel_scales=real_space_mask.pixel_scales,\n",
        "            fractional_accuracy=0.9999,\n",
        "            sub_steps=[2, 4, 8, 16, 24],\n",
        "        )\n",
        "\n",
        "        simulator = al.SimulatorInterferometer(\n",
        "            uv_wavelengths=uv_wavelengths,\n",
        "            exposure_time=300.0,\n",
        "            noise_sigma=0.1,\n",
        "            transformer_class=al.TransformerNUFFT,\n",
        "        )\n",
        "\n",
        "        simulated_dataset = simulator.via_tracer_from(tracer=tracer, grid=grid)\n",
        "\n",
        "        \"\"\"\n",
        "        The data generated by the simulate function is that which is fitted, so we should apply the mask for the \n",
        "        analysis here before we return the simulated data.\n",
        "        \"\"\"\n",
        "        return al.Interferometer(\n",
        "            data=simulated_dataset.visibilities,\n",
        "            noise_map=simulated_dataset.noise_map,\n",
        "            uv_wavelengths=uv_wavelengths,\n",
        "            real_space_mask=real_space_mask,\n",
        "        )\n",
        "\n",
        "    \"\"\"\n",
        "    We next specify the search used to perform each model fit by the sensitivity mapper.\n",
        "    \"\"\"\n",
        "    search = af.Nautilus(\n",
        "        name=\"subhalo__sensitivity\", **settings_autofit.search_dict, n_live=100\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    We can now combine all of the objects created above and perform sensitivity mapping. The inputs to the `Sensitivity`\n",
        "    object below are:\n",
        "\n",
        "    - `simulation_instance`: This is an instance of the model used to simulate every dataset that is fitted. In this \n",
        "    example it is a lens model that does not include a subhalo, which was inferred by fitting the dataset we perform \n",
        "    sensitivity mapping on.\n",
        "\n",
        "    - `base_model`: This is the lens model that is fitted to every simulated dataset, which does not include a subhalo. \n",
        "    In this example is composed of an `Isothermal` lens and `Sersic` source.\n",
        "\n",
        "    - `perturbation_model`: This is the extra model component that alongside the `base_model` is fitted to every \n",
        "    simulated dataset. In this example it is a `NFWMCRLudlowSph` dark matter subhalo.\n",
        "\n",
        "    - `simulate_function`: This is the function that uses the `simulation_instance` and many instances of the \n",
        "    `perturbation_model` to simulate many datasets that are fitted with the `base_model` \n",
        "    and `base_model` + `perturbation_model`.\n",
        "\n",
        "    - `analysis_class`: The wrapper `Analysis` class that passes each simulated dataset to the `Analysis` class that \n",
        "    fits the data.\n",
        "\n",
        "    - `number_of_steps`: The number of steps over which the parameters in the `perturbation_model` are iterated. In \n",
        "    this example, `mass_at_200` has a `LogUniformPrior` with lower limit 1e6 and upper limit 1e11, therefore \n",
        "    the `number_of_steps` of 2 will simulate and fit just 2 datasets where the `mass_at_200` is between 1e6 and 1e11.\n",
        "\n",
        "    - `number_of_cores`: The number of cores over which the sensitivity mapping is performed, enabling parallel \n",
        "    processing if set above 1.\n",
        "    \"\"\"\n",
        "    sensitivity_mapper = s.Sensitivity(\n",
        "        search=search,\n",
        "        simulation_instance=simulation_instance,\n",
        "        base_model=base_model,\n",
        "        perturbation_model=perturbation_model,\n",
        "        simulate_function=simulate_function,\n",
        "        analysis_class=analysis_cls,\n",
        "        number_of_steps=number_of_steps,\n",
        "        number_of_cores=settings_autofit.number_of_cores,\n",
        "    )\n",
        "\n",
        "    return sensitivity_mapper.run()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}