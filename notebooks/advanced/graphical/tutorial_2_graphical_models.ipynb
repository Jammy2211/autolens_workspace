{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 2: Graphical Models\n",
        "============================\n",
        "\n",
        "In the previous tutorial we fitted individual lens models to individual lens datasets. We knew that every lens in\n",
        "the dataset had same value of `slope`, which we estimated using the weighted average of the slopes inferred for each \n",
        "lens fit.\n",
        "\n",
        "Graphical modeling follows a different approach. It composes a single model that is fitted to the entire lens dataset.\n",
        "This model includes specific model component for every individual lens in the sample. However, the graphical\n",
        "model also has shared parameters between these individual lens models.\n",
        "\n",
        "This example fits a graphical model using the same sample fitted in the previous tutorial, consisting of\n",
        "imaging data of three lenses. We fit the `PowerLawSph` plus `SphExpoenntial` model to each lens and source galaxy.\n",
        "However, whereas previously the `slope` of each lens model component was a free parameter in each fit, in the \n",
        "graphical model there is only a single value of `slope` shared by all three lenses (which is how the galaxy data was \n",
        "simulated).\n",
        "\n",
        "This graphical model creates a non-linear parameter space that has parameters for every lens in our sample. In this\n",
        "example, there are 3 lenses each with their own lens model, therefore:\n",
        "\n",
        " - Each lens has 1 free parameter from the components of its `SphIsoterhaml` that are not \n",
        " shared (the `einstein_radius` paramrters).\n",
        "\n",
        " - Each source has 4 free parameters for their `ExponentialSph` components.\n",
        "\n",
        "- There are three lenses and source in total, giving [3 x 1 + 3 x 4 = 16 free parameters]\n",
        "\n",
        " - There is one additional free parameter, which is the `slope` shared by all 3 lenses.\n",
        "\n",
        "The overall dimensionality of parameter space is therefore N=17.\n",
        "\n",
        "__Sample Simulation__\n",
        "\n",
        "The dataset fitted in this example script is simulated imaging data of a sample of 3 galaxies.\n",
        "\n",
        "This data is not automatically provided with the autogalaxy workspace, and must be first simulated by running the\n",
        "script `autolens_workspace/scripts/simulators/imaging/samples/simple__no_lens_light.py`.\n",
        "\n",
        "__Realism__\n",
        "\n",
        "For an realistic lens sample, one would not expect that each lens has the same value of `slope`, as is\n",
        "assumed in tutorials 1, 2 and 3. We make this assumption here to simplify the problem and make it easier to\n",
        "illustrate graphical models. Later tutorials fit more realistic graphical models where each lens has its own value of\n",
        "slope!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autolens as al\n",
        "import autofit as af\n",
        "from os import path"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "For each galaxy dataset in our sample we set up the correct path and load it by iterating over a for loop. \n",
        "\n",
        "This data is not automatically provided with the autogalaxy workspace, and must be first simulated by running the \n",
        "script `autolens_workspace/scripts/simulators/imaging/samples/simple__no_lens_light.py`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_label = \"samples\"\n",
        "dataset_type = \"imaging\"\n",
        "dataset_sample_name = \"simple__no_lens_light__mass_sis\"\n",
        "\n",
        "dataset_path = path.join(\"dataset\", dataset_type, dataset_label, dataset_sample_name)\n",
        "\n",
        "total_datasets = 3\n",
        "\n",
        "dataset_list = []\n",
        "\n",
        "for dataset_index in range(total_datasets):\n",
        "    dataset_sample_path = path.join(dataset_path, f\"dataset_{dataset_index}\")\n",
        "\n",
        "    dataset_list.append(\n",
        "        al.Imaging.from_fits(\n",
        "            data_path=path.join(dataset_sample_path, \"data.fits\"),\n",
        "            psf_path=path.join(dataset_sample_path, \"psf.fits\"),\n",
        "            noise_map_path=path.join(dataset_sample_path, \"noise_map.fits\"),\n",
        "            pixel_scales=0.1,\n",
        "        )\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We now mask each lens in our dataset, using the imaging list we created above.\n",
        "\n",
        "We will assume a 3.0\" mask for every lens in the dataset is appropriate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "masked_imaging_list = []\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    mask = al.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        "    )\n",
        "\n",
        "    masked_imaging_list.append(dataset.apply_mask(mask=mask))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Paths__\n",
        "\n",
        "The path the results of all model-fits are output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path_prefix = path.join(\"imaging\", \"hierarchical\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We first set up a shared prior for `slope` which will be attached to the mass profile of every model lens.\n",
        "\n",
        "By overwriting their `slope` parameters in this way, only one `slope` parameter shared across the whole \n",
        "model is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "slope_shared_prior = af.UniformPrior(lower_limit=0.8, upper_limit=5.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our model using `Model` objects, which represent the lenses we fit to our data.\n",
        "\n",
        "This graphical model creates a non-linear parameter space that has parameters for every lens and source galaxy in our \n",
        "sample. In this example, there are 3 lenses each with their own model, therefore:\n",
        "\n",
        " - Each lens galaxy's total mass distribution is an `PowerLawSph` with its centre fixed to its true value of \n",
        " (0.0, 0.0) [1 parameter].\n",
        " \n",
        " - Each source galaxy's light is a linear parametric `ExponentialSph` [3 parameters].\n",
        "\n",
        " - There are three lenses in our graphical model [3 x 1 = 3 parameters]. \n",
        "\n",
        " - There are three source in our graphical model [3 x 4 = 12 parameters]. \n",
        "\n",
        " - There is one additional free parameter, which is the `slope` shared by all 3 lenses.\n",
        "\n",
        "The overall dimensionality of parameter space is therefore N=16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_list = []\n",
        "\n",
        "for model_index in range(total_datasets):\n",
        "    lens = af.Model(al.Galaxy, redshift=0.5, mass=al.mp.PowerLawSph)\n",
        "    lens.mass.centre = (0.0, 0.0)\n",
        "\n",
        "    # This makes every Galaxy share the same `slope`.\n",
        "    lens.mass.slope = slope_shared_prior\n",
        "\n",
        "    source = af.Model(al.Galaxy, redshift=1.0, bulge=al.lp_linear.ExponentialCoreSph)\n",
        "\n",
        "    model = af.Collection(galaxies=af.Collection(lens=lens, source=source))\n",
        "\n",
        "    model_list.append(model)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "For each dataset we now create a corresponding `AnalysisImaging` class, as we are used to doing for `Imaging` data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = []\n",
        "\n",
        "for masked_dataset in masked_imaging_list:\n",
        "    analysis = al.AnalysisImaging(dataset=masked_dataset)\n",
        "\n",
        "    analysis_list.append(analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis Factors__\n",
        "\n",
        "Above, we composed a `model_list` consisting of three lens models which each had a shared `slope` prior. We \n",
        "also loaded three datasets which we intend to fit with each of these lens models, setting up each in an `Analysis` \n",
        "class that defines how the model is used to fit the data.\n",
        "\n",
        "We now simply pair each lens model to each `Analysis` class, so that **PyAutoLens** knows that: \n",
        "\n",
        "- `model_list[0]` fits `masked_imaging_list[0]` via `analysis_list[0]`.\n",
        "- `model_list[1]` fits `masked_imaging_list[1]` via `analysis_list[1]`.\n",
        "- `model_list[2]` fits `masked_imaging_list[2]` via `analysis_list[2]`.\n",
        "\n",
        "The point where a `Model` and `Analysis` class meet is called an `AnalysisFactor`. \n",
        "\n",
        "This term is used to denote that we are composing a graphical model, which is commonly termed a 'factor graph'. A \n",
        "factor defines a node on this graph where we have some data, a model, and we fit the two together. The 'links' between \n",
        "these different nodes then define the global model we are fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_factor_list = []\n",
        "\n",
        "for model, analysis in zip(model_list, analysis_list):\n",
        "    analysis_factor = af.AnalysisFactor(prior_model=model, analysis=analysis)\n",
        "\n",
        "    analysis_factor_list.append(analysis_factor)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Factor Graph__\n",
        "\n",
        "We combine our `AnalysisFactor`'s to compose a factor graph.\n",
        "\n",
        "What is a factor graph? A factor graph defines the graphical model we have composed. For example, it defines the \n",
        "different model components that make up our model (e.g. the three `Collection` objects containing the lens and source\n",
        "galaxies) and how their parameters are linked or shared (e.g. that each `PowerLawSph` has its own unique parameters \n",
        "but a shared `slope` parameter).\n",
        "\n",
        "This is what our factor graph looks like (visualization of graphs not implemented in **PyAutoFit** yet): \n",
        "\n",
        "The factor graph above is made up of two components:\n",
        "\n",
        "- Nodes: these are points on the graph where we have a unique set of data and a model that is made up of a subset of \n",
        "our overall graphical model. This is effectively the `AnalysisFactor` objects we created above. \n",
        "\n",
        "- Links: these define the model components and parameters that are shared across different nodes and thus retain the \n",
        "same values when fitting different datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "factor_graph = af.FactorGraphModel(*analysis_factor_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit will use the factor graph's `global_prior_model`, which uses the models contained in every analysis factor \n",
        "to contrast the overall global model that is fitted.\n",
        "\n",
        "Printing the `info` attribute of this model reveals the overall structure of the model, which is grouped in terms\n",
        "of the analysis factors and therefore datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph.global_prior_model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We can now create a non-linear search and used it to the fit the factor graph, using its `global_prior_model` property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Nautilus = af.Nautilus(\n",
        "    path_prefix=path_prefix,\n",
        "    name=\"tutorial_2_graphical_models\",\n",
        "    n_live=150,\n",
        ")\n",
        "\n",
        "result = Nautilus.fit(model=factor_graph.global_prior_model, analysis=factor_graph)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result's `info` attribute shows that the result is expressed following the same struture of analysis factors\n",
        "that the `global_prior_model.info` attribute revealed above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now inspect the inferred value of `slope`, and compare this to the value we estimated in the previous tutorial\n",
        "via a weighted average.\n",
        "\n",
        "(The errors of the weighted average below is what was estimated for a run on my PC, yours may be slightly \n",
        "different!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    f\"Weighted Average slope Estimate = 1.996152957641609 (0.02161402431870052) [1.0 sigma confidence intervals] \\n\"\n",
        ")\n",
        "\n",
        "slope = result.samples.median_pdf()[0].galaxies.lens.mass.slope\n",
        "\n",
        "u1_error = result.samples.values_at_upper_sigma(sigma=1.0)[0].galaxies.lens.mass.slope\n",
        "l1_error = result.samples.values_at_lower_sigma(sigma=1.0)[0].galaxies.lens.mass.slope\n",
        "\n",
        "u3_error = result.samples.values_at_upper_sigma(sigma=3.0)[0].galaxies.lens.mass.slope\n",
        "l3_error = result.samples.values_at_lower_sigma(sigma=3.0)[0].galaxies.lens.mass.slope\n",
        "\n",
        "print(\"Inferred value of the shared slope via a graphical model fit: \\n\")\n",
        "print(f\"{slope} ({l1_error} {u1_error}) [1.0 sigma confidence intervals]\")\n",
        "print(f\"{slope} ({l3_error} {u3_error}) [3.0 sigma confidence intervals]\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "The graphical model's slope estimate and errors are pretty much exactly the same as the weighted average!\n",
        "\n",
        "Whats the point of fitting a graphical model if the much simpler approach of the previous tutorial gives the\n",
        "same answer? \n",
        "\n",
        "The answer, is model complexity. Graphical models become more powerful as we make our model more complex,\n",
        "our non-linear parameter space higher dimensionality and the degeneracies between different parameters on the graph\n",
        "more significant. \n",
        "\n",
        "We will demonstrate this in the next tutorial.\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "In this tutorial, we showed that for our extremely simple model the graphical model gives pretty much the\n",
        "same estimate of the lens mass model slope's as simpler approaches followed in the previous tutorial. \n",
        "\n",
        "We will next show the strengths of graphical models by fitting more complex models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}