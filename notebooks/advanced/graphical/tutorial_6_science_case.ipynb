{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 6: Science Case\n",
        "========================\n",
        "\n",
        "This tutorial shows a realistic science case.\n",
        "\n",
        "We have a dataset containing 10 double Einstein ring lenses, which allow one to measure certain Cosmological\n",
        "parameters.\n",
        "\n",
        "In this example we include the Cosmological parameter Omega_m as a shared free parameter in an graphical model fit\n",
        "via Expectation Propagation (EP).\n",
        "\n",
        "__Sample Simulation__\n",
        "\n",
        "The dataset fitted in this example script is simulated imaging data of a sample of 3 galaxies.\n",
        "\n",
        "This data is not automatically provided with the autogalaxy workspace, and must be first simulated by running the\n",
        "script `autolens_workspace/scripts/simulators/imaging/samples/advanced/double_einstein_ring.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autolens as al\n",
        "import autofit as af\n",
        "from os import path"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initialization__\n",
        "\n",
        "The following steps repeat all the initial steps performed in tutorial 2 and 3:\n",
        "\n",
        "This data is not automatically provided with the autogalaxy workspace, and must be first simulated by running the \n",
        "script `autolens_workspace/scripts/simulators/imaging/samples/advanced/mass_power_law.py`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_label = \"samples\"\n",
        "dataset_type = \"imaging\"\n",
        "dataset_sample_name = \"double_einstein_ring\"\n",
        "\n",
        "dataset_path = path.join(\"dataset\", dataset_type, dataset_label, dataset_sample_name)\n",
        "\n",
        "total_datasets = 10\n",
        "\n",
        "dataset_list = []\n",
        "\n",
        "for dataset_index in range(total_datasets):\n",
        "    dataset_sample_path = path.join(dataset_path, f\"dataset_{dataset_index}\")\n",
        "\n",
        "    dataset_list.append(\n",
        "        al.Imaging.from_fits(\n",
        "            data_path=path.join(dataset_sample_path, \"data.fits\"),\n",
        "            psf_path=path.join(dataset_sample_path, \"psf.fits\"),\n",
        "            noise_map_path=path.join(dataset_sample_path, \"noise_map.fits\"),\n",
        "            pixel_scales=0.1,\n",
        "        )\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "masked_imaging_list = []\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    mask = al.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        "    )\n",
        "\n",
        "    masked_imaging_list.append(dataset.apply_mask(mask=mask))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Paths__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path_prefix = path.join(\"imaging\", \"hierarchical\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our model using `Model` objects, which represent the lenses we fit to our data.\n",
        "\n",
        "This graphical model creates a non-linear parameter space that has parameters for every lens and source galaxy in our \n",
        "sample. In this example, there are 3 lenses each with their own model, therefore:\n",
        "\n",
        " - The first lens galaxy's total mass distribution is an `Isothermal` [5 parameters].\n",
        " \n",
        " - The second lens / first source galaxy's light is a linear parametric `ExponentialSph` and its mass \n",
        " a `IsothermalSph` [6 parameters].\n",
        " \n",
        " - The second source galaxy's light is a linear parametric `ExponentialSph` [3 parameters].\n",
        "\n",
        " - There is a single cosmological shared free parameter, Omage_m [1 parameter]\n",
        "\n",
        " - There are ten strong lenses in our graphical model [(10 x 16) + 1 = 161 parameters]. \n",
        "\n",
        "The overall dimensionality of each parameter space fitted separately via EP is therefore N=17.\n",
        "\n",
        "In total, the graph has N = 10 x 16 + 1 = 161 free parameters, albeit EP knows the `Omage_k` is shared and fits it \n",
        "using EP.\n",
        "\n",
        "__CHEATING__\n",
        "\n",
        "Initializing a double Einstein ring lens model is extremely difficult, due to the complexity of parameter space. It is\n",
        "common to infer local maxima, which this script typically does if default priors on every model parameter are \n",
        "assumed.\n",
        "\n",
        "To ensure we infer the correct model, we therefore cheat and overwrite all of the priors of the model parameters to \n",
        "start centred on their true values.\n",
        "\n",
        "To model a double Einstein ring system without cheating (which is the only feasible strategy on real data), it is \n",
        "advised that **PyAutoLens**'s advanced feature of non-linear search chaining is used. The \n",
        "scripts `imaging/chaining/double_einstein_ring.py`  and `imaging/pipelines/double_einstein_ring.py` describe how to \n",
        "do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "shared_cosmology_parameter = af.GaussianPrior(\n",
        "    mean=0.3, sigma=0.3, lower_limit=0.0, upper_limit=1.0\n",
        ")\n",
        "\n",
        "model_list = []\n",
        "\n",
        "for model_index in range(total_datasets):\n",
        "    lens = af.Model(al.Galaxy, redshift=0.5, mass=al.mp.Isothermal)\n",
        "    source_0 = af.Model(\n",
        "        al.Galaxy,\n",
        "        redshift=1.0,\n",
        "        mass=al.mp.IsothermalSph,\n",
        "        bulge=al.lp_linear.ExponentialCoreSph,\n",
        "    )\n",
        "    source_1 = af.Model(al.Galaxy, redshift=2.0, bulge=al.lp_linear.ExponentialCoreSph)\n",
        "\n",
        "    lens.mass.centre_0 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "    lens.mass.centre_1 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "    lens.mass.ell_comps.ell_comps_0 = af.GaussianPrior(mean=0.052, sigma=0.1)\n",
        "    lens.mass.ell_comps.ell_comps_1 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "    lens.mass.einstein_radius = af.GaussianPrior(mean=1.5, sigma=0.2)\n",
        "\n",
        "    source_0.mass.centre_0 = af.GaussianPrior(mean=-0.15, sigma=0.2)\n",
        "    source_0.mass.centre_1 = af.GaussianPrior(mean=-0.15, sigma=0.2)\n",
        "    source_0.mass.einstein_radius = af.GaussianPrior(mean=0.4, sigma=0.1)\n",
        "    source_0.bulge.centre_0 = af.GaussianPrior(mean=-0.15, sigma=0.2)\n",
        "    source_0.bulge.centre_1 = af.GaussianPrior(mean=-0.15, sigma=0.2)\n",
        "    source_0.bulge.intensity = af.GaussianPrior(mean=1.2, sigma=0.5)\n",
        "    source_0.bulge.effective_radius = af.GaussianPrior(mean=0.1, sigma=0.1)\n",
        "\n",
        "    source_1.bulge.centre_0 = af.GaussianPrior(mean=0.0, sigma=0.2)\n",
        "    source_1.bulge.centre_1 = af.GaussianPrior(mean=0.0, sigma=0.2)\n",
        "    source_1.bulge.intensity = af.GaussianPrior(mean=0.6, sigma=0.3)\n",
        "    source_1.bulge.effective_radius = af.GaussianPrior(mean=0.07, sigma=0.07)\n",
        "\n",
        "    cosmology = af.Model(al.cosmo.FlatLambdaCDMWrap)\n",
        "    cosmology.Om0 = af.GaussianPrior(mean=0.3, sigma=0.1)\n",
        "\n",
        "    model = af.Collection(\n",
        "        galaxies=af.Collection(lens=lens, source_0=source_0, source_1=source_1),\n",
        "        cosmology=cosmology,\n",
        "    )\n",
        "\n",
        "    model_list.append(model)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = []\n",
        "\n",
        "for masked_dataset in masked_imaging_list:\n",
        "    analysis = al.AnalysisImaging(dataset=masked_dataset)\n",
        "\n",
        "    analysis_list.append(analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis Factors__\n",
        "\n",
        "Now we have our `Analysis` classes and graphical model, we can compose our `AnalysisFactor`'s, just like we did in the\n",
        "previous tutorial.\n",
        "\n",
        "However, unlike the previous tutorial, each `AnalysisFactor` is now assigned its own `search`. This is because the EP \n",
        "framework performs a model-fit to each node on the factor graph (e.g. each `AnalysisFactor`). Therefore, each node \n",
        "requires its own non-linear search. \n",
        "\n",
        "For complex graphs consisting of many  nodes, one could easily use different searches for different nodes on the factor \n",
        "graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Nautilus = af.Nautilus(\n",
        "    path_prefix=path.join(\"imaging\", \"hierarchical\"),\n",
        "    name=\"tutorial_6_science_case\",\n",
        "    n_live=150,\n",
        ")\n",
        "\n",
        "analysis_factor_list = []\n",
        "dataset_index = 0\n",
        "\n",
        "for model, analysis in zip(model_list, analysis_list):\n",
        "    dataset_name = f\"dataset_{dataset_index}\"\n",
        "    dataset_index += 1\n",
        "\n",
        "    analysis_factor = af.AnalysisFactor(\n",
        "        prior_model=model, analysis=analysis, optimiser=Nautilus, name=dataset_name\n",
        "    )\n",
        "\n",
        "    analysis_factor_list.append(analysis_factor)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We again combine our `AnalysisFactors` into one, to compose the factor graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "factor_graph = af.FactorGraphModel(*analysis_factor_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The factor graph model `info` attribute shows the complex model we are fitting, including both cosmological parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph.global_prior_model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Expectation Propagation__\n",
        "\n",
        "We perform the fit using EP as we did in tutorial 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "laplace = af.LaplaceOptimiser()\n",
        "\n",
        "paths = af.DirectoryPaths(name=path.join(path_prefix, \"tutorial_6_science_case\"))\n",
        "\n",
        "factor_graph_result = factor_graph.optimise(\n",
        "    optimiser=laplace, paths=paths, ep_history=af.EPHistory(kl_tol=0.05), max_steps=5\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output__\n",
        "\n",
        "The results of the factor graph, using the EP framework and message passing, are contained in the folder \n",
        "`output/graphical/imaging/tutorial_6_science_case`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "print(factor_graph_result)\n",
        "\n",
        "print(factor_graph_result.updated_ep_mean_field.mean_field)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output__\n",
        "\n",
        "The MeanField object representing the posterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph_result.updated_ep_mean_field.mean_field)\n",
        "print()\n",
        "\n",
        "print(factor_graph_result.updated_ep_mean_field.mean_field.variables)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The logpdf of the posterior at the point specified by the dictionary values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# factor_graph_result.updated_ep_mean_field.mean_field(values=None)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A dictionary of the mean with variables as keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph_result.updated_ep_mean_field.mean_field.mean)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A dictionary of the variance with variables as keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph_result.updated_ep_mean_field.mean_field.variance)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A dictionary of the s.d./variance**0.5 with variables as keys."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph_result.updated_ep_mean_field.mean_field.scale)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "self.updated_ep_mean_field.mean_field[v: Variable] gives the Message/approximation of the posterior for an \n",
        "individual variable of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# factor_graph_result.updated_ep_mean_field.mean_field[\"help\"]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}