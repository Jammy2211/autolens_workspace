{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Log Likelihood Function: Pixelization__\n",
        "\n",
        "This script provides a step-by-step guide of the **PyAutoLens** `log_likelihood_function` which is used to fit\n",
        "`Interferometer` data with an inversion (specifically a `Rectangular` mesh and `Constant` regularization scheme`).\n",
        "\n",
        "This script has the following aims:\n",
        "\n",
        " - To provide a resource that authors can include in papers using **PyAutoLens**, so that readers can understand the\n",
        " likelihood function (including references to the previous literature from which it is defined) without having to\n",
        " write large quantities of text and equations.\n",
        "\n",
        " - To make inversions in **PyAutoLens** less of a \"black-box\" to users.\n",
        "\n",
        "Accompanying this script is the `contributor_guide.py` which provides URL's to every part of the source-code that\n",
        "is illustrated in this guide. This gives contributors a sequential run through of what source-code functions, modules and\n",
        "packages are called when the likelihood is evaluated.\n",
        "\n",
        "__Prerequisites__\n",
        "\n",
        "The likelihood function of pixelizations is the most complicated likelihood function.\n",
        "\n",
        "It is advised you read through the following two simpler likelihood functions first, which break down a number of the\n",
        "concepts used in this script:\n",
        "\n",
        " - `interferometer/light_profile/log_likelihood_function.py` the likelihood function for a parametric light profile.\n",
        " - `imaging/linear_light_profile/log_likelihood_function.py` the likelihood function for a linear light profile, which\n",
        " introduces the linear algebra used for a pixelization but with a simpler use case.\n",
        "\n",
        "This script repeats all text and code examples in the above likelihood function examples. It therefore can be used to\n",
        "learn about the linear light profile likelihood function without reading other likelihood scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from os import path\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We define the \u2018real_space_mask\u2019 which defines the grid the image the galaxy is evaluated using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "real_space_mask = al.Mask2D.circular(\n",
        "    shape_native=(80, 80), pixel_scales=0.05, radius=4.0\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the galaxy `Interferometer` dataset `simple` from .fits files, which we will fit \n",
        "with the model.\n",
        "\n",
        "This includes the method used to Fourier transform the real-space image of the galaxy to the uv-plane and compare \n",
        "directly to the visibilities. We use a non-uniform fast Fourier transform, which is the most efficient method for \n",
        "interferometer datasets containing ~1-10 million visibilities. We will discuss how the calculation of the likelihood\n",
        "function changes for different methods of Fourier transforming in this guide."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"interferometer\", dataset_name)\n",
        "\n",
        "dataset = al.Interferometer.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    uv_wavelengths_path=path.join(dataset_path, \"uv_wavelengths.fits\"),\n",
        "    real_space_mask=real_space_mask,\n",
        "    transformer_class=al.TransformerDFT,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This guide uses in-built visualization tools for plotting. \n",
        "\n",
        "For example, using the `InterferometerPlotter` the dataset we perform a likelihood evaluation on is plotted.\n",
        "\n",
        "The `subplot_dataset` displays the visibilities in the uv-plane, which are the raw data of the interferometer\n",
        "dataset. These are what will ultimately be directly fitted in the Fourier space.\n",
        "\n",
        "The `subplot_dirty_images` displays the dirty images of the dataset, which are the reconstructed images of visibilities\n",
        "using an inverse Fourier transform to convert these to real-space. These dirty images are not the images we fit, but\n",
        "visualization of the dirty images are often used in radio interferometry to show the data in a way that is more\n",
        "interpretable to the human eye."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.InterferometerPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "dataset_plotter.subplot_dirty_images()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Over Sampling__\n",
        "\n",
        "Over sampling evaluates a light profile using multiple samples of its intensity per image-pixel.\n",
        "\n",
        "For simplicity, in previous likelihood function examples we disabled over sampling by setting `sub_size=1`. \n",
        "\n",
        "A full description of over sampling and how to use it is given in `autogalaxy_workspace/*/guides/over_sampling.py`.\n",
        "\n",
        "Over sampling is used for the same purpose in a pixelization, whereby it uses multiple samples of a pixel to\n",
        "perform the reconstruction via the pixelization. It uses an independent over sampling factor to the light profile\n",
        "over sampling factor, called `over_sample_size_pixelization`.\n",
        "\n",
        "However, for interferometer datasets, over sampling is not used in the pixelization (or for light profiles)\n",
        "therefore it is implicitly set to 1 and can be ignored hereafter.\n",
        "\n",
        "The notebook `log_likelihood_function/imaging/pixelization/with_over_sampling.ipynb` describes how the likelihood\n",
        "function of a pixelization changes when over sampling is used.\n",
        "\n",
        "__Masked Image Grid__\n",
        "\n",
        "To perform galaxy calculations we define a 2D image-plane grid of (y,x) coordinates.\n",
        "\n",
        "For light profiles these are given by `dataset.lp`, which is a uniform grid of (y,x) Cartesian coordinates\n",
        "which have had the 3.0\" circular mask applied.\n",
        "\n",
        "A pixelization uses a separate grid of (y,x) coordinates, called `dataset.grids.pixelization`, which is\n",
        "identical to the light profile grid but may of had a different over-sampling scale applied (but in this example\n",
        "does not).\n",
        "\n",
        "Each (y,x) coordinate coordinates to the centre of each image-pixel in the dataset, meaning that when this grid is\n",
        "used to construct a pixelization there is a straight forward mapping between the image data and pixelization pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_plotter = aplt.Grid2DPlotter(grid=dataset.grids.pixelization)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Setup: Galaxy__\n",
        "\n",
        "We combine the pixelization into a single `Galaxy` object.\n",
        "\n",
        "The galaxy includes the rectangular mesh and constant regularization scheme, which will ultimately be used\n",
        "to reconstruct its star forming clumps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    mesh=al.mesh.Rectangular(shape=(30, 30)),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "galaxy = al.Galaxy(redshift=0.5, pixelization=pixelization)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Rectangular Mesh__\n",
        "\n",
        "The pixelization is used to create the rectangular mesh which is used to reconstruct the galaxy.\n",
        "\n",
        "The function below does this by overlaying the rectangular mesh over the masked image grid, such that the edges of\n",
        "the rectangular mesh touch the ask grid's edges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_rectangular = al.Mesh2DRectangular.overlay_grid(\n",
        "    shape_native=galaxy.pixelization.mesh.shape, grid=dataset.grids.pixelization\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The rectangular mesh will now be referred to interchangeably as the `source-plane`, to represent that it is a \n",
        "pixelization which will reconstruct a source of light,\n",
        "\n",
        "Plotting the rectangular mesh shows that the source-plane has been discretized into a grid of rectangular pixels.\n",
        "\n",
        "(To plot the rectangular mesh, we have to convert it to a `Mapper` object, which is described in the next likelihood \n",
        "step).\n",
        "\n",
        "Below, we plot the rectangular mesh without the image-grid pixels (for clarity) and with them as black dots in order\n",
        "to show how each set of image-pixels fall within a rectangular pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_grids = al.MapperGrids(\n",
        "    mask=real_space_mask,\n",
        "    source_plane_data_grid=dataset.grids.pixelization,\n",
        "    source_plane_mesh_grid=grid_rectangular,\n",
        ")\n",
        "\n",
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "include = aplt.Include2D(mapper_source_plane_data_grid=False)\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper, include_2d=include)\n",
        "mapper_plotter.figure_2d()\n",
        "\n",
        "include = aplt.Include2D(mapper_source_plane_data_grid=True)\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper, include_2d=include)\n",
        "mapper_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Image-Source Mapping__\n",
        "\n",
        "We now combine grids computed above to create a `Mapper`, which describes how every masked image grid pixel maps to\n",
        "every rectangular pixelization pixel. \n",
        "\n",
        "There are two steps in this calculation, which we show individually below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_grids = al.MapperGrids(\n",
        "    mask=real_space_mask,\n",
        "    source_plane_data_grid=dataset.grids.pixelization,\n",
        "    source_plane_mesh_grid=grid_rectangular,\n",
        ")\n",
        "\n",
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Mapper` contains:\n",
        "\n",
        " 1) `source_plane_data_grid`: the grid of masked (y,x) image-pixel coordinate centres (`dataset.grids.pixelization`).\n",
        " 2) `source_plane_mesh_grid`: The rectangular mesh of (y,x) pixelization pixel coordinates (`grid_rectangular`).\n",
        "\n",
        "We have therefore discretized the source-plane into a rectangular mesh, and can pair every image-pixel coordinate\n",
        "with the corresponding rectangular pixel it lands in.\n",
        "\n",
        "This pairing is contained in the ndarray `pix_indexes_for_sub_slim_index` which maps every image-pixel index to \n",
        "every pixelization pixel index.\n",
        "\n",
        "In the API, the `pix_indexes` refers to the pixelization pixel indexes (e.g. rectangular pixel 0, 1, 2 etc.) \n",
        "and `sub_slim_index`  refers to the index of an image pixel (e.g. image-pixel 0, 1, 2 etc.). \n",
        "\n",
        "For example, printing the first ten entries of `pix_indexes_for_sub_slim_index` shows the first ten rectanfgular \n",
        "pixelization pixel indexes these image sub-pixels map too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pix_indexes_for_sub_slim_index = mapper.pix_indexes_for_sub_slim_index\n",
        "\n",
        "print(pix_indexes_for_sub_slim_index[0:9])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This array can be used to visualize how an input list of image-pixel indexes map to the rectangular pixelization.\n",
        "\n",
        "It also shows that image-pixel indexing begins from the top-left and goes rightwards and downwards, accounting for \n",
        "all image-pixels which are not masked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "include = aplt.Include2D(mapper_source_plane_data_grid=False)\n",
        "\n",
        "visuals = aplt.Visuals2D(indexes=[list(range(2050, 2090))])\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(\n",
        "    mapper=mapper, visuals_2d=visuals, include_2d=include\n",
        ")\n",
        "mapper_plotter.subplot_image_and_mapper(\n",
        "    image=dataset.dirty_image, interpolate_to_uniform=False\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The reverse mappings of pixelization pixels to image-pixels can also be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(pix_indexes=[[200]])\n",
        "mapper_plotter = aplt.MapperPlotter(\n",
        "    mapper=mapper, visuals_2d=visuals, include_2d=include\n",
        ")\n",
        "\n",
        "mapper_plotter.subplot_image_and_mapper(\n",
        "    image=dataset.dirty_image, interpolate_to_uniform=False\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapping Matrix__\n",
        "\n",
        "The `mapping_matrix` represents the image-pixel to pixelization-pixel mappings above in a 2D matrix. \n",
        "\n",
        "It has dimensions `(total_image_pixels, total_rectangular_pixels)`.\n",
        "\n",
        "(A number of inputs are not used for the `Rectangular` mesh and are expanded upon in the `with_interpolation.ipynb`\n",
        "log likelihood guide notebook)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapping_matrix = al.util.mapper.mapping_matrix_from(\n",
        "    pix_indexes_for_sub_slim_index=pix_indexes_for_sub_slim_index,\n",
        "    pix_size_for_sub_slim_index=mapper.pix_sizes_for_sub_slim_index,  # unused for rectangular\n",
        "    pix_weights_for_sub_slim_index=mapper.pix_weights_for_sub_slim_index,  # unused for rectangular\n",
        "    pixels=mapper.pixels,\n",
        "    total_mask_pixels=mapper.source_plane_data_grid.mask.pixels_in_mask,\n",
        "    slim_index_for_sub_slim_index=mapper.slim_index_for_sub_slim_index,\n",
        "    sub_fraction=np.array(mapper.over_sampler.sub_fraction),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A 2D plot of the `mapping_matrix` shows of all image-pixelization pixel mappings.\n",
        "\n",
        "No row of pixels has more than one non-zero entry. It is not possible for two image pixels to map to the same \n",
        "pixelization pixel (meaning that there are no correlated pixels in the mapping matrix)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(mapping_matrix, aspect=(mapping_matrix.shape[1] / mapping_matrix.shape[0]))\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each column of the `mapping_matrix` can therefore be used to show all image-pixels it maps too. \n",
        "\n",
        "For example, above, we plotted all image-pixels of pixelization pixel 200 (as well as 202 and 204). We can extract all\n",
        "image-pixel indexes of pixelization pixels 200 using the `mapping_matrix` and use them to plot the image of this\n",
        "pixelization pixel (which corresponds to only values of zeros or ones)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "indexes_pix_200 = np.nonzero(mapping_matrix[:, 200])\n",
        "\n",
        "print(indexes_pix_200[0])\n",
        "\n",
        "array_2d = al.Array2D(values=mapping_matrix[:, 200], mask=dataset.mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Transformed Mapping Matrix ($f$)__\n",
        "\n",
        "Each pixelization pixel can therefore be thought of as an image (where all entries of this image are zeros and ones). \n",
        "\n",
        "However, for interferometer datasets we want to fit the visibilities in the uv-plane, not the image-plane. Therefore,\n",
        "each image in the `mapping_matrix` must be transformed to the uv-plane via a Fourier transform, such that each\n",
        "column in the `transformed_mapping_matrix` represents the visibilities in the uv-plane of each pixelization pixel.\n",
        "\n",
        "This operation changes the dimensions of the mapping matrix, meaning the `transformed_mapping_matrix` has\n",
        "dimensions `(total_image_pixels, total_visibilities)`. \n",
        "\n",
        "If the number of visibilities is large (e.g. 10^6) this matrix becomes extremely large and computationally expensive to \n",
        "store memory, meaning the `w_tilde` likelihood function, described in \n",
        "the `/log_likelihood_function/interferometer/`w_tilde.ipynb` notebook must be used instead.\n",
        "\n",
        "The `transformed_mapping_matrix` is also complex, storing all entries of the visibilities after the NUFFT as real\n",
        "and complex values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "transformed_mapping_matrix = dataset.transformer.transform_mapping_matrix(\n",
        "    mapping_matrix=mapping_matrix\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A 2D plot of the `transformed_mapping_matrix` shows all visibility-source pixel mappings.\n",
        "\n",
        "Note how, unlike for the `mapping_matrix`, every row of image-pixels fully consists of non-zero entries. This\n",
        "means the matrix is fully dense, making it even more difficult to store in memory for large datasets.\n",
        "\n",
        "Below, we plot the real and imaginary components of the `transformed_mapping_matrix` separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(\n",
        "    transformed_mapping_matrix.real,\n",
        "    aspect=(transformed_mapping_matrix.shape[1] / transformed_mapping_matrix.shape[0]),\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "plt.imshow(\n",
        "    transformed_mapping_matrix.imag,\n",
        "    aspect=(transformed_mapping_matrix.shape[1] / transformed_mapping_matrix.shape[0]),\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each column of the `transformed_mapping_matrix` shows all visibilities it maps to after the NUFFT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "indexes_pix_200 = np.nonzero(transformed_mapping_matrix[:, 200])\n",
        "\n",
        "print(indexes_pix_200[0])\n",
        "\n",
        "visibilities = al.Visibilities(visibilities=transformed_mapping_matrix[:, 200])\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=visibilities.in_grid)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In Warren & Dye 2003 (https://arxiv.org/abs/astro-ph/0302587) the `transformed_mapping_matrix` is denoted $f_{ij}$\n",
        "where $i$ maps over all $I$ source pixels and $j$ maps over all $J$ visibilities. \n",
        "\n",
        "For example: \n",
        "\n",
        " - $f_{0, 2} = 0.3$ indicates that visibility number $2$ maps to pixelization pixel $0$ with a weight of $0.3$ after the NUFFT.\n",
        "\n",
        "The indexing of the `mapping_matrix` is reversed compared to the notation of WD03 (e.g. visibilities\n",
        "are the first entry of `mapping_matrix` whereas for $f$ they are the second index)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Mapping between visibility 0 and rectangular pixel 2 = {mapping_matrix[0, 2]}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data Vector (D)__\n",
        "\n",
        "To solve for the rectangular pixel fluxes we now pose the problem as a linear inversion.\n",
        "\n",
        "This requires us to convert the `transformed_mapping_matrix` and our `data` and `noise map` into matrices of certain dimensions. \n",
        "\n",
        "The `data_vector`, $D$, is the first matrix and it has dimensions `(total_rectangular_pixels,)`.\n",
        "\n",
        "In WD03 (https://arxiv.org/abs/astro-ph/0302587) and N15 (https://arxiv.org/abs/1412.7436) the data vector \n",
        "is give by: \n",
        "\n",
        " $\\vec{D}_{i} = \\sum_{\\rm  j=1}^{J}f_{ij}(d_{j})/\\sigma_{j}^2 \\, \\, .$\n",
        "\n",
        "Where:\n",
        "\n",
        " - $d_{\\rm j}$ are the image-pixel data flux values.\n",
        " - $\\sigma{\\rm _j}^2$ are the statistical uncertainties of each image-pixel value.\n",
        "\n",
        "$i$ maps over all $I$ source pixels and $j$ maps over all $J$ image pixels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_vector = (\n",
        "    al.util.inversion_interferometer.data_vector_via_transformed_mapping_matrix_from(\n",
        "        transformed_mapping_matrix=transformed_mapping_matrix,\n",
        "        visibilities=np.array(dataset.data),\n",
        "        noise_map=np.array(dataset.noise_map),\n",
        "    )\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$D$ describes which rectangular pixels trace to which visibilities, with associated weights, after the NUFFT. This \n",
        "ensures the reconstruction fully accounts for the NUFFT when fitting the data.\n",
        "\n",
        "We can plot $D$ as a column vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(\n",
        "    data_vector.reshape(data_vector.shape[0], 1), aspect=10.0 / data_vector.shape[0]\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dimensions of $D$ are the number of source pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Data Vector:\")\n",
        "print(data_vector)\n",
        "print(data_vector.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Curvature Matrix (F)__\n",
        "\n",
        "The `curvature_matrix` $F$ is the second matrix and it has \n",
        "dimensions `(total_rectangular_pixels, total_rectangular_pixels)`.\n",
        "\n",
        "In WD03 / N15 (https://arxiv.org/abs/astro-ph/0302587) the curvature matrix is a 2D matrix given by:\n",
        "\n",
        " ${F}_{ik} = \\sum_{\\rm  j=1}^{J}f_{ij}f_{kj}/\\sigma_{j}^2 \\, \\, .$\n",
        "\n",
        "NOTE: this notation implicitly assumes a summation over $K$, where $k$ runs over all pixelization pixel indexes $K$.\n",
        "\n",
        "Note how summation over $J$ runs over $f$ twice, such that every entry of $F$ is the sum of the multiplication\n",
        "between all values in every two columns of $f$.\n",
        "\n",
        "For example, $F_{0,1}$ is the sum of all visibility values in $f$ of source pixel 0 multiplied by\n",
        "all visibility values of source pixel 1.\n",
        "\n",
        "Visibilities are both real and complex values, and the `curvature_matrix` is computed separately for the real and\n",
        "imaginary components of the visibilities and then summed together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "real_curvature_matrix = al.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=transformed_mapping_matrix.real,\n",
        "    noise_map=dataset.noise_map.real,\n",
        ")\n",
        "\n",
        "imag_curvature_matrix = al.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=transformed_mapping_matrix.imag,\n",
        "    noise_map=dataset.noise_map.imag,\n",
        ")\n",
        "\n",
        "curvature_matrix = np.add(real_curvature_matrix, imag_curvature_matrix)\n",
        "\n",
        "plt.imshow(curvature_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For $F_{ik}$ to be non-zero, this requires that the images of rectangular pixels $i$ and $k$ share at least one\n",
        "image-pixel, which for visibilities after the NUFFT is always true for all $i$ and $k$.\n",
        "\n",
        "For example, we can see a non-zero entry for $F_{100,101}$ and plotting their images\n",
        "show overlap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_pixel_0 = 0\n",
        "source_pixel_1 = 1\n",
        "\n",
        "print(curvature_matrix[source_pixel_0, source_pixel_1])\n",
        "\n",
        "visibilities = al.Visibilities(\n",
        "    visibilities=transformed_mapping_matrix[:, source_pixel_0],\n",
        ")\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=visibilities.in_grid)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "visibilities = al.Visibilities(\n",
        "    visibilities=transformed_mapping_matrix[:, source_pixel_1],\n",
        ")\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=visibilities.in_grid)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following chi-squared is minimized when we perform the inversion and reconstruct the galaxy:\n",
        "\n",
        "$\\chi^2 = \\sum_{\\rm  j=1}^{J} \\bigg[ \\frac{(\\sum_{\\rm  i=1}^{I} s_{i} f_{ij}) - d_{j}}{\\sigma_{j}} \\bigg]$\n",
        "\n",
        "Where $s$ is the reconstructed pixel fluxes in all $I$ rectangular pixels.\n",
        "\n",
        "The solution for $s$ is therefore given by (equation 5 WD03):\n",
        "\n",
        " $s = F^{-1} D$\n",
        "\n",
        "We can compute this using NumPy linear algebra:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Because we are no using regularizartion (see below) it is common for the curvature matrix to be singular and lead\n",
        "# to a LinAlgException. The loop below mitigates this -- you can ignore it as it is not important for understanding\n",
        "# the PyAutoLens likelihood function.\n",
        "\n",
        "for i in range(curvature_matrix.shape[0]):\n",
        "    curvature_matrix[i, i] += 1e-8\n",
        "\n",
        "reconstruction = np.linalg.solve(curvature_matrix, data_vector)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot this reconstruction -- it looks like a mess.\n",
        "\n",
        "The pixelization pixels have noisy and unsmooth values, and it is hard to make out if a galaxy is even being \n",
        "reconstructed. \n",
        "\n",
        "In fact, the linear inversion is (over-)fitting noise in the image data, meaning this system of equations is \n",
        "ill-posed. We need to apply some form of smoothing on the reconstruction to avoid over fitting noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "\n",
        "mapper_plotter.figure_2d(solution_vector=reconstruction, interpolate_to_uniform=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Regularization Matrix (H)__\n",
        "\n",
        "Regularization adds a linear regularization term $G_{\\rm L}$ to the $\\chi^2$ we solve for giving us a new merit \n",
        "function $G$ (equation 11 WD03):\n",
        "\n",
        " $G = \\chi^2 + \\lambda \\, G_{\\rm L}$\n",
        "\n",
        "where $\\lambda$ is the `regularization_coefficient` which describes the magnitude of smoothness that is applied. A \n",
        "higher $\\lambda$ will regularize the source more, leading to a smoother galaxy reconstruction.\n",
        "\n",
        "Different forms for $G_{\\rm L}$ can be defined which regularize the reconstruction in different ways. The \n",
        "`Constant` regularization scheme used in this example applies gradient regularization (equation 14 WD03):\n",
        "\n",
        " $G_{\\rm L} = \\sum_{\\rm  i}^{I} \\sum_{\\rm  n=1}^{N}  [s_{i} - s_{i, v}]$\n",
        "\n",
        "This regularization scheme is easier to express in words -- the summation goes to each rectangular pixelization pixel,\n",
        "determines all rectangular pixels with which it shares a direct vertex (e.g. its neighbors) and penalizes solutions \n",
        "where the difference in reconstructed flux of these two neighboring pixels is large.\n",
        "\n",
        "The summation does this for all rectangular pixels, thus it favours solutions where neighboring rectangular \n",
        "pixels reconstruct similar values to one another (e.g. it favours a smooth galaxy reconstruction).\n",
        "\n",
        "We now define the `regularization matrix`, $H$, which allows us to include this smoothing when we solve for $s$. $H$\n",
        "has dimensions `(total_rectangular_pixels, total_rectangular_pixels)`.\n",
        "\n",
        "This relates to $G_{\\rm L}$ as (equation 13 WD03):\n",
        "\n",
        " $H_{ik} = \\frac{1}{2} \\frac{\\partial G_{\\rm L}}{\\partial s_{i} \\partial s_{k}}$\n",
        "\n",
        "$H$ has the `regularization_coefficient` $\\lambda$ folded into it such $\\lambda$'s control on the degree of smoothing\n",
        "is accounted for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "regularization_matrix = al.util.regularization.constant_regularization_matrix_from(\n",
        "    coefficient=galaxy.pixelization.regularization.coefficient,\n",
        "    neighbors=mapper.source_plane_mesh_grid.neighbors,\n",
        "    neighbors_sizes=mapper.source_plane_mesh_grid.neighbors.sizes,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the regularization matrix and note that:\n",
        "\n",
        " - non-zero entries indicate that two rectangular pixelization pixels are neighbors and therefore are regularized \n",
        " with one another.\n",
        "\n",
        " - Zeros indicate the two rectangular pixels do not neighbor one another.\n",
        "\n",
        "The majority of entries are zero, because the majority of rectangular pixels are not neighbors with one another."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(regularization_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__F + Lamdba H__\n",
        "\n",
        "$H$ enters the linear algebra system we solve for as follows (WD03 equation (12)):\n",
        "\n",
        " $s = [F + H]^{-1} D$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "curvature_reg_matrix = np.add(curvature_matrix, regularization_matrix)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Galaxy Reconstruction (s)__\n",
        "\n",
        "We can now solve the linear system above using NumPy linear algebra. \n",
        "\n",
        "Note that the for loop used above to prevent a LinAlgException is no longer required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "reconstruction = np.linalg.solve(curvature_reg_matrix, data_vector)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting this galaxy reconstruction we can see that regularization has lead us to reconstruct a smoother galaxy,\n",
        "which actually looks like the star forming clumps in the galaxy imaging data! \n",
        "\n",
        "This also implies we are not over-fitting the noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "\n",
        "mapper_plotter.figure_2d(solution_vector=reconstruction, interpolate_to_uniform=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Visibilities Reconstruction__\n",
        "\n",
        "Using the reconstructed pixel fluxes we can map the reconstruction back to the image plane (via \n",
        "the `blurred mapping_matrix`) and produce a reconstruction of the image data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapped_reconstructed_visibilities = (\n",
        "    al.util.inversion_interferometer.mapped_reconstructed_visibilities_from(\n",
        "        transformed_mapping_matrix=transformed_mapping_matrix,\n",
        "        reconstruction=reconstruction,\n",
        "    )\n",
        ")\n",
        "\n",
        "mapped_reconstructed_visibilities = al.Visibilities(\n",
        "    visibilities=mapped_reconstructed_visibilities\n",
        ")\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=mapped_reconstructed_visibilities.in_grid)\n",
        "grid_plotter.figure_2d()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Function__\n",
        "\n",
        "We now quantify the goodness-of-fit of our pixelization galaxy reconstruction. \n",
        "\n",
        "We compute the `log_likelihood` of the fit, which is the value returned by the `log_likelihood_function`.\n",
        "\n",
        "The likelihood function for galaxy modeling consists of five terms:\n",
        "\n",
        " $-2 \\mathrm{ln} \\, \\epsilon = \\chi^2 + s^{T} H s + \\mathrm{ln} \\, \\left[ \\mathrm{det} (F + H) \\right] - { \\mathrm{ln}} \\, \\left[ \\mathrm{det} (H) \\right] + \\sum_{\\rm  j=1}^{J} { \\mathrm{ln}} \\left [2 \\pi (\\sigma_j)^2 \\right]  \\, .$\n",
        "\n",
        "This expression was first derived by Suyu 2006 (https://arxiv.org/abs/astro-ph/0601493) and is given by equation (19).\n",
        "It was derived into **PyAutoLens** notation in Dye 2008 (https://arxiv.org/abs/0804.4002) equation (5).\n",
        "\n",
        "We now explain what each of these terms mean.\n",
        "\n",
        "__Chi Squared__\n",
        "\n",
        "The first term is a $\\chi^2$ statistic, which is defined above in our merit function as and is computed as follows:\n",
        "\n",
        " - `model_data` = `mapped_reconstructed_visibilities`\n",
        " - `residual_map` = (`data` - `model_data`)\n",
        " - `normalized_residual_map` = (`data` - `model_data`) / `noise_map`\n",
        " - `chi_squared_map` = (`normalized_residuals`) ** 2.0 = ((`data` - `model_data`)**2.0)/(`variances`)\n",
        " - `chi_squared` = sum(`chi_squared_map`)\n",
        "\n",
        "The chi-squared therefore quantifies if our fit to the data is accurate or not. \n",
        "\n",
        "High values of chi-squared indicate that there are many image pixels our model did not produce a good fit to the image \n",
        "for, corresponding to a fit with a lower likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_visibilities = mapped_reconstructed_visibilities\n",
        "\n",
        "residual_map = dataset.data - model_visibilities\n",
        "\n",
        "\n",
        "normalized_residual_map_real = (residual_map.real / dataset.noise_map.real).astype(\n",
        "    \"complex128\"\n",
        ")\n",
        "normalized_residual_map_imag = (residual_map.imag / dataset.noise_map.imag).astype(\n",
        "    \"complex128\"\n",
        ")\n",
        "normalized_residual_map = (\n",
        "    normalized_residual_map_real + 1j * normalized_residual_map_imag\n",
        ")\n",
        "\n",
        "\n",
        "chi_squared_map_real = (residual_map.real / dataset.noise_map.real) ** 2\n",
        "chi_squared_map_imag = (residual_map.imag / dataset.noise_map.imag) ** 2\n",
        "chi_squared_map = chi_squared_map_real + 1j * chi_squared_map_imag\n",
        "\n",
        "\n",
        "chi_squared_real = np.sum(chi_squared_map.real)\n",
        "chi_squared_imag = np.sum(chi_squared_map.imag)\n",
        "chi_squared = chi_squared_real + chi_squared_imag\n",
        "\n",
        "print(chi_squared)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `chi_squared_map` indicates which regions of the image we did and did not fit accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "chi_squared_map = al.Visibilities(visibilities=chi_squared_map)\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=chi_squared_map.in_grid)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Regularization Term__\n",
        "\n",
        "The second term, $s^{T} H s$, corresponds to the $\\lambda $G_{\\rm L}$ regularization term we added to our merit \n",
        "function above.\n",
        "\n",
        "This is the term which sums up the difference in flux of all reconstructed rectangular pixels, and reduces the \n",
        "likelihood of solutions where there are large differences in flux (e.g. the galaxy is less smooth and more likely to be \n",
        "overfitting noise).\n",
        "\n",
        "We compute it below via matrix multiplication, noting that the `regularization_coefficient`, $\\lambda$, is built into \n",
        "the `regularization_matrix` already."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "regularization_term = np.matmul(\n",
        "    reconstruction.T, np.matmul(regularization_matrix, reconstruction)\n",
        ")\n",
        "\n",
        "print(regularization_term)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Complexity Terms__\n",
        "\n",
        "Up to this point, it is unclear why we chose a value of `regularization_coefficient=1.0`. \n",
        "\n",
        "We cannot rely on the `chi_squared` and `regularization_term` above to optimally choose its value, because increasing \n",
        "the `regularization_coefficient` smooths the solution more and therefore:\n",
        "\n",
        " - Decreases `chi_squared` by fitting the data worse, producing a lower `log_likelihood`.\n",
        "\n",
        " - Increases the `regularization_term` by penalizing the differences between source pixel fluxes more, again reducing\n",
        " the inferred `log_likelihood`.\n",
        "\n",
        "If we set the regularization coefficient based purely on these two terms, we would set a value of 0.0 and be back where\n",
        "we started over-fitting noise!\n",
        "\n",
        "The terms $\\left[ \\mathrm{det} (F + H) \\right]$ and $ - { \\mathrm{ln}} \\, \\left[ \\mathrm{det} (H) \\right]$ address \n",
        "this problem. \n",
        "\n",
        "They quantify how complex the reconstruction is, and penalize solutions where *it is more complex*. Reducing \n",
        "the `regularization_coefficient` makes the galaxy reconstruction more complex (because a galaxy that is \n",
        "smoothed less uses more flexibility to fit the data better).\n",
        "\n",
        "These two terms therefore counteract the `chi_squared` and `regularization_term`, so as to attribute a higher\n",
        "`log_likelihood` to solutions which fit the data with a more smoothed and less complex source (e.g. one with a higher \n",
        "`regularization_coefficient`).\n",
        "\n",
        "In **HowToGalaxy** -> `chapter 4` -> `tutorial_4_bayesian_regularization` we expand on this further and give a more\n",
        "detailed description of how these different terms impact the `log_likelihood_function`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_curvature_reg_matrix_term = np.linalg.slogdet(curvature_reg_matrix)[1]\n",
        "log_regularization_matrix_term = np.linalg.slogdet(regularization_matrix)[1]\n",
        "\n",
        "print(log_curvature_reg_matrix_term)\n",
        "print(log_regularization_matrix_term)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Noise Normalization Term__\n",
        "\n",
        "Our likelihood function assumes the imaging data consists of independent Gaussian noise in every image pixel.\n",
        "\n",
        "The final term ins the likelihood function is therefore a `noise_normalization` term, which consists of the sum\n",
        "of the log of every noise-map value squared. \n",
        "\n",
        "Given the `noise_map` is fixed, this term does not change during the galaxy modeling process and has no impact on the \n",
        "model we infer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "noise_normalization_real = np.sum(np.log(2 * np.pi * dataset.noise_map.real**2.0))\n",
        "noise_normalization_imag = np.sum(np.log(2 * np.pi * dataset.noise_map.imag**2.0))\n",
        "noise_normalization = noise_normalization_real + noise_normalization_imag"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Calculate The Log Likelihood__\n",
        "\n",
        "We can now, finally, compute the `log_likelihood` of the galaxy model, by combining the five terms computed above using\n",
        "the likelihood function defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_evidence = float(\n",
        "    -0.5\n",
        "    * (\n",
        "        chi_squared\n",
        "        + regularization_term\n",
        "        + log_curvature_reg_matrix_term\n",
        "        - log_regularization_matrix_term\n",
        "        + noise_normalization\n",
        "    )\n",
        ")\n",
        "\n",
        "print(log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "This process to perform a likelihood function evaluation performed via the `FitInterferometer` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxies = al.Galaxies(galaxies=[galaxy])\n",
        "\n",
        "fit = al.FitInterferometer(\n",
        "    dataset=dataset,\n",
        "    galaxies=galaxies,\n",
        "    settings_inversion=al.SettingsInversion(\n",
        "        use_w_tilde=False, use_border_relocator=True\n",
        "    ),\n",
        ")\n",
        "fit_log_evidence = fit.log_evidence\n",
        "print(fit_log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Galaxy Modeling__\n",
        "\n",
        "To fit a galaxy model to data, the likelihood function illustrated in this tutorial is sampled using a\n",
        "non-linear search algorithm.\n",
        "\n",
        "The default sampler is the nested sampling algorithm `nautilus` (https://github.com/joshspeagle/nautilus)\n",
        "but **PyAutoLens** supports multiple MCMC and optimization algorithms. \n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "We have presented a visual step-by-step guide to the pixelization likelihood function.\n",
        "\n",
        "There are a number of other inputs features which slightly change the behaviour of this likelihood function, which\n",
        "are described in additional notebooks found in this package. In brief, these describe:\n",
        "\n",
        " - **Over Sampling**: Oversampling the image grid into a finer grid of sub-pixels, which are all individually \n",
        " paired fractionally with each rectangular pixel.\n",
        "\n",
        " - **Source-plane Interpolation**: Using bilinear interpolation on the rectangular pixelization to pair each \n",
        " image (sub-)pixel to multiple rectangular pixels with interpolation weights.\n",
        "\n",
        " - **Luminosity Weighted Regularization**: Using an adaptive regularization coefficient which adapts the level of \n",
        " regularization applied to the galaxy based on its luminosity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}