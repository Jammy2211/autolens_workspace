{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Log Likelihood Function: Linear Light Profile__\n",
        "\n",
        "This script provides a step-by-step guide of the `log_likelihood_function` which is used to fit `Imaging` data with\n",
        "parametric linear light profiles (e.g. a Sersic bulge and Exponential disk).\n",
        "\n",
        "A \"linear light profile\" is a variant of a standard light profile where the `intensity` parameter is solved for\n",
        "via linear algebra every time the model is fitted to the data. This uses a process called an \"inversion\" and it\n",
        "always computes the `intensity` values that give the best fit to the data (e.g. maximize the likelihood)\n",
        "given the light profile's other parameters.\n",
        "\n",
        "This script has the following aims:\n",
        "\n",
        " - To provide a resource that authors can include in papers, so that readers can understand the likelihood\n",
        " function (including references to the previous literature from which it is defined) without having to\n",
        " write large quantities of text and equations.\n",
        "\n",
        "Accompanying this script is the `contributor_guide.py` which provides URL's to every part of the source-code that\n",
        "is illustrated in this guide. This gives contributors a sequential run through of what source-code functions, modules and\n",
        "packages are called when the likelihood is evaluated.\n",
        "\n",
        "__Prerequisites__\n",
        "\n",
        "The likelihood function of a linear light profile builds on that used for standard parametric light profiles,\n",
        "therefore you must read the following notebooks before this script:\n",
        "\n",
        "- `light_profile/log_likelihood_function.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Following the `light_profile/log_likelihood_function.py` script, we load and mask an `Imaging` dataset and\n",
        "set oversampling to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = Path(\"dataset\", \"imaging\", \"simple\")\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "masked_dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "masked_dataset = masked_dataset.apply_over_sampling(over_sample_size_lp=1)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=masked_dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Masked Image Grid__\n",
        "\n",
        "To perform galaxy calculations we used a 2D image-plane grid of (y,x) coordinates, which evaluated the\n",
        "emission of galaxy light profiles created as `LightProfile` objects.\n",
        "\n",
        "The code below repeats that used in `light_profile/log_likelihood_function.py` to show how this was done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = al.lp.Sersic(\n",
        "    centre=(0.0, 0.0),\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    intensity=4.0,\n",
        "    effective_radius=0.6,\n",
        "    sersic_index=3.0,\n",
        ")\n",
        "\n",
        "mass = al.mp.Isothermal(\n",
        "    centre=(0.0, 0.0),\n",
        "    einstein_radius=1.6,\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        ")\n",
        "\n",
        "shear = al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05)\n",
        "\n",
        "lens_galaxy = al.Galaxy(redshift=0.5, bulge=bulge, mass=mass, shear=shear)\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp.SersicCore(\n",
        "        centre=(0.0, 0.0),\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.8, angle=60.0),\n",
        "        intensity=4.0,\n",
        "        effective_radius=0.1,\n",
        "        sersic_index=1.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "image = tracer.image_2d_from(grid=masked_dataset.grids.lp)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Linear Light Profiles__\n",
        "\n",
        "To use a linear light profile, whose `intensity` is computed via linear algebra, we simply use the `lp_Linear`\n",
        "module instead of the `lp` module used throughout other example scripts. \n",
        "\n",
        "The `intensity` parameter of the light profile is no longer passed into the light profiles created via the\n",
        "`lp_linear` module, as it is inferred via linear algebra.\n",
        "\n",
        "In this example, we assume our galaxy is composed of two light profiles, an elliptical Sersic and Exponential (a Sersic\n",
        "where `sersic_index=4`) which represent the bulge and disk of the galaxy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = al.lp_linear.Sersic(\n",
        "    centre=(0.0, 0.0),\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    effective_radius=0.6,\n",
        "    sersic_index=3.0,\n",
        ")\n",
        "\n",
        "mass = al.mp.Isothermal(\n",
        "    centre=(0.0, 0.0),\n",
        "    einstein_radius=1.6,\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        ")\n",
        "\n",
        "shear = al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05)\n",
        "\n",
        "lens_galaxy = al.Galaxy(redshift=0.5, bulge=bulge, mass=mass, shear=shear)\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp_linear.SersicCore(\n",
        "        centre=(0.0, 0.0),\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.8, angle=60.0),\n",
        "        effective_radius=0.1,\n",
        "        sersic_index=1.0,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Internally in the source code, linear light profiles have an `intensity` parameter, but its value is always set to \n",
        "1.0. It will be clear why this is later in the script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Bulge Internal Intensity:\")\n",
        "print(lens_galaxy.bulge.intensity)\n",
        "\n",
        "print(\"Disk Internal Intensity:\")\n",
        "print(source_galaxy.bulge.intensity)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Like standard light profiles, we can compute images of each linear light profile, but their overall\n",
        "normalization is arbitrary given that the internal `intensity` value of 1.0 is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_2d_bulge = lens_galaxy.bulge.image_2d_from(grid=masked_dataset.grid)\n",
        "image_2d_disk = source_galaxy.bulge.image_2d_from(grid=masked_dataset.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we try and plot a linear light profile using a plotter, an exception is raised.\n",
        "\n",
        "This is to ensure that a user does not plot and interpret the intensity of a linear light profile, as it is not a\n",
        "physical quantity. Plotting only works after a linear light profile has had its `intensity` computed via linear\n",
        "algebra.\n",
        "\n",
        "Uncomment and run the code below to see the exception."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"This will raise an exception\")\n",
        "\n",
        "# bulge_plotter = aplt.LightProfilePlotter(light_profile=bulge, grid=masked_dataset.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now put them together in a `Tracer` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__LightProfileLinearObjFuncList__\n",
        "\n",
        "For standard light profiles, we combined our linear light profiles into a single `Galaxies` object. The \n",
        "galaxies object computed each individual light profile's image and added them together.\n",
        "\n",
        "This no longer occurs for linear light profiles, instead linear light profiles are passed into the \n",
        "`LightProfileLinearObjFuncList` object, which acts as an interface between the linear light profiles and the\n",
        "linear algebra used to compute their intensity via the inversion.\n",
        "\n",
        "The quantities used to compute the image, blurring image and blurred image of each light profiles (the\n",
        "dataset grid, PSF, etc.) are passed to the `LightProfileLinearObjFuncList` object, because it internally uses these\n",
        "to compute each linear light profile image to set up the linear algebra.\n",
        "\n",
        "For lensing, this means we have to use a different `LightProfileLinearObjFuncList` object for each plane, because\n",
        "each plane has its own ray-traced grid of (y,x) coordinates. Below, we set up the first `LightProfileLinearObjFuncList`,\n",
        "which uses the image-plane grid and lens galaxy bulge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lp_linear_func_lens = al.LightProfileLinearObjFuncList(\n",
        "    grid=masked_dataset.grids.lp,\n",
        "    blurring_grid=masked_dataset.grids.blurring,\n",
        "    light_profile_list=[tracer.galaxies[0].bulge],\n",
        "    regularization=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This has a property `params` which is the number of intensity values that are computed via the inversion,\n",
        "which because we have 1 light profiles is equal to 1.\n",
        "\n",
        "The `params` defines the dimensions of many of the matrices used in the linear algebra we discuss below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Number of Parameters (Intensity Values) in Linear Algebra:\")\n",
        "print(lp_linear_func_lens.params)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapping Matrix__\n",
        "\n",
        "The `mapping_matrix` is a matrix where each column is an image of each linear light profiles (assuming its \n",
        "intensity is 1.0), not accounting for the PSF convolution.\n",
        "\n",
        "It has dimensions `(total_image_pixels, total_linear_light_profiles)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapping_matrix = lp_linear_func_lens.mapping_matrix"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Printing the first column of the mapping matrix shows the image of the lens bulge light profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge_image = mapping_matrix[:, 0]\n",
        "print(bulge_image)\n",
        "print(image_2d_bulge.slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A 2D plot of the `mapping_matrix` shows each light profile image in 1D, which is a bit odd to look at but\n",
        "is a good way to think about the linear algebra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(mapping_matrix, aspect=(mapping_matrix.shape[1] / mapping_matrix.shape[0]))\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now make the second `LightProfileLinearObjFuncList`, which uses the ray-traced source-plane grid and source\n",
        "galaxy bulge light profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "traced_grids_of_planes_list = tracer.traced_grid_2d_list_from(\n",
        "    grid=masked_dataset.grids.lp\n",
        ")\n",
        "traced_blurring_grids_of_planes_list = tracer.traced_grid_2d_list_from(\n",
        "    grid=masked_dataset.grids.blurring\n",
        ")\n",
        "\n",
        "lp_linear_func_source = al.LightProfileLinearObjFuncList(\n",
        "    grid=traced_grids_of_planes_list[-1],\n",
        "    blurring_grid=traced_blurring_grids_of_planes_list[1],\n",
        "    psf=masked_dataset.psf,\n",
        "    light_profile_list=[tracer.galaxies[1].bulge],\n",
        "    regularization=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Printing the first column of the mapping matrix shows the image of the source bulge light profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapping_matrix = lp_linear_func_source.mapping_matrix\n",
        "\n",
        "bulge_image = mapping_matrix[:, 0]\n",
        "print(bulge_image)\n",
        "print(image_2d_bulge.slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Combining Matrices__\n",
        "\n",
        "The linear algebra system solves for all light profile `intensity` values at once, so we need to combine\n",
        "each of their individual mapping matrices into a single matrix.\n",
        "\n",
        "This is done via `hstack`, which stacks the two matrices horizontally to create a single matrix with dimensions\n",
        "`(total_image_pixels, total_linear_light_profiles)`, where the latter dimension is now 2 because we have combined\n",
        "two linear light profiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapping_matrix = np.hstack(\n",
        "    [lp_linear_func_lens.mapping_matrix, lp_linear_func_source.mapping_matrix]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Blurred Mapping Matrix ($f$)__\n",
        "\n",
        "The `mapping_matrix` does not account for the blurring of the light profile images by the PSF and therefore \n",
        "is not used directly to compute the likelihood.\n",
        "\n",
        "Instead, we create a `blurred_mapping_matrix` which does account for this blurring. This is computed by \n",
        "convolving each light profile image with the PSF.\n",
        "\n",
        "The `blurred_mapping_matrix` is a matrix analogous to the mapping matrix, but where each column is the image of each\n",
        "light profile after it has been blurred by the PSF.\n",
        "\n",
        "This operation does not change the dimensions of the mapping matrix, meaning the `blurred_mapping_matrix` also has\n",
        "dimensions `(total_image_pixels, total_linear_light_profiles)`. \n",
        "\n",
        "The property is actually called `operated_mapping_matrix_override` for two reasons: \n",
        "\n",
        "1) The operated signifies that this matrix could have any operation applied to it, it just happens for imaging\n",
        "   data that this operation is a convolution with the PSF.\n",
        "\n",
        "2) The `override` signifies that in the source code is changes how the `operated_mapping_matrix` is computed internally. \n",
        "   This is important if you are looking at the source code, but not important for the description of the likelihood \n",
        "   function in this guide.\n",
        "   \n",
        "We have two separate `LightProfileLinearObjFuncList` objects, one for the lens and one for the source, we combine\n",
        "the `blurred_mapping_matrix` of each via `hstack` to create a single `blurred_mapping_matrix` that represents\n",
        "the linear system that will be solved for both."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "blurred_mapping_matrix = np.hstack(\n",
        "    [\n",
        "        lp_linear_func_lens.operated_mapping_matrix_override,\n",
        "        lp_linear_func_source.operated_mapping_matrix_override,\n",
        "    ],\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Printing the first column of the mapping matrix shows the blurred image of the bulge light profile, the\n",
        "second the blurred image of the source light profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(blurred_mapping_matrix[:, 0])\n",
        "print(blurred_mapping_matrix[:, 1])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A 2D plot of the `mapping_matrix` shows each light profile image in 1D, with a PSF convolution applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(\n",
        "    blurred_mapping_matrix,\n",
        "    aspect=(blurred_mapping_matrix.shape[1] / blurred_mapping_matrix.shape[0]),\n",
        ")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Warren & Dye 2003 (https://arxiv.org/abs/astro-ph/0302587) (hereafter WD03) introduce the linear inversion formalism \n",
        "used to compute the intensity values of the linear light profiles. In WD03, the science case is centred around strong\n",
        "gravitational lensing and the galaxy is reconstructed on a rectangular grid of pixels, as opposed to linear light \n",
        "profiles.\n",
        "\n",
        "However, the mathematics of the WD03 linear inversion formalism is the same as that used here, therefore this guide \n",
        "describes which quantities in the linear inversion formalism map to the equations given in WD03. The pixelized \n",
        "reconstruction methods, available in the code but described in the `pixelization` likelihood function guide, \n",
        "also follow the WD03 formalism.\n",
        "\n",
        "The `blurred_mapping_matrix` is denoted $f_{ij}$ where $i$ maps over all $I$ linear light profiles and $j$ maps \n",
        "over all $J$ image pixels. \n",
        "\n",
        "For example: \n",
        "\n",
        " - $f_{0, 1} = 0.3$ indicates that image-pixel $2$ maps to linear light profile $1$ with an intensity in that image \n",
        "   pixel of $0.3$ after PSF convolution.\n",
        "\n",
        "The indexing of the `mapping_matrix` is reversed compared to the notation of WD03 (e.g. image pixels\n",
        "are the first entry of `mapping_matrix` whereas for $f$ they are the second index)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    f\"Mapping between image pixel 0 and linear light profile pixel 1 = {mapping_matrix[0, 1]}\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data Vector (D)__\n",
        "\n",
        "To solve for the linear light profile intensities we now pose the problem as a linear inversion.\n",
        "\n",
        "This requires us to convert the `blurred_mapping_matrix` and our `data` and `noise map` into matrices of certain \n",
        "dimensions. \n",
        "\n",
        "The `data_vector`, $D$, is the first matrix and it has dimensions `(total_linear_light_profiles,)`.\n",
        "\n",
        "In WD03 (https://arxiv.org/abs/astro-ph/0302587) the data vector is given by: \n",
        "\n",
        " $\\vec{D}_{i} = \\sum_{\\rm  j=1}^{J}f_{ij}(d_{j} - b_{j})/\\sigma_{j}^2 \\, \\, .$\n",
        "\n",
        "Where:\n",
        "\n",
        " - $d_{\\rm j}$ are the image-pixel data flux values.\n",
        " - $b_{\\rm j}$ are the image values of all standard light profiles (therefore $d_{\\rm  j} - b_{\\rm j}$ is \n",
        " the data minus any standard light profiles).\n",
        " - $\\sigma{\\rm _j}^2$ are the statistical uncertainties of each image-pixel value.\n",
        "\n",
        "$i$ maps over all $I$ linear light profiles and $j$ maps over all $J$ image pixels. \n",
        "\n",
        "This equation highlights a first aspect of linear inversions, if we are combining standard light profiles (which\n",
        "have an input `intensity` value) with linear light profiles, the inversion is performed on the data minus\n",
        "the standard light profile images. In this example, we have no standard light profiles and therefore the data\n",
        "vector uses the data directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_vector = al.util.inversion_imaging.data_vector_via_blurred_mapping_matrix_from(\n",
        "    blurred_mapping_matrix=blurred_mapping_matrix,\n",
        "    image=np.array(masked_dataset.data),\n",
        "    noise_map=np.array(masked_dataset.noise_map),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$D$'s meaning is a bit abstract, it essentially weights each linear light profile's `intensity` based on how it\n",
        "maps to the data, so that the linear algebra can compute the `intensity` values that best-fit the data.\n",
        "\n",
        "We can plot $D$ as a column vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(\n",
        "    data_vector.reshape(data_vector.shape[0], 1), aspect=10.0 / data_vector.shape[0]\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dimensions of $D$ are the number of linear light profiles, which in this case is 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Data Vector:\")\n",
        "print(data_vector)\n",
        "print(data_vector.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Curvature Matrix (F)__\n",
        "\n",
        "The `curvature_matrix` $F$ is the second matrix and it has \n",
        "dimensions `(total_linear_light_profiles, total_linear_light_profiles)`.\n",
        "\n",
        "In WD03 (https://arxiv.org/abs/astro-ph/0302587) the curvature matrix is a 2D matrix given by:\n",
        "\n",
        " ${F}_{ik} = \\sum_{\\rm  j=1}^{J}f_{ij}f_{kj}/\\sigma_{j}^2 \\, \\, .$\n",
        "\n",
        "NOTE: this notation implicitly assumes a summation over $K$, where $k$ runs over all linear light profile indexes $K$.\n",
        "\n",
        "Note how summation over $J$ runs over $f$ twice, such that every entry of $F$ is the sum of the multiplication\n",
        "between all values in every two columns of $f$.\n",
        "\n",
        "For example, $F_{0,1}$ is the sum of every blurred image pixels values in $f$ of linear light profile 0 multiplied by\n",
        "every blurred image pixel value of linear light profile 1.\n",
        "\n",
        "$F$'s meaning is also a bit abstract, but it essentially quantifies how much each linear light profile's image\n",
        "overlaps with every other linear light profile's image, weighted by the noise in the data. This is what combined with\n",
        "the `data_vector` allows the inversion to compute the `intensity` values that best-fit the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "curvature_matrix = al.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=blurred_mapping_matrix, noise_map=masked_dataset.noise_map\n",
        ")\n",
        "\n",
        "plt.imshow(curvature_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction (Positive-Negative)__\n",
        "\n",
        "The following chi-squared is minimized when we perform the inversion and reconstruct the galaxy:\n",
        "\n",
        "$\\chi^2 = \\sum_{\\rm  j=1}^{J} \\bigg[ \\frac{(\\sum_{\\rm  i=1}^{I} s_{i} f_{ij}) + b_{j} - d_{j}}{\\sigma_{j}} \\bigg]$\n",
        "\n",
        "Where $s$ is the `intensity` values in all $I$ linear light profile images.\n",
        "\n",
        "The solution for $s$ is therefore given by (equation 5 WD03):\n",
        "\n",
        " $s = F^{-1} D$\n",
        "\n",
        "We can compute this using NumPy linear algebra and the `solve` function.\n",
        "\n",
        "However, this function allows for the solved `intensity` values to be negative. For linear light profiles which\n",
        "are a good fit to the data, this is unlikely to happen and the `intensity` values will be positive. However, \n",
        "for more complex models this may not be the case. Below, we describes how we can ensure the `intensity` values\n",
        "are positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "reconstruction = np.linalg.solve(curvature_matrix, data_vector)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `reconstruction` is a 1D vector of length equal to the number of linear light profiles, which in this case is 2.\n",
        "\n",
        "Each value represents the intensity of the linear light profile.\n",
        "\n",
        "In this example, both values are positive, but remember that this is not guaranteed for all linear inversions\n",
        "that are solve using this method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Reconstruction (S) of Linear Light Profiles Intensity:\")\n",
        "print(reconstruction)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction (Positive Only)__\n",
        "\n",
        "The linear algebra can be solved for with the constraint that all solutions, and therefore all `intensity` values,\n",
        "are positive. \n",
        "\n",
        "This could be achieved by using the `scipy` `nnls` non-negative least squares solver.\n",
        "\n",
        "The nnls poses the problem slightly different than the code above. It solves for the `intensity` values in an\n",
        "iterative manner meaning that it is slower. It does not use `data_vector` $D$ and `curvature_matrix` $F$ but instead\n",
        "works directly with the `blurred_mapping_matrix` $f$ and the data and noise-map.\n",
        "\n",
        "The `nnls` function is therefore computationally slow, especially for cases where there are many linear light profiles \n",
        "or even  more complex linear inversions like a pixelized reconstruction.\n",
        "\n",
        "The source code therefore uses a \"fast nnls\" algorithm, which is an adaptation of the algorithm found at\n",
        "this URL: https://github.com/jvendrow/fnnls\n",
        "\n",
        "Unlike the scipy nnls function, the fnnls method uses the `data_vector` $D$ and `curvature_matrix` $F$ to solve for\n",
        "the `intensity` values. This provides it with additional information about the linear algebra problem, which is\n",
        "why it is faster.\n",
        "\n",
        "The function `reconstruction_positive_only_from` uses the `fnnls` algorithm to compute the `intensity` values\n",
        "of the linear light profiles, ensuring they are positive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "reconstruction = al.util.inversion.reconstruction_positive_only_from(\n",
        "    data_vector=data_vector,\n",
        "    curvature_reg_matrix=curvature_matrix,  # ignore _reg_ tag in this guide\n",
        ")\n",
        "\n",
        "print(reconstruction)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Image Reconstruction__\n",
        "\n",
        "Using the reconstructed `intensity` values we can map the reconstruction back to the image plane (via \n",
        "the `blurred mapping_matrix`) and produce a reconstruction of the image data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapped_reconstructed_image_2d = (\n",
        "    al.util.inversion.mapped_reconstructed_data_via_mapping_matrix_from(\n",
        "        mapping_matrix=blurred_mapping_matrix, reconstruction=reconstruction\n",
        "    )\n",
        ")\n",
        "\n",
        "mapped_reconstructed_image_2d = al.Array2D(\n",
        "    values=mapped_reconstructed_image_2d, mask=mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=mapped_reconstructed_image_2d)\n",
        "array_2d_plotter.figure_2d()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Function__\n",
        "\n",
        "We now quantify the goodness-of-fit of our galaxy model.\n",
        "\n",
        "We compute the `log_likelihood` of the fit, which is the value returned by the `log_likelihood_function`.\n",
        "\n",
        "The likelihood function for parametric galaxy modeling, even if linear light profiles are used, consists of two terms:\n",
        "\n",
        " $-2 \\mathrm{ln} \\, \\epsilon = \\chi^2 + \\sum_{\\rm  j=1}^{J} { \\mathrm{ln}} \\left [2 \\pi (\\sigma_j)^2 \\right]  \\, .$\n",
        "\n",
        "We now explain what each of these terms mean.\n",
        "\n",
        "__Chi Squared__\n",
        "\n",
        "The first term is a $\\chi^2$ statistic, which is defined above in our merit function as and is computed as follows:\n",
        "\n",
        " - `model_data` = `convolved_image_2d`\n",
        " - `residual_map` = (`data` - `model_data`)\n",
        " - `normalized_residual_map` = (`data` - `model_data`) / `noise_map`\n",
        " - `chi_squared_map` = (`normalized_residuals`) ** 2.0 = ((`data` - `model_data`)**2.0)/(`variances`)\n",
        " - `chi_squared` = sum(`chi_squared_map`)\n",
        "\n",
        "The chi-squared therefore quantifies if our fit to the data is accurate or not. \n",
        "\n",
        "High values of chi-squared indicate that there are many image pixels our model did not produce a good fit to the image \n",
        "for, corresponding to a fit with a lower likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_image = mapped_reconstructed_image_2d\n",
        "\n",
        "residual_map = masked_dataset.data - model_image\n",
        "normalized_residual_map = residual_map / masked_dataset.noise_map\n",
        "chi_squared_map = normalized_residual_map**2.0\n",
        "\n",
        "chi_squared = np.sum(chi_squared_map)\n",
        "\n",
        "print(chi_squared)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `chi_squared_map` indicates which regions of the image we did and did not fit accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "chi_squared_map = al.Array2D(values=chi_squared_map, mask=mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=chi_squared_map)\n",
        "array_2d_plotter.figure_2d()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Noise Normalization Term__\n",
        "\n",
        "Our likelihood function assumes the imaging data consists of independent Gaussian noise in every image pixel.\n",
        "\n",
        "The final term in the likelihood function is therefore a `noise_normalization` term, which consists of the sum\n",
        "of the log of every noise-map value squared. \n",
        "\n",
        "Given the `noise_map` is fixed, this term does not change during the galaxy modeling process and has no impact on the \n",
        "model we infer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "noise_normalization = float(np.sum(np.log(2 * np.pi * masked_dataset.noise_map**2.0)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Calculate The Log Likelihood__\n",
        "\n",
        "We can now, finally, compute the `log_likelihood` of the galaxy model, by combining the two terms computed above using\n",
        "the likelihood function defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "figure_of_merit = float(-0.5 * (chi_squared + noise_normalization))\n",
        "\n",
        "print(figure_of_merit)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "This process to perform a likelihood function evaluation is what is performed in the `FitImaging` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = al.FitImaging(\n",
        "    dataset=masked_dataset,\n",
        "    tracer=tracer,\n",
        "    settings_inversion=al.SettingsInversion(\n",
        "        use_w_tilde=False, use_border_relocator=True\n",
        "    ),\n",
        ")\n",
        "fit_log_evidence = fit.log_evidence\n",
        "print(fit_log_evidence)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit contains an `Inversion` object, which handles all the linear algebra we have covered in this script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.inversion)\n",
        "print(fit.inversion.data_vector)\n",
        "print(fit.inversion.curvature_matrix)\n",
        "print(fit.inversion.reconstruction)\n",
        "print(fit.inversion.mapped_reconstructed_image)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Inversion` object can be computed from a tracer and a dataset, by passing them to the `TracerToInversion` object.\n",
        "\n",
        "This objects handles a lot of extra functionality that we have not covered in this script, such as:\n",
        "\n",
        "- Separating out the linear light profiles from the standard light profiles.\n",
        "- Separating out objects which reconstruct the galaxy using a pixelized reconstruction, which are passed into\n",
        "  the `Inversion` object as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_to_inversion = al.TracerToInversion(\n",
        "    tracer=tracer,\n",
        "    dataset=masked_dataset,\n",
        ")\n",
        "\n",
        "inversion = tracer_to_inversion.inversion"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Lens Modeling__\n",
        "\n",
        "To fit a lens model to data, the likelihood function illustrated in this tutorial is sampled using a\n",
        "non-linear search algorithm.\n",
        "\n",
        "The default sampler is the nested sampling algorithm `nautilus` (https://github.com/joshspeagle/nautilus)\n",
        "but **PyAutoLens** supports multiple MCMC and optimization algorithms. \n",
        "\n",
        "For linear light profiles, the reduced number of free parameters (e.g. the `intensity` values are solved for\n",
        "via linear algebra and not a dimension of the non-linear parameter space) means that the sampler converges in fewer\n",
        "iterations and is less likely to infer a local maximum.\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "We have presented a visual step-by-step guide to the parametric linear light profile likelihood function, which uses \n",
        "analytic light profiles to fit the galaxies light and solve for the `intensity` values via linear algebra.\n",
        "\n",
        "There are a number of other inputs features which slightly change the behaviour of this likelihood function, which\n",
        "are described in additional notebooks found in the `guides` package:\n",
        "\n",
        " - `over_sampling`: Oversampling the image grid into a finer grid of sub-pixels, which are all individually \n",
        " ray-traced to the source-plane and used to evaluate the light profile more accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}