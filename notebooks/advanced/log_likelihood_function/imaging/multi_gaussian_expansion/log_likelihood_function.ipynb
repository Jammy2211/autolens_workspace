{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Log Likelihood Function: Multi Gaussian Expansion__\n",
        "\n",
        "This script provides a step-by-step guide of the `log_likelihood_function` which is used to fit `Imaging` data with\n",
        "a multi-Gaussian expansion (MGE), which is a superposition of multiple 2D Gaussian linear light profiles.\n",
        "\n",
        "You should be familiar with the `log_likelihood_function` of a parametric linear light profile before reading this script,\n",
        "which is described in the `log_likelihood_function/imaging/linear_light_profile/log_likelihood_function.ipynb` notebook.\n",
        "\n",
        "This script has the following aims:\n",
        "\n",
        " - To provide a resource that authors can include in papers, so that readers can understand the likelihood\n",
        " function (including references to the previous literature from which it is defined) without having to\n",
        " write large quantities of text and equations.\n",
        "\n",
        "Accompanying this script is the `contributor_guide.py` which provides URL's to every part of the source-code that\n",
        "is illustrated in this guide. This gives contributors a sequential run through of what source-code functions, modules and\n",
        "packages are called when the likelihood is evaluated.\n",
        "\n",
        "__Prerequisites__\n",
        "\n",
        "The likelihood function of a multi Gaussian expansion builds on that used for standard parametric light profiles and\n",
        "linear light profiles, therefore you must read the following notebooks before this script:\n",
        "\n",
        "- `light_profile/log_likelihood_function.ipynb`.\n",
        "- `linear_light_profile/log_likelihood_function.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.optimize import nnls\n",
        "from pathlib import Path\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Following the `linear_light_profile/log_likelihood_function.py` script, we load and mask an `Imaging` dataset and\n",
        "set oversampling to 1.\n",
        "\n",
        "This example fits a simulated galaxy where galaxy has an asymmetric light distribution, which cannot be accurately \n",
        "fitted with `Sersic` profile and therefore requires a multi-Gaussian expansion to fit accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"lens_light_asymmetric\"\n",
        "dataset_path = Path(\"dataset\", \"imaging\", \"simple\")\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "masked_dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "masked_dataset = masked_dataset.apply_over_sampling(over_sample_size_lp=1)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=masked_dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Masked Image Grid__\n",
        "\n",
        "To perform galaxy calculations we used a 2D image-plane grid of (y,x) coordinates, which evaluated the\n",
        "emission of galaxy light profiles created as `LightProfile` objects.\n",
        "\n",
        "The code below repeats that used in `light_profile/log_likelihood_function.py` to show how this was done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = al.lp.Sersic(\n",
        "    centre=(0.0, 0.0),\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    intensity=4.0,\n",
        "    effective_radius=0.6,\n",
        "    sersic_index=3.0,\n",
        ")\n",
        "\n",
        "mass = al.mp.Isothermal(\n",
        "    centre=(0.0, 0.0),\n",
        "    einstein_radius=1.6,\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        ")\n",
        "\n",
        "shear = al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05)\n",
        "\n",
        "lens_galaxy = al.Galaxy(redshift=0.5, bulge=bulge, mass=mass, shear=shear)\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp_linear.SersicCore(\n",
        "        centre=(0.0, 0.0),\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.8, angle=60.0),\n",
        "        effective_radius=0.1,\n",
        "        sersic_index=1.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "image = tracer.image_2d_from(grid=masked_dataset.grids.lp)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Multiple Gaussians & Linear Light Profiles__\n",
        "\n",
        "To use a linear light profile, whose `intensity` is computed via linear algebra, we simply use the `lp_Linear`\n",
        "module instead of the `lp` module used throughout other example scripts. \n",
        "\n",
        "The `intensity` parameter of the light profile is no longer passed into the light profiles created via the\n",
        "`lp_linear` module, as it is inferred via linear algebra.\n",
        "\n",
        "For a multi-Gaussian expansion, we use 30 linear light profile `Gaussian`'s, which is easily achieved by creating a\n",
        "list of `Gaussian` objects via a for loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "total_gaussians = 30\n",
        "\n",
        "# The sigma values of the Gaussians will be fixed to values spanning 0.01 to the mask radius, 3.0\".\n",
        "\n",
        "mask_radius = 3.0\n",
        "log10_sigma_list = np.linspace(-2, np.log10(mask_radius), total_gaussians)\n",
        "\n",
        "# A list of linear light profile Gaussians will be input here, which will then be used to fit the data.\n",
        "\n",
        "basis_gaussian_list = []\n",
        "\n",
        "# Iterate over every Gaussian and create it, with it centered at (0.0\", 0.0\") and assuming spherical symmetry.\n",
        "\n",
        "for i in range(total_gaussians):\n",
        "    gaussian = al.lp_linear.Gaussian(\n",
        "        centre=(0.0, 0.0),\n",
        "        ell_comps=(0.0, 0.0),\n",
        "        sigma=10 ** log10_sigma_list[i],\n",
        "    )\n",
        "\n",
        "    basis_gaussian_list.append(gaussian)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Basis__\n",
        "\n",
        "For a multi-Gaussian expansion (and other mdoels where the light profile is a superposition of multiple light profiles),\n",
        "the list of linear light profiles is passed to the `Basis` class.\n",
        "\n",
        "The `Basis` basically stores all these light profiles into a single object such that they can collectively be used to\n",
        "perform the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "basis = al.lp_basis.Basis(profile_list=basis_gaussian_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Basis` is composed of many Gaussians, each with different sizes (the `sigma` value) and therefore capturing\n",
        "emission on different scales.\n",
        "\n",
        "These Gaussians are visualized below using a `BasisPlotter`, which shows that the Gaussians expand in size as the\n",
        "sigma value increases, in log10 increments.\n",
        "\n",
        "This figure is a brilliant way to visualize the multi-Gaussian expansion, showing the 30 different Gaussian light\n",
        "profiles that will be used perform the expansion on the data.\n",
        "\n",
        "Below, we will discuss how linear light profiles cannot be visualized (an exception is raised if you try). Therefore\n",
        "below we make a separate `Basis` object of `Gaussians` using standard light profiles with input `intensity` values,\n",
        "which we can visualize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "basis_plot_gaussian_list = []\n",
        "\n",
        "for i in range(total_gaussians):\n",
        "    gaussian = al.lp.Gaussian(\n",
        "        centre=(0.0, 0.0),\n",
        "        ell_comps=(0.0, 0.0),\n",
        "        intensity=1.0,\n",
        "        sigma=10 ** log10_sigma_list[i],\n",
        "    )\n",
        "\n",
        "    basis_plot_gaussian_list.append(gaussian)\n",
        "\n",
        "basis_plot = al.lp_basis.Basis(profile_list=basis_plot_gaussian_list)\n",
        "\n",
        "grid = al.Grid2D.uniform(shape_native=(100, 100), pixel_scales=0.05)\n",
        "\n",
        "basis_plotter = aplt.BasisPlotter(basis=basis_plot, grid=grid)\n",
        "basis_plotter.subplot_image()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Internally in the source code, linear light profiles have an `intensity` parameter, but its value is always set to \n",
        "1.0. \n",
        "\n",
        "This can be seen by printing the intensity of the first two Gaussians in the basis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Basis Internal Intensity Of First Gaussian:\")\n",
        "print(basis.light_profile_list[0].intensity)\n",
        "\n",
        "print(\"Basis Internal Intensity Of Second Gaussian:\")\n",
        "print(basis.light_profile_list[1].intensity)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Like standard light profiles, we can compute images of each linear light profile in the basis, but their overall\n",
        "normalization is arbitrary given that the internal `intensity` value of 1.0 is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_2d_basis_0 = basis.light_profile_list[0].image_2d_from(grid=masked_dataset.grid)\n",
        "image_2d_basis_1 = basis.light_profile_list[1].image_2d_from(grid=masked_dataset.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we try and plot a linear light profile using a plotter, an exception is raised.\n",
        "\n",
        "This is to ensure that a user does not plot and interpret the intensity of a linear light profile, as it is not a\n",
        "physical quantity. Plotting only works after a linear light profile has had its `intensity` computed via linear\n",
        "algebra.\n",
        "\n",
        "Uncomment and run the code below to see the exception.\n",
        "\n",
        "Note that the `BasisPlotter` used above did not raise an exception, because its intended purpose is to visualize\n",
        "the basis light profiles and not the intensity of the light profiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"This will raise an exception\")\n",
        "\n",
        "# basis_plotter = aplt.LightProfilePlotter(light_profile=basis, grid=masked_dataset.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now set up a `Tracer` using the MGE for the lens galaxy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mass = al.mp.Isothermal(\n",
        "    centre=(0.0, 0.0),\n",
        "    einstein_radius=1.6,\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        ")\n",
        "\n",
        "shear = al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05)\n",
        "\n",
        "lens_galaxy = al.Galaxy(redshift=0.5, bulge=basis, mass=mass, shear=shear)\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp_linear.SersicCore(\n",
        "        centre=(0.0, 0.0),\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.8, angle=60.0),\n",
        "        effective_radius=0.1,\n",
        "        sersic_index=1.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Comparison To Linear Light Profiles Example__\n",
        "\n",
        "The text below is nearly identical to the `linear_light_profile/log_likelihood_function.ipynb` example, because the \n",
        "linear algebra and likelihood function of a multi-Gaussian expansion is essentially identical to that of a single \n",
        "linear light profile.\n",
        "\n",
        "The key difference between the linear light profile and multi-Gaussian expansion calculation is essentially the\n",
        "following:\n",
        "\n",
        "- The `mapping_matrix`, which for 2 linear light profiles had dimensions `(total_image_pixels, 2)`, now has dimensions\n",
        " `(total_image_pixels, 30)`, corresponding to the 30 different Gaussian light profiles.\n",
        " \n",
        "- Each column of this `mapping_matrix` is the image of each Gaussian light profile, as opposed to the Sersic and\n",
        "  Exponential light profiles used in the previous example.\n",
        "\n",
        "- The use of the positive only solver for the reconstruction is more important for an MGE, because MGEs can otherwise\n",
        "  infer unphysical solutions where the Gaussians alternate between large positive and large negative values.\n",
        "\n",
        "Other than the above change, the calculation is performed in an identical manner to the linear light profile example,\n",
        "with the `data_vector`, `curvature_matrix`, `reconstruction` and `log_likelihood` all computed in the same way\n",
        "with the same dimensions. \n",
        "\n",
        "__LightProfileLinearObjFuncList__\n",
        "\n",
        "For standard light profiles, we combined our linear light profiles into a single `Galaxies` object. The \n",
        "galaxies object computed each individual light profile's image and added them together.\n",
        "\n",
        "This no longer occurs for linear light profiles, instead linear light profiles are passed into the \n",
        "`LightProfileLinearObjFuncList` object, which acts as an interface between the linear light profiles and the\n",
        "linear algebra used to compute their intensity via the inversion.\n",
        "\n",
        "For an MGE, we input the whole `Basis` object into the `LightProfileLinearObjFuncList` object, which\n",
        "contains all the Gaussian linmear light profiles.\n",
        "\n",
        "The quantities used to compute the image, blurring image and blurred image of each light profiles (the\n",
        "dataset grid, PSF, etc.) are passed to the `LightProfileLinearObjFuncList` object, because it internally uses these\n",
        "to compute each linear light profile image to set up the linear algebra.\n",
        "\n",
        "For lensing, this means we have to use a different `LightProfileLinearObjFuncList` object for each plane, because\n",
        "each plane has its own ray-traced grid of (y,x) coordinates. Below, we set up the first `LightProfileLinearObjFuncList`,\n",
        "which uses the image-plane grid and lens galaxy bulge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lp_linear_func_lens = al.LightProfileLinearObjFuncList(\n",
        "    grid=masked_dataset.grids.lp,\n",
        "    blurring_grid=masked_dataset.grids.blurring,\n",
        "    psf=masked_dataset.psf,\n",
        "    light_profile_list=basis.light_profile_list,\n",
        "    regularization=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This has a property `params` which is the number of intensity values that are computed via the inversion,\n",
        "which because we have 30 Gaussian linear light profiles is equal to 30.\n",
        "\n",
        "The `params` defines the dimensions of many of the matrices used in the linear algebra we discuss below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Number of Parameters (Intensity Values) in Linear Algebra:\")\n",
        "print(lp_linear_func_lens.params)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Combining Matrices__\n",
        "\n",
        "In the `linear_light_profile/log_likelihood_function.py` example, we used two `LightProfileLinearObjFuncList` to set\n",
        "up the linear algebra for the different planes of the `Tracer`, which we do again below.\n",
        "\n",
        "In this example the source is a single Sersic linear light profile, but it could easily be an MGE itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "traced_grids_of_planes_list = tracer.traced_grid_2d_list_from(\n",
        "    grid=masked_dataset.grids.lp\n",
        ")\n",
        "traced_blurring_grids_of_planes_list = tracer.traced_grid_2d_list_from(\n",
        "    grid=masked_dataset.grids.blurring\n",
        ")\n",
        "\n",
        "lp_linear_func_source = al.LightProfileLinearObjFuncList(\n",
        "    grid=traced_grids_of_planes_list[-1],\n",
        "    blurring_grid=traced_blurring_grids_of_planes_list[1],\n",
        "    psf=masked_dataset.psf,\n",
        "    light_profile_list=[tracer.galaxies[1].bulge],\n",
        "    regularization=None,\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapping Matrix__\n",
        "\n",
        "The `mapping_matrix` is a matrix where each column is an image of each Gaussian linear light profiles (assuming its \n",
        "intensity is 1.0), not accounting for the PSF convolution.\n",
        "\n",
        "We combine the `mapping_matrix` of the lens and source plane into a single matrix, which is used to compute the\n",
        "`blurred_mapping_matrix` and the `data_vector` below.\n",
        "\n",
        "It has dimensions `(total_image_pixels, total_linear_light_profiles)` = `(total_image_pixels, 31)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapping_matrix = np.hstack(\n",
        "    [lp_linear_func_lens.mapping_matrix, lp_linear_func_source.mapping_matrix]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Printing the first column of the mapping matrix shows the image of the basis light profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "basis_image = mapping_matrix[:, 0]\n",
        "print(basis_image)\n",
        "print(image_2d_basis_0.slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A 2D plot of the `mapping_matrix` shows each light profile image in 1D, which is a bit odd to look at but\n",
        "is a good way to think about the linear algebra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(mapping_matrix, aspect=(mapping_matrix.shape[1] / mapping_matrix.shape[0]))\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Blurred Mapping Matrix ($f$)__\n",
        "\n",
        "The `mapping_matrix` does not account for the blurring of the light profile images by the PSF and therefore \n",
        "is not used directly to compute the likelihood.\n",
        "\n",
        "Instead, we create a `blurred_mapping_matrix` which does account for this blurring. This is computed by \n",
        "convolving each light profile image with the PSF.\n",
        "\n",
        "The `blurred_mapping_matrix` is a matrix analogous to the mapping matrix, but where each column is the image of each\n",
        "light profile after it has been blurred by the PSF.\n",
        "\n",
        "This operation does not change the dimensions of the mapping matrix, meaning the `blurred_mapping_matrix` also has\n",
        "dimensions `(total_image_pixels, total_rectangular_pixels)`. \n",
        "\n",
        "The property is actually called `operated_mapping_matrix_override` for two reasons: \n",
        "\n",
        "1) The operated signifies that this matrix could have any operation applied to it, it just happens for imaging\n",
        "   data that this operation is a convolution with the PSF.\n",
        "\n",
        "2) The `override` signifies that in the source code is changes how the `operated_mapping_matrix` is computed internally. \n",
        "   This is important if you are looking at the source code, but not important for the description of the likelihood \n",
        "   function in this guide."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "blurred_mapping_matrix = np.hstack(\n",
        "    [\n",
        "        lp_linear_func_lens.operated_mapping_matrix_override,\n",
        "        lp_linear_func_source.operated_mapping_matrix_override,\n",
        "    ],\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Printing the first column of the mapping matrix shows the blurred image of the basis light profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "basis_image = blurred_mapping_matrix[:, 0]\n",
        "print(basis_image)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A 2D plot of the `mapping_matrix` shows each light profile image in 1D, with a PSF convolution applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(mapping_matrix, aspect=(mapping_matrix.shape[1] / mapping_matrix.shape[0]))\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Warren & Dye 2003 (https://arxiv.org/abs/astro-ph/0302587) (hereafter WD03) introduce the linear inversion formalism \n",
        "used to compute the intensity values of the linear light profiles. In WD03, the science case is centred around strong\n",
        "gravitational lensing and the galaxy is reconstructed on a rectangular grid of pixels, as opposed to linear light \n",
        "profiles.\n",
        "\n",
        "However, the mathematics of the WD03 linear inversion formalism is the same as that used here, therefore this guide \n",
        "describes which quantities in the linear inversion formalism map to the equations given in WD03. The pixelized \n",
        "reconstruction methods, available in the code but described in the `pixelization` likelihood function guide, \n",
        "also follow the WD03 formalism.\n",
        "\n",
        "The `blurred_mapping_matrix` is denoted $f_{ij}$ where $i$ maps over all $I$ linear light profiles and $j$ maps \n",
        "over all $J$ image pixels. \n",
        "\n",
        "For example: \n",
        "\n",
        " - $f_{0, 1} = 0.3$ indicates that image-pixel $2$ maps to linear light profile $1$ with an intensity in that image \n",
        "   pixel of $0.3$ after PSF convolution.\n",
        "\n",
        "The indexing of the `mapping_matrix` is reversed compared to the notation of WD03 (e.g. image pixels\n",
        "are the first entry of `mapping_matrix` whereas for $f$ they are the second index)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    f\"Mapping between image pixel 0 and Gaussian linear light profile pixel 1 = {mapping_matrix[0, 1]}\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data Vector (D)__\n",
        "\n",
        "To solve for the linear light profile intensities we now pose the problem as a linear inversion.\n",
        "\n",
        "This requires us to convert the `blurred_mapping_matrix` and our `data` and `noise map` into matrices of certain \n",
        "dimensions. \n",
        "\n",
        "The `data_vector`, $D$, is the first matrix and it has dimensions `(total_linear_light_profiles,)`.\n",
        "\n",
        "In WD03 (https://arxiv.org/abs/astro-ph/0302587) the data vector is given by: \n",
        "\n",
        " $\\vec{D}_{i} = \\sum_{\\rm  j=1}^{J}f_{ij}(d_{j} - b_{j})/\\sigma_{j}^2 \\, \\, .$\n",
        "\n",
        "Where:\n",
        "\n",
        " - $d_{\\rm j}$ are the image-pixel data flux values.\n",
        " - $b_{\\rm j}$ are the image values of all standard light profiles (therefore $d_{\\rm  j} - b_{\\rm j}$ is \n",
        " the data minus any standard light profiles).\n",
        " - $\\sigma{\\rm _j}^2$ are the statistical uncertainties of each image-pixel value.\n",
        "\n",
        "$i$ maps over all $I$ linear light profiles and $j$ maps over all $J$ image pixels. \n",
        "\n",
        "This equation highlights a first aspect of linear inversions, if we are combining standard light profiles (which\n",
        "have an input `intensity` value) with linear light profiles, the inversion is performed on the data minus\n",
        "the standard light profile images. In this example, we have no standard light profiles and therefore the data\n",
        "vector uses the data directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_vector = al.util.inversion_imaging.data_vector_via_blurred_mapping_matrix_from(\n",
        "    blurred_mapping_matrix=blurred_mapping_matrix,\n",
        "    image=np.array(masked_dataset.data),\n",
        "    noise_map=np.array(masked_dataset.noise_map),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$D$'s meaning is a bit abstract, it essentially weights each linear light profile's `intensity` based on how it\n",
        "maps to the data, so that the linear algebra can compute the `intensity` values that best-fit the data.\n",
        "\n",
        "We can plot $D$ as a column vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plt.imshow(\n",
        "    data_vector.reshape(data_vector.shape[0], 1), aspect=10.0 / data_vector.shape[0]\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dimensions of $D$ are the number of linear light profiles, which in this case is 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Data Vector:\")\n",
        "print(data_vector)\n",
        "print(data_vector.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Curvature Matrix (F)__\n",
        "\n",
        "The `curvature_matrix` $F$ is the second matrix and it has \n",
        "dimensions `(total_linear_light_profiles, total_linear_light_profiles)`.\n",
        "\n",
        "In WD03 (https://arxiv.org/abs/astro-ph/0302587) the curvature matrix is a 2D matrix given by:\n",
        "\n",
        " ${F}_{ik} = \\sum_{\\rm  j=1}^{J}f_{ij}f_{kj}/\\sigma_{j}^2 \\, \\, .$\n",
        "\n",
        "NOTE: this notation implicitly assumes a summation over $K$, where $k$ runs over all linear light profile indexes $K$.\n",
        "\n",
        "Note how summation over $J$ runs over $f$ twice, such that every entry of $F$ is the sum of the multiplication\n",
        "between all values in every two columns of $f$.\n",
        "\n",
        "For example, $F_{0,1}$ is the sum of every blurred image pixels values in $f$ of linear light profile 0 multiplied by\n",
        "every blurred image pixel value of linear light profile 1.\n",
        "\n",
        "$F$'s meaning is also a bit abstract, but it essentially quantifies how much each linear light profile's image\n",
        "overlaps with every other linear light profile's image, weighted by the noise in the data. This is what combined with\n",
        "the `data_vector` allows the inversion to compute the `intensity` values that best-fit the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "curvature_matrix = al.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=blurred_mapping_matrix, noise_map=masked_dataset.noise_map\n",
        ")\n",
        "\n",
        "plt.imshow(curvature_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction (Positive-Negative)__\n",
        "\n",
        "The following chi-squared is minimized when we perform the inversion and reconstruct the galaxy:\n",
        "\n",
        "$\\chi^2 = \\sum_{\\rm  j=1}^{J} \\bigg[ \\frac{(\\sum_{\\rm  i=1}^{I} s_{i} f_{ij}) + b_{j} - d_{j}}{\\sigma_{j}} \\bigg]$\n",
        "\n",
        "Where $s$ is the `intensity` values in all $I$ linear light profile images.\n",
        "\n",
        "The solution for $s$ is therefore given by (equation 5 WD03):\n",
        "\n",
        " $s = F^{-1} D$\n",
        "\n",
        "We can compute this using NumPy linear algebra and the `solve` function.\n",
        "\n",
        "However, this function allows for the solved `intensity` values to be negative, which are unphysical values for\n",
        "describing the light profile of a galaxy. \n",
        "\n",
        "For a multi-Gaussian expansion, it is common for the inferred solution to contain negative `intensity` values. A common\n",
        "solution is one where the Gaussians alternate between large positive and large negative values, creating an almost\n",
        "\"ringing\" effect in the reconstruction. This is a very unphysical solution and one we want to avoid.\n",
        "\n",
        "We are able to illustrate this now, first by solving the linear algebra and then printing the `intensity` values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "reconstruction = np.linalg.solve(curvature_matrix, data_vector)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `reconstruction` is a 1D vector of length equal to the number of Gaussian linear light profiles, which in this case \n",
        "is 30.\n",
        "\n",
        "Each value represents the solved for `intensity` of the Gaussian linear light profile.\n",
        "\n",
        "In this example, the values alternate between positive and negative, indicating a solution that is not physical\n",
        "and one we must avoid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Reconstruction (S) of Linear Light Profiles Intensity:\")\n",
        "print(reconstruction)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction (Positive Only)__\n",
        "\n",
        "The linear algebra can be solved for with the constraint that all solutions, and therefore all `intensity` values,\n",
        "are positive. \n",
        "\n",
        "This could be achieved by using the `scipy` `nnls` non-negative least squares solver.\n",
        "\n",
        "The nnls poses the problem slightly different than the code above. It solves for the `intensity` values in an\n",
        "iterative manner meaning that it is slower. It does not use `data_vector` $D$ and `curvature_matrix` $F$ but instead\n",
        "works directly with the `blurred_mapping_matrix` $f$ and the data and noise-map.\n",
        "\n",
        "The `nnls` function is therefore computationally slow, especially for cases where there are many linear light profiles \n",
        "or even more complex linear inversions like a pixelized reconstruction.\n",
        "\n",
        "The source code therefore uses a \"fast nnls\" algorithm, which is an adaptation of the algorithm found at\n",
        "this URL: https://github.com/jvendrow/fnnls\n",
        "\n",
        "Unlike the scipy nnls function, the fnnls method uses the `data_vector` $D$ and `curvature_matrix` $F$ to solve for\n",
        "the `intensity` values. This provides it with additional information about the linear algebra problem, which is\n",
        "why it is faster.\n",
        "\n",
        "The function `reconstruction_positive_only_from` uses the `fnnls` algorithm to compute the `intensity` values\n",
        "of the linear light profiles, ensuring they are positive.\n",
        "\n",
        "However, the code below by itself actually produces a `LinAlgError` because the `curvature_matrix` is singular. Uncomment\n",
        "the code below to see this error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# reconstruction = al.util.inversion.reconstruction_positive_only_from(\n",
        "#     data_vector=data_vector,\n",
        "#     curvature_reg_matrix=curvature_matrix,  # ignore _reg_ tag in this guide\n",
        "# )\n",
        "#\n",
        "# print(reconstruction)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make the `curvature_matrix` non-singular, we simply add small numerical values to its diagonal elements. \n",
        "\n",
        "This is effectively add a small degree of \"zeroth order\" regularization to the inversion, which is sufficient to make\n",
        "the matrix non-singular and ensure the inversion can be performed.\n",
        "\n",
        "There are a variety of ways to regularize the inversion, and these can be manually input into the `Basis` object.\n",
        "However, for a multi-Gaussian expansion, testing has shown that adding a small degree of zeroth order regularization\n",
        "in conjunction with a positive-only solution is sufficient to ensure the inversion is robust for all reasonable\n",
        "science cases.\n",
        "\n",
        "In practise, the code only adds these small numerical values to the diagonal of the curvature matrix for elements\n",
        "which have no other regularization applied to them. Therefore, in the function call below we input \n",
        "`no_regularization_index_list=range(30)`, which tells the function to add small numerical values to all 30\n",
        "diagonal values corresponding to the 30 Gaussian linear light profiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "curvature_matrix = al.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=blurred_mapping_matrix,\n",
        "    noise_map=masked_dataset.noise_map,\n",
        "    add_to_curvature_diag=True,\n",
        "    no_regularization_index_list=list(range(30)),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `reconstruction` can now be computed successfully without a linear algebra error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "reconstruction = al.util.inversion.reconstruction_positive_only_from(\n",
        "    data_vector=data_vector,\n",
        "    curvature_reg_matrix=curvature_matrix,  # ignore _reg_ tag in this guide\n",
        ")\n",
        "\n",
        "print(reconstruction)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Image Reconstruction__\n",
        "\n",
        "Using the reconstructed `intensity` values we can map the reconstruction back to the image plane (via \n",
        "the `blurred mapping_matrix`) and produce a reconstruction of the image data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapped_reconstructed_image_2d = (\n",
        "    al.util.inversion.mapped_reconstructed_data_via_mapping_matrix_from(\n",
        "        mapping_matrix=blurred_mapping_matrix, reconstruction=reconstruction\n",
        "    )\n",
        ")\n",
        "\n",
        "mapped_reconstructed_image_2d = al.Array2D(\n",
        "    values=mapped_reconstructed_image_2d, mask=mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=mapped_reconstructed_image_2d)\n",
        "array_2d_plotter.figure_2d()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Function__\n",
        "\n",
        "We now quantify the goodness-of-fit of our galaxy model.\n",
        "\n",
        "We compute the `log_likelihood` of the fit, which is the value returned by the `log_likelihood_function`.\n",
        "\n",
        "The likelihood function for parametric galaxy modeling, even if linear light profiles are used, consists of two terms:\n",
        "\n",
        " $-2 \\mathrm{ln} \\, \\epsilon = \\chi^2 + \\sum_{\\rm  j=1}^{J} { \\mathrm{ln}} \\left [2 \\pi (\\sigma_j)^2 \\right]  \\, .$\n",
        "\n",
        "We now explain what each of these terms mean.\n",
        "\n",
        "__Chi Squared__\n",
        "\n",
        "The first term is a $\\chi^2$ statistic, which is defined above in our merit function as and is computed as follows:\n",
        "\n",
        " - `model_data` = `convolved_image_2d`\n",
        " - `residual_map` = (`data` - `model_data`)\n",
        " - `normalized_residual_map` = (`data` - `model_data`) / `noise_map`\n",
        " - `chi_squared_map` = (`normalized_residuals`) ** 2.0 = ((`data` - `model_data`)**2.0)/(`variances`)\n",
        " - `chi_squared` = sum(`chi_squared_map`)\n",
        "\n",
        "The chi-squared therefore quantifies if our fit to the data is accurate or not. \n",
        "\n",
        "High values of chi-squared indicate that there are many image pixels our model did not produce a good fit to the image \n",
        "for, corresponding to a fit with a lower likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_image = mapped_reconstructed_image_2d\n",
        "\n",
        "residual_map = masked_dataset.data - model_image\n",
        "normalized_residual_map = residual_map / masked_dataset.noise_map\n",
        "chi_squared_map = normalized_residual_map**2.0\n",
        "\n",
        "chi_squared = np.sum(chi_squared_map)\n",
        "\n",
        "print(chi_squared)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `chi_squared_map` indicates which regions of the image we did and did not fit accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "chi_squared_map = al.Array2D(values=chi_squared_map, mask=mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=chi_squared_map)\n",
        "array_2d_plotter.figure_2d()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Noise Normalization Term__\n",
        "\n",
        "Our likelihood function assumes the imaging data consists of independent Gaussian noise in every image pixel.\n",
        "\n",
        "The final term in the likelihood function is therefore a `noise_normalization` term, which consists of the sum\n",
        "of the log of every noise-map value squared. \n",
        "\n",
        "Given the `noise_map` is fixed, this term does not change during the galaxy modeling process and has no impact on the \n",
        "model we infer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "noise_normalization = float(np.sum(np.log(2 * np.pi * masked_dataset.noise_map**2.0)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Calculate The Log Likelihood__\n",
        "\n",
        "We can now, finally, compute the `log_likelihood` of the galaxy model, by combining the two terms computed above using\n",
        "the likelihood function defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "figure_of_merit = float(-0.5 * (chi_squared + noise_normalization))\n",
        "\n",
        "print(figure_of_merit)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "This process to perform a likelihood function evaluation is what is performed in the `FitImaging` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    basis=basis,\n",
        ")\n",
        "\n",
        "galaxies = al.Galaxies(galaxies=[galaxy])\n",
        "\n",
        "fit = al.FitImaging(\n",
        "    dataset=masked_dataset,\n",
        "    tracer=tracer,\n",
        "    settings_inversion=al.SettingsInversion(\n",
        "        use_w_tilde=False, use_border_relocator=True\n",
        "    ),\n",
        ")\n",
        "fit_log_evidence = fit.log_evidence\n",
        "print(fit_log_evidence)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit contains an `Inversion` object, which handles all the linear algebra we have covered in this script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.inversion)\n",
        "print(fit.inversion.data_vector)\n",
        "print(fit.inversion.curvature_matrix)\n",
        "print(fit.inversion.reconstruction)\n",
        "print(fit.inversion.mapped_reconstructed_image)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Inversion` object can be computed from a tracer and a dataset, by passing them to the `TracerToInversion` object.\n",
        "\n",
        "This objects handles a lot of extra functionality that we have not covered in this script, such as:\n",
        "\n",
        "- Separating out the linear light profiles from the standard light profiles.\n",
        "- Separating out objects which reconstruct the galaxy using a pixelized reconstruction, which are passed into\n",
        "  the `Inversion` object as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_to_inversion = al.TracerToInversion(\n",
        "    tracer=tracer,\n",
        "    dataset=masked_dataset,\n",
        ")\n",
        "\n",
        "inversion = tracer_to_inversion.inversion\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Galaxy Modeling__\n",
        "\n",
        "To fit a galaxy model to data, the likelihood function illustrated in this tutorial is sampled using a\n",
        "non-linear search algorithm.\n",
        "\n",
        "The default sampler is the nested sampling algorithm `nautilus` (https://github.com/joshspeagle/nautilus)\n",
        "but **PyAutoLens** supports multiple MCMC and optimization algorithms. \n",
        "\n",
        "For an MGE, the reduced number of free parameters (e.g. the `intensity` values are solved for\n",
        "via linear algebra and not a dimension of the non-linear parameter space) means that the sampler converges in fewer\n",
        "iterations and is less likely to infer a local maximum. \n",
        "\n",
        "Furthermore, the size of the lens galaxy, controlled by the `sigma` values of the Gaussians, are also all fixed\n",
        "and not non-linear free parameters. This further simplifies the non-linear parameter space.\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "We have presented a visual step-by-step guide to the multi Gaussian expansion likelihood function, which uses \n",
        "many 2D Gaussians to fit the galaxy light and solve for the `intensity` values via linear algebra.\n",
        "\n",
        "There are a number of other inputs features which slightly change the behaviour of this likelihood function, which\n",
        "are described in additional notebooks found in the `guides` package:\n",
        "\n",
        " - `over_sampling`: Oversampling the image grid into a finer grid of sub-pixels, which are all individually \n",
        " ray-traced to the source-plane and used to evaluate the light profile more accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}