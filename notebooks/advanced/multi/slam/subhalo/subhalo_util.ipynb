{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "from typing import Tuple\n",
        "\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "\n",
        "from autofit.non_linear.grid.sensitivity.result import SensitivityResult\n",
        "\n",
        "\n",
        "def visualize_subhalo_detect(\n",
        "    result_no_subhalo: af.Result,\n",
        "    result: af.GridSearchResult,\n",
        "    analysis,\n",
        "    paths: af.DirectoryPaths,\n",
        "):\n",
        "    \"\"\"\n",
        "    Visualize the results of a subhalo detection grid search using the SLaM pipeline.\n",
        "\n",
        "    This outputs the following visuals:\n",
        "\n",
        "    - The `log_evidence` increases in each cell of the subhalo detection grid search, which is plotted over a lens\n",
        "    subtracted  image of the dataset.\n",
        "\n",
        "    - The subhalo `mass` inferred for every cell of the grid search, plotted over the lens subtracted image.\n",
        "\n",
        "    - A subplot showing different aspects of the fit, so that the its with and without a subhalo can be compared.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    result_no_subhalo\n",
        "        The result of the model-fitting without a subhalo.\n",
        "    result\n",
        "        The grid search result of the subhalo detection model-fitting.\n",
        "    analysis\n",
        "        The analysis class used to perform the model fit.\n",
        "    paths\n",
        "        The paths object which defines the output path for the results of the subhalo detection grid search.\n",
        "    \"\"\"\n",
        "    result = al.subhalo.SubhaloGridSearchResult(\n",
        "        result=result,\n",
        "    )\n",
        "\n",
        "    fit_no_subhalo = result_no_subhalo.max_log_likelihood_fit\n",
        "\n",
        "    fit_imaging_with_subhalo = analysis.fit_from(\n",
        "        instance=result.best_samples.max_log_likelihood(),\n",
        "    )\n",
        "\n",
        "    output = aplt.Output(\n",
        "        path=paths.output_path,\n",
        "        format=\"png\",\n",
        "    )\n",
        "\n",
        "    evidence_max = 30.0\n",
        "    evidence_half = evidence_max / 2.0\n",
        "\n",
        "    colorbar = aplt.Colorbar(\n",
        "        manual_tick_values=[0.0, evidence_half, evidence_max],\n",
        "        manual_tick_labels=[\n",
        "            0.0,\n",
        "            np.round(evidence_half, 1),\n",
        "            np.round(evidence_max, 1),\n",
        "        ],\n",
        "    )\n",
        "    colorbar_tickparams = aplt.ColorbarTickParams(labelsize=22, labelrotation=90)\n",
        "\n",
        "    mat_plot = aplt.MatPlot2D(\n",
        "        axis=aplt.Axis(extent=result.extent),\n",
        "        #  colorbar=colorbar,\n",
        "        #  colorbar_tickparams=colorbar_tickparams,\n",
        "        output=output,\n",
        "    )\n",
        "\n",
        "    subhalo_plotter = al.subhalo.SubhaloPlotter(\n",
        "        result=result,\n",
        "        fit_imaging_no_subhalo=fit_no_subhalo,\n",
        "        fit_imaging_with_subhalo=fit_imaging_with_subhalo,\n",
        "        mat_plot_2d=mat_plot,\n",
        "    )\n",
        "\n",
        "    subhalo_plotter.figure_figures_of_merit_grid(\n",
        "        use_log_evidences=True,\n",
        "        relative_to_value=result_no_subhalo.samples.log_evidence,\n",
        "        remove_zeros=True,\n",
        "    )\n",
        "\n",
        "    subhalo_plotter.figure_mass_grid()\n",
        "    subhalo_plotter.subplot_detection_imaging()\n",
        "    subhalo_plotter.subplot_detection_fits()\n",
        "\n",
        "\n",
        "def visualize_sensitivity(\n",
        "    result: SensitivityResult,\n",
        "    paths: af.DirectoryPaths,\n",
        "    mass_result: af.Result,\n",
        "    mask: al.Mask2D,\n",
        "):\n",
        "    \"\"\"\n",
        "    Visualize the results of strong lens sensitivity mapping via the SLaM pipeline.\n",
        "\n",
        "    This outputs the following visuals:\n",
        "\n",
        "    - The `log_evidences_differences` and `log_likelihood_differences` of the sensitivity mapping,\n",
        "    overlaid as a 2D grid of values over the lens subtracted image of the dataset.\n",
        "\n",
        "    - The `log_evidences_differences` and `log_likelihood_differences` of the sensitivity mapping, as a 2D array\n",
        "    not overlaid an image.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    result\n",
        "        The result of the sensitivity mapping, which contains grids of the log evidence and log likelihood differences.\n",
        "    paths\n",
        "        The paths object which defines the output path for the results of the sensitivity mapping.\n",
        "    mass_result\n",
        "        The result of the mass pipeline, which is used to subtract the lens light from the dataset.\n",
        "    mask\n",
        "        The mask used to mask the dataset, which is plotted over the lens subtracted image.\n",
        "    \"\"\"\n",
        "\n",
        "    result = al.SubhaloSensitivityResult(\n",
        "        result=result,\n",
        "    )\n",
        "\n",
        "    output = aplt.Output(\n",
        "        path=paths.output_path,\n",
        "        format=\"png\",\n",
        "    )\n",
        "\n",
        "    data_subtracted = (\n",
        "        mass_result.max_log_likelihood_fit.subtracted_images_of_planes_list[-1]\n",
        "    )\n",
        "\n",
        "    data_subtracted = data_subtracted.apply_mask(mask=mask)\n",
        "\n",
        "    mat_plot_2d = aplt.MatPlot2D(axis=aplt.Axis(extent=result.extent), output=output)\n",
        "\n",
        "    plotter = aplt.SubhaloSensitivityPlotter(\n",
        "        result=result, data_subtracted=data_subtracted, mat_plot_2d=mat_plot_2d\n",
        "    )\n",
        "\n",
        "    plotter.subplot_sensitivity()\n",
        "    plotter.sensitivity_to_fits()\n",
        "\n",
        "\n",
        "def sensitivty_mask_brightest_from(\n",
        "    mass_result,\n",
        "    grid_dimensions_extent: Tuple[float, float, float, float],\n",
        "    number_of_pixels: int = 27,\n",
        ") -> al.Mask2D:\n",
        "    \"\"\"\n",
        "    Returns a sensitivity mask that only includes the N brightest pixels in the lensed source image in order to focus\n",
        "    sensitivity mapping on the brightest regions of the source.\n",
        "\n",
        "    This function extracts the lensed source image from the mass result and sorts the pixels by intensity, extracting\n",
        "    the input `number_of_pixels` brightest pixels such that sensitivity mapping is only performed on these pixels.\n",
        "\n",
        "    The mask is also trimmed to the grid dimensions extent to ensure that the sensitivity mapping is only performed\n",
        "    within a specific region of the image, for example to remove large regions of empty space at the edges in\n",
        "    visualization.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mass_result\n",
        "        The result of the mass pipeline, which contains the lensed source image.\n",
        "    grid_dimensions_extent\n",
        "        The extent of the grid dimensions to trim the sensitivity mask to, input as a tuple of (y0, y1, x0, x1).\n",
        "    number_of_pixels\n",
        "        The number of brightest pixels to include in the sensitivity mask.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    The sensitivity mask that includes only the N brightest pixels in the lensed source image.\n",
        "    \"\"\"\n",
        "\n",
        "    lensed_source_image = (\n",
        "        mass_result.max_log_likelihood_fit.model_images_of_planes_list[-1]\n",
        "    )\n",
        "\n",
        "    mask = mass_result.max_log_likelihood_fit.dataset.mask\n",
        "\n",
        "    y0 = grid_dimensions_extent[0]\n",
        "    y1 = grid_dimensions_extent[1]\n",
        "    x0 = grid_dimensions_extent[2]\n",
        "    x1 = grid_dimensions_extent[3]\n",
        "\n",
        "    y0_pix = mask.geometry.pixel_coordinates_2d_from(scaled_coordinates_2d=(y1, x1))[0]\n",
        "    y1_pix = mask.geometry.pixel_coordinates_2d_from(scaled_coordinates_2d=(y0, x0))[0]\n",
        "    x0_pix = mask.geometry.pixel_coordinates_2d_from(scaled_coordinates_2d=(y0, x0))[1]\n",
        "    x1_pix = mask.geometry.pixel_coordinates_2d_from(scaled_coordinates_2d=(y1, x1))[1]\n",
        "\n",
        "    lensed_source_image = lensed_source_image.native[y0_pix:y1_pix, x0_pix:x1_pix]\n",
        "\n",
        "    sorted_lensed_source_image = np.sort(lensed_source_image.flatten())[::-1]\n",
        "    sensitivity_mask = (\n",
        "        lensed_source_image < sorted_lensed_source_image[number_of_pixels - 1]\n",
        "    )\n",
        "\n",
        "    sensitivity_mask = np.flipud(sensitivity_mask)\n",
        "\n",
        "    return al.Mask2D(\n",
        "        mask=sensitivity_mask,\n",
        "        pixel_scales=lensed_source_image.pixel_scales,\n",
        "    )\n",
        "\n",
        "\n",
        "def visualize_sensitivity_mask(mass_result, sensitivity_mask, paths):\n",
        "    \"\"\"\n",
        "    Visualize the sensitivity mask used in the sensitivity mapping, as well as an image of the mask laid over\n",
        "    the lensed source image.\n",
        "\n",
        "    This visual makes it clear which regions of the lensed source image are included in the sensitivity mapping\n",
        "    and which are excluded.\n",
        "\n",
        "    The visuals are output to the output path specified in the settings search which points to where sensitivity\n",
        "    mapping results are stored.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    mass_result\n",
        "        The result of the mass pipeline, which contains the lensed source image.\n",
        "    sensitivity_mask\n",
        "        The mask used in the sensitivity mapping.\n",
        "    paths\n",
        "        The paths object which defines the output path for the results of the sensitivity mapping.\n",
        "    \"\"\"\n",
        "    lensed_source_image = (\n",
        "        mass_result.max_log_likelihood_fit.model_images_of_planes_list[-1]\n",
        "    )\n",
        "\n",
        "    sensitivity_mask = np.flipud(sensitivity_mask)\n",
        "\n",
        "    sensitivity_mask = al.Mask2D(\n",
        "        mask=sensitivity_mask, pixel_scales=lensed_source_image.pixel_scales\n",
        "    )\n",
        "\n",
        "    sensitivity_mask_plot = np.where(sensitivity_mask, 0.0, 1.0)\n",
        "\n",
        "    sensitivity_mask_plot = al.Array2D(\n",
        "        values=sensitivity_mask_plot,\n",
        "        mask=sensitivity_mask,\n",
        "    )\n",
        "\n",
        "    output = aplt.Output(\n",
        "        path=paths.output_path,\n",
        "        format=\"png\",\n",
        "    )\n",
        "\n",
        "    plotter = aplt.Array2DPlotter(\n",
        "        array=sensitivity_mask_plot,\n",
        "        mat_plot_2d=aplt.MatPlot2D(output=output),\n",
        "    )\n",
        "    plotter.set_filename(\"sensitivity_mask\")\n",
        "    plotter.figure_2d()\n",
        "\n",
        "    plotter = aplt.Array2DPlotter(\n",
        "        array=lensed_source_image,\n",
        "        mat_plot_2d=aplt.MatPlot2D(\n",
        "            axis=aplt.Axis(extent=sensitivity_mask.geometry.extent_square),\n",
        "            output=output,\n",
        "        ),\n",
        "    )\n",
        "    plotter.set_filename(\"sensitivity_masked_image\")\n",
        "    plotter.figure_2d()\n",
        "\n",
        "\n",
        "class Visualizer:\n",
        "    def __init__(self, mass_result: af.Result, mask: al.Mask2D):\n",
        "        \"\"\"\n",
        "        Performs on-the-fly visualization of the sensitivity mapping, outputting the results of the sensitivity\n",
        "        mapping so far to hard disk after each sensitivity cell fit is complete.\n",
        "\n",
        "        This means that the sensitivity mapping results grid are updated throughout the sensitivity mapping run and\n",
        "        can be inspected before the full analysis has completed. Due to the long run times of sensitivity mapping,\n",
        "        this allows inspection of the results before the full analysis has completed.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mass_result\n",
        "            The result of the SLaM MASS PIPELINE which ran before this pipeline.\n",
        "        mask\n",
        "            The Mask2D that is applied to the imaging data for model-fitting.\n",
        "        \"\"\"\n",
        "\n",
        "        self.mass_result = mass_result\n",
        "        self.mask = mask\n",
        "\n",
        "    def __call__(self, sensitivity_result, paths: af.DirectoryPaths):\n",
        "        \"\"\"\n",
        "        The `visualizer_cls` is called by the `Sensitivity` class after the `base_model` and `perturb_model` have been\n",
        "        fitted to the simulated data, after every sensitivity cell has been fitted.\n",
        "\n",
        "        This function receives the result of the fit to the `base_model` and `perturb_model` of all previously completed\n",
        "        sensitivity cells and is able to visualize the results of all of sensitivity mapping perform so far.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        sensitivity_result\n",
        "            The result of the sensitivity mapping search so far.\n",
        "        paths\n",
        "            The `Paths` instance which contains the path to the folder where the results of the fit are written to.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        \"\"\"\n",
        "        visualize_sensitivity(\n",
        "            result=sensitivity_result,\n",
        "            paths=paths,\n",
        "            mass_result=self.mass_result,\n",
        "            mask=self.mask,\n",
        "        )\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}