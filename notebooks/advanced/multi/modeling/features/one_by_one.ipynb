{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling Features: One By One\n",
        "=============================\n",
        "\n",
        "Multi-wavelength analysis does not necessarily require us to fit all datasets simultaneously. Instead, we can fit one\n",
        "dataset first in order to infer a robust lens and source model, and then fit the next dataset, using the inferred\n",
        "model as the starting point.\n",
        "\n",
        "There are many occasions where this approach is beneficial, for example:\n",
        "\n",
        "- When certain datasets are worse quality (e.g. lower resolution) than others. Fitting them simultaneously may mean this\n",
        "  dataset's lower quality makes the model fit less robust. By fitting them one by one, using the inferred model of the\n",
        "  best dataset first, we can ensure the model-fit is as robust as possible and interpret the results of the lower\n",
        "  quality datasets more clearly.\n",
        "\n",
        "- It can often produce faster run times, as although more non-linear searches are performed, each search is faster\n",
        "  than a search which fits all datasets simultaneously.\n",
        "\n",
        "- To investigate whether lens modeling results inferred when we model all datasets simultanoeusly are robust. If the\n",
        "  result disappears for fits to individual datasets, this may suggest the result is not robust.\n",
        "\n",
        "To perform modeling one-by-one, we have to make decision about how simple or complex we make the model after\n",
        "fitting the highest quality dataset. For example, we may:\n",
        "\n",
        "- Fix the lens mass model and only allow the lens light and source light to vary.\n",
        "\n",
        "- Fix the lens mass model and the majority of lens light and source light parameters, allowing only the `intensity`\n",
        "  values to vary.\n",
        "\n",
        "- Allow all parameters to vary, but use the highest quality dataset's inferred model as the starting point.\n",
        "\n",
        "- Whether to account for offsets between the datasets, or to assume the datasets are aligned.\n",
        "\n",
        "We illustrate different examples in this script, with the appropriate choice depending on your specific science case.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits an `Imaging` dataset of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's light is a linear parametric linear `Sersic` bulge.\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's light is a linear parametric linear `Sersic`.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Colors__\n",
        "\n",
        "The colors of the multi-wavelength image, which in this case are green (g-band) and red (r-band).\n",
        "\n",
        "The strings are used for load each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "color_list = [\"g\", \"r\"]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixel Scales__\n",
        "\n",
        "Every multi-wavelength dataset can have its own unique pixel-scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixel_scales_list = [0.08, 0.12]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot each multi-wavelength strong lens dataset, using a list of their waveband colors.\n",
        "\n",
        "The plotted images show that the datasets have a small offset between them, half a pixel based on the resolution of\n",
        "the second image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"multi\"\n",
        "dataset_label = \"imaging\"\n",
        "dataset_name = \"dataset_offsets\"\n",
        "\n",
        "dataset_path = path.join(\"dataset\", dataset_type, dataset_label, dataset_name)\n",
        "\n",
        "dataset_list = [\n",
        "    al.Imaging.from_fits(\n",
        "        data_path=path.join(dataset_path, f\"{color}_data.fits\"),\n",
        "        psf_path=path.join(dataset_path, f\"{color}_psf.fits\"),\n",
        "        noise_map_path=path.join(dataset_path, f\"{color}_noise_map.fits\"),\n",
        "        pixel_scales=pixel_scales,\n",
        "    )\n",
        "    for color, pixel_scales in zip(color_list, pixel_scales_list)\n",
        "]\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the lens and source galaxies.\n",
        "\n",
        "For multi-wavelength lens modeling, we use the same mask for every dataset whenever possible. This is not\n",
        "absolutely necessary, but provides a more reliable analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_list = [\n",
        "    al.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        "    )\n",
        "    for dataset in dataset_list\n",
        "]\n",
        "\n",
        "dataset_list = [\n",
        "    dataset.apply_mask(mask=mask) for imaging, mask in zip(dataset_list, mask_list)\n",
        "]\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "We create an `Analysis` object for every dataset.\n",
        "\n",
        "We do not sum the analyses, like we do in most other example scripts, as we are going to fit each dataset one-by-one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [al.AnalysisImaging(dataset=dataset) for dataset in dataset_list]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose a lens model where:\n",
        "\n",
        " - The lens galaxy's light is a linear parametric `Sersic`, where the `intensity` parameter of the lens galaxy\n",
        "   is solved for linearly [6 parameters].\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear` [7 parameters].\n",
        " \n",
        " - The source galaxy's light is a linear parametric `Sersic`, where the `intensity` parameter of the lens galaxy\n",
        "   is solved for linearly [6 parameters].\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=19."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(\n",
        "    al.Galaxy,\n",
        "    redshift=0.5,\n",
        "    bulge=al.lp_linear.Sersic,\n",
        "    mass=al.mp.Isothermal,\n",
        "    shear=al.mp.ExternalShear,\n",
        ")\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=al.lp_linear.SersicCore)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"multi\", \"modeling\"),\n",
        "    name=\"one_by_one__main_dataset\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=4,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis_list[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result object returned by this model-fit is a `Result` object. It is not a list like other examples, because we \n",
        "did not use a combined analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the result's tracer shows the source,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=result.grids.uniform\n",
        ")\n",
        "tracer_plotter.subplot_tracer()\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Second Dataset Mass Model Fixed__\n",
        "\n",
        "We now fit the second dataset using the inferred model of the first dataset as the starting point.\n",
        "\n",
        "We compose a simple lens model where the mass model is fixed to the result of the first dataset fit, and the lens\n",
        "and source galaxy's light are varied. \n",
        "\n",
        "This model therefore assumes that the mass does not change over wavelength, but the lens and source light do, which\n",
        "is what we expect for a strong lens system.\n",
        "\n",
        "The code below uses the search chaining API to link the priors between model parameters, if you are not\n",
        "familiar with this feature, checkout the `imaging/advanced/chaining` package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# model = af.Collection(\n",
        "#     galaxies=af.Collection(\n",
        "#         lens=af.Model(\n",
        "#             al.Galaxy,\n",
        "#             redshift=result.instance.galaxies.lens.redshift,\n",
        "#             bulge=result.model.galaxies.lens.bulge,\n",
        "#             mass=result.instance.galaxies.lens.mass,\n",
        "#             shear=result.instance.galaxies.lens.shear,\n",
        "#         ),\n",
        "#         source=result.model.galaxies.source,\n",
        "#     ),\n",
        "# )\n",
        "#\n",
        "# print(model.info)\n",
        "#\n",
        "# search = af.Nautilus(\n",
        "#     path_prefix=path.join(\"multi\", \"modeling\"),\n",
        "#     name=\"one_by_one__second_mass_model_fixed\",\n",
        "#     unique_tag=dataset_name,\n",
        "#     n_live=100,\n",
        "#     number_of_cores=4,\n",
        "# )\n",
        "#\n",
        "# result_mass_model_fixed = search.fit(model=model, analysis=analysis_list[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Second Dataset Offset__\n",
        "\n",
        "Multi-wavelength datasets often have offsets between their images, which are due to the different telescope pointings\n",
        "during the observations.\n",
        "\n",
        "These offsets are often accounted for during the data reduction process, but may not be perfectly corrected and\n",
        "have uncertainties associated with them.\n",
        "\n",
        "Fitting datasets one-by-one offers a straightforward method to account for these offsets, by allowing the offset\n",
        "between the datasets to vary during the model-fit as two free parameters (y and x).\n",
        "\n",
        "We now fit for the offset between datasets, keeping all lens model parameters fixed to the result of the first dataset\n",
        "fit. \n",
        "\n",
        "In this example, the two datasets are not offset, so the model-fit will infer an offset consistent with (0.0\", 0.0\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_model = af.Model(al.DatasetModel)\n",
        "\n",
        "dataset_model.grid_offset.grid_offset_0 = af.UniformPrior(\n",
        "    lower_limit=-0.1, upper_limit=0.1\n",
        ")\n",
        "dataset_model.grid_offset.grid_offset_1 = af.UniformPrior(\n",
        "    lower_limit=-0.1, upper_limit=0.1\n",
        ")\n",
        "\n",
        "model = af.Collection(\n",
        "    dataset_model=dataset_model,\n",
        "    galaxies=result.instance.galaxies,\n",
        ")\n",
        "\n",
        "print(model.info)\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"multi\", \"modeling\"),\n",
        "    name=\"one_by_one__dataset_offset\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=4,\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis_list[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autolens_workspace/*/imaging/results` for a full description of analysing results in **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}