{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling: Same Wavelength\n",
        "=========================\n",
        "\n",
        "This script fits a multiple `Imaging` datasets observed at the same wavelength of a 'galaxy-scale' strong lens with a\n",
        "model where:\n",
        "\n",
        " - The lens galaxy's light is omitted (and is not present in the simulated data).\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's light is a linear parametric `SersicCore`.\n",
        "\n",
        "This script demonstrates how PyAutoLens's multi-dataset modeling tools can also simultaneously analyse datasets\n",
        "observed at the same wavelength.\n",
        "\n",
        "An example use case might be analysing undithered HST images before they are combined via the multidrizzing process,\n",
        "to remove correlated noise in the data.\n",
        "\n",
        "This is an advanced script and assumes previous knowledge of the core **PyAutoLens** API for lens modeling. Thus,\n",
        "certain parts of code are not documented to ensure the script is concise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixel Scales__\n",
        "\n",
        "If observed at the same wavelength, it is likely the datasets have the same pixel-scale.\n",
        "\n",
        "Nevertheless, we specify this as a list as there could be an exception."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixel_scales_list = [0.1, 0.1]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot each multi-wavelength strong lens dataset, using a list of their waveband colors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"multi\"\n",
        "dataset_label = \"imaging\"\n",
        "dataset_name = \"same_wavelength\"\n",
        "\n",
        "dataset_path = path.join(\"dataset\", dataset_type, dataset_label, dataset_name)\n",
        "\n",
        "dataset_list = [\n",
        "    al.Imaging.from_fits(\n",
        "        data_path=path.join(dataset_path, f\"image_{i}.fits\"),\n",
        "        psf_path=path.join(dataset_path, f\"psf_{i}.fits\"),\n",
        "        noise_map_path=path.join(dataset_path, f\"noise_map_{i}.fits\"),\n",
        "        pixel_scales=pixel_scales,\n",
        "    )\n",
        "    for i, pixel_scales in enumerate(pixel_scales_list)\n",
        "]\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the lens and source galaxies.\n",
        "\n",
        "For multi-wavelength lens modeling, we use the same mask for every dataset whenever possible. This is not\n",
        "absolutely necessary, but provides a more reliable analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_list = [\n",
        "    al.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        "    )\n",
        "    for dataset in dataset_list\n",
        "]\n",
        "\n",
        "\n",
        "dataset_list = [\n",
        "    dataset.apply_mask(mask=mask) for imaging, mask in zip(dataset_list, mask_list)\n",
        "]\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "We create an `Analysis` object for every dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [al.AnalysisImaging(dataset=dataset) for dataset in dataset_list]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose a lens model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear` [7 parameters].\n",
        " \n",
        " - The source galaxy's light is a linear parametric `SersicCore` [6 parameters].\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=14."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=mass, shear=shear)\n",
        "\n",
        "# Source:\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=al.lp_linear.SersicCore)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now combine them using the factor analysis class, which allows us to fit the two datasets simultaneously.\n",
        "\n",
        "Unlike other examples, no customization to the model is applied that, for example, adds more free parameters,\n",
        "given that the datasets do not vary over wavelength."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_factor_list = []\n",
        "\n",
        "for analysis in analysis_list:\n",
        "\n",
        "    bulge = af.Model(ag.lp_linear.Sersic)\n",
        "    disk = af.Model(ag.lp_linear.Exponential)\n",
        "\n",
        "    galaxy = af.Model(ag.Galaxy, redshift=0.5, bulge=bulge, disk=disk)\n",
        "\n",
        "    model_analysis = af.Collection(galaxies=af.Collection(galaxy=galaxy))\n",
        "\n",
        "    analysis_factor = af.AnalysisFactor(prior_model=model_analysis, analysis=analysis)\n",
        "\n",
        "    analysis_factor_list.append(analysis_factor)\n",
        "\n",
        "factor_graph = af.FactorGraphModel(*analysis_factor_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` of the model shows us there are two models each with linear light profiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph.global_prior_model.info)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using the nested sampling algorithm Nautilus (see `start.here.py` for a \n",
        "full description)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"multi\", \"modeling\"),\n",
        "    name=\"same_wavelength\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_list = search.fit(model=factor_graph.global_prior_model, analysis=factor_graph)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result object returned by this model-fit is a list of `Result` objects, because we used a combined analysis.\n",
        "Each result corresponds to each analysis, and therefore corresponds to the model-fit at that wavelength."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_list[0].max_log_likelihood_instance)\n",
        "print(result_list[1].max_log_likelihood_instance)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting each result's tracer shows that the source appears different, owning to its different intensities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for result in result_list:\n",
        "    tracer_plotter = aplt.TracerPlotter(\n",
        "        tracer=result.max_log_likelihood_tracer, grid=result.grids.lp\n",
        "    )\n",
        "    tracer_plotter.subplot_tracer()\n",
        "\n",
        "    fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "    fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Samples` object still has the dimensions of the overall non-linear search (in this case N=15). \n",
        "\n",
        "Therefore, the samples is identical in every result object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plotter = aplt.NestPlotter(samples=result_list.samples)\n",
        "plotter.corner_anesthetic()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autolens_workspace/*/imaging/results` for a full description of analysing results in **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}