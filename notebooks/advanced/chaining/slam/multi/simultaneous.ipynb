{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SLaM: Multi Wavelength Simultaneous\n",
        "===================================\n",
        "\n",
        "This example shows how to use the SLaM pipeline to fit a lens dataset at multiple wavelengths simultaneously.\n",
        "\n",
        "Simultaneous multi-dataset fits are currently built into the SLaM pipeline without user input or customization.\n",
        "Therefore, as long as lists of `Analysis` objects are created, summed and passed to the SLaM pipelines, the analysis\n",
        "will fit every dataset simultaneously and it will adapt the model as follows:\n",
        "\n",
        "- Sub-pixel offsets between the datasets are fully modeled as free parameters in each stage of the pipeline, assuming\n",
        "  broad uniform priors for every step. This is because the precision of a lens model can often be less than the\n",
        "  requirements on astrometry.\n",
        "\n",
        "- The regularization parameters are free for every dataset in the `source_pix[1]` and `source_pix[2]` stages. This is because\n",
        "  the source morphology can be different between datasets, and the regularization scheme adapts to this.\n",
        "\n",
        "- From the `light_lp` stage onwards, the regularization scheme for each dataset is different fixed to that inferred\n",
        "  for the `source_pix[2]` stage.\n",
        "\n",
        "Simultaneous fitting SLaM pipelines are not designed for customization, for example changing the model from the\n",
        "set up above. This is because we are still figuring out the best way to perform multi-wavelength modeling, but have\n",
        "so far figured the above settings are important.\n",
        "\n",
        "If you need customization of the model or pipeline, you should pick apart the SLaM pipeline and customize\n",
        "them as you see fit.\n",
        "\n",
        "__Preqrequisites__\n",
        "\n",
        "Before reading this script, you should have familiarity with the following key concepts:\n",
        "\n",
        "- **Multi**: The `autolens_workspace/*/advanced/multi` package describes many different ways that multiple datasets\n",
        "  can be modeled in a single analysis.\n",
        "\n",
        "__This Script__\n",
        "\n",
        "Using a SOURCE LP PIPELINE, SOURCE PIX PIPELINE, LIGHT LP PIPELINE and TOTAL MASS PIPELINE this SLaM modeling\n",
        "script  fits `Imaging` dataset  of a strong lens system where in the final model:\n",
        "\n",
        " - The lens galaxy's light is a bulge with Multiple Gaussian Expansion (MGE) light profile.\n",
        " - The lens galaxy's total mass distribution is an `PowerLaw` plus an `ExternalShear`.\n",
        " - The source galaxy's light is a `Pixelization`.\n",
        "\n",
        "This modeling script uses the SLaM pipelines:\n",
        "\n",
        " `source_lp`\n",
        " `source_pix`\n",
        " `light_lp`\n",
        " `mass_total`\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `chaining/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "\n",
        "sys.path.insert(0, os.getcwd())\n",
        "import slam"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__ \n",
        "\n",
        "Load, plot and mask the `Imaging` data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_waveband_list = [\"g\", \"r\"]\n",
        "pixel_scale_list = [0.12, 0.08]\n",
        "\n",
        "dataset_name = \"lens_sersic\"\n",
        "dataset_main_path = path.join(\"dataset\", \"multi\", \"imaging\", dataset_name)\n",
        "dataset_path = path.join(dataset_main_path, dataset_name)\n",
        "\n",
        "\n",
        "dataset_list = []\n",
        "\n",
        "for dataset_waveband, pixel_scale in zip(dataset_waveband_list, pixel_scale_list):\n",
        "    dataset = al.Imaging.from_fits(\n",
        "        data_path=path.join(dataset_main_path, f\"{dataset_waveband}_data.fits\"),\n",
        "        noise_map_path=path.join(\n",
        "            dataset_main_path, f\"{dataset_waveband}_noise_map.fits\"\n",
        "        ),\n",
        "        psf_path=path.join(dataset_main_path, f\"{dataset_waveband}_psf.fits\"),\n",
        "        pixel_scales=pixel_scale,\n",
        "    )\n",
        "\n",
        "    mask_radius = 3.0\n",
        "\n",
        "    mask = al.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native,\n",
        "        pixel_scales=dataset.pixel_scales,\n",
        "        radius=mask_radius,\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "    dataset_list.append(dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Settings AutoFit__\n",
        "\n",
        "The settings of autofit, which controls the output paths, parallelization, database use, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings_search = af.SettingsSearch(\n",
        "    path_prefix=path.join(\"slam\", \"multi\", \"simultaneous\"),\n",
        "    unique_tag=dataset_name,\n",
        "    info=None,\n",
        "    number_of_cores=4,\n",
        "    session=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Redshifts__\n",
        "\n",
        "The redshifts of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "redshift_lens = 0.5\n",
        "redshift_source = 1.0"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE LP PIPELINE__\n",
        "\n",
        "The SOURCE LP PIPELINE fits an identical to the `start_here.ipynb` example, except:\n",
        "\n",
        " - The model includes the (y,x) offset of each dataset relative to the first dataset, which is added to every\n",
        "  `AnalysisImaging` object such that there are 2 extra parameters fitted for each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [al.AnalysisImaging(dataset=dataset) for dataset in dataset_list]\n",
        "\n",
        "analysis = sum(analysis_list)\n",
        "\n",
        "# Lens Light\n",
        "\n",
        "centre_0 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "centre_1 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "\n",
        "total_gaussians = 30\n",
        "gaussian_per_basis = 2\n",
        "\n",
        "log10_sigma_list = np.linspace(-2, np.log10(mask_radius), total_gaussians)\n",
        "\n",
        "bulge_gaussian_list = []\n",
        "\n",
        "for j in range(gaussian_per_basis):\n",
        "    gaussian_list = af.Collection(\n",
        "        af.Model(al.lp_linear.Gaussian) for _ in range(total_gaussians)\n",
        "    )\n",
        "\n",
        "    for i, gaussian in enumerate(gaussian_list):\n",
        "        gaussian.centre.centre_0 = centre_0\n",
        "        gaussian.centre.centre_1 = centre_1\n",
        "        gaussian.ell_comps = gaussian_list[0].ell_comps\n",
        "        gaussian.sigma = 10 ** log10_sigma_list[i]\n",
        "\n",
        "    bulge_gaussian_list += gaussian_list\n",
        "\n",
        "lens_bulge = af.Model(\n",
        "    al.lp_basis.Basis,\n",
        "    profile_list=bulge_gaussian_list,\n",
        ")\n",
        "\n",
        "# Source Light\n",
        "\n",
        "centre_0 = af.GaussianPrior(mean=0.0, sigma=0.3)\n",
        "centre_1 = af.GaussianPrior(mean=0.0, sigma=0.3)\n",
        "\n",
        "total_gaussians = 30\n",
        "gaussian_per_basis = 1\n",
        "\n",
        "log10_sigma_list = np.linspace(-3, np.log10(1.0), total_gaussians)\n",
        "\n",
        "bulge_gaussian_list = []\n",
        "\n",
        "for j in range(gaussian_per_basis):\n",
        "    gaussian_list = af.Collection(\n",
        "        af.Model(al.lp_linear.Gaussian) for _ in range(total_gaussians)\n",
        "    )\n",
        "\n",
        "    for i, gaussian in enumerate(gaussian_list):\n",
        "        gaussian.centre.centre_0 = centre_0\n",
        "        gaussian.centre.centre_1 = centre_1\n",
        "        gaussian.ell_comps = gaussian_list[0].ell_comps\n",
        "        gaussian.sigma = 10 ** log10_sigma_list[i]\n",
        "\n",
        "    bulge_gaussian_list += gaussian_list\n",
        "\n",
        "source_bulge = af.Model(\n",
        "    al.lp_basis.Basis,\n",
        "    profile_list=bulge_gaussian_list,\n",
        ")\n",
        "\n",
        "source_lp_result = slam.source_lp.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    lens_bulge=lens_bulge,\n",
        "    lens_disk=None,\n",
        "    mass=af.Model(al.mp.Isothermal),\n",
        "    shear=af.Model(al.mp.ExternalShear),\n",
        "    source_bulge=source_bulge,\n",
        "    mass_centre=(0.0, 0.0),\n",
        "    redshift_lens=redshift_lens,\n",
        "    redshift_source=redshift_source,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE PIX PIPELINE__\n",
        "\n",
        "The SOURCE PIX PIPELINE uses two searches to initialize a robust model for the `Pixelization` that\n",
        "reconstructs the source galaxy's light. \n",
        "\n",
        "This pixelization adapts its source pixels to the morphology of the source, placing more pixels in its \n",
        "brightest regions. To do this, an \"adapt image\" is required, which is the lens light subtracted image meaning\n",
        "only the lensed source emission is present.\n",
        "\n",
        "The SOURCE LP Pipeline result is not good enough quality to set up this adapt image (e.g. the source\n",
        "may be more complex than a simple light profile). The first step of the SOURCE PIX PIPELINE therefore fits a new\n",
        "model using a pixelization to create this adapt image.\n",
        "\n",
        "The first search, which is an initialization search, fits an `Overlay` image-mesh, `Delaunay` mesh \n",
        "and `AdaptiveBrightnessSplit` regularization.\n",
        "\n",
        "__Adapt Images / Image Mesh Settings__\n",
        "\n",
        "If you are unclear what the `adapt_images` and `SettingsInversion` inputs are doing below, refer to the \n",
        "`autolens_workspace/*/imaging/advanced/chaining/pix_adapt/start_here.py` example script.\n",
        "\n",
        "__Settings__:\n",
        "\n",
        " - Positions: We update the positions and positions threshold using the previous model-fitting result (as described \n",
        " in `chaining/examples/parametric_to_pixelization.py`) to remove unphysical solutions from the `Inversion` model-fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions_likelihood = source_lp_result[0].positions_likelihood_from(\n",
        "    factor=3.0, minimum_threshold=0.2\n",
        ")\n",
        "\n",
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_image_maker=al.AdaptImageMaker(result=result),\n",
        "        positions_likelihood=positions_likelihood,\n",
        "    )\n",
        "    for result in source_lp_result\n",
        "]\n",
        "\n",
        "analysis = sum(analysis_list)\n",
        "\n",
        "source_pix_result_1 = slam.source_pix.run_1(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_lp_result=source_lp_result,\n",
        "    mesh_init=al.mesh.Delaunay,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE PIX PIPELINE 2 (with lens light)__\n",
        "\n",
        "The second search, which uses the mesh and regularization used throughout the remainder of the SLaM pipelines,\n",
        "fits the following model:\n",
        "\n",
        "- Uses a `Hilbert` image-mesh. \n",
        "\n",
        "- Uses a `Delaunay` mesh.\n",
        "\n",
        " - Uses an `AdaptiveBrightnessSplit` regularization.\n",
        "\n",
        " - Carries the lens redshift, source redshift and `ExternalShear` of the SOURCE LP PIPELINE through to the\n",
        " SOURCE PIX PIPELINE.\n",
        "\n",
        "The `Hilbert` image-mesh and `AdaptiveBrightness` regularization adapt the source pixels and regularization weights\n",
        "to the source's morphology.\n",
        "\n",
        "Below, we therefore set up the adapt image using this result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_image_maker=al.AdaptImageMaker(result=result),\n",
        "        settings_inversion=al.SettingsInversion(\n",
        "            image_mesh_min_mesh_pixels_per_pixel=3,\n",
        "            image_mesh_min_mesh_number=5,\n",
        "            image_mesh_adapt_background_percent_threshold=0.1,\n",
        "            image_mesh_adapt_background_percent_check=0.8,\n",
        "        ),\n",
        "    )\n",
        "    for result in source_pix_result_1\n",
        "]\n",
        "\n",
        "analysis = sum(analysis_list)\n",
        "\n",
        "source_pix_result_2 = slam.source_pix.run_2(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_lp_result=source_lp_result,\n",
        "    source_pix_result_1=source_pix_result_1,\n",
        "    image_mesh=al.image_mesh.Hilbert,\n",
        "    mesh=al.mesh.Delaunay,\n",
        "    regularization=al.reg.AdaptiveBrightnessSplit,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__LIGHT LP PIPELINE__\n",
        "\n",
        "The LIGHT LP PIPELINE uses one search to fit a complex lens light model to a high level of accuracy, using the\n",
        "lens mass model and source light model fixed to the maximum log likelihood result of the SOURCE LP PIPELINE.\n",
        "In this example it:\n",
        "\n",
        " - Uses a multi Gaussian expansion with 2 sets of 30 Gaussians for the lens galaxy's light. [6 Free Parameters].\n",
        "\n",
        " - Uses an `Isothermal` mass model with `ExternalShear` for the lens's total mass distribution [fixed from SOURCE PIX PIPELINE].\n",
        "\n",
        " - Uses a `Pixelization` for the source's light [fixed from SOURCE PIX PIPELINE].\n",
        "\n",
        " - Carries the lens redshift and source redshift of the SOURCE PIPELINE through to the MASS PIPELINE [fixed values].   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_image_maker=al.AdaptImageMaker(result=result),\n",
        "        raise_inversion_positions_likelihood_exception=False,\n",
        "    )\n",
        "    for result in source_pix_result_1\n",
        "]\n",
        "\n",
        "analysis = sum(analysis_list)\n",
        "total_gaussians = 30\n",
        "gaussian_per_basis = 2\n",
        "\n",
        "log10_sigma_list = np.linspace(-2, np.log10(mask_radius), total_gaussians)\n",
        "\n",
        "bulge_gaussian_list = []\n",
        "\n",
        "for j in range(gaussian_per_basis):\n",
        "    gaussian_list = af.Collection(\n",
        "        af.Model(al.lp_linear.Gaussian) for _ in range(total_gaussians)\n",
        "    )\n",
        "\n",
        "    for i, gaussian in enumerate(gaussian_list):\n",
        "        gaussian.centre.centre_0 = gaussian_list[0].centre.centre_0\n",
        "        gaussian.centre.centre_1 = gaussian_list[0].centre.centre_1\n",
        "        gaussian.ell_comps = gaussian_list[0].ell_comps\n",
        "        gaussian.sigma = 10 ** log10_sigma_list[i]\n",
        "\n",
        "    bulge_gaussian_list += gaussian_list\n",
        "\n",
        "lens_bulge = af.Model(\n",
        "    al.lp_basis.Basis,\n",
        "    profile_list=bulge_gaussian_list,\n",
        ")\n",
        "\n",
        "light_result = slam.light_lp.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_result_for_lens=source_pix_result_1,\n",
        "    source_result_for_source=source_pix_result_2,\n",
        "    lens_bulge=lens_bulge,\n",
        "    lens_disk=None,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__MASS TOTAL PIPELINE__\n",
        "\n",
        "The MASS TOTAL PIPELINE uses one search to fits a complex lens mass model to a high level of accuracy, \n",
        "using the lens mass model and source model of the SOURCE PIX PIPELINE to initialize the model priors and the lens \n",
        "light model of the LIGHT LP PIPELINE. \n",
        "\n",
        "In this example it:\n",
        "\n",
        " - Uses a linear Multi Gaussian Expansion bulge [fixed from LIGHT LP PIPELINE].\n",
        "\n",
        " - Uses an `PowerLaw` model for the lens's total mass distribution [priors initialized from SOURCE \n",
        " PARAMETRIC PIPELINE + centre unfixed from (0.0, 0.0)].\n",
        "\n",
        " - Uses a `Pixelization` for the source's light [fixed from SOURCE PIX PIPELINE].\n",
        "\n",
        " - Carries the lens redshift and source redshift of the SOURCE PIPELINE through to the MASS TOTAL PIPELINE.\n",
        "\n",
        "__Settings__:\n",
        "\n",
        " - adapt: We may be using adapt features and therefore pass the result of the SOURCE PIX PIPELINE to use as the\n",
        " hyper dataset if required.\n",
        "\n",
        " - Positions: We update the positions and positions threshold using the previous model-fitting result (as described \n",
        " in `chaining/examples/parametric_to_pixelization.py`) to remove unphysical solutions from the `Inversion` model-fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions_likelihood = source_lp_result[0].positions_likelihood_from(\n",
        "    factor=3.0, minimum_threshold=0.2\n",
        ")\n",
        "\n",
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_image_maker=al.AdaptImageMaker(result=result),\n",
        "        positions_likelihood=positions_likelihood,\n",
        "    )\n",
        "    for result in source_lp_result\n",
        "]\n",
        "\n",
        "analysis = sum(analysis_list)\n",
        "\n",
        "mass_result = slam.mass_total.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_result_for_lens=source_pix_result_1,\n",
        "    source_result_for_source=source_pix_result_2,\n",
        "    light_result=light_result,\n",
        "    mass=af.Model(al.mp.PowerLaw),\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output__\n",
        "\n",
        "The SLaM pipeline above outputs the model-fitting results to the `output` folder of the workspace, which includes\n",
        "the usual model results, visualization, and .json files.\n",
        "\n",
        "As described in the `autolens_workspace/*/results` package there is an API for loading these results from hard disk\n",
        "to Python, for example so they can be manipulated in a Juypter notebook.\n",
        "\n",
        "However, it is also often useful to output the results to the dataset folder of each lens in standard formats, for\n",
        "example images of the lens and lensed source in .fits or visualization outputs like .png files. This makes transferring\n",
        "the results more portable, especially if they are to be used by other people.\n",
        "\n",
        "The `slam_util` module provides convenience methods for outputting many results to the dataset folder, we\n",
        "use it below to output the following results:\n",
        "\n",
        " - Images of the model lens light, lensed source light and source reconstruction to .fits files.\n",
        " - A text `model.results` file containing the lens model parameter estimates.\n",
        " - A subplot containing the fit in one row, which is output to .png.\n",
        " - A subplot of the source reconstruction in the source plane in one row, which is output to .png."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "slam.slam_util.output_model_to_fits(\n",
        "    output_path=path.join(dataset_path, \"model\"),\n",
        "    result=mass_result,\n",
        "    model_lens_light=True,\n",
        "    model_source_light=True,\n",
        "    source_reconstruction=True,\n",
        ")\n",
        "\n",
        "slam.slam_util.output_model_results(\n",
        "    output_path=path.join(dataset_path, \"model\"),\n",
        "    result=mass_result,\n",
        "    filename=\"model.results\",\n",
        ")\n",
        "\n",
        "slam.slam_util.output_fit_multi_png(\n",
        "    output_path=dataset_path,\n",
        "    result_list=[mass_result],\n",
        "    filename=\"sie_fit\",\n",
        ")\n",
        "\n",
        "slam.slam_util.output_source_multi_png(\n",
        "    output_path=dataset_path,\n",
        "    result_list=[mass_result],\n",
        "    filename=\"source_reconstruction\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}