{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chaining: Point Source to Imaging\n",
        "=================================\n",
        "\n",
        "This script chains three searches to fit `Imaging` data of a strong lens with multiple lens galaxies where:\n",
        "\n",
        " - The group consists of three whose light models are `SersicSph` profiles and total mass distributions\n",
        " are `IsothermalSph` models.\n",
        " - The source galaxy's light is an `Sersic`.\n",
        "\n",
        "The two searches break down as follows:\n",
        "\n",
        " 1) Model the lens galaxy masses with a point source galaxy, fitting just the position information in the source.\n",
        " 2) Model the full surface brightness information in the `Imaging` data using `LightProfile`'s for the lens galaxies\n",
        " and lensed source.\n",
        "\n",
        "__Why Chain?__\n",
        "\n",
        "There are a number of benefits of chaining a point source fit to an imaging fit, as opposed to doing just one fit:\n",
        "\n",
        " - The point source fit is lower dimensionality than a light profile fit and computationally very fast. It can\n",
        " therefore provide accurate estimates for the lens and source model parameters. However, the point source fit does\n",
        " not extract anywhere near the maximal amount of information from the data.\n",
        "\n",
        " - The fit to the imaging data is much higher dimensionality and computationally slower. It would be challenging to\n",
        " fit this model without accurate initialization of the lens model parameters. However, it extracts a lot more\n",
        " information from the data.\n",
        "\n",
        "This script therefore initializes the lens model efficiently using a point-source fit and then switches to a full\n",
        "fit on the imaging data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load the strong lens dataset `group` point source dataset and imaging, and plot them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"lens_x3__source_x1\"\n",
        "dataset_path = path.join(\"dataset\", \"group\", dataset_name)\n",
        "\n",
        "imaging = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset = al.from_json(\n",
        "    file_path=path.join(dataset_path, \"point_dataset.json\"),\n",
        ")\n",
        "\n",
        "visuals = aplt.Visuals2D(positions=dataset.positions)\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=imaging.data, visuals_2d=visuals)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Paths__\n",
        "\n",
        "The path the results of all chained searches are output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "path_prefix = path.join(\"group\", \"chaining\", \"point_to_imaging\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__PointSolver__\n",
        "\n",
        "Define the position solver used for the point source fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(100, 100),\n",
        "    pixel_scales=0.2,  # <- The pixel-scale describes the conversion from pixel units to arc-seconds.\n",
        ")\n",
        "\n",
        "solver = al.PointSolver.for_grid(\n",
        "    grid=grid, pixel_scale_precision=0.001, magnification_threshold=0.1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model (Search 1)__\n",
        "\n",
        "Compose the lens model by loading it from a .json file made in the file `group/model_maker/lens_x3__source_x1.py`:\n",
        "\n",
        " - There are three lens galaxy's with `IsothermalSph` total mass distributions, with the prior on the centre of each \n",
        " profile informed by its observed centre of light [9 parameters].\n",
        " - The source galaxy's light is a point `PointFlux` [3 parameters].\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=12."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_path = path.join(\"dataset\", \"group\", dataset_name)\n",
        "\n",
        "lenses_file = path.join(model_path, \"lenses.json\")\n",
        "lenses = af.Collection.from_json(file=lenses_file)\n",
        "\n",
        "sources_file = path.join(model_path, \"sources.json\")\n",
        "sources = af.Collection.from_json(file=sources_file)\n",
        "\n",
        "galaxies = lenses + sources\n",
        "\n",
        "model_1 = af.Collection(galaxies=galaxies)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model_1.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search + Analysis + Model-Fit (Search 1)__\n",
        "\n",
        "We now create the non-linear search, analysis and perform the model-fit using this model.\n",
        "\n",
        "You may wish to inspect the results of the search 1 model-fit to ensure a fast non-linear search has been provided that \n",
        "provides a reasonably accurate lens model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_1 = af.Nautilus(\n",
        "    path_prefix=path_prefix,\n",
        "    name=\"search[1]_point_source\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "analysis_1 = al.AnalysisPoint(dataset=dataset, solver=solver)\n",
        "\n",
        "result_1 = search_1.fit(model=model_1, analysis=analysis_1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result (Search 1)__\n",
        "\n",
        "The results which are used for prior passing are summarized in the `info` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_1.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Masking (Search 2)__\n",
        "\n",
        "The model-fit to imaging data requires a `Mask2D`. \n",
        "\n",
        "Note how this has a radius of 9.0\", much larger than most example lenses!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=imaging.shape_native, pixel_scales=imaging.pixel_scales, radius=9.0\n",
        ")\n",
        "\n",
        "imaging = imaging.apply_mask(mask=mask)\n",
        "\n",
        "imaging_plotter = aplt.ImagingPlotter(dataset=imaging)\n",
        "imaging_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model (Search 2)__\n",
        "\n",
        "We use the results of search 1 to create the lens model fitted in search 2, where:\n",
        "\n",
        " - There are again three lens galaxy's with `SersicSph` light profiles [15 parameters: centres initialized from model].\n",
        " - The three lens galaxy's have `IsothermalSph` mass distributions [9 parameters: priors initialized from search 1].\n",
        " - The source-galaxy's light uses a `Sersic` light profile [7 parameters: centre initialized from search 1].\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=31.\n",
        "\n",
        "The term `model` below passes the source model as model-components that are to be fitted for by the \n",
        "non-linear search. We pass the `lens` as a `model`, so that we can use the mass model inferred by search 1. The source\n",
        "does not use any priors from the result of search 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_0 = af.Model(\n",
        "    al.Galaxy, redshift=0.5, bulge=al.lp_linear.SersicSph, mass=al.mp.IsothermalSph\n",
        ")\n",
        "lens_0.bulge.centre = model_1.galaxies.lens_0.mass.centre\n",
        "lens_0.mass = result_1.model.galaxies.lens_0.mass\n",
        "\n",
        "lens_1 = af.Model(\n",
        "    al.Galaxy, redshift=0.5, bulge=al.lp_linear.SersicSph, mass=al.mp.IsothermalSph\n",
        ")\n",
        "lens_1.bulge.centre = model_1.galaxies.lens_1.mass.centre\n",
        "lens_1.mass = result_1.model.galaxies.lens_1.mass\n",
        "\n",
        "lens_2 = af.Model(\n",
        "    al.Galaxy, redshift=0.5, bulge=al.lp_linear.SersicSph, mass=al.mp.IsothermalSph\n",
        ")\n",
        "lens_2.bulge.centre = model_1.galaxies.lens_2.mass.centre\n",
        "lens_2.mass = result_1.model.galaxies.lens_2.mass\n",
        "\n",
        "source_0 = af.Model(al.Galaxy, redshift=1.0, bulge=al.lp_linear.Sersic)\n",
        "source_0.bulge.centre = result_1.model.galaxies.source_0.point_0.centre\n",
        "\n",
        "model_2 = af.Collection(\n",
        "    galaxies=af.Collection(\n",
        "        lens_0=lens_0, lens_1=lens_1, lens_2=lens_2, source_0=source_0\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model, including how parameters and priors were passed from `result_1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model_2.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis + Position Likelihood__\n",
        "\n",
        "We add a penalty term ot the likelihood function, which penalizes models where the brightest multiple images of\n",
        "the lensed source galaxy do not trace close to one another in the source plane. This removes \"demagnified source\n",
        "solutions\" from the source pixelization, which one is likely to infer without this penalty.\n",
        "\n",
        "A comprehensive description of why we do this is given at the following readthedocs page. I strongly recommend you \n",
        "read this page in full if you are not familiar with the positions likelihood penalty and demagnified source reconstructions:\n",
        "\n",
        " https://pyautolens.readthedocs.io/en/latest/general/demagnified_solutions.html\n",
        "\n",
        "__Brief Description__\n",
        "\n",
        "In this example we update the positions between searches, where the positions correspond to the (y,x) locations of the \n",
        "lensed source's multiple images. When a model-fit uses positions, it requires them to trace within a threshold value of \n",
        "one another for every mass model sampled by the non-linear search. If they do not, a penalty term is added to the\n",
        "likelihood penalizing that solution \n",
        "\n",
        "Below, we use the results of the first search to compute the lensed source positions that are input into search 2. The\n",
        "code below uses the maximum log likelihood model mass model and source galaxy centre, to determine where the source\n",
        "positions are located in the image-plane. \n",
        "\n",
        "We also use this result to set the `threshold`, whereby the threshold value is based on how close these positions \n",
        "trace to one another in the source-plane (using the best-fit mass model again). This threshold is multiplied by \n",
        "a `factor` to ensure it is not too small (and thus does not remove plausible mass  models). If, after this \n",
        "multiplication, the threshold is below the `minimum_threshold`, it is rounded up to this minimum value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions_likelihood = al.PositionsLHPenalty(threshold=1.0, positions=dataset.positions)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis + Positions__\n",
        "\n",
        "In this example we update the positions between searches, where the positions correspond to the (y,x) locations of the \n",
        "lensed source's multiple images. When a model-fit uses positions, it requires them to trace within a threshold value of \n",
        "one another for every mass model sampled by the non-linear search. If they do not, the model likelihood is heavily\n",
        "penalized.\n",
        "\n",
        "Below, we use the point source dictionary positions and a threshold double the resolution of the data, which should be\n",
        "sufficient for this analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_2 = al.AnalysisImaging(\n",
        "    dataset=imaging, positions_likelihood=positions_likelihood\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search + Model-Fit__\n",
        "\n",
        "We now create the non-linear search and perform the model-fit using this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_2 = af.Nautilus(\n",
        "    path_prefix=path_prefix,\n",
        "    name=\"search[2]__imaging\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=150,\n",
        "    number_of_cores=4,\n",
        ")\n",
        "\n",
        "result_2 = search_2.fit(model=model_2, analysis=analysis_2)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result (Search 2)__\n",
        "\n",
        "The final results can be summarized via printing `info`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_2.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "In this example, we passed used prior passing to initialize a lens model using a point source dataset and passed this \n",
        "a second fit which fitted the full `Imaging` dataset. \n",
        "\n",
        "This circumvented the challenge with initializing a high dimensionality complex lens model to `Imaging` data where\n",
        "the computational run time is slower."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}