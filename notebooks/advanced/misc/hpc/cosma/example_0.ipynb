{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# %%\n",
        "'''\n",
        "__WELCOME__ \n",
        "\n",
        "Welcome to a cosma modeling script Python script, which illustrates how to load a strong lens dataset and analyse it on cosma.\n",
        "\n",
        "This example shows how to set off many single CPU jobs in a single COSMA submission script, where each job\n",
        "fits a different imaging dataset using the same lens model analysis. This form of parallelization is therefore\n",
        "benefitial when we have many datasets we wish to fit simultaneously.\n",
        "\n",
        "The script `example_1.py` describes how to fit a single dataset with a parallelized Nautilus model-fit. You should\n",
        "only read this example after reading and understanding this example.\n",
        "\n",
        "This fits a lens model using a simple example taken from the autolens_workspace.\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# %%\n",
        "# %%\n",
        "'''\n",
        "__COSMA PATHS SETUP__\n",
        "\n",
        "Setup the path to the cosma output directory.\n",
        "\n",
        "This exmaple assumes you are using cosma7 and outputting results to the cosma7 output directory:\n",
        "\n",
        " `/cosma7/data/dp004/cosma_username`.\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from os import path\n",
        "\n",
        "cosma_path = path.join(path.sep, \"cosma7\", \"data\", \"dp004\", \"cosma_username\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use this path to set the path to the dataset directory on COSMA, as well as the folders within this directory the .fits\n",
        "are stored in.\n",
        "\n",
        "Below, we set `cosma_dataset_path=/cosma7/data/dp004/cosma_username/dataset/example/mass_sie__source_seric`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_folder = \"example\"\n",
        "dataset_name = \"simple__no_lens_light\"\n",
        "\n",
        "cosma_dataset_path = path.join(cosma_path, \"dataset\", dataset_folder, dataset_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also set the output path on COSMA to `cosma_output_path=/cosma7/data/dp004/cosma_username/output`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "cosma_output_path = path.join(cosma_path, \"output\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In contrast to the dataset and output folders, our workspace path is in your COSMA home directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "workspace_path = \"/cosma/home/dp004/cosma_username/autolens_workspace/\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use this to set the path to the config files that are used in this analysis, which are contained within the `cosma` \n",
        "directory of the example project in your COSMA home directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "config_path = path.join(workspace_path, \"cosma\", \"config\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the config and output paths using autoconf, as you would for a laptop run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf import conf\n",
        "\n",
        "conf.instance.push(new_path=config_path, output_path=cosma_output_path)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cosma submissions require a`batch script`, which tells Cosma the PyAutoLens runners you want it to execute and \n",
        "distributes them to nodes and CPUs. Lets look at the batch script \n",
        "\n",
        " `autolens_workspace/misc/hpc/batch/example\n",
        "    \n",
        "The following options are worth noting:\n",
        "\n",
        " `#SBATCH -N 1` - The number of nodes we require, where 1 node contains 28 CPUs on COSMA7.\n",
        " `#SBATCH --ntasks=16` - The total number of task we are submitting.\n",
        " `#SBATCH --cpus-per-task=1` - The number of tasks per CPU.\n",
        " `#SBATCH -J example` - The name of the job, which is how it appears on cosma when you inspect it.\n",
        " `#SBATCH -o output/output.%A.out` - Python interpreter output is placed in a file in the `output` folder.\n",
        " `#SBATCH -o error/error.%A.out` - Python interpreter errors are placed in a file in the `error` folder.\n",
        " `#SBATCH -p cosma7` - Signifies we are running the job on COSMA7.\n",
        " `#SBATCH -A dp004` - The project code of the submission.\n",
        " `#SBATCH -t 48:00:00` - The job will terminate after this length of time (if it does not end naturally).\n",
        " `#SBATCH --mail-type=END` - If you input your email, when you`ll get an email about the job (END means once finished).\n",
        " `#SBATCH --mail-user=fill@me.co.uk` - The email address COSMA sends the email too.\n",
        "\n",
        "The following line activates the PyAutoLens virtual environment we set up on cosma for this run:\n",
        "\n",
        " `source /cosma/home/dp004/cosma_username/autolens_workspace/activate.sh`\n",
        "\n",
        "These lines prevent the NumPy linear algebra libraries from overloading the CPUs during calculations.\n",
        "    \n",
        "export CPUS_PER_TASK=1\n",
        "\n",
        "export OPENBLAS_NUM_THREADS=$CPUS_PER_TASK\n",
        "export MKL_NUM_THREADS=$CPUS_PER_TASK\n",
        "export OMP_NUM_THREADS=$CPUS_PER_TASK\n",
        "export VECLIB_MAXIMUM_THREADS=$CPUS_PER_TASK\n",
        "export NUMEXPR_NUM_THREADS=$CPUS_PER_TASK\n",
        "\n",
        "This line sets off the job:\n",
        "\n",
        "    srun -n 16 --multi-prog conf/example.conf\n",
        "\n",
        "Lets checkout the file `example.conf`:\n",
        "\n",
        "    0 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 0\n",
        "    1 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 1\n",
        "    2 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 2\n",
        "    3 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 3\n",
        "    4 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 4\n",
        "    5 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 5\n",
        "    6 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 6\n",
        "    7 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 7\n",
        "    8 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 8\n",
        "    9 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 9\n",
        "    10 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 10\n",
        "    11 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 11\n",
        "    12 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 12\n",
        "    13 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 13\n",
        "    14 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 14\n",
        "    15 python3 /cosma/home/dp004/cosma_username/autolens_workspace/cosma/runners/example.py 15\n",
        "    \n",
        "This file contains lines of python3 commands which set off our modeling script script(s)! It is now clear how to set off many \n",
        "cosma jobs; just add each modeling script you want to run to this script. \n",
        "\n",
        "The numbers on the left running from 0-15 specify the CPU number and should always run from 0. \n",
        "\n",
        "The numbers on the right are inputting an integer, which is then used to load a specific dataset. Below, using \n",
        "the `sys.argv[1]` command, we load each integer into the Python script. For example, the first job loads the integer\n",
        "0, the second job the integer 1 and so forth. Each job will therefore have a unique integer value in the `cosma_id` \n",
        "variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "\n",
        "cosma_id = int(sys.argv[1])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now use this variable to load a specific piece of data for this run!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "dataset_type = \"imaging\"\n",
        "pixel_scales = 0.1\n",
        "\n",
        "dataset_name = []\n",
        "dataset_name.append(\"example_image_1\")  # Index 0\n",
        "dataset_name.append(\"example_image_2\")  # Index 1\n",
        "dataset_name.append(\"example_image_3\")  # Index 2\n",
        "dataset_name.append(\"example_image_4\")  # Index 3\n",
        "dataset_name.append(\"example_image_5\")  # Index 4\n",
        "dataset_name.append(\"example_image_6\")  # Index 5\n",
        "dataset_name.append(\"example_image_7\")  # Index 6\n",
        "dataset_name.append(\"example_image_8\")  # Index 7\n",
        "# ...and so on."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now extract the dataset name specific to this cosma id, meaning every CPU run will load and fit a different dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = dataset_name[cosma_id]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now create the overall path to the dataset this specific call of the script fits, which for the first line in the \n",
        "`.conf` file above (which has integer input 0) is: \n",
        "\n",
        " `/cosma7/data/dp004/cosma_username/dataset/imaging/example_image_1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(cosma_dataset_path, dataset_type, dataset_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "COMPLETE\n",
        "\n",
        "This completes all COSMA specific code required for submitting jobs to COSMA. All of the code below is not specific to \n",
        "COSMA, and is simply the code you are used to running in modeling script scripts not on COSMA.\n",
        "\n",
        "In this example, we assumed that every job used a single CPU and we paralleized over the datasets being fitted. \n",
        "Checkout the file `example_1.py` for a description of how to fit a single dataset and parallelie the Nautilus search\n",
        "over multiply cores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import autofit as af\n",
        "import autolens as al\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the strong lens dataset `example_image_1` via .fits files, which we will fit with the lens model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose a lens model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear` [7 parameters].\n",
        " \n",
        " - The source galaxy's light is a parametric `SersicCore` [7 parameters].\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=14."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=mass, shear=shear)\n",
        "\n",
        "# Source:\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=al.lp.SersicCore)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The lens model is fitted to the data using the nested sampling algorithm Nautilus (see `start.here.py` for a \n",
        "full description).\n",
        "\n",
        "The folders: \n",
        "\n",
        " - `autolens_workspace/*/modeling/imaging/searches`.\n",
        " - `autolens_workspace/*/modeling/imaging/customize`\n",
        "  \n",
        "Give overviews of the non-linear searches **PyAutoLens** supports and more details on how to customize the\n",
        "model-fit, including the priors on the model.\n",
        "\n",
        "The `name` and `path_prefix` below specify the path where results ae stored in the output folder:  \n",
        "\n",
        " `/autolens_workspace/output/modeling/imaging/simple__no_lens_light/mass[sie]_source[bulge]/unique_identifier`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"cosma_example\"),\n",
        "    name=\"mass[sie]_source[bulge]\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the `AnalysisImaging` object defining how the via Nautilus the model is fitted to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(dataset=dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}