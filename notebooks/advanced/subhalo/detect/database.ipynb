{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Subhalo Detection: Database\n",
        "===========================\n",
        "\n",
        "The example `subhalo/detect/start_here.ipynb` shows how to perform dark matter subhalo detection in strong lens\n",
        "with **PyAutoLens**, including using results to inspect and visualize the fit.\n",
        "\n",
        "This example shows how to load the results of subhalo detection analysis into a `.sqlite` database, which can be\n",
        "manipulated stand-alone in this Python script or in a Jupyter notebook. This is useful when fits are performed on a\n",
        "super computer and results are downloaded separately for inspection.\n",
        "\n",
        "The database in this example is built by scraping the results of the `subhalo/detect/start_here.ipynb` example. You\n",
        "can also write results directly to the database during the fit by using a session.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script uses the results of the `subhalo/detect/start_here.ipynb` example. You must run this script to completion\n",
        "first to ensure the results the database uses are available.\n",
        "\n",
        "__Start Here Notebooks__\n",
        "\n",
        "You should be familiar with dark matter subhalo detection, by reading the example `subhalo/detect/start_here.ipynb`.\n",
        "\n",
        "You should also be familiar with the database, by reading the example `imaging/advanced/database/start_here.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import json\n",
        "import os\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "___Database__\n",
        "\n",
        "The name of the database, which corresponds to the output results folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "database_name = \"subhalo_detect\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the `.sqlite` file of the database is already in the output folder we delete it and create a new database immediately\n",
        "afterwards.\n",
        "\n",
        "This ensures we don't double up on results if we run the script multiple times, and if new results are added to the\n",
        "output folder (e.g. download from a super computer) they are added to the database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    os.remove(path.join(\"output\", f\"{database_name}.sqlite\"))\n",
        "except FileNotFoundError:\n",
        "    pass"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the database file `subhalo_detect.sqlite` in the output folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg = af.Aggregator.from_database(\n",
        "    filename=f\"{database_name}.sqlite\", completed_only=False\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add all results in the directory \"output\" to the database, which we manipulate below via the aggregator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg.add_directory(directory=path.join(\"output\", database_name))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Agg No / With Subhalo__\n",
        "\n",
        "Standard aggregator querying can be used to get aggregates of results for lens models with and without a subhalo.\n",
        "\n",
        "The easiest query uses the name of the subhalo searches in the SLaM subhalo pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg_no_subhalo = agg.query(agg.search.name == \"subhalo[1]\")\n",
        "agg_with_subhalo = agg.query(agg.search.name == \"subhalo[3]_[single_plane_refine]\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can extract the `log_evidence` values of the results with and without and DM subhalo via the aggregators.\n",
        "\n",
        "We create a dictionary of these values where the keys are the `unique_tag` of each search, which is the name of the\n",
        "dataset fitted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_evidence_no_subhalo_dict = {}\n",
        "\n",
        "for search, samples in zip(\n",
        "    agg_no_subhalo.values(\"search\"), agg_no_subhalo.values(\"samples\")\n",
        "):\n",
        "    log_evidence_no_subhalo_dict[search.unique_tag] = samples.log_evidence\n",
        "\n",
        "print(\"\\nLog Evidence No Subhalo\")\n",
        "print(log_evidence_no_subhalo_dict)\n",
        "\n",
        "log_evidence_with_subhalo_dict = {}\n",
        "\n",
        "for search, samples in zip(\n",
        "    agg_with_subhalo.values(\"search\"), agg_with_subhalo.values(\"samples\")\n",
        "):\n",
        "    log_evidence_with_subhalo_dict[search.unique_tag] = samples.log_evidence\n",
        "\n",
        "print(\"\\nLog Evidence With Subhalo\")\n",
        "print(log_evidence_with_subhalo_dict)\n",
        "\n",
        "log_evidence_difference_dict = {}\n",
        "\n",
        "# for key in log_evidence_no_subhalo_dict.keys():\n",
        "\n",
        "#    log_evidence_difference_dict[key] = log_evidence_with_subhalo_dict[key] - log_evidence_no_subhalo_dict[key]\n",
        "\n",
        "print(\"\\nLog Evidence Difference\")\n",
        "print(log_evidence_difference_dict)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From these, we can create the maximum likelihood instances of the lens model and corresponding `FitImaging` objects.\n",
        "\n",
        "These can then be passed to the `SubhaloPlotter` to visualize the results of the subhalo detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg_no_subhalo = al.agg.FitImagingAgg(aggregator=agg_no_subhalo)\n",
        "fit_no_subhalo_gen = fit_agg_no_subhalo.max_log_likelihood_gen_from()\n",
        "fit_no_subhalo = list(fit_no_subhalo_gen)[0]\n",
        "\n",
        "fit_agg_with_subhalo = al.agg.FitImagingAgg(aggregator=agg_with_subhalo)\n",
        "fit_with_subhalo_gen = fit_agg_with_subhalo.max_log_likelihood_gen_from()\n",
        "fit_with_subhalo = list(fit_with_subhalo_gen)[0]\n",
        "\n",
        "subhalo_plotter = al.subhalo.SubhaloPlotter(\n",
        "    fit_imaging_no_subhalo=fit_no_subhalo[0],\n",
        "    fit_imaging_with_subhalo=fit_with_subhalo[0],\n",
        ")\n",
        "\n",
        "subhalo_plotter.subplot_detection_fits()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Grid Searches__\n",
        "\n",
        "If the results of the database include a grid search of non-linear searches, the aggregator has a dedicated method\n",
        "to return the grid of results.\n",
        "\n",
        "We iterate over these results using a for loop below, where each iteration will correspond to a different lens in \n",
        "our analysis (e.g. if there are multiple lenses in the dataset that are fitted). In the `start_here.ipynb` example,\n",
        "only one lens is fitted, so this for loop is only iterated over once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for agg_grid, search in zip(\n",
        "    agg.grid_searches(), agg.grid_searches().best_fits().values(\"search\")\n",
        "):\n",
        "    # Extract the `GridSearchResult` which the `start_here.ipynb` example uses\n",
        "    # for result inspection and visualization.\n",
        "\n",
        "    result_subhalo_grid_search = agg_grid[\"result\"]\n",
        "\n",
        "    # This can be manipulated in the ways shown in `start_here.ipynb`, for example\n",
        "    # to plot the log evidence of each cell.\n",
        "\n",
        "    result_subhalo_grid_search = al.subhalo.SubhaloGridSearchResult(\n",
        "        result=result_subhalo_grid_search\n",
        "    )\n",
        "\n",
        "    log_evidence_array = result_subhalo_grid_search.figure_of_merit_array(\n",
        "        use_log_evidences=True,\n",
        "        relative_to_value=log_evidence_no_subhalo_dict[search.unique_tag],\n",
        "    )\n",
        "\n",
        "    print(log_evidence_array)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Grid Search Visualization__\n",
        "\n",
        "The grid search visualization tools can also be used to plot the results of the grid search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples_no_subhalo_gen = agg_no_subhalo.values(\"samples\")\n",
        "\n",
        "fit_agg_no_subhalo = al.agg.FitImagingAgg(aggregator=agg_no_subhalo)\n",
        "fit_no_subhalo_gen = fit_agg_no_subhalo.max_log_likelihood_gen_from()\n",
        "\n",
        "fit_agg_with_subhalo = al.agg.FitImagingAgg(aggregator=agg_with_subhalo)\n",
        "fit_with_subhalo_gen = fit_agg_with_subhalo.max_log_likelihood_gen_from()\n",
        "\n",
        "for agg_grid, fit_no_subhalo, fit_with_subhalo, samples_no_subhalo in zip(\n",
        "    agg.grid_searches(),\n",
        "    fit_no_subhalo_gen,\n",
        "    fit_with_subhalo_gen,\n",
        "    samples_no_subhalo_gen,\n",
        "):\n",
        "    # Extract the `GridSearchResult` which the `start_here.ipynb` example uses\n",
        "    # for result inspection and visualization.\n",
        "\n",
        "    result_subhalo_grid_search = agg_grid[\"result\"]\n",
        "\n",
        "    # This can be manipulated in the ways shown in `start_here.ipynb`, for example\n",
        "    # to plot the log evidence of each cell.\n",
        "\n",
        "    result_subhalo_grid_search = al.subhalo.SubhaloGridSearchResult(\n",
        "        result=result_subhalo_grid_search\n",
        "    )\n",
        "\n",
        "    subhalo_plotter = al.subhalo.SubhaloPlotter(\n",
        "        result=result_subhalo_grid_search,\n",
        "        fit_imaging_no_subhalo=fit_no_subhalo[0],\n",
        "        fit_imaging_with_subhalo=fit_with_subhalo[0],\n",
        "    )\n",
        "\n",
        "    subhalo_plotter.figure_figures_of_merit_grid(\n",
        "        use_log_evidences=True,\n",
        "        relative_to_value=samples.log_evidence,\n",
        "        remove_zeros=True,\n",
        "    )\n",
        "\n",
        "    subhalo_plotter.figure_mass_grid()\n",
        "    subhalo_plotter.subplot_detection_imaging()\n",
        "    subhalo_plotter.subplot_detection_fits()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Best Fit__\n",
        "\n",
        "We can retrieve a new aggregator containing only the maximum log evidence results of the grid search. \n",
        "\n",
        "This can then be used as a normal aggregator to inspect the `Samples` of the fit or plot the best-fit `FitImaging`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg_best_fit = agg.grid_searches().best_fits()\n",
        "\n",
        "samples_gen = agg_best_fit.values(\"samples\")\n",
        "\n",
        "for samples in samples_gen:\n",
        "    print(samples.log_evidence)\n",
        "\n",
        "fit_agg = al.agg.FitImagingAgg(\n",
        "    aggregator=agg_best_fit,\n",
        ")\n",
        "fit_gen = fit_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "for fit_list in fit_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    fit = fit_list[0]\n",
        "\n",
        "    fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "    fit_plotter.subplot_fit()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}