{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 1: Non-linear Search\n",
        "=============================\n",
        "\n",
        "__Lens Modeling__\n",
        "\n",
        "In chapter 1, we learned how to use **PyAutoLens** to do many things: create galaxies, ray-trace light, simulate and fit\n",
        "data. However, we did not learn how to answer the core questions that any scientist, when faced with observations of a\n",
        "strong lens, seeks to answer:\n",
        "\n",
        " What lens galaxy mass distribution(s) and source galaxy light distribution(s) are responsible for the strong lens\n",
        " data I have observed? How can I explain the true deflection of light in this data, that is actually occuring in the\n",
        " real Universe? What does this tell me about galaxy structure and Cosmology?\n",
        "\n",
        "To answer questions like this, and therefore use **PyAutoLens** to actually learn about the Universe, we need to\n",
        "perform 'lens modeling', the topic of this chapter of the **HowToLens** lectures.\n",
        "\n",
        "In this tutorial, we are going to load imaging data of strong lens and determine the light and mass profiles that best\n",
        "represent the observed lensed source's light. That is, we are going to find the 'lens model' that best fits the data,\n",
        "without any prior knowledge of what the `correct` model is.\n",
        "\n",
        "To begin, we have to choose the parametrization of our lens model. We don't need to specify the values of its light\n",
        "and mass profiles (e.g. the centre, intensity, einstein_radius, etc.), only the profiles themselves. In this example,\n",
        "we use the following lens model:\n",
        "\n",
        " 1) A Spherical Isothermal Sphere (SIS) mass profile via the `IsothermalSph` profile for the lens galaxy's mass.\n",
        " 2) A Spherical Exponential light profile via the `ExponentialSph` for the source-galaxy's light.\n",
        "\n",
        "This is a very simple model, with very few parameters, so its a great starting point for us to learn how to perform\n",
        "lens modeling!\n",
        "\n",
        "__Non Linear Search__\n",
        "\n",
        "So, how do we infer the parameters of our light and mass profiles above that give a good fit to our data?\n",
        "\n",
        "Well, with the tools that we learned in chapter 1, we could try the following:\n",
        "\n",
        " 1) Randomly guess a lens model, corresponding to some random set of parameters values for the light and mass profiles.\n",
        " 2) Use this lens model to create a `Tracer` and fit the `Imaging` with it, via a `FitImaging` object.\n",
        " 3) Quantify the goodness of fit using the `log_likelihood`.\n",
        " 4) Keep guessing lens models, repeating steps 1-3, until we eventually find a model that provides a good fit (i.e.\n",
        " a high value log likelihood)!\n",
        "\n",
        "It may sound surprising, but this is actually the basis of how lens modeling works. However, we can do a lot better\n",
        "than random guessing. Instead, we we can track the log likelihoods of all of our previous guesses, and guess more\n",
        "models using the combinations of light and mass profile parameters that gave high log likelihood solutions previously.\n",
        "\n",
        "The idea is that if a set of parameters provided a good fit to the data, another set of parameters with similar values\n",
        "probably will too. Furthermore, if by following this approach we are able to keep guessing models with higher and higher\n",
        "likelihoods, we should eventually 'climb' our way to the model with the highest likelihood overall!\n",
        "\n",
        "This approach to model-fitting is called a `non-linear search` and it is a common algorithm applied by scientists to\n",
        "many different problems. Over the next few tutorials, we are going to really get our heads around the concept of a\n",
        "non-linear search; intuition which will prove crucial for us to become a successful lens modeler.\n",
        "\n",
        "An animation of a non-linear search fitting a lens model is shown below. Note how the initial models that it fits give\n",
        "a poor fit to the data, but that they gradually improve as more iterations are performed as the search begins to only\n",
        "guess models that are near other, high likelihood, models.\n",
        "\n",
        "![Lens Modeling Animation](https://github.com/Jammy2211/auto_files/blob/main/lensmodel.gif?raw=true \"model\")\n",
        "\n",
        "**Credit: Amy Etherington**\n",
        "\n",
        "In this tutorial, and throughout this enture chapter, we are going to use the non-linear search\n",
        "called `Nautilus` (https://github.com/joshspeagle/Nautilus). I have found this to be a great non-linear search for\n",
        "lens modeling, albeit alternatives are available in **PyAutoLens** and will be discussed later in this chapter.\n",
        "\n",
        "For now, lets not worry about the details of how Nautilus actually works and simply keep in our minds the described of\n",
        "a non-linear search provided above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__PyAutoFit__\n",
        "\n",
        "Lens modeling uses the probabilistic programming language\n",
        "[PyAutoFit](https://github.com/rhayes777/PyAutoFit), an open-source project that allows complex model\n",
        "fitting techniques to be straightforwardly integrated into scientific modeling software. \n",
        "\n",
        "**PyAutoFit** is actually a spin-off project of **PyAutoLens**. whereby we found that the statistic techniques and\n",
        "methods we applied to model strong lenses could be used in a more general setting to many different scientrific \n",
        "problems. Check it out if you are interested in developing your own software to perform advanced model-fitting!\n",
        "\n",
        "We import this library separately from **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initial Setup__\n",
        "\n",
        "Lets first load the `Imaging` dataset we'll fit a lens model with using a non-linear search. \n",
        "\n",
        "If you are interested in how we simulate the strong lens data, checkout the scripts in the \n",
        "package `autolens_workspace/*/imaging/simulators`.\n",
        "\n",
        "The strong lens in this image was generated using:\n",
        "\n",
        " - The lens galaxy's total mass distribution is a `IsothermalSph`.\n",
        " - The source galaxy's light is a `ExponentialSph`.\n",
        "\n",
        "Note how the model used to simulate the data is the same as the model we will fit in this tutorial.\n",
        "\n",
        "This dataset (and all datasets used in tutorials from here are on) are stored and loaded from the \n",
        "`autolens_workspace/dataset/imaging` folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light__mass_sis\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "The non-linear fit also needs a `Mask2D`, lets use a 3.0\" circle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "To compose a lens model, we set up a `Galaxy` as a `Model`. Whereas previously we manually specified the value of \n",
        "every parameter of a `Galaxy`'s light and mass profiles, when the galaxy is a `Model` only the class of each profile is \n",
        "passed. By creating the galaxy as `Model` we are telling **PyAutoLens** that the parameter's of its profiles are\n",
        "to be fitted for via the non-linear search.\n",
        "\n",
        "Lets model the lens galaxy with an spherical isothermal mass profile (which is what it was simulated with)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.IsothermalSph)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=mass)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets model the source galaxy with a spherical exponential light profile (again, what it was simulated with).\n",
        "\n",
        "\n",
        "NOTE: The `Exponential` light profile corresponds to the `Sersic` light profile with a fixed value of `sersic_index=1`.\n",
        "In later tutorials we'll fit the `Sersic`, so its worth noting the `Exponential` is a specific case of the `Sersic`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(al.lp.ExponentialSph)\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=bulge)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now have multiple `Model` components, which we bring together into a final model via the `Collection` object.\n",
        "\n",
        "Just like we are used to giving profiles descriptive names, like `bulge`, `disk` and `mass` we also name the galaxies \n",
        "that make up our model. Of course, its good practise for us to give them descriptive names and we'll use `lens` and\n",
        "`source` to do this throughout the tutorials.\n",
        "\n",
        "[It may seem odd that we define two `Collections`, with the `Collection` in the outer loop only having a `galaxies`\n",
        "attribute. In future tutorials, we'll see that we can add additional model-components to a model other than just\n",
        "galaxies, and the API below therefore makes it simple to extend the model to include these components.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format.\n",
        "\n",
        "[The `info` below may not display optimally on your computer screen, for example the whitespace between parameter\n",
        "names on the left and parameter priors on the right may lead them to appear across multiple lines. This is a\n",
        "common issue in Jupyter notebooks.\n",
        "\n",
        "The`info_whitespace_length` parameter in the file `config/general.yaml` in the [output] section can be changed to \n",
        "increase or decrease the amount of whitespace (The Jupyter notebook kernel will need to be reset for this change to \n",
        "appear in a notebook).]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We now create the non-linear search object which will fit the lens model, which as discussed above is the nested\n",
        "sampling algorithm Nautilus. We pass the `Nautilus` object the following:\n",
        "   \n",
        " - A `path_prefix` which tells the search to output its results in the \n",
        " folder `autolens_workspace/output/howtolens/chapter_2`. \n",
        " \n",
        " - A `name`, which gives the search a name and means the full output path is \n",
        "   `autolens_workspace/output/howtolens/chapter_2/tutorial_1_non_linear_search`. \n",
        "\n",
        " - Input parameters like `n_live` which control how it samples parameter space. These are discussed in more detail \n",
        " in a later tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"howtolens\", \"chapter_2\"),\n",
        "    name=\"tutorial_1_non_linear_search\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=150,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "The `AnalysisImaging` object defines how the non-linear search fits each lens model that it guesses (which consists of \n",
        "a set of parameters values for the light and mass profiles guessed by the search) to the `Imaging` dataset.\n",
        "\n",
        "The fit is performed using the analysis class's `log_likelihood_function`, which in model-fitting is a commonly used \n",
        "term to describe a function that given a model and data, fits the model to the data to return a value of log \n",
        "likelihood, which the non-linear search uses the evaluate the goodness-of-fit.\n",
        "\n",
        "This likelihood function is written in the **PyAutoLens** source code, but it essentially repeats the steps we discussed\n",
        "in tutorial 8 of chapter 1 of **HowToLens**, where we computed a value of `log_likelihood` via a `FitImaging` object.\n",
        "\n",
        "A detailed step-by-step visual guide of the likelihood function is provided \n",
        "at `autolens_workspace/*/imaging/log_likelihood_function/parametric.ipynb`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(dataset=dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Times__\n",
        "\n",
        "Lens modeling can be a computationally expensive process. When fitting complex models to high resolution datasets \n",
        "run times can be of order hours, days, weeks or even months.\n",
        "\n",
        "Run times are dictated by two factors:\n",
        "\n",
        " - The log likelihood evaluation time: the time it takes for a single `instance` of the lens model to be fitted to \n",
        "   the dataset such that a log likelihood is returned.\n",
        "\n",
        " - The number of iterations (e.g. log likelihood evaluations) performed by the non-linear search: more complex lens\n",
        "   models require more iterations to converge to a solution.\n",
        "\n",
        "The log likelihood evaluation time can be estimated before a fit using the `profile_log_likelihood_function` method,\n",
        "which returns two dictionaries containing the run-times and information about the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The overall log likelihood evaluation time is given by the `fit_time` key.\n",
        "\n",
        "For this example, it is ~0.01 seconds, which is extremely fast for lens modeling. More advanced lens\n",
        "modeling features (e.g. shapelets, multi Gaussian expansions, pixelizations) have slower log likelihood evaluation\n",
        "times (1-3 seconds), and you should be wary of this when using these features.\n",
        "\n",
        "Feel free to go ahead a print the full `run_time_dict` and `info_dict` to see the other information they contain. The\n",
        "former has a break-down of the run-time of every individual function call in the log likelihood function, whereas the \n",
        "latter stores information about the data which drives the run-time (e.g. number of image-pixels in the mask, the\n",
        "shape of the PSF, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To estimate the expected overall run time of the model-fit we multiply the log likelihood evaluation time by an \n",
        "estimate of the number of iterations the non-linear search will perform. \n",
        "\n",
        "Estimating this quantity is more tricky, as it varies depending on the lens model complexity (e.g. number of parameters)\n",
        "and the properties of the dataset and model being fitted.\n",
        "\n",
        "For this example, we conservatively estimate that the non-linear search will perform ~10000 iterations per free \n",
        "parameter in the model. This is an upper limit, with models typically converging in far fewer iterations.\n",
        "\n",
        "If you perform the fit over multiple CPUs, you can divide the run time by the number of cores to get an estimate of\n",
        "the time it will take to fit the model. Parallelization with Nautilus scales well, it speeds up the model-fit by the \n",
        "`number_of_cores` for N < 8 CPUs and roughly `0.5*number_of_cores` for N > 8 CPUs. This scaling continues \n",
        "for N> 50 CPUs, meaning that with super computing facilities you can always achieve fast run times!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We can now begin the model-fit by passing the model and analysis object to the search, which performs a non-linear\n",
        "search to find which models fit the data with the highest likelihood.\n",
        "\n",
        "Model fits using a non-linear search can take a long time to run. Whilst the fit in this tutorial should take just a  \n",
        "few minutes, fitting more complex models can take upwards of hours! \n",
        "\n",
        "This is fine (lens modeling is simply a computationally expensive exercise), but it does make going through the \n",
        "tutorials problematic. This is especially true in Jupyter notebooks, as whilst the non-linear search is running \n",
        "you won't be able to continue to the next notebook cell until the search has finished. \n",
        "\n",
        "For this reason, we recommend that you **do not** run each non-linear search in these tutorials via your Jupyter \n",
        "notebook, but instead run the corresponding Python script found in \n",
        "the `autolens_workspace/*/howtolens/chapter_2_lens_modeling` folder. \n",
        "\n",
        "This can be run either using the `python3` command on the command line, e.g.:\n",
        "\n",
        " `python3 scripts/howtolens/chapter_2_lens_modeling/tutoial_1_non_linear_search.py` \n",
        "\n",
        "Or via your IDE (if you are using one).\n",
        "\n",
        "A non-linear search outputs all results to your hard-disk, in the `output` folder. Thus once it has run and is finished \n",
        "you can run its corresponding Jupyter notebook cell and it immediately load the result.\n",
        "\n",
        "It is generally good practise to run lens modeling scripts outside of a notebook, given that the long run times make\n",
        "notebook use cumbersome. For everything else though (loading results, inspection, plotting, interpretation) you should\n",
        "use notebooks!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    \"The non-linear search has begun running - checkout the autolens_workspace/output/\"\n",
        "    \" folder for live output of the results, images and lens model.\"\n",
        "    \" This Jupyter notebook cell with progress once search has completed - this could take some time!\"\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "print(\"Search has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output Folder__\n",
        "\n",
        "Now this is running you should checkout the `autolens_workspace/output` folder. This is where the results of the \n",
        "search are written to hard-disk (in the `tutorial_1_non_linear_search` folder), where all outputs are human \n",
        "readable (e.g. as .json, .csv or text files).\n",
        "\n",
        "As the fit progresses, results are written to the `output` folder on the fly using the highest likelihood model found\n",
        "by the non-linear search so far. This means you can inspect the results of the model-fit as it runs, without having to\n",
        "wait for the non-linear search to terminate.\n",
        " \n",
        "The `output` folder includes:\n",
        "\n",
        " - `model.info`: Summarizes the lens model, its parameters and their priors discussed in the next tutorial.\n",
        " \n",
        " - `model.results`: Summarizes the highest likelihood lens model inferred so far including errors.\n",
        " \n",
        " - `images`: Visualization of the highest likelihood model-fit to the dataset, (e.g. a fit subplot showing the lens \n",
        " and source galaxies, model data and residuals).\n",
        " \n",
        " - `files`: A folder containing .fits files of the dataset, the model as a human-readable .json file, \n",
        " a `.csv` table of every non-linear search sample and other files containing information about the model-fit.\n",
        " \n",
        " - search.summary: A file providing summary statistics on the performance of the non-linear search.\n",
        " \n",
        " - `search_internal`: Internal files of the non-linear search (in this case Nautilus) used for resuming the fit and\n",
        "  visualizing the search.\n",
        "\n",
        "NOTE: `Nautilus` does not currently support `iterations_per_update` and therefore on-the-fly output of results\n",
        "is disabled. However, you can output the best-fit results by cancelling the job (Ctrl + C for Python script,\n",
        "kill cell for Jupyter notebook) and restarting. \n",
        "\n",
        "Nautilus produces a significant improvement to lens modeling over other libraries (e.g. Dynesty, MultiNest, Emcee) \n",
        "therefore although on-the-fly output is not natively supported, we switched it to the default fitter given the \n",
        "significantly improved model-fits. \n",
        "\n",
        "__Result Info__\n",
        "\n",
        "A concise readable summary of the results is given by printing its `info` attribute.\n",
        "\n",
        "[Above, we discussed that the `info_whitespace_length` parameter in the config files could b changed to make \n",
        "the `model.info` attribute display optimally on your computer. This attribute also controls the whitespace of the\n",
        "`result.info` attribute.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Unique Identifier__\n",
        "\n",
        "In the output folder, you will note that results are in a folder which is a collection of random characters. This acts \n",
        "as a `unique_identifier` of the model-fit, where this identifier is generated based on the model, search and dataset \n",
        "that are used in the fit.\n",
        " \n",
        "An identical combination of model, search and dataset generates the same identifier, meaning that rerunning the\n",
        "script will use the existing results to resume the model-fit. In contrast, if you change the model, search or dataset,\n",
        "a new unique identifier will be generated, ensuring that the model-fit results are output into a separate folder. \n",
        "\n",
        "__Result__\n",
        "\n",
        "The `search.fit` method above returned a `result`, which contains lots of information about the lens model fit. We\n",
        "will cover this in detail in a later tutorial.\n",
        "\n",
        "One thing the result contains we'll use now is the `FitImaging` object that corresponds to the set of a model\n",
        "parameters that gae the maximum log likelihood solution. We plot this object as per usual to inspect how good our\n",
        "fit was."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Probability Density Functions (PDF's) of the results can be plotted using Nautilus's in-built visualization \n",
        "library, which is wrapped via the `NautilusPlotter` object.\n",
        "\n",
        "The PDF shows the 1D and 2D probabilities estimated for every parameter after the model-fit. The two dimensional \n",
        "figures can show the degeneracies between different parameters, for example how increasing the intensity $I$ of the\n",
        "source galaxy and decreasing its effective radius $R_{Eff}$ lead to similar likelihoods and probabilities.\n",
        "\n",
        "This PDF will be discussed more in the next tutorial.\n",
        "\n",
        "The plot is labeled with short hand parameter names (e.g. `sersic_index` is mapped to the short hand \n",
        "parameter `n`). These mappings ate specified in the `config/notation.yaml` file and can be customized by users.\n",
        "\n",
        "The superscripts of labels correspond to the name each component was given in the model (e.g. for the `Isothermal`\n",
        "mass its name `mass` defined when making the `Model` above is used)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_plotter = aplt.NautilusPlotter(samples=result.samples)\n",
        "search_plotter.cornerplot()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit looks good and we've therefore found a model close to the one I used to simulate the image with (you can \n",
        "confirm this yourself if you want, by comparing the inferred parameters to those found in the script\n",
        "`autolens_workspace/*/imaging/simulators/simple__no_lens_light.py`).\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "And with that, we are done. You have successfully modeled your first strong lens! Before moving \n",
        "onto the next tutorial, I want you to think about the following:\n",
        "\n",
        " 1) a non-linear search is often said to search a `non-linear parameter-space`, why is the term parameter-space \n",
        " used?\n",
        "\n",
        " 2) Why is this parameter space 'non-linear'?\n",
        "\n",
        " 3) Initially, the non-linear search randomly guesses the values of the parameters. However, how does it know what \n",
        " a reasonable value for each parameter is? Why did it guess values of Einstein radius between 0.0 and 4.0, instead of\n",
        " between -10000000000000.0 and some other outlandish number? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}