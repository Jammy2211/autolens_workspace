{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 4: Dealing With Failure\n",
        "================================\n",
        "\n",
        "In the previous tutorial we intentionally made our non-linear search infer a local maxima solution and therefore return\n",
        "a physically incorrect lens model. In this tutorial, we will pretend that we have modeled our lens and inferred a local\n",
        "maxima. We introduce three approaches one can take that changes how we fit the model, all of which have the aim of\n",
        "ensuring we infer the global maxima:\n",
        "\n",
        " 1) Prior Tuning: Tell the non-linear search where to search parameter space.\n",
        " 2) Reduce Complexity: Fit a lens model with fewer parameters and therefore a simpler parameter space.\n",
        " 3) Look Harder: Brute force a global maxima by telling the non-linear search to sample parameter space more thoroughly.\n",
        "\n",
        "Each approach has its benefits and disadvantages and we will discuss them in detail.\n",
        "\n",
        "In the previous tutorial, when we inferred a local maxima we knew that we had done so. For modeling a real lens,\n",
        "we do not know the true lens model and it may be unclear if the solution we infered is a global or local maxima. The\n",
        "methods we learn in this tutorial are therefore equally important for verifying that a solution that looks like a\n",
        "global maxima solution is in indeed the global maxima."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initial Setup__\n",
        "\n",
        "we'll use the same strong lensing data as the previous tutorial, where:\n",
        "\n",
        " - The lens galaxy's light is an `Sersic`.\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's light is an `Exponential`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"lens_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "we'll create and use a smaller 2.6\" `Mask2D` again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=2.6\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When plotted, the lens light`s is clearly visible in the centre of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.ImagingPlotter(\n",
        "    dataset=dataset, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Prior Tuning__\n",
        "\n",
        "First, we will try to assist our non-linear search by tuning our priors. Priors guide the non-linear search on where \n",
        "to look in the parameter space. By setting our priors more accurately ('tuning' them), we can help the search find the \n",
        "global solution instead of getting stuck at a local maxima.\n",
        "\n",
        "In a previous tutorial, we learned how to fully customize priors in **PyAutoLens**. Let's apply this knowledge \n",
        "now. I've set up a custom search below with priors adjusted to give the non-linear search a better chance of finding \n",
        "the global maxima solution. I'll also explain how each prior has been changed from the default values specified in\n",
        " the `config/priors/default` configuration files.\n",
        "\n",
        "We will call our lens and source galaxies `lens` and `source` this time, for shorter more readable code.\n",
        "\n",
        "In a previous tutorial, we customized the priors of a model by creating a `Galaxy` as a `Model` and customizing each\n",
        "prior:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=al.mp.IsothermalSph)\n",
        "lens.mass.centre_0 = af.UniformPrior(lower_limit=-0.1, upper_limit=0.1)\n",
        "lens.mass.centre_1 = af.UniformPrior(lower_limit=-0.1, upper_limit=0.1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can alternatively create the light and mass profiles as a `Model` and customize their parameters, and then pass them\n",
        "to the model galaxy and overall model. These two approaches are equivalent, but in this example the style below \n",
        "provides more concise and readable code. We will therefore switch to this code style in this tutorial, but may swap \n",
        "back and forth between the two styles throughout **HowToLEns** depending on what is more readable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(al.lp.Sersic)\n",
        "mass = af.Model(al.mp.Isothermal)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, the prior on the $(y,x)$ coordinates of a `LightProfile` / `MassProfile` is a GaussianPrior with \n",
        "`mean=0.0` and `sigma=0.3`. However, visual inspection of our strong lens image tells us that its centre (based on the\n",
        "lens galaxy's luminous emission) is at x = 0.0\" and y = 0.0\", so lets reduce the `sigma` value on this prior so the\n",
        "non-linear search looks over a very narrow range of `centre` values in parameter space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge.centre.centre_0 = af.UniformPrior(lower_limit=-0.05, upper_limit=0.05)\n",
        "bulge.centre.centre_1 = af.UniformPrior(lower_limit=-0.05, upper_limit=0.05)\n",
        "mass.centre.centre_0 = af.UniformPrior(lower_limit=-0.05, upper_limit=0.05)\n",
        "mass.centre.centre_1 = af.UniformPrior(lower_limit=-0.05, upper_limit=0.05)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, the elliptical components of the of our lens galaxy's elliptical `LightProfile` are `GaussianPrior`'s \n",
        "with `mean=0.0` and `sigma=0.5`. Note that the solution `ell_comps=(0.0, 0.0)` corresponds to a spherical system\n",
        "and that all physical solutions (e.g. with axis-ratios running from 0.0 -> 1.0 and position angles 0.0 -> 180.0 degrees) \n",
        "are encapsulated for solutions where each component runs from -1.0 -> 1.0). \n",
        "\n",
        "However, through visual inspection of the image we can often determine the position angle of the lens's light, which \n",
        "for this data is clearly 45.0 degrees counter-clockwise from the x-axis. We can update the priors on our elliptical \n",
        "components to reflect this. The `lower_limit` and `upper_limit` on a `GaussianPrior` ensure the solutions cannot go\n",
        "outside the physically plausible range -1.0 -> 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge.ell_comps.ell_comps_0 = af.GaussianPrior(\n",
        "    mean=0.333333, sigma=0.1, lower_limit=-1.0, upper_limit=1.0\n",
        ")\n",
        "bulge.ell_comps.ell_comps_1 = af.GaussianPrior(\n",
        "    mean=0.0, sigma=0.1, lower_limit=-1.0, upper_limit=1.0\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets also assume that the ellipticity of the light profile can be used as a prior on that of the mass profile. This may \n",
        "not be strictly true (e.g. because of dark matter) so we will use a wider prior, such that the non-linear search can \n",
        "change the mass model's ellipticity from that of the light if fitting the data necessitates it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mass.ell_comps.ell_comps_0 = af.GaussianPrior(\n",
        "    mean=0.333333, sigma=0.3, lower_limit=-1.0, upper_limit=1.0\n",
        ")\n",
        "mass.ell_comps.ell_comps_1 = af.GaussianPrior(\n",
        "    mean=0.0, sigma=0.3, lower_limit=-1.0, upper_limit=1.0\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `effective_radius` of light profile is its 'half-light' radius, the radius at which 50% of its total luminosity \n",
        "is internal to a circle defined within that radius. **PyAutoLens** assumes a `UniformPrior` on this quantity between \n",
        "0.0\" and 30.0\". This large range of values is required to cover the size of all possible strong lenses that can be \n",
        "observed in the Universe.\n",
        "\n",
        "However, inspection of this image shows the lens's light does not extend anywhere near 30.0\", so lets reduce it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge.effective_radius = af.GaussianPrior(\n",
        "    mean=1.0, sigma=0.8, lower_limit=0.0, upper_limit=np.inf\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `sersic_index` defines how concentrated the light profile is. In galaxy structure studies, values of Sersic index\n",
        "around 1.0 indicate a disk galaxy, whereas higher values of 3 or 4 indicate an elliptical galaxy. **PyAutoLens**\n",
        "assumes a `UniformPrior` between 0.8 and 8.0 by default on this parameter, as a user could model strong lenses\n",
        "where the lens is of any morphology.\n",
        "\n",
        "We often have knowledge of the lens's morphology before we fit it, so in this example we will assume our lens is\n",
        "a massive elliptical galaxy with a `sersic_index` near 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge.sersic_index = af.GaussianPrior(\n",
        "    mean=4.0, sigma=1.0, lower_limit=0.0, upper_limit=np.inf\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, the `ring` that the lensed source forms clearly has a radius of about 1.6\". This is its Einstein radius, so \n",
        "lets change the prior from a UniformPrior between 0.0\" and 4.0\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mass.einstein_radius = af.GaussianPrior(\n",
        "    mean=1.6, sigma=0.2, lower_limit=0.0, upper_limit=np.inf\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now compose the overall model, where the lens galaxy model uses the `Model` components above which had their\n",
        "priors customizes.\n",
        "\n",
        "In this exercise, I'm not going to change any priors on the source galaxy. Whilst lens modeling experts can look at a \n",
        "strong lens and often tell you roughly where the source-galaxy is located (in the source-plane), it is something of art \n",
        "form. Furthermore, the source's morphology can be pretty complex, making it difficult to come up with a good source \n",
        "prior!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(\n",
        "    al.Galaxy, redshift=0.5, bulge=bulge, mass=mass, shear=al.mp.ExternalShear\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=al.lp.ExponentialCore)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format, including the priors specified above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now create this custom search and run it. Our non-linear search will now start by sampling higher likelihood \n",
        "regions of parameter space, given our improved and more informed priors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"howtolens\", \"chapter_2\"),\n",
        "    name=\"tutorial_4_custom_priors\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=150,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisImaging(dataset=dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "The run time of the `log_likelihood_function` is around the usual value. \n",
        "\n",
        "Due to prior tuning, the model-fit should take less than 10000 iterations per free parameter to converge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")\n",
        "\n",
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")\n",
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the non-linear search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    \"The non-linear search has begun running - checkout the workspace/output/howtolens/chapter_2/tutorial_4_custom_priors\"\n",
        "    \" folder for live output of the results, images and lens model.\"\n",
        "    \" This Jupyter notebook cell with progress once search has completed - this could take some time!\"\n",
        ")\n",
        "\n",
        "result_custom_priors = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "print(\"Search has finished run - you may now continue the notebook.\")\n",
        "\n",
        "print(result_custom_priors.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "Bam! We get a good model, which corresponds to the global maxima. By giving our non-linear search a helping hand and \n",
        "informing it of where to sample parameter space, we can increase the odds that we find the global maxima solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter = aplt.FitImagingPlotter(fit=result_custom_priors.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Discussion__\n",
        "\n",
        "By tuning our priors to the specific lens model we are fitting, we increase the chances of finding the global maxima. \n",
        "This approach can also speed up the search, as it spends less time in regions of parameter space that do not \n",
        "correspond to good solutions.\n",
        "\n",
        "Before moving on to the next approach, let\u2019s consider the pros and cons of prior tuning:\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "- Higher likelihood of finding the global maximum log likelihood solutions in parameter space.\n",
        "\n",
        "- Faster search times, as the non-linear search explores less of the parameter space.\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "- Incorrectly specified priors could lead the non-linear search to an incorrect solution.\n",
        "\n",
        "- It is not always clear how the priors should be tuned, especially for complex lens models.\n",
        "\n",
        "- Priors tailored to a specific lens need customization for each fit. For large samples of lenses, \n",
        "this process would be very time-consuming.\n",
        "\n",
        "__Approach 2: Reducing Complexity__\n",
        "\n",
        "The non-linear search may fail because the lens model is too complex, making its parameter space too difficult to \n",
        "sample accurately. To address this, we can simplify the lens model while ensuring it remains realistic enough for \n",
        "our scientific study. By making certain assumptions, we can reduce the number of model parameters, thereby lowering \n",
        "the dimensionality of the parameter space and improving the search's performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(al.lp.Sersic)\n",
        "mass = af.Model(al.mp.Isothermal)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we create a search that assumes that light-traces-mass. That  is, the light profile centre and elliptical \n",
        "components are perfectly aligned with the centre and elliptical components of the mass profile. This may, or may \n",
        "not, be a reasonable assumption, but it`ll remove 4 parameters from the lens model (the centre and elliptical \n",
        "components of the mass profile), so it is worth trying!\n",
        "\n",
        "To apply our assumption that light traces mass to the model, we `pair` the `centre` and `ell_comps` parameters \n",
        "by setting them equal to one another. This removes the  parameter on the left-hand side of the pairing from the lens \n",
        "model such that when a model is created it has the same value as the parameter on the right-hand side."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mass.centre = bulge.centre\n",
        "mass.ell_comps = bulge.ell_comps"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now compose the model, which will have a non-linear parameter space with 4 less dimensions than the fit performed\n",
        "previously. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(\n",
        "    al.Galaxy, redshift=0.5, bulge=bulge, mass=mass, shear=al.mp.ExternalShear\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=al.lp.ExponentialCore)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format, including the parameter links specified above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now create this search and run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"howtolens\", \"chapter_2\"),\n",
        "    name=\"tutorial_4_reducing_complexity\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=200,\n",
        "    number_of_cores=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "The run time of the `log_likelihood_function` is around the usual value. \n",
        "\n",
        "Due to the simplest model parameterization, the model-fit should take less than 10000 iterations per free parameter to \n",
        "converge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")\n",
        "\n",
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")\n",
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the non-linear search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    \"The non-linear search has begun running - checkout the workspace/output/howtolens/chapter_2/tutorial_4_reducing_complexity\"\n",
        "    \" folder for live output of the results, images and lens model.\"\n",
        "    \" This Jupyter notebook cell with progress once search has completed - this could take some time!\"\n",
        ")\n",
        "\n",
        "result_light_trace_mass = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "print(\"Search has finished run - you may now continue the notebook.\")\n",
        "\n",
        "print(result_light_trace_mass.info)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result_light_trace_mass.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The results look pretty good. Our source galaxy fits the data pretty well and we've clearly inferred a model that \n",
        "looks similar to the one above. However, inspection of the residuals shows that the fit was not quite as good as the \n",
        "first search.\n",
        "\n",
        "It turns out that for this simulated lens, light did not perfectly trace mass. The quality of the fit suffered and the \n",
        "highest value of log likelihood the search inferred was lower as a result.\n",
        "\n",
        "Herein lies the pitfalls of making assumptions, they may make your model less realistic and your fits worse! \n",
        "\n",
        "__Discussion__\n",
        "\n",
        "Let\u2019s consider the advantages and disadvantages of simplifying the model:\n",
        "\n",
        "Advantages:\n",
        "\n",
        "- By reducing the complexity of the parameter space, we increase the chances of finding the global maximum log \n",
        "likelihood, and the search requires less time to do so.\n",
        "\n",
        "- Unlike with tuned priors, this approach is not specific to a single lens, allowing us to use it on many strong lens \n",
        "images.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "- Our model is less realistic, which may negatively impact the accuracy of our fit and the scientific results we\n",
        "derive from it.\n",
        "\n",
        "__Approach 3: Look Harder__\n",
        "\n",
        "In approaches 1 and 2, we assisted our non-linear search to find the highest log likelihood regions of parameter \n",
        "space. In approach 3, we're simply going to tell it to \"look harder.\"\n",
        "\n",
        "Every non-linear search has settings that control how thoroughly it explores parameter space. One such setting is the \n",
        "number of live points used by `Nautilus`. The more thoroughly the search examines the space, the more likely it is to \n",
        "find the global maximum lens model. However, this also means the search will take longer!\n",
        "\n",
        "Below, we configure a more thorough Nautilus search with `n_live=200`. These settings and what they change are \n",
        "discussed in the optional tutorial `howtolens/chapter_optional/tutorial_searches.ipynb`.\n",
        "\n",
        "Due to the long run times of this search, the output is commented out below. Feel free to uncomment it to run the \n",
        "script faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(\n",
        "    al.Galaxy,\n",
        "    redshift=0.5,\n",
        "    bulge=al.lp.Sersic,\n",
        "    mass=al.mp.Isothermal,\n",
        "    shear=al.mp.ExternalShear,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=al.lp.ExponentialCore)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"howtolens\", \"chapter_2\"),\n",
        "    name=\"tutorial_4_look_harder\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=300,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "# %%\n",
        "'''\n",
        "__Run Time__\n",
        "\n",
        "The run time of the `log_likelihood_function` is around the usual value. \n",
        "\n",
        "Due to the more thorough Nautilus settings, the the model-fit should take more than 10000 iterations per free parameter \n",
        "to converge and thus take longer than we are used too.\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")\n",
        "\n",
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")\n",
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the non-linear search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    \"The non-linear search has begun running - checkout the workspace/output/howtolens/chapter_2/tutorial_4_look_harder\"\n",
        "    \" folder for live output of the results, images and lens model.\"\n",
        "    \" This Jupyter notebook cell with progress once search has completed - this could take some time!\"\n",
        ")\n",
        "\n",
        "result_look_harder = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "print(\"Search has finished run - you may now continue the notebook.\")\n",
        "\n",
        "print(result_look_harder.info)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result_look_harder.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's list the advantages and disadvantages of simply adjusting the non-linear search:\n",
        "\n",
        "**Advantages:**\n",
        "\n",
        "- It\u2019s easy to set up; just change the settings of the non-linear search.\n",
        "\n",
        "- It generalizes to any strong lens.\n",
        "\n",
        "- We can retain a more complex lens model.\n",
        "\n",
        "**Disadvantage:**\n",
        "\n",
        "- It can be very expensive in terms of time. For very complex models, the run times can extend to hours, days, \n",
        "weeks, or even months!\n",
        "\n",
        "In conclusion, we can now fit strong lenses effectively. When the process fails, we know how to make it work.\n",
        "In chapter 3 of **HowToLens**, we will introduce a technique called 'non-linear search chaining', which performs a model \n",
        "fit by chaining together multiple searches back-to-back . This allows us to combine the 3 different approaches \n",
        "discussed and exploit the advantages of each, whilst not being hindered by their disadvantages.\n",
        "\n",
        "With search chaining, we can:\n",
        "\n",
        " - Fit simpler models with lower dimensionality parameter spaces in the earlier searches and gradually increase the\n",
        "  lens model complexity search-by-search, guiding the model-fit to a sufficiently realistic lens model. \n",
        "  \n",
        " - In these earlier searches (with easier to sample parameter spaces), use fast non-linear search settings to compute \n",
        " the results quickly and switch to slower settings in later searches when we fit more complex lens models.\n",
        "\n",
        " - Use 'prior passing' to setup the priors of each parameter in the later searches, based on the lens models inferred \n",
        " by the earlier searches. We can therefore guide each search on how to sample a complex lens model's parameter space \n",
        " in a way that can be fully generalized to any strong lens.\n",
        " \n",
        "To wrap up chapter 2, we have a few more tutorials, where we will discuss masking in more detail, the `Result` object\n",
        "and how to make **PyAutoLens** run faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}