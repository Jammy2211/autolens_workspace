{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 2: Prior Passing\n",
        "=========================\n",
        "\n",
        "In the previous tutorial, we used non-linear search chaining to break the model-fitting procedure down into two\n",
        "non-linear searches. This used an initial search to fit a simple lens model, whose results were used to tune and\n",
        "initialize the priors of a more complex lens model that was fitted by the second search.\n",
        "\n",
        "However, the results were passed between searches were passed manually. I explicitly wrote out every result as a prior\n",
        "containing the values inferred in the first search. **PyAutoLens** has an API for passing priors in a more generalized\n",
        "way, which is the topic of this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initial Setup__\n",
        "\n",
        "we'll use the same strong lensing data as the previous tutorial, where:\n",
        "\n",
        " - The lens galaxy's light is an `Sersic`.\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's light is an `Exponential`.\n",
        " \n",
        "All the usual steps for setting up a model fit (masking, analysis, etc.) are included below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"lens_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=2.6\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(\n",
        "    dataset=dataset, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We are going to use the same result of search 1 from the previous tutorial. Thus, we set up an identical model such \n",
        "that we instantly load the result from hard-disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(al.lp_linear.Sersic)\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "bulge.centre_0 = 0.0\n",
        "bulge.centre_1 = 0.0\n",
        "mass.centre_0 = 0.0\n",
        "mass.centre_1 = 0.0\n",
        "\n",
        "mass.ell_comps = bulge.ell_comps\n",
        "\n",
        "bulge.sersic_index = 4.0\n",
        "\n",
        "lens = af.Model(\n",
        "    al.Galaxy, redshift=0.5, bulge=bulge, mass=mass, shear=al.mp.ExternalShear\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=al.lp_linear.ExponentialCore)\n",
        "\n",
        "model_1 = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model_1.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We also create the same search as the previous tutorial, using the same name to ensure we use the same results, and \n",
        "run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_1 = af.Nautilus(\n",
        "    path_prefix=path.join(\"howtolens\", \"chapter_3\"),\n",
        "    name=\"tutorial_1_search_chaining_1\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "analysis_1 = al.AnalysisImaging(dataset=dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "It is good practise to always check the `log_likelihood_function` run time before starting the non-linear search.  \n",
        "It will be similar to the value we saw in the previous chapter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis_1.profile_log_likelihood_function(\n",
        "    instance=model_1.random_instance()\n",
        ")\n",
        "\n",
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")\n",
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model_1.total_free_parameters * 10000)\n",
        "    / search_1.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_1 = search_1.fit(model=model_1, analysis=analysis_1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result (Search 1)__\n",
        "\n",
        "The results which are used for prior passing are summarized in the `info` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_1.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Prior Passing__\n",
        "\n",
        "We are now going to use the prior passing API to pass these results, in a way which does not require us to manually \n",
        "write out the inferred parameter values of each component. The details of how prior passing is performed will be \n",
        "expanded upon at the end of the tutorial.\n",
        "\n",
        "We start with the lens's bulge, which in the previous search was an `Sersic` with its centre fixed to (0.0, 0.0) \n",
        "and its `sersic_index` fixed to 4.0. The API for passing priors is shown below and there are two things worth noting:\n",
        "\n",
        " 1) We pass the priors using the `model` attribute of the result. This informs **PyAutoLens** to pass the result as a\n",
        " model component that is to be fitted for in the next search, using priors that are initialized from the previous\n",
        " search's result. Note, if we pass as a `model` a parameter that was fixed in search 1 (e.g. the `sersic_index`) it \n",
        " will be fixed to the same value in search 2.\n",
        "\n",
        " 2) We do not pass the `centre` or `sersic_index` using `model`, because it would be fixed to the values that it was in \n",
        " the first search. By omitting the centre, it uses the default priors on a lens galaxy, whereas we manually tell the \n",
        " Sersic index to use a `GaussianPrior` centred on 4.0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(al.lp_linear.Sersic)\n",
        "\n",
        "bulge.ell_comps = result_1.model.galaxies.lens.bulge.ell_comps\n",
        "bulge.effective_radius = result_1.model.galaxies.lens.bulge.effective_radius\n",
        "bulge.sersic_index = af.GaussianPrior(\n",
        "    mean=4.0, sigma=2.0, lower_limit=0.0, upper_limit=5.0\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the mass, we again must account for how its centre was fixed to (0.0\", 0.0\") and therefore not pass the centre.\n",
        "Passing the other parameters is the same as how we passed the bulge parameters, as is the shear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mass = af.Model(al.mp.Isothermal)\n",
        "mass.einstein_radius = result_1.model.galaxies.lens.mass.einstein_radius\n",
        "mass.ell_comps = result_1.model.galaxies.lens.mass.ell_comps\n",
        "shear = result_1.model.galaxies.lens.shear"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the source's bulge, we are passing the result of an `Exponential` to an `Sersic`. \n",
        "\n",
        "We can use a special prior passing method to do this, called `take_attributes`. This scans the `Exponential`\n",
        "passed to the `take_attributes` method for all parameters which have the same name as the `Sersic` model,\n",
        "and if their names are the same it passes their prior as a `model` (like we did above). Thus, it will locate all 6\n",
        "parameters in common between the two profiles (centre_, ell_comps, intensity, effective_radius) and pass those,\n",
        "leaving the `sersic_index`'s priors as the default values.\n",
        "\n",
        "The `take_attributes` method is used in many examples of prior passing, when we pass a simpler parameterization of a\n",
        "model to a more complex model. Another good example would be passing the result of a `IsothermalSph` to an\n",
        "`Isothermal`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_bulge = af.Model(al.lp_linear.Sersic)\n",
        "source_bulge.take_attributes(result_1.model.galaxies.source.bulge)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now compose the model with these components that have had their priors customized. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(al.Galaxy, redshift=0.5, bulge=bulge, mass=mass, shear=shear)\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=source_bulge)\n",
        "\n",
        "model_2 = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model, including how all priors are updated via prior passing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model_2.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "Lets setup and run the search. I have given it a different name to the previous tutorial so we can compare the priors\n",
        "that were passed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_2 = af.Nautilus(\n",
        "    path_prefix=path.join(\"howtolens\", \"chapter_3\"),\n",
        "    name=\"tutorial_2_search_chaining_2\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "analysis_2 = al.AnalysisImaging(dataset=dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "Whilst the run-time of the log likelihood function is pretty much unchanged from the first search, the overall run-time\n",
        "of the search should decrease.\n",
        "\n",
        "This is because via prior passing we have informed the search of where to look in parameter space, meaning it \n",
        "should spend far fewer than ~10000 iterations per free parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis_2.profile_log_likelihood_function(\n",
        "    instance=model_2.random_instance()\n",
        ")\n",
        "\n",
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")\n",
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model_2.total_free_parameters * 10000)\n",
        "    / search_2.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    \"The non-linear search has begun running - checkout the workspace/output/5_chaining_searches\"\n",
        "    \" folder for live output of the results, images and lens model.\"\n",
        "    \" This Jupyter notebook cell with progress once search has completed - this could take some time!\"\n",
        ")\n",
        "\n",
        "result_2 = search_2.fit(model=model_2, analysis=analysis_2)\n",
        "\n",
        "print(\"Search has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "We can again inspect the results via the `info` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_2.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And a plot of the image shows we get a good model again!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter = aplt.FitImagingPlotter(fit=result_2.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "We will expand on the prior passing API in the following tutorials. The main thing to note is that we can pass \n",
        "entire profiles or galaxies using prior passing, if their model does not change (which for the bulge, mass and \n",
        "source_bulge above, was not true). The API to pass a whole profile or galaxy is as follows:\n",
        " \n",
        " bulge = result_1.model.galaxies.lens.bulge\n",
        " lens = result_1.model.galaxies.lens\n",
        " source = result_1.model.galaxies.source\n",
        " \n",
        "We can also pass priors using an `instance` instead of a `model`. When an `instance` is used, the maximum likelihood\n",
        "parameter values are passed as fixed values that are therefore not fitted for nby the non-linear search (reducing its\n",
        "dimensionality). We will use this in the next tutorial to fit the lens light, fix it to the best-fit model in a second\n",
        "search, and then go on to fit it as a model in the final search.\n",
        " \n",
        "Lets now think about how priors are passed. Checkout the `model.info` file of the second search of this tutorial. The \n",
        "parameters do not use the default priors we saw in search 1 (which are typically broad UniformPriors). Instead, \n",
        "they use GaussianPrior`s where:\n",
        "\n",
        " - The mean values are the median PDF results of every parameter in search 1.\n",
        " - The sigma values are specified in the `width_modifier` field of the profile's entry in the `priors.yaml' config \n",
        "   file (we will discuss why this is used in a moment).\n",
        "\n",
        "Like the manual `GaussianPrior`'s that were used in tutorial 1, the prior passing API sets up the prior on each \n",
        "parameter with a `GaussianPrior` centred on the high likelihood regions of parameter space!\n",
        "\n",
        "__Detailed Explanation Of Prior Passing__\n",
        "\n",
        "To end, I provide a detailed overview of how prior passing works and illustrate tools that can be used to customize\n",
        "its behaviour. It is up to you whether you want read this, or go ahead to the next tutorial!\n",
        "\n",
        "Lets say I chain two parameters as follows:\n",
        " \n",
        " `mass.einstein_radius = result_1.model.galaxies.lens.mass.einstein_radius`\n",
        "\n",
        "By invoking the `model` attribute, the prior is passed following 3 rules:\n",
        "\n",
        " 1) The new parameter, in this case the einstein radius, uses a `GaussianPrior`.This is ideal, as the 1D pdf results \n",
        " we compute at the end of a search are easily summarized as a Gaussian.\n",
        "\n",
        " 2) The mean of the `GaussianPrior` is the median PDF value of the parameter estimated in search 1.\n",
        "    \n",
        " This ensures that the initial sampling of the new search's non-linear starts by searching the region of non-linear \n",
        " parameter space that correspond to highest log likelihood solutions in the previous search. Our priors therefore \n",
        " correspond to the `correct` regions of parameter space.\n",
        "\n",
        " 3) The sigma of the Gaussian uses the value specified for the profile in the `config/priors/*.yaml` config file's \n",
        " `width_modifer` field (check these files out now).\n",
        "\n",
        "The idea here is simple. We want a value of sigma that gives a `GaussianPrior` wide enough to search a broad \n",
        "region of parameter space, so that the lens model can change if a better solution is nearby. However, we want it \n",
        "to be narrow enough that we don't search too much of parameter space, as this will be slow or risk leading us \n",
        "into an incorrect solution! \n",
        "\n",
        "The `width_modifier` values in the priors config file have been chosen based on our experience as being a good\n",
        "balance broadly sampling parameter space but not being so narrow important solutions are missed.\n",
        "       \n",
        "There are two ways a value is specified using the priors/width file:\n",
        "\n",
        " 1) Absolute: In this case, the error assumed on the parameter is the value given in the config file. \n",
        " For example, if for the width on centre_0 of a light profile, the width modifier reads \"Absolute\" with a value \n",
        " 0.05. This means if the error on the parameter centre_0 was less than 0.05 in the previous search, the sigma of \n",
        " its `GaussianPrior` in this search will be 0.05.\n",
        "    \n",
        " 2) Relative: In this case, the error assumed on the parameter is the % of the value of the estimated value given in \n",
        " the config file. For example, if the intensity estimated in the previous search was 2.0, and the relative error in \n",
        " the config file reads \"Relative\" with a value 0.5, then the sigma of the `GaussianPrior` will be 50% of this \n",
        " value, i.e. sigma = 0.5 * 2.0 = 1.0.\n",
        "\n",
        "We use absolute and relative values for different parameters, depending on their properties. For example, using the \n",
        "relative value of a parameter like the `Profile` centre makes no sense. If our lens galaxy is centred at (0.0, 0.0), \n",
        "the relative error will always be tiny and thus poorly defined. Therefore, the default configs in **PyAutoLens** use \n",
        "absolute errors on the centre.\n",
        "\n",
        "However, there are parameters where using an absolute value does not make sense. Intensity is a good example of this. \n",
        "The intensity of an image depends on its units, S/N, galaxy brightness, etc. There is no single absolute value that \n",
        "one can use to generically chain the intensity of any two proflies. Thus, it makes more sense to chain them using \n",
        "the relative value from a previous search.\n",
        "\n",
        "We can customize how priors are passed from the results of a search and non-linear search by editing the\n",
        " `prior_passer` settings in the `general.yaml` config file.\n",
        "\n",
        "__EXAMPLE__\n",
        "\n",
        "Lets go through an example using a real parameter. Lets say in search 1 we fit the lens galaxy's light with an \n",
        "elliptical Sersic profile, and we estimate that its sersic index is equal to 4.0.\n",
        " \n",
        "To pass this as a prior to search 2 we write:\n",
        "\n",
        " lens.bulge.sersic_index = result_1.model.lens.bulge.sersic_index\n",
        "\n",
        "The prior on the lens galaxy's bulge sersic index in search 2 would thus be a `GaussianPrior` with mean=4.0. \n",
        "\n",
        "The value of the Sersic index `width_modifier` in the priors config file sets sigma. The prior config file specifies \n",
        "that we use an \"Absolute\" value of 0.8 to chain this prior. Thus, the `GaussianPrior` in search 2 would have a \n",
        "mean=4.0 and sigma=0.8.\n",
        "\n",
        "If the prior config file had specified that we use an relative value of 0.8, the GaussianPrior in search 2 would have a \n",
        "mean=4.0 and sigma = 4.0 * 0.8 = 3.2.\n",
        "\n",
        "And with that, we're done. Chaining priors is a bit of an art form, but one that works really well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}