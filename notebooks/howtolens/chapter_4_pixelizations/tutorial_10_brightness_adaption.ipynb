{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 2: Brightness Adaption\n",
        "===============================\n",
        "\n",
        "In the previous tutorial we motivated our need to adapt the pixelization to the source's morphology, such that source\n",
        "pixels congregates in the source's brightest regions regardless of where the source is located in the source-plane. This\n",
        "raises an interesting question; how do we adapt our pixelization to the reconstructed source's light, before we've\n",
        "actually reconstructed the source and therefore know what to adapt it too?\n",
        "\n",
        "To do this, we define 'adapt_images' of the lensed source galaxy. A hyper image is a model image of the source computed\n",
        "using a previous lens model that has been fit to the image (e.g. in the earlier search of a pipeline). This image tells\n",
        "us where in the image our source is located, thus informing us of where we need to adapt our source pixelization!\n",
        "\n",
        "This tutorial goes into the details of how this works. We'll use the same compact source galaxy as the previous\n",
        "tutorial and we'll begin by fitting it with a magnification based pixelization. Why? So we can use its model image to\n",
        "set up the hyper-galaxy-image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initial Setup__\n",
        "\n",
        "we'll use the same strong lensing data as the previous tutorial, where:\n",
        "\n",
        " - The lens galaxy's light is omitted.\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's light is an `Sersic`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    sub_size=2,\n",
        "    radius=3.0,\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we're going to fit the image using our magnification based grid. The code below does all the usual steps \n",
        "required to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.0, 0.0),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        "    shear=al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05),\n",
        ")\n",
        "\n",
        "pixelization = al.Pixelization(\n",
        "    mesh=al.mesh.DelaunayMagnification(shape=(30, 30)),\n",
        "    regularization=al.reg.Constant(coefficient=3.3),\n",
        ")\n",
        "\n",
        "source_galaxy_magnification = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy_magnification])\n",
        "\n",
        "fit = al.FitImaging(dataset=dataset, tracer=tracer)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets have a quick look to make sure it has the same residuals we saw in tutorial 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "include = aplt.Include2D(\n",
        "    mask=True, mapper_image_plane_mesh_grid=True, mapper_source_plane_mesh_grid=True\n",
        ")\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include)\n",
        "fit_plotter.subplot_fit()\n",
        "fit_plotter.subplot_of_planes(plane_index=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Hyper Image__\n",
        "\n",
        "Finally, we can use this fit to set up our hyper-image. This hyper-image is not perfect, because there are residuals in \n",
        "the central regions of the reconstructed source. However, it is *good enough** for us to use to adapt our pixelization\n",
        "to the lensed source.\n",
        "\n",
        "(The `binned` attribute below ensures our hyper-image is at the native resolution of the imaging data, as opposed to a \n",
        "higher resolution sub-grid)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "hyper_image_2d = fit.model_image.binned.slim"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Adaption__\n",
        "\n",
        "Now lets take a look at brightness based adaption in action! Below, we define a source-galaxy using our new \n",
        "`DelaunayBrightnessImage` pixelization and use this to fit the lens-data. \n",
        "\n",
        "We also attach the hyper_image to the source galaxy, via the inputs `adapt_model_image` and `adapt_galaxy_image`. In\n",
        "tutorial 4, we will explain why the hyper image is input twice as two seperate inputs, for now just ignore this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelizaiton = al.Pixelization(\n",
        "    mesh=al.mesh.DelaunayBrightnessImage(\n",
        "        pixels=500, weight_floor=0.0, weight_power=10.0\n",
        "    ),\n",
        "    regularization=al.reg.Constant(coefficient=0.5),\n",
        ")\n",
        "\n",
        "source_galaxy_brightness = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=pixelization,\n",
        "    adapt_model_image=hyper_image_2d,\n",
        "    adapt_galaxy_image=hyper_image_2d,\n",
        ")\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_galaxy_brightness])\n",
        "\n",
        "fit = al.FitImaging(dataset=dataset, tracer=tracer)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include)\n",
        "fit_plotter.subplot_fit()\n",
        "fit_plotter.subplot_of_planes(plane_index=1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Would you look at that! Our reconstruction of the image no longer has residuals! By congregating more source \n",
        "pixels in the brightest regions of the source reconstruction we get a better fit. Furthermore, we can check that \n",
        "this provides an increase in Bayesian log evidence, noting that the log evidence of the compact source when using a \n",
        "`DelaunayMagnification` mesh was 4216:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Evidence using magnification based pixelization. \", 4216)\n",
        "print(\"Evidence using brightness based pixelization. \", fit.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It increases! By over 1000, which, for a Bayesian evidence, is pretty damn large! By any measure, this \n",
        "pixelization is a huge success. It turns out that we should have been adapting to the source's brightness all along! \n",
        "In doing so, we will *always* reconstruct the detailed structure of the source's brightest regions with a sufficiently \n",
        "high resolution. Hurrah!\n",
        "\n",
        "So, we are now able to adapt the pixelization to the morphology of the lensed source galaxy. To my knowledge, this\n",
        "is the *best* approach one can take in lens modeling. Its more tricky to implement and introduces additional non-linear \n",
        "parameters. But the pay-off is more than worth it, as we fit our data better and use fewer source pixels to reconstruct\n",
        "the source, given that we 'waste' pixels reconstructing regions of the source-plane where there is no signal.\n",
        "\n",
        "__KMeans__\n",
        "\n",
        "So how does the `hyper_image` adapt the pixelization to the source's brightness? It uses a 'weighted KMeans clustering \n",
        "algorithm', which is a standard algorithm for partioning data in statistics.\n",
        "\n",
        "In simple terms, this algorithm works as follows:\n",
        "\n",
        " 1) Give the KMeans algorithm a set of weighted data (e.g. these weight_list are determined from the hyper-image).\n",
        "    \n",
        " 2) For a given number of K-clusters, this algorithm finds a set of $(y,x)$ coordinates that equally partition the \n",
        " weighted data-set. Wherever the data has higher weighting, more clusters congregate and visa versa.\n",
        "    \n",
        " 3) The returned $(y,x)$ 'clusters' then make up our source-pixel centres, where the brightest (e.g. higher weighted \n",
        " regions of the hyper-image) will have more clusters! We can then trace these coordinates to the source-plane to define \n",
        " our source-pixel pixelization.\n",
        "\n",
        "This is a fairly simplistic description of a KMeans algorithm. Feel free to check out the chains below for a more \n",
        "in-depth view:\n",
        "\n",
        " https://en.wikipedia.org/wiki/K-means_clustering\n",
        " https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
        "\n",
        "\n",
        "__Weight Map__\n",
        "\n",
        "We now have a sense of how our `DelaunayBrightnessImage` pixelization is computed. Now, lets look at how we create the \n",
        "weighted data the KMeans algorithm uses.\n",
        "\n",
        "This image, called the `cluster_weight_map` is generated using the `weight_floor` and `weight_power` parameters of \n",
        "the `DelaunayBrightnessImage` object. The cluster weight map is generated following 4 steps:\n",
        "\n",
        " 1) Increase all values of the hyper-image that are < 0.02 to 0.02. This is necessary because negative values and \n",
        " zeros break the KMeans clustering algorithm.\n",
        "    \n",
        " 2) Divide all values of this image by its maximum value, such that the hyper-image now only contains values between \n",
        " 0.0 and 1.0 (where the values of 1.0 are the maximum values of the hyper-image).\n",
        "    \n",
        " 3) Add the weight_floor to all values (a weight_floor of 0.0 therefore does not change the cluster weight map).\n",
        "    \n",
        " 4) Raise all values to the power of weight_power (a weight_power of 1.0 therefore does not change the cluster \n",
        " weight map, whereas a value of 0.0 means all values 1.0 and therefore weighted equally).\n",
        "\n",
        "Lets look at this in action. we'll inspect 3 cluster_weight_maps, using a weight_power of 0.0, 5.0 and 10.0, \n",
        "setting the `weight_floor` to 0.0 such that it does not change the cluster weight map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    mesh=al.mesh.DelaunayBrightnessImage(\n",
        "        pixels=500, weight_floor=0.0, weight_power=0.0\n",
        "    ),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "source_weight_power_0 = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=pixelization,\n",
        "    adapt_model_image=hyper_image_2d,\n",
        "    adapt_galaxy_image=hyper_image_2d,\n",
        ")\n",
        "\n",
        "cluster_weight_power_0 = source_weight_power_0.pixelization.mesh.weight_map_from(\n",
        "    adapt_data=source_weight_power_0.adapt_galaxy_image\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(\n",
        "    array=cluster_weight_power_0, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "array_plotter.figure_2d()\n",
        "\n",
        "\n",
        "pixelization = al.Pixelization(\n",
        "    mesh=al.mesh.DelaunayBrightnessImage(\n",
        "        pixels=500, weight_floor=0.0, weight_power=5.0\n",
        "    ),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "source_weight_power_5 = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=pixelization,\n",
        "    adapt_model_image=hyper_image_2d,\n",
        "    adapt_galaxy_image=hyper_image_2d,\n",
        ")\n",
        "\n",
        "cluster_weight_power_5 = source_weight_power_5.pixelization.mesh.weight_map_from(\n",
        "    adapt_data=source_weight_power_5.adapt_galaxy_image\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(\n",
        "    array=cluster_weight_power_0, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "array_plotter.figure_2d()\n",
        "\n",
        "\n",
        "ixelization = al.Pixelization(\n",
        "    mesh=al.mesh.DelaunayBrightnessImage(\n",
        "        pixels=500, weight_floor=0.0, weight_power=10.0\n",
        "    ),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "source_weight_power_10 = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    pixelization=pixelization,\n",
        "    adapt_model_image=hyper_image_2d,\n",
        "    adapt_galaxy_image=hyper_image_2d,\n",
        ")\n",
        "\n",
        "cluster_weight_power_10 = source_weight_power_10.pixelization.mesh.weight_map_from(\n",
        "    adapt_data=source_weight_power_10.adapt_galaxy_image\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(\n",
        "    array=cluster_weight_power_0, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we increase the weight-power the brightest regions of the hyper-image become weighted higher relative to the \n",
        "fainter regions. This means that the KMeans algorithm will adapt its pixelization to the brightest regions of the \n",
        "source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_weight_power_0])\n",
        "\n",
        "fit = al.FitImaging(dataset=dataset, tracer=tracer)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include)\n",
        "fit_plotter.figures_2d_of_planes(plane_index=1, plane_image=True)\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_weight_power_5])\n",
        "\n",
        "fit = al.FitImaging(dataset=dataset, tracer=tracer)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include)\n",
        "fit_plotter.figures_2d_of_planes(plane_index=1, plane_image=True)\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_weight_power_10])\n",
        "\n",
        "fit = al.FitImaging(dataset=dataset, tracer=tracer)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include)\n",
        "fit_plotter.figures_2d_of_planes(plane_index=1, plane_image=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, what does the `weight_floor` do? Increasing the weight-power congregates pixels around the source. However, there \n",
        "is a risk that by congregating too many source pixels in its brightest regions we lose resolution further out, where \n",
        "the source is bright, but not its brightest!\n",
        "\n",
        "The `noise-floor` allows these regions to maintain a higher weighting whilst the `noise_power` increases. This means \n",
        "that the pixelization can fully adapt to the source's brightest and faintest regions simultaneously.\n",
        "\n",
        "Lets look at once example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ixelization = al.Pixelization(\n",
        "    mesh=al.mesh.DelaunayBrightnessImage(\n",
        "        pixels=500, weight_floor=0.5, weight_power=10.0\n",
        "    ),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "source_weight_floor = al.Galaxy(\n",
        "    redshift=1.0, pixelization=pixelization, adapt_galaxy_image=hyper_image_2d\n",
        ")\n",
        "\n",
        "cluster_weight_floor = source_weight_floor.pixelization.mesh.weight_map_from(\n",
        "    adapt_data=source_weight_floor.adapt_galaxy_image\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(\n",
        "    array=cluster_weight_power_0, visuals_2d=aplt.Visuals2D(mask=mask)\n",
        ")\n",
        "array_plotter.figure_2d()\n",
        "\n",
        "tracer = al.Tracer.from_galaxies(galaxies=[lens_galaxy, source_weight_floor])\n",
        "\n",
        "fit = al.FitImaging(dataset=dataset, tracer=tracer)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include)\n",
        "fit_plotter.figures_2d_of_planes(plane_index=1, plane_image=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "To end, lets think about the Bayesian evidence, which we saw now goes to significantly higher values than for a \n",
        "magnification-based grid. At this point, it might be worth reminding yourself how the Bayesian evidence works by \n",
        "going back to description in this chapters `introduction` text file.\n",
        "\n",
        "So, why do you think why adapting to the source's brightness increases the log evidence?\n",
        "\n",
        "It is because by adapting to the source's morphology we can now access solutions that fit the data really well \n",
        "(e.g. to the Gaussian noise-limit) but use significantly fewer source-pixels than before. For instance, a typical \n",
        "magnification based grid uses resolutions of 40 x 40, or 1600 pixels. In contrast, a morphology based pixelization \n",
        "typically uses just 300-800 pixels (depending on the source itself). Clearly, the easiest way to make our source \n",
        "solution simpler is to use fewer pixels overall!\n",
        "\n",
        "This provides a second benefit. If the best solutions in our fit want to use the fewest source-pixels possible and \n",
        "**PyAutoLens** can now access those solutions, this means that hyper-mode will run much faster than the magnification \n",
        "based grid! Put simply, fewer source-pixels means lower computational overheads. YAY!\n",
        "\n",
        "Tutorial 2 done, next up, adaptive regularization!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}