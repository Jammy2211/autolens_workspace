{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 9: Fit Problems\n",
        "========================\n",
        "\n",
        "To begin, make sure you have read the `introduction` file carefully, as a clear understanding of how the Bayesian\n",
        "evidence works is key to understanding this chapter!\n",
        "\n",
        "In the previous chapter we investigated two pixelization's: `Rectangular` and `Delaunay`. We argued that the\n",
        "latter was better than the former, because it dedicated more source-pixels to the regions of the source-plane where we\n",
        "had more data, e.g, the high-magnification regions. Therefore, we could fit the data using fewer source pixels,\n",
        "which improved computational efficiency and increased the Bayesian evidence.\n",
        "\n",
        "So far, we've used just one regularization scheme; `Constant`. As the name suggests, this scheme applies just one\n",
        "regularization coefficient when comparing source pixel fluxes to apply smoothing. Here is a recap of our discussion\n",
        "about regularization from chapter 4:\n",
        "\n",
        "-------------------------------------------- \n",
        "\n",
        "When the inversion reconstructs the source, it does not *only* compute the set of source-pixel fluxes that best-fit\n",
        "the image. It also regularizes this solution, whereby it goes to every pixel on the rectangular source-plane grid\n",
        "and computes the different between the reconstructed flux values of every source pixel with its 4 neighboring pixels.\n",
        "If the difference in flux is large the solution is penalized, reducing its log likelihood. You can think of this as\n",
        "us applying a 'smoothness prior' on the reconstructed source galaxy's light.\n",
        "\n",
        "This smoothing adds a 'penalty term' to the log likelihood of an inversion which is the summed difference between the\n",
        "reconstructed fluxes of every source-pixel pair multiplied by the `coefficient`. By setting the regularization\n",
        "coefficient to zero, we set this penalty term to zero, meaning that regularization is completely omitted.\n",
        "\n",
        "Why do we need to regularize our solution? We just saw why, if we do not apply this smoothness prior to the source, we\n",
        "`over-fit` the image and reconstruct a noisy source with lots of extraneous features. This is what the  large flux\n",
        "values located at the exterior regions of the source reconstruction above are. If the inversions's sole aim is to\n",
        "maximize the log likelihood, it can do this by fitting *everything* accurately, including the noise.\n",
        "\n",
        "----------------------------------------------\n",
        "\n",
        "When using a `ConstantSplit` regularization scheme, we regularize the source by adding up the difference in fluxes \n",
        "between all source-pixels multiplied by one single value of the regularization coefficient. This means that every\n",
        "single source pixel receives the same `level` of regularization, regardless of whether it is reconstructing the\n",
        "bright central regions of the source or its faint exterior regions.\n",
        "\n",
        "In this tutorial, we'll learn why our magnification-based pixelization and constant regularization schemes are not\n",
        "optimal. We'll inspect fits to three strong lenses, simulated using the same mass profile but with different\n",
        "sources whose light profiles become gradually more compact. For all 3 fits, we'll use the same source-plane resolution\n",
        "and a regularization_coefficient that maximize the Bayesian evidence. Thus, these are the `best` source reconstructions\n",
        "we can hope to achieve when adapting to the magnification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initial Setup__\n",
        "\n",
        "we'll use 3 sources whose `effective_radius` and `sersic_index` are changed such that each is more compact that the last."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_galaxy_flat = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp.Sersic(\n",
        "        centre=(0.0, 0.0),\n",
        "        ell_comps=(0.0, 0.15),\n",
        "        intensity=0.2,\n",
        "        effective_radius=0.5,\n",
        "        sersic_index=1.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "source_galaxy_compact = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp.Sersic(\n",
        "        centre=(0.0, 0.0),\n",
        "        ell_comps=(0.0, 0.15),\n",
        "        intensity=0.2,\n",
        "        effective_radius=0.2,\n",
        "        sersic_index=2.5,\n",
        "    ),\n",
        ")\n",
        "\n",
        "source_galaxy_super_compact = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp.Sersic(\n",
        "        centre=(0.0, 0.0),\n",
        "        ell_comps=(0.0, 0.15),\n",
        "        intensity=0.2,\n",
        "        effective_radius=0.1,\n",
        "        sersic_index=4.0,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The function below uses each source galaxy to simulate imaging data. It performs the usual tasks we are used to \n",
        "seeing (make the PSF, galaxies, tracer, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def simulate_for_source_galaxy(source_galaxy):\n",
        "    grid = al.Grid2D.uniform(shape_native=(150, 150), pixel_scales=0.05)\n",
        "\n",
        "    psf = al.Kernel2D.from_gaussian(\n",
        "        shape_native=(11, 11), sigma=0.05, pixel_scales=0.05\n",
        "    )\n",
        "\n",
        "    lens_galaxy = al.Galaxy(\n",
        "        redshift=0.5,\n",
        "        mass=al.mp.Isothermal(\n",
        "            centre=(0.0, 0.0), ell_comps=(0.111111, 0.0), einstein_radius=1.6\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "    simulator = al.SimulatorImaging(\n",
        "        exposure_time=300.0,\n",
        "        psf=psf,\n",
        "        background_sky_level=100.0,\n",
        "        add_poisson_noise=True,\n",
        "        noise_seed=1,\n",
        "    )\n",
        "\n",
        "    return simulator.via_tracer_from(tracer=tracer, grid=grid)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "we'll use a 3.0\" mask to fit all three of our sources."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(shape_native=(150, 150), pixel_scales=0.05, radius=3.0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Simulator__\n",
        "\n",
        "Now, lets simulate all 3 of our source's as to create `Imaging` data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_source_flat = simulate_for_source_galaxy(source_galaxy=source_galaxy_flat)\n",
        "\n",
        "dataset_source_compact = simulate_for_source_galaxy(source_galaxy=source_galaxy_compact)\n",
        "\n",
        "dataset_source_super_compact = simulate_for_source_galaxy(\n",
        "    source_galaxy=source_galaxy_super_compact\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fitting__\n",
        "\n",
        "we'll make one more convenience function which fits the simulated imaging data with an `Overlay` image-mesh, \n",
        "`Delaunay` mesh  and `Constant` regularization scheme pixelization.\n",
        "\n",
        "We'll input the `coefficient` of each fit, so that for each simulated source we regularize it at an appropriate level. \n",
        "There is nothing new in this function you haven't seen before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def fit_with_delaunay_from(dataset, mask, coefficient):\n",
        "    dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "    lens_galaxy = al.Galaxy(\n",
        "        redshift=0.5,\n",
        "        mass=al.mp.Isothermal(\n",
        "            centre=(0.0, 0.0), ell_comps=(0.111111, 0.0), einstein_radius=1.6\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    pixelization = al.Pixelization(\n",
        "        image_mesh=al.image_mesh.Overlay(shape=(30, 30)),\n",
        "        mesh=al.mesh.Delaunay(),\n",
        "        regularization=al.reg.Constant(coefficient=coefficient),\n",
        "    )\n",
        "\n",
        "    source_galaxy = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "    tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "    return al.FitImaging(dataset=dataset, tracer=tracer)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit Problems__\n",
        "\n",
        "Lets fit our first source which was simulated using the flattest light profile. One should note that this uses the \n",
        "highest regularization coefficient of our 3 fits (as determined by maximizing the Bayesian log evidence)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_flat = fit_with_delaunay_from(\n",
        "    dataset=dataset_source_flat, mask=mask, coefficient=9.2\n",
        ")\n",
        "\n",
        "include = aplt.Include2D(mapper_image_plane_mesh_grid=True, mask=True)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit_flat, include_2d=include)\n",
        "fit_plotter.subplot_fit()\n",
        "fit_plotter.subplot_of_planes(plane_index=1)\n",
        "\n",
        "\n",
        "print(fit_flat.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit was *excellent*. There were effectively no residuals in the fit, and the source has been reconstructed using \n",
        "lots of pixels! Nice!\n",
        "\n",
        "Now, lets fit the next source, which is more compact."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_compact = fit_with_delaunay_from(\n",
        "    dataset=dataset_source_compact, mask=mask, coefficient=3.3\n",
        ")\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit_compact, include_2d=include)\n",
        "fit_plotter.subplot_fit()\n",
        "fit_plotter.subplot_of_planes(plane_index=1)\n",
        "\n",
        "print(fit_compact.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit does not look so good! \n",
        "\n",
        "It reconstructs most of the lensed source's structure, but there are two  clear blobs in the residual map where \n",
        "the fit is failing to reconstruct the central regions of the source galaxy.\n",
        "\n",
        "Take a second to think about why this might be. Is it the mesh or how the regularization is applying smoothing?\n",
        "\n",
        "Finally, lets fit the very compact source. Given that the results for the compact source did not look good, you are \n",
        "right in thinking this is going to make things even worse. Again, think about why this might be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_super_compact = fit_with_delaunay_from(\n",
        "    dataset=dataset_source_super_compact, mask=mask, coefficient=3.1\n",
        ")\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit_super_compact, include_2d=include)\n",
        "fit_plotter.subplot_fit()\n",
        "fit_plotter.subplot_of_planes(plane_index=1)\n",
        "\n",
        "print(fit_super_compact.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Discussion__\n",
        "\n",
        "Okay, so what did we learn? The more compact our source, the worse the fit. This happens even though we are using the \n",
        "correct lens mass model, telling us that something is going fundamentally wrong with our source reconstruction and \n",
        "pixelization. Both the mesh and regularization are to blame!\n",
        "\n",
        "*Image-Mesh / Mesh*:\n",
        "\n",
        "The problem is the same one we discussed when we compared the `Rectangular` and `Delaunay` meshes in tutorial 7. \n",
        "\n",
        "We are simply not dedicating enough source-pixels to the central regions of the source reconstruction, \n",
        "e.g. where it`s brightest. As the source becomes more compact, the source reconstruction no longer has enough \n",
        "resolution to resolve its fine-detailed central structure, causing the fit to the image to degrade.\n",
        "\n",
        "As we made our sources more compact we go from reconstructing them using ~100 source pixels, to ~20  source pixels \n",
        "to ~ 10 source pixels. This is why we advocated not using the `Rectangular` mesh previously!\n",
        "\n",
        "Adapting to the mass model magnification is not the best approach. As we simulated more compact sources the \n",
        "magnification (which is determined via the mass model) does not change. We therefore reconstructed each source\n",
        "using fewer and fewer pixels, leading to a worse and worse fit. \n",
        "\n",
        "Furthermore, the source galaxies above are located in the highest magnification regions of the source plane! If the \n",
        "source's were further away from the caustic, the pixelization would use *even less* pixels to reconstruct them. \n",
        "Clearly, we want to adapt to something else. \n",
        "\n",
        "**Regularization**:\n",
        "\n",
        "Regularization also causes problems. When using a `ConstantSplit` regularization scheme, we regularize the source by \n",
        "adding up the difference in fluxes between all source-pixels multiplied by one single value, the regularization\n",
        "coefficient. This means that, every single source pixel receives the same `level` of regularization, regardless of \n",
        "whether it is reconstructing the bright central regions of the source or its faint exterior regions. \n",
        "\n",
        "To visualize this, we are going to plot the `regularization_weights`. \n",
        "\n",
        "The `FitImagingPlotter` does not have a method that is able to plot this attribute of the `Inversion`. However, \n",
        "the `FitImagingPlotter` has its own  `InversionPlotter` which we can use to make this plot. The benefit of using this \n",
        "is that it inherits from the `FitImagingPlotter` properties like the caustics, so they appear on the figure (this \n",
        "would not happen if we manually set up an `InversionPlotter` as we did in previous tutorials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion_plotter = fit_plotter.inversion_plotter_of_plane(plane_index=1)\n",
        "inversion_plotter.figures_2d_of_pixelization(\n",
        "    pixelization_index=0, regularization_weights=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, all pixels are regularized with our input regularization_coefficient value of 3.6.\n",
        "\n",
        "This is not the best approach to regularizing the source. In fact, different regions of the source prefer different \n",
        "levels of regularization:\n",
        "\n",
        " 1) In the source's central regions its flux gradient is steepest; the change in flux between two source pixels is \n",
        " much larger than in the exterior regions where the gradient is flatter (or there is no source flux at all). To \n",
        " reconstruct the detailed structure of the source's cuspy inner regions, the regularization coefficient needs to \n",
        " be much lower to avoid over-smoothing.\n",
        "\n",
        " 2) On the other hand, the source reconstruction wants to assume a high regularization coefficient further out \n",
        " because the source's flux gradient is flat (or there is no source signal at all). Higher regularization coefficients \n",
        " will increase the Bayesian evidence because by smoothing more source-pixels it makes the solution `simpler`, given \n",
        " that correlating the flux in these source pixels the solution effectively uses fewer source-pixels (e.g. degrees of \n",
        " freedom).\n",
        "\n",
        "This outlines the problem using a constant regularization scheme. Some parts of the reconstructed source demand a \n",
        "low regularization coefficient whereas other parts want a high value. \n",
        "\n",
        "By using a single regularization coefficient, we infer an intermediate regularization coefficient that over-smooths \n",
        "the source's central regions whilst failing to fully correlate exterior pixels. \n",
        "\n",
        "An adaptive regularization scheme, where the regularization coefficient varies from the outskirts to the centrel \n",
        "regions, will produce solutions that further increase the Bayesian evidence.\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "We have motivated an even more adaptive pixelization, where the mesh and regularization scheme adapt to the source's \n",
        "unlensed morphology. \n",
        "\n",
        "The next two tutorials will show **PyAutoLens**'s adapt-model which enables this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}