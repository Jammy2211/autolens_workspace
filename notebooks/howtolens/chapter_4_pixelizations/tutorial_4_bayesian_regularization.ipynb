{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial 4: Bayesian Regularization\n",
        "===================================\n",
        "\n",
        "So far, we have:\n",
        "\n",
        " - Used pixelizations and mappers to map source-pixels to image-pixels and visa versa.\n",
        " - Successfully used an inversion to reconstruct a source.\n",
        " - Seen that this reconstruction provides a good fit of the observed image, providing a high likelihood solution.\n",
        "\n",
        "The explanation of *how* an inversion works has so far been overly simplified. You'll have noted the regularization\n",
        "inputs which we have not so far discussed. This will be the topic of this tutorial, and where inversions become more\n",
        "conceptually challenging!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initial Setup__\n",
        "\n",
        "we'll use the same strong lensing data as the previous tutorial, where:\n",
        "\n",
        " - The lens galaxy's light is omitted.\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's light is an `Sersic`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Convenience Function__\n",
        "\n",
        "we're going to perform a lot of fits using an `Inversion` this tutorial. This would create a lot of code, so to keep \n",
        "things tidy, I've setup this function which handles it all for us.\n",
        "\n",
        "(You may notice we include an option to `use_pixelization_border, ignore this for now, as we'll be covering borders in \n",
        "the next tutorial)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "def perform_fit_with_source_galaxy(dataset, source_galaxy):\n",
        "    mask = al.Mask2D.circular_annular(\n",
        "        shape_native=dataset.shape_native,\n",
        "        pixel_scales=dataset.pixel_scales,\n",
        "        inner_radius=0.3,\n",
        "        outer_radius=2.6,\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "    lens_galaxy = al.Galaxy(\n",
        "        redshift=0.5,\n",
        "        mass=al.mp.Isothermal(\n",
        "            centre=(0.0, 0.0),\n",
        "            einstein_radius=1.6,\n",
        "            ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "        ),\n",
        "        shear=al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05),\n",
        "    )\n",
        "\n",
        "    tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "    return al.FitImaging(dataset=dataset, tracer=tracer)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixelization__\n",
        "\n",
        "Okay, so lets look at our fit from the previous tutorial in more detail. we'll use a higher resolution 40 x 40 grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    mesh=al.mesh.Rectangular(shape=(40, 40)),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "fit = perform_fit_with_source_galaxy(dataset=dataset, source_galaxy=source_galaxy)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Regularization__\n",
        "\n",
        "The source reconstruction looks excellent! \n",
        "\n",
        "However, the high quality of this solution was possible because I chose a `coefficient` for the regularization input of\n",
        "1.0. If we reduce this `coefficient` to zero, the source reconstruction goes *very* weird."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    mesh=al.mesh.Rectangular(shape=(40, 40)),\n",
        "    regularization=al.reg.Constant(coefficient=0.0),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "no_regularization_fit = perform_fit_with_source_galaxy(\n",
        "    dataset=dataset, source_galaxy=source_galaxy\n",
        ")\n",
        "\n",
        "include = aplt.Include2D(mask=True)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=no_regularization_fit, include_2d=include)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So, what is happening here? Why does reducing the `coefficient` do this to our source reconstruction? First, we need\n",
        "to understand what regularization actually does!\n",
        "\n",
        "When the inversion reconstructs the source, it does not *only* compute the set of source-pixel fluxes that best-fit \n",
        "the image. It also regularizes this solution, whereby it goes to every pixel on the rectangular source-plane grid \n",
        "and computes the different between the reconstructed flux values of every source pixel with its 4 neighboring pixels. \n",
        "If the difference in flux is large the solution is penalized, reducing its log likelihood. You can think of this as \n",
        "us applying a 'smoothness prior' on the reconstructed source galaxy's light.\n",
        "\n",
        "This smoothing adds a 'penalty term' to the log likelihood of an inversion which is the summed difference between the \n",
        "reconstructed fluxes of every source-pixel pair multiplied by the `coefficient`. By setting the regularization \n",
        "coefficient to zero, we set this penalty term to zero, meaning that regularization is completely omitted.\n",
        "\n",
        "Why do we need to regularize our solution? We just saw why, if we do not apply this smoothness prior to the source, we \n",
        "`over-fit` the image and reconstruct a noisy source with lots of extraneous features. This is what the  large flux \n",
        "values located at the exterior regions of the source reconstruction above are. If the inversions's sole aim is to \n",
        "maximize the log likelihood, it can do this by fitting *everything* accurately, including the noise.\n",
        "\n",
        "If we change the `vmax` and `vmin` variables of the `Plotter`'s `CMap` such that the color-map is restricted to a \n",
        "narrower range of values, we can see that even without regularization we are still reconstructing the actual source \n",
        "galaxy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mat_plot = aplt.MatPlot2D(cmap=aplt.Cmap(vmax=0.5, vmin=-0.5))\n",
        "\n",
        "inversion_plotter = aplt.InversionPlotter(\n",
        "    inversion=no_regularization_fit.inversion, mat_plot_2d=mat_plot\n",
        ")\n",
        "inversion_plotter.figures_2d_of_pixelization(pixelization_index=0, reconstruction=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Over-fitting is why regularization is necessary. Solutions like this will completely ruin our attempts to model a \n",
        "strong lens. By smoothing our source reconstruction we ensure it does not over fit noise in the image. \n",
        "\n",
        "So, what happens if we apply a high value for the regularization coefficient?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    mesh=al.mesh.Rectangular(shape=(40, 40)),\n",
        "    regularization=al.reg.Constant(coefficient=100.0),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "high_regularization_fit = perform_fit_with_source_galaxy(\n",
        "    dataset=dataset, source_galaxy=source_galaxy\n",
        ")\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=high_regularization_fit, include_2d=include)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "inversion_plotter = aplt.InversionPlotter(\n",
        "    inversion=high_regularization_fit.inversion, mat_plot_2d=mat_plot\n",
        ")\n",
        "inversion_plotter.figures_2d_of_pixelization(pixelization_index=0, reconstruction=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The figure above shows that we completely remove over-fitting. However, we now fit the image data less accurately,\n",
        "due to the much higher level of smoothing.\n",
        "\n",
        "So, we now understand what regularization is and why it is necessary. There is one nagging question that remains, how \n",
        "do I choose the regularization coefficient value? We can not use the log likelihood, as decreasing the regularization\n",
        "coefficient will always increase the log likelihood, because less smoothing allows the source reconstruction to fit \n",
        "the data better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Likelihood Without Regularization:\")\n",
        "print(no_regularization_fit.log_likelihood_with_regularization)\n",
        "print(\"Likelihood With Normal Regularization:\")\n",
        "print(fit.log_likelihood_with_regularization)\n",
        "print(\"Likelihood With High Regularization:\")\n",
        "print(high_regularization_fit.log_likelihood_with_regularization)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Bayesian Evidence__\n",
        "\n",
        "For inversions, we therefore need a different goodness-of-fit measure to choose the appropriate level of regularization. \n",
        "\n",
        "For this, we invoke the `Bayesian Evidence`, which quantifies the goodness of the fit as follows:\n",
        "\n",
        " - It requires that the residuals of the fit are consistent with Gaussian noise (which is the type of noise expected \n",
        " in the imaging data). If this Gaussian pattern is not visible in the residuals, the noise must have been over-fitted\n",
        " by the inversion. The Bayesian evidence will therefore decrease. If the image is fitted poorly due to over smoothing, \n",
        " the residuals will again not appear Gaussian either, again producing a decrease in the Bayesian evidence value.\n",
        "\n",
        " - There can be many solutions which fit the data to the noise level, without over-fitting. To determine the best \n",
        " solutions from these solutions, the Bayesian evidence therefore also quantifies the complexity of the source \n",
        " reconstruction. If an inversion requires many pixels and a low level of regularization to achieve a good fit, the \n",
        " Bayesian  evidence will decrease. The evidence penalizes solutions which are complex, which, in a Bayesian sense, are \n",
        " less probable (you may want to look up `Occam`s Razor`).\n",
        "\n",
        "The Bayesian evidence therefore ensures we only invoke a more complex source reconstruction when the data absolutely \n",
        "necessitates it.\n",
        "\n",
        "Lets take a look at the Bayesian evidence of the fits that we performed above, which is accessible from a `FitImaging` \n",
        "object via the `log_evidence` property:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Bayesian Evidence Without Regularization:\")\n",
        "print(no_regularization_fit.log_evidence)\n",
        "print(\"Bayesian Evidence With Normal Regularization:\")\n",
        "print(fit.log_evidence)\n",
        "print(\"Bayesian Evidence With High Regularization:\")\n",
        "print(high_regularization_fit.log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the solution that we could see `by-eye` was the best solution corresponds to the highest log evidence \n",
        "solution.\n",
        "\n",
        "__Non-Linear and Linear__\n",
        "\n",
        "Before we end, lets consider which aspects of an inversion are linear and which are non-linear.\n",
        "\n",
        "The linear part of the inversion is the step that solves for the reconstruct source pixel fluxes, including accounting\n",
        "for the smoothing via regularizaton. We do not have to perform a non-linear search to determine the source-pixel\n",
        "fluxes or compute the Bayesian evidence discussed above.\n",
        "\n",
        "However, determining the regularization `coefficient` that maximizes the Bayesian log evidence is a non-linear problem \n",
        "that requires a non-linear search. The Bayesian evidence also depends on the source grid resolution, which means the \n",
        "pixel-grid's `shape` parameter may also now become dimensions of non linear parameter space. Nevertheless, these total \n",
        "only 3 non-linear parameters, far fewer than the 20+ that are required when modeling sources uses light profiles! \n",
        "\n",
        "Here are a few questions for you to think about.\n",
        "\n",
        " 1) We maximize the log evidence by using simpler source reconstructions. Therefore, decreasing the pixel-grid \n",
        " size should provide a higher log_evidence, provided it still has sufficiently high resolution to fit the image well \n",
        " (and provided that the regularization coefficient is set to an appropriate value). Can you increase the log evidence \n",
        " from the value above by changing these parameters, I've set you up with a code to do so below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    mesh=al.mesh.Rectangular(shape=(40, 40)),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "fit = perform_fit_with_source_galaxy(dataset=dataset, source_galaxy=source_galaxy)\n",
        "\n",
        "print(\"Previous Bayesian Evidence:\")\n",
        "print(3988.0716851250163)\n",
        "print(\"New Bayesian Evidence:\")\n",
        "print(fit.log_evidence)\n",
        "\n",
        "include = aplt.Include2D(mask=True)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit, include_2d=include)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " 2) Can you think of any other ways we might increase the Bayesian evidence even further? In future tutorials we will \n",
        " learn how **PyAutoLens** can adapts the source reconstructions to the properties of the image so as to maximize the \n",
        " Bayesian evidence!\n",
        " \n",
        "__Detailed Description__\n",
        "\n",
        "Below, I provide a more detailed discussion of the Bayesian evidence. It is not paramount that you understand this to\n",
        "use **PyAutoLens**, but I recommend you give it a read to get an intuition for how the evidence works.\n",
        "\n",
        "The Bayesian log evidence quantifies the following 3 aspects of a fit to strong lens imaging data:\n",
        "\n",
        "1) *The quality of the image reconstruction:*  The source reconstruction is a linear inversion which uses the observed\n",
        " values in the image-data to fit it and reconstruct the source. It is in principle able to perfectly reconstruct the\n",
        " image regardless of the image\u2019s noise or the accuracy of the lens model (e.g. at infinite source resolution without\n",
        " regularization). The problem is therefore \u2018ill-posed\u2019 and this is why regularization is necessary.\n",
        "\n",
        " However, this raises the question of what constitutes a \u2018good\u2019 solution? The Bayesian evidence defines this by\n",
        " assuming that the image data consists of independent Gaussian noise in every image pixel. A \u2018good\u2019 solution is one\n",
        " whose chi-squared residuals are consistent with Gaussian noise, producing a reduced chi-squared near 1.0 .Solutions\n",
        " which give a reduced chi squared below 1 are penalized for being overly complex and fitting the image\u2019s noise, whereas\n",
        " solutions with a reduced chi-squared above are penalized for not invoking a more complex source model when the data it\n",
        " is necessary to fit the data bettter. In both circumstances, these penalties reduce the inferred Bayesian evidence!\n",
        "\n",
        "2) *The complexity of the source reconstruction:* The log evidence estimates the number of source pixels that are used \n",
        " to reconstruct the image, after accounting for their correlation with one another due to regularization. Solutions that\n",
        " require fewer correlated source pixels increase the Bayesian evidence. Thus, simpler and less complex source \n",
        " reconstructions are favoured.\n",
        "\n",
        "3) *The signal-to-noise (S/N) of the image that is fitted:* The Bayesian evidence favours models which fit higher S/N\n",
        " realizations of the observed data (where the S/N is determined using the image-pixel variances, e.g. the noise-map). Up \n",
        " to now, all **PyAutoLens** fits assumed fixed variances, meaning that this aspect of the Bayeisan evidence has no impact \n",
        " on the inferred evidence values. However, in hyper-mode we will invoke functionality that increases the variances \n",
        " of image-pixels where the lens model fits the data poorly.\n",
        "   \n",
        " The premise is that whilst increasing the variances of image pixels lowers their S/N values and therefore also\n",
        " decreases the log evidence, doing so may produce a net increase in log evidence. This occurs when the chi-squared \n",
        " values of the image pixels whose variances are increased were initially very high (e.g. they were fit poorly by the \n",
        " lens model).\n",
        "\n",
        "In summary, the log evidence is maximized for solutions which most accurately reconstruct the highest S/N realization of\n",
        "the observed image, without over-fitting its noise and using the fewest correlated source pixels. By employing this\n",
        "framework throughout, **PyAutoLens** objectively determines the final lens model following the principles of Bayesian\n",
        "analysis and Occam\u2019s Razor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}