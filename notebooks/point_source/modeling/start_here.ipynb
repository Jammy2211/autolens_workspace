{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling: Point-Source Mass Total\n",
        "=================================\n",
        "\n",
        "This script is the starting point for lens modeling of point-source lens datasets (E.g. the multiple image positions\n",
        "of a lensed quasar) with **PyAutoLens** and it provides an overview of the lens modeling API.\n",
        "\n",
        "After reading this script, the `features`, `customize` and `searches` folders provide example for performing lens\n",
        "modeling in different ways and customizing the analysis.\n",
        "\n",
        "__Not Using Light Profiles__\n",
        "\n",
        "Users familiar with PyAutoLens who are familiar with analysing imaging data will be surprised to see that point-source\n",
        "based mass modeling does not use light profiles at all. That is, the source galaxy's light is never modeled as a light\n",
        "profile (e.g. a `Sersic`) and it would never be appropriate to use a pixelized source reconstruction.\n",
        "\n",
        "The reason for this is because the source is, as the name suggest, a point-source of light. It is not extended in\n",
        "any way, meaning that modeling it as a light profile would be an incorrect assumption.\n",
        "\n",
        "If this is a surprise to you or unclear, I recommend you read through the overview example\n",
        "`autolens_workspace/*/overview/overview_8_point_sources.py` before continuing. This example explains how point-source\n",
        "modeling differs from imaging data and why it is a completely different approach.\n",
        "\n",
        "__Source Plane Chi Squared__\n",
        "\n",
        "This example performs point-source modeling using a source-plane chi-squared. This means the likelihood of a model\n",
        "is evaluated based on how close the multiple image positions it predicts trace to the centre of the point source\n",
        "in the source-plane.\n",
        "\n",
        "This is often regard as a less robust way to perform point-source modeling than an image-plane chi-squared, and it\n",
        "means that other information about the multiple images of the point source (e.g. their fluxes) cannot be used. On\n",
        "the plus side, it is much faster to perform modeling using a source-plane chi-squared.\n",
        "\n",
        "Visualization of point-source modeling results are also limited, as the feature is still in development.\n",
        "\n",
        "__Image Plane Chi Squared (In Development)__\n",
        "\n",
        "An image-plane chi-squared is also available, however it is an in development feature with limitations. The main\n",
        "limitation is that the solver for the image-plane positions of a point-source in the source-plane is not robust. It\n",
        "often infers incorrect additional multiple image positions or fails to locate the correct ones.\n",
        "\n",
        "This is because I made the foolish decision to try and locate the positions by ray-tracing squares surrounding the\n",
        "image-plane positions to the source-plane and using a nearest neighbor based approach based on the Euclidean distance.\n",
        "This contrasts standard implementations elsewhere in the literature, which use a more robust approach based on ray\n",
        "tracing triangles to the source-plane and using whether the source-plane position lands within each triangle.\n",
        "\n",
        "This will one day be fixed, but we have so far not found time to do so.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits a `PointDict` data of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal`.\n",
        " - The source `Galaxy` is a point source `PointSourceChi`.\n",
        "\n",
        "The `ExternalShear` is also not included in the mass model, where it is for the `imaging` and `interferometer` examples.\n",
        "For a quadruply imaged point source (8 data points) there is insufficient information to fully constain a model with\n",
        "an `Isothermal` and `ExternalShear` (9 parameters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load the strong lens dataset `simple`, which is the dataset we will use to perform lens modeling.\n",
        "\n",
        "We begin by loading an image of the dataset. Although we are performing point-source modeling and will not use this\n",
        "data in the model-fit, it is useful to load it for visualization. By passing this dataset to the model-fit at the\n",
        "end of the script it will be used when visualizing the results. However, the use of an image in this way is entirely\n",
        "optional, and if it were not included in the model-fit visualization would simple be performed using grids without\n",
        "the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"point_source\", dataset_name)\n",
        "\n",
        "data = al.Array2D.from_fits(\n",
        "    file_path=path.join(dataset_path, \"data.fits\"), pixel_scales=0.05\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now load the point source dataset we will fit using point source modeling. We load this data as a `PointDict`,\n",
        "which is a Python dictionary containing the positions and fluxes of every point source. \n",
        "\n",
        "In this example there is just one point source, but point source model can be applied to datasets with any number \n",
        "of source's."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "point_dict = al.PointDict.from_json(\n",
        "    file_path=path.join(dataset_path, \"point_dict.json\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can print this dictionary to see the `name`, `positions` and `fluxes` of the dataset, as well as their noise-map values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Point Source Dict:\")\n",
        "print(point_dict)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also just plot the positions and fluxes of the `PointDict`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "point_dict_plotter = aplt.PointDictPlotter(point_dict=point_dict)\n",
        "point_dict_plotter.subplot_positions()\n",
        "point_dict_plotter.subplot_fluxes()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot our positions dataset over the observed image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(positions=point_dict.positions_list)\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data, visuals_2d=visuals)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose a lens model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` [5 parameters].\n",
        " - The source galaxy's light is a point `PointSourceChi` [2 parameters].\n",
        "\n",
        "The `PointSourceChi` model component indiciates that the chi-squared value of the point source is evaluated in the\n",
        "source-plane. By changing this component to a `Point`, the chi-squared value would instead be evaluated in the\n",
        "image-plane (this feature is in development and currently does not work well, as discussed at the top of this \n",
        "example script).\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=7.\n",
        "\n",
        "__Name Pairing__\n",
        "\n",
        "Every point-source dataset in the `PointDict` has a name, which in this example was `point_0`. This `name` pairs \n",
        "the dataset to the `Point` in the model below. Because the name of the dataset is `point_0`, the \n",
        "only `Point` object that is used to fit it must have the name `point_0`.\n",
        "\n",
        "If there is no point-source in the model that has the same name as a `PointDataset`, that data is not used in\n",
        "the model-fit. If a point-source is included in the model whose name has no corresponding entry in \n",
        "the `PointDataset` **PyAutoLens** will raise an error.\n",
        "\n",
        "In this example, where there is just one source, name pairing appears unecessary. However, point-source datasets may\n",
        "have many source galaxies in them, and name pairing is necessary to ensure every point source in the lens model is \n",
        "fitted to its particular lensed images in the `PointDict`!\n",
        "**PyAutoLens** assumes that the lens galaxy centre is near the coordinates (0.0\", 0.0\"). \n",
        "\n",
        "If for your dataset the  lens is not centred at (0.0\", 0.0\"), we recommend that you either: \n",
        "\n",
        " - Reduce your data so that the centre is (`autolens_workspace/*/data_preparation`). \n",
        " - Manually override the lens model priors (`autolens_workspace/*/imaging/modeling/customize/priors.py`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=al.mp.Isothermal)\n",
        "\n",
        "# Source:\n",
        "\n",
        "point_0 = af.Model(al.ps.PointSourceChi)\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, point_0=point_0)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format.\n",
        "\n",
        "[The `info` below may not display optimally on your computer screen, for example the whitespace between parameter\n",
        "names on the left and parameter priors on the right may lead them to appear across multiple lines. This is a\n",
        "common issue in Jupyter notebooks.\n",
        "\n",
        "The`info_whitespace_length` parameter in the file `config/general.yaml` in the [output] section can be changed to \n",
        "increase or decrease the amount of whitespace (The Jupyter notebook kernel will need to be reset for this change to \n",
        "appear in a notebook).]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Solver__\n",
        "\n",
        "For point-source modeling we also need to define our `PointSolver`. This object determines the multiple-images of \n",
        "a mass model for a point source at location (y,x) in the source plane, by iteratively ray-tracing light rays to the \n",
        "source-plane. \n",
        "\n",
        "[For a source-plane chi-squared, we actually do not need to use a `PointSolver` at all, as its only purpose is to\n",
        "find the multiple-images of a source in the image-plane.\n",
        "\n",
        "Nevertheless, if you are feeling bold enough to try and use the current imaege-plage chi-squared feature, go ahead\n",
        "and use the `PointSolver` below.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(shape_native=data.shape_native, pixel_scales=data.pixel_scales)\n",
        "\n",
        "point_solver = al.PointSolver(grid=grid, pixel_scale_precision=0.025)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The lens model is fitted to the data using a non-linear search. \n",
        "\n",
        "All examples in the autolens workspace use the nested sampling algorithm \n",
        "Nautilus (https://nautilus-sampler.readthedocs.io/en/latest/), which extensive testing has revealed gives the most accurate\n",
        "and efficient  modeling results.\n",
        "\n",
        "We make the following changes to the Nautilus settings:\n",
        "\n",
        " - Increase the number of live points, `n_live`, from the default value of 50 to 100. \n",
        "\n",
        "These are the two main Nautilus parameters that trade-off slower run time for a more reliable and accurate fit.\n",
        "Increasing both of these parameter produces a more reliable fit at the expense of longer run-times.\n",
        "\n",
        "__Customization__\n",
        "\n",
        "The folders `autolens_workspace/*/point_source/modeling/searches` gives an overview of alternative non-linear searches,\n",
        "other than Nautilus, that can be used to fit lens models. They also provide details on how to customize the\n",
        "model-fit, for example the priors.\n",
        "\n",
        "The `name` and `path_prefix` below specify the path where results ae stored in the output folder:  \n",
        "\n",
        " `/autolens_workspace/output/point_source/modeling/simple/mass[sie]_source[point]/unique_identifier`.\n",
        "\n",
        "__Unique Identifier__\n",
        "\n",
        "In the path above, the `unique_identifier` appears as a collection of characters, where this identifier is generated \n",
        "based on the model, search and dataset that are used in the fit.\n",
        " \n",
        "An identical combination of model and search generates the same identifier, meaning that rerunning the script will use \n",
        "the existing results to resume the model-fit. In contrast, if you change the model or search, a new unique identifier \n",
        "will be generated, ensuring that the model-fit results are output into a separate folder.\n",
        "\n",
        "We additionally want the unique identifier to be specific to the dataset fitted, so that if we fit different datasets\n",
        "with the same model and search results are output to a different folder. We achieve this below by passing \n",
        "the `dataset_name` to the search's `unique_tag`.\n",
        "\n",
        "__Number Of Cores__\n",
        "\n",
        "We include an input `number_of_cores`, which when above 1 means that Nautilus uses parallel processing to sample multiple \n",
        "lens models at once on your CPU. When `number_of_cores=2` the search will run roughly two times as\n",
        "fast, for `number_of_cores=3` three times as fast, and so on. The downside is more cores on your CPU will be in-use\n",
        "which may hurt the general performance of your computer.\n",
        "\n",
        "You should experiment to figure out the highest value which does not give a noticeable loss in performance of your \n",
        "computer. If you know that your processor is a quad-core processor you should be able to use `number_of_cores=4`. \n",
        "\n",
        "Above `number_of_cores=4` the speed-up from parallelization diminishes greatly. We therefore recommend you do not\n",
        "use a value above this.\n",
        "\n",
        "For users on a Windows Operating system, using `number_of_cores>1` may lead to an error, in which case it should be \n",
        "reduced back to 1 to fix it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"point_source\"),\n",
        "    name=\"mass[sie]_source[point]\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=150,\n",
        "    number_of_cores=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "The `AnalysisPoint` object defines the `log_likelihood_function` used by the non-linear search to fit the model \n",
        "to the `PointDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisPoint(point_dict=point_dict, solver=None)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Times__\n",
        "\n",
        "Lens modeling can be a computationally expensive process. When fitting complex models to high resolution datasets \n",
        "run times can be of order hours, days, weeks or even months.\n",
        "\n",
        "Run times are dictated by two factors:\n",
        "\n",
        " - The log likelihood evaluation time: the time it takes for a single `instance` of the lens model to be fitted to \n",
        "   the dataset such that a log likelihood is returned.\n",
        "\n",
        " - The number of iterations (e.g. log likelihood evaluations) performed by the non-linear search: more complex lens\n",
        "   models require more iterations to converge to a solution.\n",
        "\n",
        "The log likelihood evaluation time can be estimated before a fit using the `profile_log_likelihood_function` method,\n",
        "which returns two dictionaries containing the run-times and information about the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The overall log likelihood evaluation time is given by the `fit_time` key.\n",
        "\n",
        "For this example, it is ~0.001 seconds, which is extremely fast for lens modeling. The source-plane chi-squared\n",
        "is possibly the fastest way to fit a lens model to a dataset, and therefore whilst it has limitations it is a good\n",
        "way to get a rough estimate of the lens model parameters quickly.\n",
        "\n",
        "Feel free to go ahead a print the full `run_time_dict` and `info_dict` to see the other information they contain. The\n",
        "former has a break-down of the run-time of every individual function call in the log likelihood function, whereas the \n",
        "latter stores information about the data which drives the run-time (e.g. number of image-pixels in the mask, the\n",
        "shape of the PSF, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To estimate the expected overall run time of the model-fit we multiply the log likelihood evaluation time by an \n",
        "estimate of the number of iterations the non-linear search will perform. \n",
        "\n",
        "Estimating this quantity is more tricky, as it varies depending on the lens model complexity (e.g. number of parameters)\n",
        "and the properties of the dataset and model being fitted.\n",
        "\n",
        "For this example, we conservatively estimate that the non-linear search will perform ~10000 iterations per free \n",
        "parameter in the model. This is an upper limit, with models typically converging in far fewer iterations.\n",
        "\n",
        "If you perform the fit over multiple CPUs, you can divide the run time by the number of cores to get an estimate of\n",
        "the time it will take to fit the model. Parallelization with Nautilus scales well, it speeds up the model-fit by the \n",
        "`number_of_cores` for N < 8 CPUs and roughly `0.5*number_of_cores` for N > 8 CPUs. This scaling continues \n",
        "for N> 50 CPUs, meaning that with super computing facilities you can always achieve fast run times!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output Folder__\n",
        "\n",
        "Now this is running you should checkout the `autolens_workspace/output` folder. This is where the results of the \n",
        "search are written to hard-disk (in the `start_here` folder), where all outputs are human readable (e.g. as .json,\n",
        ".csv or text files).\n",
        "\n",
        "As the fit progresses, results are written to the `output` folder on the fly using the highest likelihood model found\n",
        "by the non-linear search so far. This means you can inspect the results of the model-fit as it runs, without having to\n",
        "wait for the non-linear search to terminate.\n",
        " \n",
        "The `output` folder includes:\n",
        "\n",
        " - `model.info`: Summarizes the lens model, its parameters and their priors discussed in the next tutorial.\n",
        " \n",
        " - `model.results`: Summarizes the highest likelihood lens model inferred so far including errors.\n",
        " \n",
        " - `images`: Visualization of the highest likelihood model-fit to the dataset, (e.g. a fit subplot showing the lens \n",
        " and source galaxies, model data and residuals).\n",
        " \n",
        " - `files`: A folder containing .fits files of the dataset, the model as a human-readable .json file, \n",
        " a `.csv` table of every non-linear search sample and other files containing information about the model-fit.\n",
        " \n",
        " - search.summary: A file providing summary statistics on the performance of the non-linear search.\n",
        " \n",
        " - `search_internal`: Internal files of the non-linear search (in this case Nautilus) used for resuming the fit and\n",
        "  visualizing the search.\n",
        "\n",
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format.\n",
        "\n",
        "[Above, we discussed that the `info_whitespace_length` parameter in the config files could b changed to make \n",
        "the `model.info` attribute display optimally on your computer. This attribute also controls the whitespace of the\n",
        "`result.info` attribute.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the maximum likelihood fit, tracer images and posteriors inferred via Nautilus.\n",
        "\n",
        "Checkout `autolens_workspace/*/imaging/results` for a full description of analysing results in **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=result.grid\n",
        ")\n",
        "tracer_plotter.subplot_tracer()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result contains the full posterior information of our non-linear search, including all parameter samples, \n",
        "log likelihood values and tools to compute the errors on the lens model. \n",
        "\n",
        "There are built in visualization tools for plotting this.\n",
        "\n",
        "The plot is labeled with short hand parameter names (e.g. `sersic_index` is mapped to the short hand \n",
        "parameter `n`). These mappings ate specified in the `config/notation.yaml` file and can be customized by users.\n",
        "\n",
        "The superscripts of labels correspond to the name each component was given in the model (e.g. for the `Isothermal`\n",
        "mass its name `mass` defined when making the `Model` above is used)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plotter = aplt.NestPlotter(samples=result.samples)\n",
        "plotter.cornerplot()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autolens_workspace/*/imaging/results` for a full description of analysing results in **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}