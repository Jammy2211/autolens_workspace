{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulator: Point Source\n",
        "=======================\n",
        "\n",
        "This script simulates `PointDataset` data of a strong lens where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal`.\n",
        " - The source `Galaxy` is a `Point`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import numpy as np\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset Paths__\n",
        "\n",
        "The `dataset_type` describes the type of data being simulated (in this case, `PointDataset` data) and `dataset_name` \n",
        "gives it a descriptive name. They define the folder the dataset is output to on your hard-disk:\n",
        "\n",
        " - The image will be output to `/autolens_workspace/dataset/dataset_type/dataset_name/positions.json`.\n",
        " - The noise-map will be output to `/autolens_workspace/dataset/dataset_type/dataset_name/noise_map.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"point_source\"\n",
        "dataset_name = \"simple\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The path where the dataset will be output, which in this case is:\n",
        "`/autolens_workspace/dataset/positions/simple`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", dataset_type, dataset_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Ray Tracing__\n",
        "\n",
        "Setup the lens galaxy's mass (SIE) and source galaxy `Point` for this simulated lens. We include a \n",
        "faint dist in the source for purely visualization purposes to show where the multiple images appear.\n",
        "\n",
        "For lens modeling, defining ellipticity in terms of the `ell_comps` improves the model-fitting procedure.\n",
        "\n",
        "However, for simulating a strong lens you may find it more intuitive to define the elliptical geometry using the \n",
        "axis-ratio of the profile (axis_ratio = semi-major axis / semi-minor axis = b/a) and position angle, where angle is\n",
        "in degrees and defined counter clockwise from the positive x-axis.\n",
        "\n",
        "We can use the **PyAutoLens** `convert` module to determine the elliptical components from the axis-ratio and angle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.0, 0.0),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    light=al.lp.Exponential(centre=(0.0, 0.0), intensity=0.1, effective_radius=0.02),\n",
        "    point_0=al.ps.Point(centre=(0.0, 0.0)),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use these galaxies to setup a tracer, which will compute the multiple image positions of the simulated dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use a `PositionSolver` to locate the multiple images. \n",
        "\n",
        "We will use computationally slow but robust settings to ensure we accurately locate the image-plane positions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(100, 100),\n",
        "    pixel_scales=0.05,  # <- The pixel-scale describes the conversion from pixel units to arc-seconds.\n",
        ")\n",
        "\n",
        "solver = al.PointSolver(\n",
        "    grid=grid, use_upscaling=True, pixel_scale_precision=0.001, upscale_factor=2\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now pass the `Tracer` to the solver. This will then find the image-plane coordinates that map directly to the\n",
        "source-plane coordinate (0.0\", 0.0\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = solver.solve(\n",
        "    lensing_obj=tracer, source_plane_coordinate=source_galaxy.point_0.centre\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the positions to compute the magnification of the `Tracer` at every position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "magnifications = tracer.magnification_2d_via_hessian_from(grid=positions)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now compute the observed fluxes of the `Point`, give we know how much each is magnified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "flux = 1.0\n",
        "fluxes = [flux * np.abs(magnification) for magnification in magnifications]\n",
        "fluxes = al.ArrayIrregular(values=fluxes)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output__\n",
        "\n",
        "We now output the image of this strong lens to `.fits` which can be used for visualize when performing point-source \n",
        "modeling and to `.png` for general inspection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(multiple_images=positions)\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid, visuals_2d=visuals)\n",
        "tracer_plotter.figures_2d(image=True)\n",
        "\n",
        "mat_plot = aplt.MatPlot2D(\n",
        "    output=aplt.Output(path=dataset_path, filename=\"data\", format=\"fits\")\n",
        ")\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid, mat_plot_2d=mat_plot)\n",
        "tracer_plotter.figures_2d(image=True)\n",
        "\n",
        "mat_plot = aplt.MatPlot2D(output=aplt.Output(path=dataset_path, format=\"png\"))\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid, mat_plot_2d=mat_plot)\n",
        "tracer_plotter.subplot_tracer()\n",
        "tracer_plotter.subplot_galaxies_images()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Datasets__\n",
        "\n",
        "Create a point-source dictionary data object and output this to a `.json` file, which is the format used to load and\n",
        "analyse the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "point_dataset = al.PointDataset(\n",
        "    name=\"point_0\",\n",
        "    positions=positions,\n",
        "    positions_noise_map=positions.values_via_value_from(value=grid.pixel_scale),\n",
        "    fluxes=fluxes,\n",
        "    fluxes_noise_map=al.ArrayIrregular(values=[1.0, 1.0, 1.0, 1.0]),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now convert this `PointDataset` into a `PointDict`, which is a dictionary containing the dataset. This is\n",
        "the object used in the `modeling` scripts to perform lens modeling.\n",
        "\n",
        "In this example there is only one `PointDataset`, making the `PointDict` somewhat redundant. However, in other examples \n",
        "multiple `PointDataset`'s are passed to the `PointDict` object. \n",
        "\n",
        "This means it can be used for the more general case where there are multiple source's observed in the strong lens\n",
        "system, which each have their own unique multiple images and therefore own unique `PointDataset`, which are all\n",
        "stored in the `PointDict`.\n",
        "\n",
        "For an example, see `autolens_workspace/notebooks/point_source/simulators/advanced/double_einstein_cross.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "point_dict = al.PointDict(point_dataset_list=[point_dataset])\n",
        "\n",
        "point_dict.output_to_json(\n",
        "    file_path=path.join(dataset_path, \"point_dict.json\"), overwrite=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Visualize__\n",
        "\n",
        "Output a subplot of the simulated point source dataset and the tracer's quantities to the dataset path as .png files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mat_plot_1d = aplt.MatPlot1D(output=aplt.Output(path=dataset_path, format=\"png\"))\n",
        "mat_plot_2d = aplt.MatPlot2D(output=aplt.Output(path=dataset_path, format=\"png\"))\n",
        "\n",
        "point_dataset_plotter = aplt.PointDatasetPlotter(\n",
        "    point_dataset=point_dataset, mat_plot_1d=mat_plot_1d, mat_plot_2d=mat_plot_2d\n",
        ")\n",
        "point_dataset_plotter.subplot_dataset()\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid, mat_plot_2d=mat_plot_2d)\n",
        "tracer_plotter.subplot_tracer()\n",
        "tracer_plotter.subplot_galaxies_images()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Tracer json__\n",
        "\n",
        "Save the `Tracer` in the dataset folder as a .json file, ensuring the true light profiles, mass profiles and galaxies\n",
        "are safely stored and available to check how the dataset was simulated in the future. \n",
        "\n",
        "This can be loaded via the method `tracer = al.from_json()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "al.output_to_json(\n",
        "    obj=tracer,\n",
        "    file_path=path.join(dataset_path, \"tracer.json\"),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}