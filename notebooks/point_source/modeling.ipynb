{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling: Start Here\n",
        "====================\n",
        "\n",
        "This script is the starting point for lens modeling of point-source lens datasets, for example the multiple image\n",
        "positions of a lensed quasar.\n",
        "\n",
        "__Not Using Light Profiles__\n",
        "\n",
        "Users who are familiar with analysing imaging or interferometer data will be used to\n",
        "performing lens modeling using light profiles, which have parameter that describe the shape and size of the\n",
        "galaxy's luminous emission.\n",
        "\n",
        "For point sources, for example a lensed quasar, it is invalid to model the source using light profiles, because they\n",
        "implicitly assume an extended surface brightness distribution. Point source modeling instead assumes the source\n",
        "has a (y,x) `centre` (y,x), but does not have other parameters like elliptical components or an effective radius.\n",
        "\n",
        "This changes how the ray-tracing calculations that go into point source modeling are performed. They are briefly\n",
        "touched on in this example, but for a more detailed explanation checkout the\n",
        "`autolens_workspace/*/overview/overview_8_point_sources.py` example.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits a `PointDataset` data of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal`.\n",
        " - The source `Galaxy` is a point source `Point`.\n",
        "\n",
        "The `ExternalShear` is also not included in the mass model, where it is for the `imaging` and `interferometer` examples.\n",
        "For a quadruply imaged point source (8 data points) there is insufficient information to fully constain a model with\n",
        "an `Isothermal` and `ExternalShear` (9 parameters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import jax.numpy as jnp\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load the strong lens point-source dataset `simple`, which is the dataset we will use to perform point source \n",
        "lens modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = Path(\"dataset\") / \"point_source\" / dataset_name"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now load the point source dataset we will fit using point source modeling. \n",
        "\n",
        "We load this data as a `PointDataset`, which contains the positions of every point source. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.from_json(\n",
        "    file_path=dataset_path / \"point_dataset_positions_only.json\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can print this dictionary to see the dataset's `name`, `positions`and noise-map values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Point Dataset Info:\")\n",
        "print(dataset.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the positions of the `PointDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.PointDatasetPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We next load an image of the dataset. \n",
        "\n",
        "Although we are performing point-source modeling and do not use this data in the actual modeling, it is useful to \n",
        "load it for visualization, for example to see where the multiple images of the point source are located relative to the \n",
        "lens galaxy.\n",
        "\n",
        "The image will also be passed to the analysis further down, meaning that visualization of the point-source model\n",
        "overlaid over the image will be output making interpretation of the results straight forward.\n",
        "\n",
        "Loading and inputting the image of the dataset in this way is entirely optional, and if you are only interested in\n",
        "performing point-source modeling you do not need to do this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = al.Array2D.from_fits(file_path=dataset_path / \"data.fits\", pixel_scales=0.05)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the dataset's multiple image positions over the observed image, to ensure they overlap the\n",
        "lensed source's multiple images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(positions=dataset.positions)\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data, visuals_2d=visuals)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Solver__\n",
        "\n",
        "For point-source modeling we require a `PointSolver`, which determines the multiple-images of the mass model for a \n",
        "point source at location (y,x) in the source plane. \n",
        "\n",
        "It does this by ray tracing triangles from the image-plane to the source-plane and calculating if the \n",
        "source-plane (y,x) centre is inside the triangle. The method gradually ray-traces smaller and smaller triangles so \n",
        "that the multiple images can be determine with sub-pixel precision.\n",
        "\n",
        "The `PointSolver` requires a starting grid of (y,x) coordinates in the image-plane which defines the first set\n",
        "of triangles that are ray-traced to the source-plane. It also requires that a `pixel_scale_precision` is input, \n",
        "which is the resolution up to which the multiple images are computed. The lower the `pixel_scale_precision`, the\n",
        "longer the calculation, with the value of 0.001 below balancing efficiency with precision.\n",
        "\n",
        "Strong lens mass models have a multiple image called the \"central image\". However, the image is nearly always \n",
        "significantly demagnified, meaning that it is not observed and cannot constrain the lens model. As this image is a\n",
        "valid multiple image, the `PointSolver` will locate it irrespective of whether its so demagnified it is not observed.\n",
        "To ensure this does not occur, we set a `magnification_threshold=0.1`, which discards this image because its\n",
        "magnification will be well below this threshold.\n",
        "\n",
        "If your dataset contains a central image that is observed you should reduce to include it in\n",
        "the analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(100, 100),\n",
        "    pixel_scales=0.2,  # <- The pixel-scale describes the conversion from pixel units to arc-seconds.\n",
        ")\n",
        "\n",
        "solver = al.PointSolver.for_grid(\n",
        "    grid=grid,\n",
        "    pixel_scale_precision=0.001,\n",
        "    magnification_threshold=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose a lens model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` [5 parameters].\n",
        " \n",
        " - The source galaxy's light is a point `Point` [2 parameters].\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=7.\n",
        "\n",
        "__Model Composition__\n",
        "\n",
        "The API below for composing a lens model uses the `Model` and `Collection` objects, which are imported from \n",
        "**PyAutoLens**'s parent project **PyAutoFit** \n",
        "\n",
        "The API is fairly self explanatory and is straight forward to extend, for example adding more light profiles\n",
        "to the lens and source or using a different mass profile.\n",
        "\n",
        "A full description of model composition is provided by the model cookbook: \n",
        "\n",
        "https://pyautolens.readthedocs.io/en/latest/general/model_cookbook.html\n",
        "\n",
        "__Name Pairing__\n",
        "\n",
        "Every point-source dataset in the `PointDataset` has a name, which in this example was `point_0`. This `name` pairs \n",
        "the dataset to the `Point` in the model below. Because the name of the dataset is `point_0`, the \n",
        "only `Point` object that is used to fit it must have the name `point_0`.\n",
        "\n",
        "If there is no point-source in the model that has the same name as a `PointDataset`, that data is not used in\n",
        "the model-fit. If a point-source is included in the model whose name has no corresponding entry in \n",
        "the `PointDataset` it will raise an error.\n",
        "\n",
        "In this example, where there is just one source, name pairing appears unnecessary. However, point-source datasets may\n",
        "have many source galaxies in them, and name pairing is necessary to ensure every point source in the lens model is \n",
        "fitted to its particular lensed images in the `PointDataset`.\n",
        "\n",
        "__Coordinates__\n",
        "\n",
        "The model fitting default settings assume that the lens galaxy centre is near the coordinates (0.0\", 0.0\"). \n",
        "\n",
        "If for your dataset the  lens is not centred at (0.0\", 0.0\"), we recommend that you either: \n",
        "\n",
        " - Reduce your data so that the centre is (`autolens_workspace/*/data_preparation`). \n",
        " - Manually override the lens model priors (`autolens_workspace/*/guides/modeling/customize`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=al.mp.Isothermal)\n",
        "\n",
        "# Source:\n",
        "\n",
        "point_0 = af.Model(al.ps.Point)\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, point_0=point_0)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format.\n",
        "\n",
        "[The `info` below may not display optimally on your computer screen, for example the whitespace between parameter\n",
        "names on the left and parameter priors on the right may lead them to appear across multiple lines. This is a\n",
        "common issue in Jupyter notebooks.\n",
        "\n",
        "The`info_whitespace_length` parameter in the file `config/general.yaml` in the [output] section can be changed to \n",
        "increase or decrease the amount of whitespace (The Jupyter notebook kernel will need to be reset for this change to \n",
        "appear in a notebook).]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The lens model is fitted to the data using a non-linear search. \n",
        "\n",
        "All examples in the autolens workspace use the nested sampling algorithm \n",
        "Nautilus (https://nautilus-sampler.readthedocs.io/en/latest/), which extensive testing has revealed gives the most \n",
        "accurate and efficient modeling results.\n",
        "\n",
        "Nautilus has one main setting that trades-off accuracy and computational run-time, the number of `live_points`. \n",
        "A higher number of live points gives a more accurate result, but increases the run-time. A lower value give \n",
        "less reliable lens modeling (e.g. the fit may infer a local maxima), but is faster. \n",
        "\n",
        "The suitable value depends on the model complexity whereby models with more parameters require more live points. \n",
        "The default value of 200 is sufficient for the vast majority of common lens models. Lower values often given reliable\n",
        "results though, and speed up the run-times. In this example, given the model is quite simple (N=21 parameters), we \n",
        "reduce the number of live points to 100 to speed up the run-time.\n",
        "\n",
        "__Unique Identifier__\n",
        "\n",
        "In the path above, the `unique_identifier` appears as a collection of characters, where this identifier is generated \n",
        "based on the model, search and dataset that are used in the fit.\n",
        " \n",
        "An identical combination of model and search generates the same identifier, meaning that rerunning the script will use \n",
        "the existing results to resume the model-fit. In contrast, if you change the model or search, a new unique identifier \n",
        "will be generated, ensuring that the model-fit results are output into a separate folder.\n",
        "\n",
        "We additionally want the unique identifier to be specific to the dataset fitted, so that if we fit different datasets\n",
        "with the same model and search results are output to a different folder. We achieve this below by passing \n",
        "the `dataset_name` to the search's `unique_tag`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"point_source\"),  # The path where results and output are stored.\n",
        "    name=\"modeling\",  # The name of the fit and folder results are output to.\n",
        "    unique_tag=dataset_name,  # A unique tag which also defines the folder.\n",
        "    n_live=100,  # The number of Nautilus \"live\" points, increase for more complex models.\n",
        "    n_batch=50,  # For fast GPU fitting lens model fits are batched and run simultaneously.\n",
        "    iterations_per_quick_update=10000,  # Every N iterations the max likelihood model, is visualized in the Jupter Notebook and output to hard-disk.\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Chi Squared__\n",
        "\n",
        "For point-source modeling, there are many different ways to define the likelihood function, broadly referred to a\n",
        "an `image-plane chi-squared` or `source-plane chi-squared`. This determines whether the multiple images of the point\n",
        "source are used to compute the likelihood in the source-plane or image-plane.\n",
        "\n",
        "We will use an \"image-plane chi-squared\", which uses the `PointSolver` to determine the multiple images of the point\n",
        "source in the image-plane for the given mass model and compares the positions of these model images to the observed\n",
        "images to compute the chi-squared and likelihood.\n",
        "\n",
        "There are still many different ways the image-plane chi-squared can be computed, for example do we allow for \n",
        "repeat image-pairs (i.e. the same multiple image being observed multiple times)? Do we pair all possible combinations\n",
        "of multiple images to observed images? This example uses the simplest approach, which is to pair each multiple image\n",
        "with the observed image that is closest to it, allowing for repeat image pairs. \n",
        "\n",
        "For a \"source-plane chi-squared\", the likelihood is computed in the source-plane. The analysis basically just ray-traces\n",
        "the multiple images back to the source-plane and defines a chi-squared metric. For example, the default implementation \n",
        "sums the Euclidean distance between the image positions and the point source centre in the source-plane.\n",
        "\n",
        "The source-plane chi-squared is significantly faster to compute than the image-plane chi-squared, as it requires \n",
        "only ray-tracing the ~4 observed image positions and does not require the iterative triangle ray-tracing approach\n",
        "of the image-plane chi-squared. However, the source-plane chi-squared is less robust than the image-plane chi-squared,\n",
        "and can lead to biased lens model results. If you are using the source-plane chi-squared, you should be aware of this\n",
        "and interpret the results with caution.\n",
        "\n",
        "Checkout the guide `autolens_workspace/*/guides/point_source.py` for more details and a full illustration of the\n",
        "different ways the chi-squared can be computed.\n",
        "\n",
        "__Analysis__\n",
        "\n",
        "We next create an `AnalysisPoint` object, which can be given many inputs customizing how the lens model is \n",
        "fitted to the data, which in this example includes the solver and the chi-squared method.\n",
        "\n",
        "Internally, this object defines the `log_likelihood_function` used by the non-linear search to fit the model to \n",
        "the `Imaging` dataset. \n",
        "\n",
        "It is not vital that you as a user understand the details of how the `log_likelihood_function` fits a lens model to \n",
        "data, but interested readers can find a step-by-step guide of the likelihood \n",
        "function at ``autolens_workspace/*/point_source/log_likelihood_function`\n",
        "\n",
        "__JAX__\n",
        "\n",
        "PyAutoLens uses JAX under the hood for fast GPU/CPU acceleration. If JAX is installed with GPU\n",
        "support, your fits will run much faster (around 10 minutes instead of an hour). If only a CPU is available,\n",
        "JAX will still provide a speed up via multithreading, with fits taking around 20-30 minutes.\n",
        "\n",
        "If you don\u2019t have a GPU locally, consider Google Colab which provides free GPUs, so your modeling runs are much faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Hacky way to use JAX PointSolver, fix soon\n",
        "\n",
        "solver_jax = al.PointSolver.for_grid(\n",
        "    grid=grid,\n",
        "    pixel_scale_precision=0.001,\n",
        "    magnification_threshold=0.1,\n",
        "    xp=jnp,\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisPoint(\n",
        "    dataset=dataset,\n",
        "    solver=solver_jax,\n",
        "    fit_positions_cls=al.FitPositionsImagePairRepeat,  # Image-plane chi-squared with repeat image pairs.\n",
        "    use_jax=True,  # JAX will use GPUs for acceleration if available, else JAX will use multithreaded CPUs.\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Times__\n",
        "\n",
        "Lens modeling can be a computationally expensive process. When fitting complex models to high resolution datasets \n",
        "run times can be of order hours, days, weeks or even months.\n",
        "\n",
        "Run times are dictated by two factors:\n",
        "\n",
        " - The log likelihood evaluation time: the time it takes for a single `instance` of the lens model to be fitted to \n",
        "   the dataset such that a log likelihood is returned.\n",
        " \n",
        " - The number of iterations (e.g. log likelihood evaluations) performed by the non-linear search: more complex lens\n",
        "   models require more iterations to converge to a solution.\n",
        "   \n",
        "For this analysis, the log likelihood evaluation time is < 0.001 seconds on GPU, ~0.01 seconds on CPU, which is \n",
        "extremely fast for lens modeling. \n",
        "\n",
        "To estimate the expected overall run time of the model-fit we multiply the log likelihood evaluation time by an \n",
        "estimate of the number of iterations the non-linear search will perform, which is around 10000 to 30000 for this model.\n",
        "\n",
        "GPU run times are around 10 minutes, CPU run times are around 30 minutes.\n",
        "\n",
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results).\n",
        "\n",
        "**Run Time Error:** On certain operating systems (e.g. Windows, Linux) and Python versions, the code below may produce \n",
        "an error. If this occurs, see the `autolens_workspace/guides/modeling/bug_fix` example for a fix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\n",
        "    \"\"\"\n",
        "    The non-linear search has begun running.\n",
        "\n",
        "    This Jupyter notebook cell with progress once the search has completed - this could take a few minutes!\n",
        "\n",
        "    On-the-fly updates every iterations_per_quick_update are printed to the notebook.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "print(\"The search has finished run - you may now continue the notebook.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output Folder__\n",
        "\n",
        "Now this is running you should checkout the `autolens_workspace/output` folder. This is where the results of the \n",
        "search are written to hard-disk (in the `start_here` folder), where all outputs are human readable (e.g. as .json,\n",
        ".csv or text files).\n",
        "\n",
        "As the fit progresses, results are written to the `output` folder on the fly using the highest likelihood model found\n",
        "by the non-linear search so far. This means you can inspect the results of the model-fit as it runs, without having to\n",
        "wait for the non-linear search to terminate.\n",
        " \n",
        "The `output` folder includes:\n",
        "\n",
        " - `model.info`: Summarizes the lens model, its parameters and their priors discussed in the next tutorial.\n",
        " \n",
        " - `model.results`: Summarizes the highest likelihood lens model inferred so far including errors.\n",
        " \n",
        " - `image`: Visualization of the highest likelihood model-fit to the dataset, (e.g. a fit subplot showing the lens \n",
        " and source galaxies, model data and residuals) in .png and .fits formats.\n",
        " \n",
        " - `files`: A folder containing human-readable .json file describing the model, search and other aspects of the fit and \n",
        "   a `.csv` table of every non-linear search sample.\n",
        " \n",
        " - search.summary: A file providing summary statistics on the performance of the non-linear search.\n",
        " \n",
        " - `search_internal`: Internal files of the non-linear search (in this case Nautilus) used for resuming the fit and\n",
        "  visualizing the search.\n",
        "\n",
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format.\n",
        "\n",
        "[Above, we discussed that the `info_whitespace_length` parameter in the config files could b changed to make \n",
        "the `model.info` attribute display optimally on your computer. This attribute also controls the whitespace of the\n",
        "`result.info` attribute.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the maximum likelihood fit, tracer images and posteriors inferred via Nautilus.\n",
        "\n",
        "Checkout `autolens_workspace/*/guides/results` for a full description of analysing results in **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=result.grid\n",
        ")\n",
        "tracer_plotter.subplot_tracer()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result contains the full posterior information of our non-linear search, including all parameter samples, \n",
        "log likelihood values and tools to compute the errors on the lens model. \n",
        "\n",
        "There are built in visualization tools for plotting this.\n",
        "\n",
        "The plot is labeled with short hand parameter names (e.g. `sersic_index` is mapped to the short hand \n",
        "parameter `n`). These mappings ate specified in the `config/notation.yaml` file and can be customized by users.\n",
        "\n",
        "The superscripts of labels correspond to the name each component was given in the model (e.g. for the `Isothermal`\n",
        "mass its name `mass` defined when making the `Model` above is used)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "plotter = aplt.NestPlotter(samples=result.samples)\n",
        "plotter.corner_anesthetic()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Results__\n",
        "\n",
        "Checkout `autolens_workspace/*/guides/results` for a full description of analysing results in **PyAutoLens**.\n",
        "\n",
        "__Modeling Customization__\n",
        "\n",
        "The folders `autolens_workspace/*/guides/modeling/searches` gives an overview of alternative non-linear searches,\n",
        "other than Nautilus, that can be used to fit lens models. \n",
        "\n",
        "They also provide details on how to customize the model-fit, for example the priors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}