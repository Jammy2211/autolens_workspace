{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling: Fluxes\n",
        "================\n",
        "\n",
        "A measurable quantity of a point source is its flux\u2014the total amount of light received from each multiple image\n",
        "of the point source (e.g., the quasar images).\n",
        "\n",
        "In practice, fluxes are often measured but not used directly when analyzing lensed point sources such as quasars or\n",
        "supernovae. This is because fluxes can be significantly affected by microlensing, which many lens models do not\n",
        "accurately capture. However, in this simulation, microlensing is not included, so the fluxes can be simulated and\n",
        "fitted reliably.\n",
        "\n",
        "Nevertheless, this script describes how to perform point source lens modeling using the fluxes of the point source\n",
        "dataset as additional information on top of the positions of the point source, in case you are studying microlensing\n",
        "or confident the fluxes are not affected by it.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits a `PointDataset` data of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal`.\n",
        " - The source `Galaxy` is a point source with flux, a `PointFlux`.\n",
        "\n",
        "The `ExternalShear` is also not included in the mass model, where it is for the `imaging` and `interferometer` examples.\n",
        "For a quadruply imaged point source (8 data points) there is insufficient information to fully constain a model with\n",
        "an `Isothermal` and `ExternalShear` (9 parameters).\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import jax.numpy as jnp\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load the strong lens point-source dataset `simple`, which is the dataset we will use to perform point source \n",
        "lens modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = Path(\"dataset\") / \"point_source\" / dataset_name"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now load the point source dataset we will fit using point source modeling. \n",
        "\n",
        "We load this data as a `PointDataset`, which contains the positions and fluxes of every point source. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.from_json(\n",
        "    file_path=dataset_path / \"point_dataset_with_fluxes.json\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can print this dictionary to see the dataset's `name`, `positions` and `fluxes` and noise-map values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Point Dataset Info:\")\n",
        "print(dataset.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the positions and fluxes of the `PointDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.PointDatasetPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We next load an image of the dataset and plot the point source data over it, because as described in \n",
        "the `modeling/start_here.ipynb` notebook, it is useful for visualizing the point source dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = al.Array2D.from_fits(file_path=dataset_path / \"data.fits\", pixel_scales=0.05)\n",
        "\n",
        "visuals = aplt.Visuals2D(positions=dataset.positions)\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data, visuals_2d=visuals)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Solver__\n",
        "\n",
        "We set up the `PointSolver`, which is used to compute the multiple images of the point source in the image-plane.\n",
        "\n",
        "There are no special settings or inputs for the fitting of fluxes, therefore the `PointSolver` is set up in the same way\n",
        "as in the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(100, 100),\n",
        "    pixel_scales=0.2,  # <- The pixel-scale describes the conversion from pixel units to arc-seconds.\n",
        ")\n",
        "\n",
        "solver = al.PointSolver.for_grid(\n",
        "    grid=grid, pixel_scale_precision=0.001, magnification_threshold=0.1, xp=jnp\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose a lens model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` [5 parameters].\n",
        " - The source galaxy's light is a point `PointFlux` [3 parameters].\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=8.\n",
        "\n",
        "Name pairing is used as before to pair the `PointDataset` to the `Point` in the model, which is discussed below.\n",
        "\n",
        "To fit fluxes, our model point source also needs a flux parameter, which is done by using the `PointFlux`\n",
        "component instead of the `Point` component. This has a free parameter `flux`, which is the flux of the point source\n",
        "in the source-plane. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=al.mp.Isothermal)\n",
        "\n",
        "# Source:\n",
        "\n",
        "point_0 = af.Model(al.ps.PointFlux)\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, point_0=point_0)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format, which now includes the `flux` parameter of the point source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using the nested sampling algorithm Nautilus (see `start.here.py` for a \n",
        "full description).\n",
        "\n",
        "In the `start_here.py` example 100 live points (`n_live=100`) were used to sample parameter space. We increase this\n",
        "to 150, to account for the additional free parameters in the model that is the source flux."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"point_source\") / \"features\",\n",
        "    name=\"fluxes\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=150,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the `AnalysisPoint` object defining how the via Nautilus the model is fitted to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisPoint(\n",
        "    dataset=dataset,\n",
        "    solver=solver,\n",
        "    fit_positions_cls=al.FitPositionsImagePairRepeat,  # Image-plane chi-squared with repeat image pairs.\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Times__\n",
        "\n",
        "For the positions-only fit, the run time of the log likelihood function was ~0.01 seconds, which is a modest run-time.\n",
        "\n",
        "Evaluating the time delays does not increase this much, with a value of around ~0.01 seconds still expected.\n",
        "\n",
        "Overall modeling run times should therefore be around 20 minutes on CPU, under 5 minutes on GPU.\n",
        "\n",
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The `info` attribute shows the model in a readable format (if this does not display clearly on your screen refer to\n",
        "`start_here.ipynb` for a description of how to fix this).\n",
        "\n",
        "This confirms that `flux` parameters of the source is inferred by the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autolens_workspace/*/guides/results` for a full description of analysing results in **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}