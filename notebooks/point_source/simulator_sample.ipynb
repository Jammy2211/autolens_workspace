{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulator: Hubble Constant Time Delays\n",
        "======================================\n",
        "\n",
        "A multiply imaged lensed quasar with time delays can measure the Hubble constant, which is a fundamental\n",
        "Cosmological parameter that describes the rate of expansion of the universe. This is because the\n",
        "the difference between the geometric time delay and the physical time delay is proportional to the Hubble constant.\n",
        "\n",
        "This script illustrates how to simulate a sample of `PointDataset` datasets of lensed quasars, which\n",
        "can easily be used to simulate hundreds or thousands of strong lenses. These, as a sample, can be used to constrain\n",
        "the Hubble constant.\n",
        "\n",
        "To simulate the sample of lenses, each lens and source galaxies are set up using the `Model` object which is also used\n",
        "in  the `modeling` scripts. This means that the parameters of each simulated strong lens are drawn from the\n",
        "distributions  defined via priors, which can be customized to simulate a wider range of strong lenses.\n",
        "\n",
        "The sample is used in `autolens_workspace/notebooks/advanced/graphical` to illustrate how a graphical and hierarchical\n",
        "model can be fitted to a large sample of double Einstein ring strong lenses in order to improve the constraints on\n",
        "Cosmological parameters.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script simulates a sample of `PointDataset` data of 'galaxy-scale' strong lenses where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal`.\n",
        " - The source `Galaxy` is a `Point`.\n",
        " - The Cosmology is `Planck15` and has a Hubble constant which can be constrained by the time delays.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `simulators/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset Paths__\n",
        "\n",
        "The `dataset_type` describes the type of data being simulated and `dataset_name` gives it a descriptive name. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_label = \"samples\"\n",
        "dataset_type = \"point_source\"\n",
        "dataset_sample_name = \"hubble_constant_time_delays\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The path where the dataset will be output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = Path(\"dataset\") / dataset_type / dataset_label / dataset_sample_name"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Solver__\n",
        "\n",
        "We use a `PointSolver` to locate the multiple images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(200, 200),\n",
        "    pixel_scales=0.05,  # <- The pixel-scale describes the conversion from pixel units to arc-seconds.\n",
        ")\n",
        "\n",
        "solver = al.PointSolver.for_grid(\n",
        "    grid=grid, pixel_scale_precision=0.001, magnification_threshold=0.1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Sample Model Distributions__\n",
        "\n",
        "To simulate a sample, we draw random instances of lens and source galaxies where the parameters of their mass profiles \n",
        "and point source profiles are drawn from distributions. These distributions are defined via priors -- the same objects \n",
        "that are used when defining the priors of each parameter for a non-linear search.\n",
        "\n",
        "Below, we define the distributions the lens galaxy's mass profiles are drawn from alongside the source's point\n",
        "source centre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "mass.centre = (0.0, 0.0)\n",
        "mass.ell_comps.ell_comps_0 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "mass.ell_comps.ell_comps_1 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "mass.einstein_radius = af.UniformPrior(lower_limit=1.0, upper_limit=1.8)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=mass)\n",
        "\n",
        "point = af.Model(al.ps.Point)\n",
        "\n",
        "point.centre_0 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "point.centre_1 = af.GaussianPrior(mean=0.0, sigma=0.1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also include a light profile component of the source, which is to aid visualization of the simulated dataset\n",
        "by providing an image where the point source is located."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(al.lp.ExponentialSph)\n",
        "\n",
        "bulge.centre_0 = point.centre_0\n",
        "bulge.centre_1 = point.centre_1\n",
        "bulge.intensity = 1.0\n",
        "bulge.effective_radius = 0.02\n",
        "bulge.signal_to_noise_ratio = 10.0\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=bulge, point=point)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Simulate__\n",
        "\n",
        "Simulate the image data using a `Grid2D` with the adaptive over sampling scheme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(150, 150),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "psf = al.Kernel2D.from_gaussian(\n",
        "    shape_native=(11, 11), sigma=0.2, pixel_scales=grid.pixel_scales\n",
        ")\n",
        "\n",
        "simulator = al.SimulatorImaging(\n",
        "    exposure_time=300.0,\n",
        "    psf=psf,\n",
        "    background_sky_level=0.1,\n",
        "    add_poisson_noise_to_data=True,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Sample Instances__\n",
        "\n",
        "Within a for loop, we will now generate instances of the lens and source galaxies using the `Model`'s defined above.\n",
        "This loop will run for `total_datasets` iterations, which sets the number of lenses that are simulated.\n",
        "\n",
        "Each iteration of the for loop will then create a tracer and use this to simulate the point dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "total_datasets = 3\n",
        "\n",
        "for sample_index in range(total_datasets):\n",
        "    dataset_sample_path = dataset_path / f\"dataset_{sample_index}\"\n",
        "\n",
        "    lens_galaxy = lens.random_instance()\n",
        "    source_galaxy = source.random_instance()\n",
        "\n",
        "    \"\"\"\n",
        "    __Ray Tracing__\n",
        "\n",
        "    Use the sample's lens and source galaxies to setup a tracer, which will generate the multiple image positions \n",
        "    and time delays for the simulated `PointDataset` dataset.\n",
        "    \"\"\"\n",
        "    tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])\n",
        "\n",
        "    tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid)\n",
        "    tracer_plotter.figures_2d(image=True)\n",
        "\n",
        "    \"\"\"\n",
        "    __Positions__\n",
        "\n",
        "    We now pass the `Tracer` to the solver to find the multiple image positions.\n",
        "\n",
        "    \"\"\"\n",
        "    positions = solver.solve(\n",
        "        tracer=tracer, source_plane_coordinate=source_galaxy.point.centre\n",
        "    )\n",
        "    positions_noise_map = grid.pixel_scale\n",
        "\n",
        "    \"\"\"\n",
        "    __Time Delays__\n",
        "\n",
        "    We next compute the time delays of the multiple images, which are used to constrain the Hubble constant.\n",
        "    \"\"\"\n",
        "    time_delays = tracer.time_delays_from(grid=positions)\n",
        "    time_delays_noise_map = al.ArrayIrregular(values=time_delays * 0.25)\n",
        "\n",
        "    \"\"\"\n",
        "    __Point Dataset__\n",
        "\n",
        "    We now output the `PointDataset` dataset, which contains the multiple image positions, their noise levels,\n",
        "    the time delays and their noise levels.\n",
        "\n",
        "    We output this to a .json file which can be loaded in point source modeling examples.\n",
        "    \"\"\"\n",
        "    dataset = al.PointDataset(\n",
        "        name=\"point_0\",\n",
        "        positions=positions,\n",
        "        positions_noise_map=grid.pixel_scale,\n",
        "        time_delays=time_delays,\n",
        "        time_delays_noise_map=time_delays_noise_map,\n",
        "    )\n",
        "\n",
        "    al.output_to_json(\n",
        "        obj=dataset,\n",
        "        file_path=dataset_sample_path / \"point_dataset_with_time_delays.json\",\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    __Imaging__\n",
        "\n",
        "    We also generate an `Imaging` dataset of the lens, which is used to visualize the lens and source galaxies\n",
        "    and the multiple image positions.\n",
        "    \"\"\"\n",
        "    dataset = simulator.via_tracer_from(tracer=tracer, grid=grid)\n",
        "\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()\n",
        "\n",
        "    \"\"\"\n",
        "    __Output__\n",
        "\n",
        "    Output the simulated dataset to the dataset path as .fits files.\n",
        "\n",
        "    This uses the updated `dataset_path_sample` which outputs this sample lens to a unique folder.\n",
        "    \"\"\"\n",
        "    dataset.output_to_fits(\n",
        "        data_path=dataset_sample_path / \"data.fits\",\n",
        "        psf_path=dataset_sample_path / \"psf.fits\",\n",
        "        noise_map_path=dataset_sample_path / \"noise_map.fits\",\n",
        "        overwrite=True,\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    __Visualize__\n",
        "\n",
        "    Output a subplot of the simulated dataset, the image and the tracer's quantities to the dataset path as .png files.\n",
        "    \"\"\"\n",
        "    mat_plot = aplt.MatPlot2D(\n",
        "        output=aplt.Output(path=dataset_sample_path, format=\"png\")\n",
        "    )\n",
        "\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset, mat_plot_2d=mat_plot)\n",
        "    dataset_plotter.subplot_dataset()\n",
        "    dataset_plotter.figures_2d(data=True)\n",
        "\n",
        "    tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid, mat_plot_2d=mat_plot)\n",
        "    tracer_plotter.subplot_tracer()\n",
        "    tracer_plotter.subplot_galaxies_images()\n",
        "\n",
        "    \"\"\"\n",
        "    __Tracer json__\n",
        "\n",
        "    Save the `Tracer` in the dataset folder as a .json file, ensuring the true light profiles, mass profiles and galaxies\n",
        "    are safely stored and available to check how the dataset was simulated in the future. \n",
        "\n",
        "    This can be loaded via the method `tracer = al.from_json()`.\n",
        "    \"\"\"\n",
        "    al.output_to_json(\n",
        "        obj=tracer,\n",
        "        file_path=dataset_sample_path / \"tracer.json\",\n",
        "    )\n",
        "\n",
        "    \"\"\"\n",
        "    The dataset can be viewed in the \n",
        "    folder `autolens_workspace/dataset/point/samples/hubble_constant_time_delays/{sample_index]`.\n",
        "    \"\"\"\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}