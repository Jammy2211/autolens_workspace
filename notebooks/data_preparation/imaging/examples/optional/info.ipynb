{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Preparation: Info (Optional)\n",
        "=================================\n",
        "\n",
        "Auxiliary information about a strong lens dataset may used during an analysis or afterwards when interpreting the\n",
        " modeling results. For example, the redshifts of the source and lens galaxy.\n",
        "\n",
        "By storing these as an `info.json` file in the lens's dataset folder, it is straight forward to load the redshifts\n",
        "in a modeling script and pass them to a fit, such that **PyAutoLens** can then output results in physical\n",
        "units (e.g. kpc instead of arc-seconds).\n",
        "\n",
        "For analysing large quantities of  modeling results, **PyAutoLens** has an sqlite database feature. The info file\n",
        "may can also be loaded by the database after a model-fit has completed, such that when one is interpreting\n",
        "the results of a model fit additional data on a lens can be used to.\n",
        "\n",
        "For example, to plot the model-results against other measurements of a lens not made by PyAutoLens. Examples of such\n",
        "data might be:\n",
        "\n",
        "- The velocity dispersion of the lens galaxy.\n",
        "- The stellar mass of the lens galaxy.\n",
        "- The results of previous strong lens models to the lens performed in previous papers.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `data_preparation/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "\n",
        "%matplotlib inline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The path where info is output, which is `dataset/imaging/simple__no_lens_light`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"imaging\"\n",
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = path.join(\"dataset\", dataset_type, dataset_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The info is written as a Python dictionary and can have as many entries as desired added to it. Any information you\n",
        "want to include int he interpretation of your lens models should be included here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "info = {\n",
        "    \"redshift_lens\": 0.5,\n",
        "    \"redshift_source\": 1.0,\n",
        "    \"velocity_dispersion\": 250000,\n",
        "    \"stellar mass\": 1e11,\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The info is stored in the dataset folder as a .json file. \n",
        "\n",
        "We cannot `dump` a .json file using a string which contains a directory, so we dump it to the location of this\n",
        "script and move it to the appropriate dataset folder. We first delete existing info file in the dataset folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import shutil\n",
        "import json\n",
        "\n",
        "info_file = \"info.json\"\n",
        "\n",
        "with open(info_file, \"w+\") as f:\n",
        "    json.dump(info, f, indent=4)\n",
        "\n",
        "if os.path.exists(path.join(dataset_path, \"info.json\")):\n",
        "    os.remove(path.join(dataset_path, \"info.json\"))\n",
        "\n",
        "shutil.move(\"info.json\", path.join(dataset_path, \"info.json\"))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the info to be available to the results of a model-fit, the modeling script must load the info file from the .json and \n",
        "pass it to the search.run() or pipeline.run() function:\n",
        "\n",
        "info_file = path.join(dataset_path, \"info.json\")\n",
        "\n",
        "with open(info_file, \"r\") as f:\n",
        "    info = json.load(f)\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis, info=info)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}