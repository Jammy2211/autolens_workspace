{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Preparation: Image\n",
        "=======================\n",
        "\n",
        "The image is the image of your galaxy, which comes from a telescope like the Hubble Space telescope (HST).\n",
        "\n",
        "This tutorial describes preprocessing your dataset`s image to adhere to the units and formats required by PyAutoLens.\n",
        "\n",
        "__Pixel Scale__\n",
        "\n",
        "The \"pixel_scale\" of the image (and the data in general) is pixel-units to arcsecond-units conversion factor of\n",
        "your telescope. You should look up now if you are unsure of the value.\n",
        "\n",
        "The pixel scale of some common telescopes is as follows:\n",
        "\n",
        " - Hubble Space telescope 0.04\" - 0.1\" (depends on the instrument and wavelength).\n",
        " - James Webb Space telescope 0.06\" - 0.1\" (depends on the instrument and wavelength).\n",
        " - Euclid 0.1\" (Optical VIS instrument) and 0.2\" (NIR NISP instrument).\n",
        " - VRO / LSST 0.2\" - 0.3\" (depends on the instrument and wavelength).\n",
        " - Keck Adaptive Optics 0.01\" - 0.03\" (depends on the instrument and wavelength).\n",
        "\n",
        "It is absolutely vital you use the correct pixel scale, so double check this value!\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `data_preparation/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "%matplotlib inline\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Loading Data From Individual Fits Files__\n",
        "\n",
        "Load an image from .fits files (a format commonly used by Astronomers) via the `Array2D` object. \n",
        "\n",
        "This image represents a good data-reduction that conforms **PyAutoLens** formatting standards!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"imaging\", \"simple\")\n",
        "\n",
        "data = al.Array2D.from_fits(\n",
        "    file_path=path.join(dataset_path, \"data.fits\"), pixel_scales=0.1\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This image conforms to **PyAutoLens** standards for the following reasons.\n",
        "\n",
        " - Units: The image flux is in units of electrons per second (as opposed to electrons, counts, ADU`s etc.). \n",
        "   Internal **PyAutoLens** functions for computing quantities like a galaxy magnitude assume the data and model\n",
        "   light profiles are in electrons per second.\n",
        "   \n",
        " - Centering: The lens galaxy is at the centre of the image (as opposed to in a corner). Default **PyAutoLens**\n",
        "   parameter priors assume the galaxy is at the centre of the image.\n",
        "   \n",
        " - Stamp Size: The image is a postage stamp cut-out of the galaxy, but does not include many pixels around the edge of\n",
        "   the galaxy. It is advisible to cut out a postage stamp of the galaxy, as opposed to the entire image, as this reduces\n",
        "   the amount of memory **PyAutoLens** uses, speeds up the analysis and ensures visualization zooms around the galaxy. \n",
        "   Conforming to this standard is not necessary to ensure an accurate analsyis.\n",
        "    \n",
        "  - Background Sky Subtraction: The image has had its background sky subtracted. \n",
        "   \n",
        "If your image conforms to all of the above standards, you are good to use it for an analysis (but must also check\n",
        "you noise-map and PSF conform to standards first!).\n",
        "\n",
        "If it does not conform to standards, this script illustrates **PyAutoLens** functionality which can be used to \n",
        "convert it to standards. \n",
        "\n",
        "__Converting Data To Electrons Per Second__\n",
        "\n",
        "Brightness units: the image`s flux values should be in units of electrons per second (as opposed to electrons, \n",
        "counts, ADU`s etc.). \n",
        "\n",
        "Although **PyAutoLens** can technically perform an analysis using other units, the default setup assumes electrons per \n",
        "second (e.g. the priors on `LightProfile` intensity and `Regularization` parameters). Thus, images not in electrons per \n",
        "second should be converted!\n",
        "\n",
        "The data loaded above is in units of electrons per second, lets convert it to counts to illustrate how this is done.\n",
        "\n",
        "Converting from electrons per second to counts (and visa versa) means we must know the exposure time of our observation, \n",
        "which will either be in the .fits header information of your data or be an output of your data reduction pipeline.\n",
        "\n",
        "We create an `Array2D` of the exposure time map, which is the exposure time of each pixel in the image assuming that\n",
        "all pixels have the same exposure time. This is a good approximation for most HST observations, but not for all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "exposure_time = 1000.0\n",
        "\n",
        "exposure_time_map = al.Array2D.full(\n",
        "    fill_value=exposure_time,\n",
        "    shape_native=data.shape_native,\n",
        "    pixel_scales=data.pixel_scales,\n",
        ")\n",
        "\n",
        "data_counts = al.preprocess.array_eps_to_counts(\n",
        "    array_eps=data, exposure_time_map=exposure_time_map\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting the image in counts, we can see that the flux values are now much higher values (e.g. ~1000 or above)\n",
        "compared to the data in electrons per second (e.g. ~1 or below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "array_plotter = aplt.Array2DPlotter(array=data_counts)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is therefore straightforward to convert an image to electrons per second from counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_eps = al.preprocess.array_counts_to_eps(\n",
        "    array_counts=data_counts, exposure_time_map=exposure_time_map\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data_eps)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the effective exposure-time map is output as part of the data reduction, you can use this to convert the image to \n",
        "electrons per second instead.\n",
        "\n",
        "[The code below is commented out because the simulated data does not have an effective exposure time map in .fits \n",
        "format.]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# exposure_time_map = al.Array2D.from_fits(\n",
        "#     file_path=path.join(dataset_path, \"exposure_time_map.fits\"),\n",
        "#     pixel_scales=data_eps.pixel_scales,\n",
        "# )\n",
        "#\n",
        "# data_eps = al.preprocess.array_counts_to_eps(\n",
        "#     array_counts=data_counts, exposure_time_map=exposure_time_map\n",
        "# )\n",
        "#\n",
        "# array_plotter = aplt.Array2DPlotter(array=data_eps)\n",
        "# array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**PyAutoLens** can also convert data to / from units of electrons per second to ADUs, which uses both the exposure \n",
        "time andinstrumental gain of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_in_adus = al.preprocess.array_eps_to_adus(\n",
        "    array_eps=data, gain=4.0, exposure_time_map=exposure_time_map\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data_in_adus)\n",
        "array_plotter.figure_2d()\n",
        "\n",
        "data_eps = al.preprocess.array_adus_to_eps(\n",
        "    array_adus=data_in_adus, gain=4.0, exposure_time_map=exposure_time_map\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data_eps)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In `autolens_workspace/*/data_preparation/noise_map.py` we show that a noise-map must also be in units of \n",
        "electrons per second, and that the same functions as above can be used to do this.\n",
        "\n",
        "__Resizing Data__\n",
        "\n",
        "The bigger the postage stamp cut-out of the image the more memory it requires to store. Visualization will be less \n",
        "ideal too, as the lens galaxy will be a smaller blob in the centre relative to the large surrounding edges of the image. Why \n",
        "keep the edges surrounding the lens and sourcegalaxy if they are masked out anyway?\n",
        "\n",
        "Lets look at an example of a very large postage stamp - we can barely even see the lens and source galaxy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"imaging\", \"simple__big_stamp\")\n",
        "\n",
        "data_large_stamp = al.Array2D.from_fits(\n",
        "    file_path=path.join(dataset_path, \"data.fits\"), pixel_scales=0.1\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data_large_stamp)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you have a large postage stamp you can trim it using the preprocess module, which is centered on the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_large_stamp_trimmed = al.preprocess.array_with_new_shape(\n",
        "    array=data_large_stamp, new_shape=(130, 130)\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data_large_stamp_trimmed)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Stamps can also be too small, if the mask you input to the analysis is larger than the postage stamp extends.\n",
        "\n",
        "In this case, you either need to reproduce the data with a larger postage stamp, or use a smaller mask.\n",
        "\n",
        "__Background Subtraction__\n",
        "\n",
        "The background of an image is the light that is not associated with the lens or source galaxies we are \n",
        "interested in. This is due to light from the sky, zodiacal light, and light from other galaxies in the \n",
        "field of view. The background should have been subtracted from the image before it was reduced, but \n",
        "sometimes this is not the case.\n",
        "\n",
        "It is recommend you use data processing tools outside of **PyAutoLens** to subtract the background from your image,\n",
        "as these have been optimized for this task. However, if you do not have access to these tools, **PyAutoLens** has\n",
        "functions in the `preprocess` module that can estimate and subtract the background of an image.\n",
        "\n",
        "The preprocess module is found here: \n",
        "\n",
        "https://github.com/Jammy2211/PyAutoArray/blob/main/autoarray/dataset/preprocess.py\n",
        "\n",
        "Functions related to background subtraction are:\n",
        "\n",
        "- `background_sky_level_via_edges_from`\n",
        "- `background_noise_map_via_edges_from`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# __Centering__\n",
        "\n",
        "########## IVE INCLUDED THE TEXT CAN BE AWARE OF CENTERING, BUT THE BUILT IN FUNCTIONALITY FOR #####\n",
        "########## RECENTERING CURRENTLY DOES NOT WORK :( ###########\n",
        "\n",
        "# galaxy Centering - The galaxy should be in the centre of the image as opposed to a corner. This ensures\n",
        "# the origin of the galaxy's light and `MassProfile`'s are near the origin (0.0\", 0.0\") of the grid used to perform\n",
        "# ray-tracing. The defaults priors on light and `MassProfile`'s assume a origin of (0.0\", 0.0\").\n",
        "\n",
        "# Lets look at an off-center image - clearly both the galaxy and Einstein ring are offset in the positive y and x d\n",
        "# directions.\n",
        "\n",
        "# dataset_path = f\"{dataset_path}/imaging_offset_centre\"\n",
        "\n",
        "# imaging_offset_centre = al.Imaging.from_fits(data_path=path+`image.fits`, pixel_scales=0.1,\n",
        "#                                   noise_map_path=path+`noise_map.fits`,\n",
        "#                                   psf_path=path+`psf.fits`)\n",
        "# aplt.Imaging.subplot(imaging=imaging_offset_centre)\n",
        "\n",
        "# We can address this by using supplying a new centre for the image, in pixels. We also supply the resized shape, to\n",
        "# instruct the code whether it should trim the image or pad the edges that now arise due to recentering.\n",
        "\n",
        "# imaging_recentred_pixels = al.Imaging.from_fits(data_path=path+`image.fits`, pixel_scales=0.1,\n",
        "#                                             noise_map_path=path+`noise_map.fits`,\n",
        "#                                             psf_path=path+`psf.fits`,\n",
        "#                                             resized_imaging_shape=(100, 100),\n",
        "#                                             resized_imaging_centre_pixels=(0, 0))\n",
        "# #                                            resized_imaging_centre_arc_seconds=(1.0, 1.0))\n",
        "# print(imaging_recentred_pixels.shape)\n",
        "# aplt.Imaging.subplot(imaging=imaging_recentred_pixels)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}