{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imaging: Data Preparation\n",
        "=========================\n",
        "\n",
        "When a CCD imaging dataset is analysed, it must conform to certain standards in order for the analysis\n",
        "to be performed correctly. This tutorial describes these standards and links to more detailed scripts which will help\n",
        "you prepare your dataset to adhere to them if it does not already.\n",
        "\n",
        "__Pixel Scale__\n",
        "\n",
        "The \"pixel_scale\" of the image (and the data in general) is pixel-units to arcsecond-units conversion factor of\n",
        "your telescope. You should look up now if you are unsure of the value.\n",
        "\n",
        "The pixel scale of some common telescopes is as follows:\n",
        "\n",
        " - Hubble Space telescope 0.04\" - 0.1\" (depends on the instrument and wavelength).\n",
        " - James Webb Space telescope 0.06\" - 0.1\" (depends on the instrument and wavelength).\n",
        " - Euclid 0.1\" (Optical VIS instrument) and 0.2\" (NIR NISP instrument).\n",
        " - VRO / LSST 0.2\" - 0.3\" (depends on the instrument and wavelength).\n",
        " - Keck Adaptive Optics 0.01\" - 0.03\" (depends on the instrument and wavelength).\n",
        "\n",
        "It is absolutely vital you use the correct pixel scale, so double check this value!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Image__\n",
        "\n",
        "The image is the image of your strong lens, which comes from a telescope like the Hubble Space telescope (HST).\n",
        "\n",
        "Lets inspect an image which conforms to **PyAutoLens** standards:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", \"imaging\", \"simple\")\n",
        "\n",
        "data = al.Array2D.from_fits(\n",
        "    file_path=path.join(dataset_path, \"data.fits\"), pixel_scales=0.1\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This image conforms to **PyAutoLens** standards for the following reasons.\n",
        "\n",
        " - Units: The image flux is in units of electrons per second (as opposed to electrons, counts, ADU`s etc.). \n",
        "   Internal **PyAutoLens** functions for computing quantities like galaxy magnitudes assume the data and model\n",
        "   light profiles are in electrons per second.\n",
        "   \n",
        " - Centering: The lens galaxy is at the centre of the image (as opposed to in a corner). Default **PyAutoLens**\n",
        "   parameter priors assume the lens galaxy is at the centre of the image.\n",
        "   \n",
        " - Stamp Size: The image is a postage stamp cut-out of the lens, but does not include many pixels around the edge of\n",
        "   the lens. It is advised to cut out a postage stamp of the lens, as opposed to the entire image, as this reduces\n",
        "   the amount of memory **PyAutoLens** uses, speeds up the analysis and ensures visualization zooms around the lens\n",
        "   and source. However, conforming to this standard is not necessary to ensure an accurate **PyAutoLens** analysis.\n",
        "   \n",
        "If your image conforms to all of the above standards, you are good to use it for an analysis (but must also check\n",
        "you noise-map and PSF conform to standards first!).\n",
        "\n",
        "**Links / Resources:**\n",
        "\n",
        " - `data_preparation/imaging/examples/data.ipynb`: tools to process the data to conform to these standards.\n",
        "\n",
        "__Noise Map__\n",
        "\n",
        "The noise-map defines the uncertainty in every pixel of your strong lens image, where values are defined as the \n",
        "RMS standard deviation in every pixel (not the variances, HST WHT-map values, etc.). \n",
        "\n",
        "Lets inspect a noise-map which conforms to **PyAutoLens** standards:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "noise_map = al.Array2D.from_fits(\n",
        "    file_path=path.join(dataset_path, \"noise_map.fits\"), pixel_scales=0.1\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=noise_map)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This noise-map conforms to **PyAutoLens** standards for the following reasons:\n",
        "\n",
        " - Units: Like its corresponding image, it is in units of electrons per second (as opposed to electrons, counts, \n",
        "   ADU`s etc.). Internal **PyAutoLens** functions for computing quantities like a galaxy magnitude assume the data and \n",
        "   model light profiles are in electrons per second.\n",
        "\n",
        " - Values: The noise-map values themselves are the RMS standard deviations of the noise in every pixel. When a model \n",
        "   is fitted to data in **PyAutoLens** and a likelihood is evaluated, this calculation assumes that this is the\n",
        "   corresponding definition of the noise-map. The noise map therefore should not be the variance of the noise, or \n",
        "   another definition of noise.\n",
        "\n",
        "If you are not certain what the definition of the noise-map you have available to you is, or do not know how to\n",
        "compute a noise-map at all, you should refer to the instrument handbook of the telescope your data is from. It is\n",
        "absolutely vital that the noise-map is correct, as it is the only way **PyAutoLens** can quantify the goodness-of-fit.\n",
        "\n",
        "A sanity check for a reliable noise map is that the signal-to-noise of the lens galaxy is somewhere between a value of \n",
        "10 - 300 and source around 5 - 50, however this is not a definitive test.\n",
        "   \n",
        "Given the image should be centred and cut-out around the lens galaxy, so should the noise-map.\n",
        "\n",
        "If your noise-map conforms to all of the above standards, you are good to use it for an analysis (but must also check\n",
        "you image and PSF conform to standards first!).\n",
        "\n",
        "**Links / Resources:**\n",
        "\n",
        " - `data_preparation/imaging/examples/noise_map.ipynb`: tools to process the noise-map to conform to these standards.\n",
        "\n",
        "__PSF__\n",
        "\n",
        "The Point Spread Function (PSF) describes blurring due the optics of your dataset`s telescope. It is used when fitting \n",
        "a dataset to include these effects, such that does not bias the model.\n",
        "\n",
        "It should be estimated from a stack of stars in the image during data reduction or using a PSF simulator (e.g. TinyTim\n",
        "for Hubble).\n",
        "\n",
        "Lets inspect a PSF which conforms to **PyAutoLens** standards:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "psf = al.Kernel2D.from_fits(\n",
        "    file_path=path.join(dataset_path, \"psf.fits\"), hdu=0, pixel_scales=0.1\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=psf)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This psf conforms to **PyAutoLens** standards for the following reasons.\n",
        "\n",
        " - Size: The PSF has a shape 21 x 21 pixels, which is large enough to capture the PSF core and thus capture the \n",
        "   majority of the blurring effect, but not so large that the convolution slows down the analysis. Large \n",
        "   PSFs (e.g. 51 x 51) are supported, but will lead to much slower run times. The size of the PSF should be carefully \n",
        "   chosen to ensure it captures the majority of blurring due to the telescope optics, which for most instruments is \n",
        "   something around 11 x 11 to 21 x 21.\n",
        "\n",
        " - Oddness: The PSF has dimensions which are odd (an even PSF would for example have shape 20 x 20). The \n",
        "   convolution of an even PSF introduces a small shift in the model images and produces an offset in the inferred\n",
        "   lens model parameters. Inputting an even PSF will lead **PyAutoLens** to raise an error.\n",
        "\n",
        " - Normalization: The PSF has been normalized such that all values within the kernel sum to 1 (note how all values in \n",
        "   the example PSF are below zero with the majority below 0.01). This ensures that flux is conserved when convolution \n",
        "   is performed, ensuring that quantities like a galaxy's magnitude are computed accurately.\n",
        "\n",
        " - Centering: The PSF is at the centre of the array (as opposed to in a corner), ensuring that no shift is introduced\n",
        "   due to PSF blurring on the inferred model parameters.\n",
        "\n",
        "If your PSF conforms to all of the above standards, you are good to use it for an analysis (but must also check\n",
        "you noise-map and image conform to standards first!).\n",
        "\n",
        "**Links / Resources:**\n",
        "\n",
        " - `data_preparation/imaging/examples/psf.ipynb`: tools to process the PSF to conform to these standards.\n",
        "\n",
        "__Data Processing Complete__\n",
        "\n",
        "If your image, noise-map and PSF conform the standards above, you are ready to analyse your dataset!\n",
        "\n",
        "Below, we provide an overview of optional data preparation steos which prepare other aspects of the analysis. \n",
        "\n",
        "New users are recommended to skim-read the optional steps below so they are aware of them, but to not perform them \n",
        "and instead analyse their dataset now. You can come back to the data preparation scripts below if it becomes necessary.\n",
        "\n",
        "__Mask (Optional)__\n",
        "\n",
        "The mask removes the regions of the image where the lens and source galaxy are not present, typically the edges of the \n",
        "image.\n",
        "\n",
        "Example modeling scripts internally create a 3.0\" circular mask and therefore do not require that a mask has been \n",
        "created externally via a data preparation script. \n",
        "\n",
        "This script shows how to create customize masked (e.g. annular, ellipses) which are tailored to match the lens or\n",
        "lensed source emission. \n",
        "\n",
        "If you have not analysed your dataset yet and do not know of a specific reason why you need the bespoke masks \n",
        "created by this script, it is recommended that you simply use the default ~3.0\" circular mask internally made in each\n",
        "script and omit this data preparation tutorial.\n",
        "\n",
        "**Links / Resources:**\n",
        "\n",
        "- `data_preparation/examples/optional/mask.ipynb`: tools to create a bespoke mask for your dataset.\n",
        "- `data_preparation/examples/gui/mask.ipynb`: use a Graphical User Interface (GUI) to create a bespoke mask.\n",
        "\n",
        "__Positions (Optional)__\n",
        "\n",
        "The script allows you to mark the (y,x) arc-second positions of the multiply imaged lensed source galaxy in \n",
        "the image-plane, under the assumption that they originate from the same location in the source-plane.\n",
        "\n",
        "A non-linear search (e.g. Nautilus) can then use these positions to preferentially choose mass models where these \n",
        "positions trace close to one another in the source-plane. This speeding up the initial fitting of lens models and \n",
        "removes unwanted solutions from parameter space which have too much or too little mass in the lens galaxy.\n",
        "\n",
        "If you create positions for your dataset, you must also update your modeling script to use them by loading them \n",
        "and passing them to the `Analysis` object via a `PositionsLH` object. \n",
        "\n",
        "If your **PyAutoLens** analysis is struggling to converge to a good lens model, you should consider using positions\n",
        "to help the non-linear search find a good lens model.\n",
        "\n",
        "**Links / Resources:**\n",
        "\n",
        "Position-based lens model resampling is particularly important for fitting pixelized source models, for the\n",
        "reasons disucssed in the following readthedocs \n",
        "webapge  https://pyautolens.readthedocs.io/en/latest/general/demagnified_solutions.html\n",
        "\n",
        "- `data_preparation/examples/optional/positions.ipynb`: input the positions manually into a Python script.\n",
        "- `data_preparation/gui/positions.ipynb` use a Graphical User Interface (GUI) to mark the positions.\n",
        "- `modeling/imaging/customize/positions.py` for an example.of how to use positions in a `modeling` script.\n",
        "\n",
        "\n",
        "__Lens Light Centre (Optional)__\n",
        "\n",
        "This script allows you to mark the (y,x) arcsecond locations of the lens galaxy light centre(s) of the strong lens\n",
        "you are analysing. These can be used as fixed values for the lens light and mass models in a model-fit.\n",
        "\n",
        "This  reduces the number of free parameters fitted for in a lens model and removes inaccurate solutions where\n",
        "the lens mass model centre is unrealistically far from its true centre.\n",
        "\n",
        "Advanced `chaining` scripts often use these input centres in the early fits to infer an accurate initial lens model,\n",
        "amd then make the centres free parameters in later searches to ensure a general and accurate lens model is inferred.\n",
        "\n",
        "If you create a `light_centre` for your dataset, you must also update your modeling script to use them.\n",
        "\n",
        "If your **PyAutoLens** analysis is struggling to converge to a good lens model, you should consider using a fixed\n",
        "lens light and / or mass centre to help the non-linear search find a good lens model.\n",
        "\n",
        "**Links / Resources:**\n",
        "\n",
        "- `data_preparation/examples/optional/lens_light_centre.py`: input the lens galaxy light centre manually into a Python script.\n",
        "- `data_preparation/gui/lens_light_centre.ipynb` use a Graphical User Interface (GUI) to mask the lens galaxy light centre.\n",
        "\n",
        "\n",
        "__Extra Galaxies (Optional)__\n",
        "\n",
        "There may be galaxies nearby the lens and source galaxies, whose emission blends with that of the lens and source\n",
        "and whose mass may contribute to the ray-tracing and lens model.\n",
        "\n",
        "We can include these galaxies in the lens model, either as light profiles, mass profiles, or both, using the\n",
        "modeling API, where these nearby objects are denoted `extra_galaxies`.\n",
        "\n",
        "The script `extra_galaxies_centres.py` marks the (y,x) arcsecond locations of these extra galaxies, so that when they \n",
        "are included in the lens model the centre of these extra galaxies light and / or mass profiles are fixed to these \n",
        "values (or their priors are  initialized surrounding these centres).\n",
        "\n",
        "The example `mask_extra_galaxies.py` (see below) masks the regions of an image where extra galaxies are present. \n",
        "This mask is used  to remove their signal from the data and increase their noise to make them not impact the fit. \n",
        "This means their  luminous emission does not need to be included in the model, reducing the number of free parameters \n",
        "and speeding up the analysis. It is still a choice whether their mass is included in the model.\n",
        "\n",
        "**Links / Resources:**\n",
        "\n",
        "- `data_preparation/examples/optional/extra_galaxies_centres.py`: input the extra galaxy centres manually into a \n",
        "  Python script.\n",
        "- `data_preparation/gui/extra_galaxies_centres.ipynb`: use a Graphical User Interface (GUI) to mark the extra galaxy centres.\n",
        "- `features/extra_galaxies.py` how to use extra galaxies in a model-fit, including loading the extra galaxy centres.\n",
        "\n",
        "\n",
        "__Mask Extra Galaxies (Optional)__\n",
        "\n",
        "There may be regions of an image that have signal near the lens and source that is from other galaxies not associated \n",
        "with the strong lens we are studying. The emission from these images will impact our model fitting and needs to be \n",
        "removed from the analysis.\n",
        "\n",
        "This script creates a mask of these regions of the image, called the `mask_extra_galaxies`, which can be used to\n",
        "prevent them from impacting a fit. This mask may also include emission from objects which are not technically galaxies,\n",
        "but blend with the galaxy we are studying in a similar way. Common examples of such objects are foreground stars\n",
        "or emission due to the data reduction process.\n",
        "\n",
        "The mask can be applied in different ways. For example, it could be applied such that the image pixels are discarded\n",
        "from the fit entirely, Alternatively the mask could be used to set the image values to (near) zero and increase their\n",
        "corresponding noise-map to large values.\n",
        "\n",
        "The exact method used depends on the nature of the model being fitted. For simple fits like a light profile a mask\n",
        "is appropriate, as removing image pixels does not change how the model is fitted. However, for more complex models\n",
        "fits, like those using a pixelization, masking regions of the image in a way that removes their image pixels entirely\n",
        "from the fit can produce discontinuities in the pixelixation. In this case, scaling the data and noise-map values\n",
        "may be a better approach.\n",
        "\n",
        "**Links / Resources:**\n",
        "\n",
        "- `data_preparation/examples/optional/mask_extra_galaxies.py`: create the extra galaxies mask manually via a Python script.\n",
        "- `data_preparation/gui/extra_galaxies_mask.ipynb` use a Graphical User Interface (GUI) to create the extra galaxies mask.\n",
        "- `features/extra_galaxies.py` how to use the extra galaxies mask in a model-fit.\n",
        "\n",
        "__Info (Optional)__\n",
        "\n",
        "Auxiliary information about a strong lens dataset may used during an analysis or afterwards when interpreting the \n",
        " modeling results. For example, the redshifts of the source and lens galaxy. \n",
        "\n",
        "By storing these as an `info.json` file in the lens's dataset folder, it is straight forward to load the redshifts \n",
        "in a modeling script and pass them to a fit, such that **PyAutoLens** can then output results in physical \n",
        "units (e.g. kpc instead of arc-seconds).\n",
        "\n",
        "For analysing large quantities of  modeling results, **PyAutoLens** has an sqlite database feature. The info file \n",
        "may can also be loaded by the database after a model-fit has completed, such that when one is interpreting\n",
        "the results of a model fit additional data on a lens can be used to. \n",
        "\n",
        "For example, to plot the model-results against other measurements of a lens not made by PyAutoLens. Examples of such \n",
        "data might be:\n",
        "\n",
        "- The velocity dispersion of the lens galaxy.\n",
        "- The stellar mass of the lens galaxy.\n",
        "- The results of previous strong lens models to the lens performed in previous papers.\n",
        "\n",
        "**Links / Resources:**\n",
        "\n",
        "- `data_preparation/examples/optional/info.py`: create the info file manually via a Python script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}