{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling: Mass Total + Source Inversion\n",
        "=======================================\n",
        "\n",
        "A pixelization reconstructs the source's light using a pixel-grid, which is regularized using a prior that forces\n",
        "the solution to have a degree of smoothness.\n",
        "\n",
        "This script fits a source galaxy model which uses a pixelization to reconstruct the source's light. A Delaunay\n",
        "mesh and constant regularization scheme are used, which are the simplest forms of mesh and regularization\n",
        "with provide computationally fast and accurate solutions in **PyAutoLens**.\n",
        "\n",
        "For simplicity, the lens galaxy's light is omitted from the model and is not present in the simulated data. It is\n",
        "straightforward to include the lens galaxy's light in the model.\n",
        "\n",
        "Pixelizations are covered in detail in chapter 4 of the **HowToLens** lectures.\n",
        "\n",
        "__Advantages__\n",
        "\n",
        "Many strongly lensed source galaxies are complex, and have asymmetric and irregular morphologies. These morphologies\n",
        "cannot be well approximated by a parametric light profiles like a Sersic, or many Sersics, and thus a pixelization\n",
        "is required to reconstruct the source's irregular light.\n",
        "\n",
        "Even basis functions like shapelets or a multi-Gaussian expansion cannot reconstruct a source-plane accurately\n",
        "if there are multiple source galaxies, or if the source galaxy has a very complex morphology.\n",
        "\n",
        "To infer detailed components of a lens mass model (e.g. its density slope, whether there's a dark matter subhalo, etc.)\n",
        "then pixelized source models are required, to ensure the mass model is fitting all of the lensed source light.\n",
        "\n",
        "There are also many science cases where one wants to study the highly magnified light of the source galaxy in detail,\n",
        "to learnt about distant and faint galaxies. A pixelization reconstructs the source's unlensed emission and thus\n",
        "enables this.\n",
        "\n",
        "__Disadvantages__\n",
        "\n",
        "Pixelizations are computationally slow, and thus the run times will be much longer than a parametric source model.\n",
        "It is not uncommon for a pixelization to take hours or even days to fit high resolution imaging data (e.g. Hubble Space\n",
        "Telescope imaging).\n",
        "\n",
        "Lens modeling with pixelizations is also more complex than parametric source models, with there being more things\n",
        "that can go wrong. For example, there are solutions where a demagnified version of the lensed source galaxy is\n",
        "reconstructed, using a mass model which effectively has no mass or too much mass. These are described in detail below,\n",
        "the point for now is that it may take you a longer time to learn how to fit lens models with a pixelization successfully!\n",
        "\n",
        "__Positive Only Solver__\n",
        "\n",
        "All pixelized source reconstructions use a positive-only solver, meaning that every source-pixel is only allowed\n",
        "to reconstruct positive flux values. This ensures that the source reconstruction is physical and that we don't\n",
        "reconstruct negative flux values that don't exist in the real source galaxy (a common systematic solution in lens\n",
        "analysis).\n",
        "\n",
        "It may be surprising to hear that this is a feature worth pointing out, but it turns out setting up the linear algebra\n",
        "to enforce positive reconstructions is difficult to make efficient. A lot of development time went into making this\n",
        "possible, where a bespoke fast non-negative linear solver was developed to achieve this.\n",
        "\n",
        "Other methods in the literature often do not use a positive only solver, and therefore suffer from these\n",
        "unphysical solutions, which can degrade the results of lens model in general.\n",
        "\n",
        "__Chaining__\n",
        "\n",
        "Due to the complexity of fitting with a pixelization, it is often best to use **PyAutoLens**'s non-linear chaining\n",
        "feature to compose a pipeline which begins by fitting a simpler model using a parametric source.\n",
        "\n",
        "More information on chaining is provided in the `autolens_workspace/notebooks/imaging/advanced/chaining` folder,\n",
        "chapter 3 of the **HowToLens** lectures.\n",
        "\n",
        "The script `autolens_workspace/scripts/imaging/advanced/chaining/parametric_to_pixelization.py` explitly uses chaining\n",
        "to link a lens model using a light profile source to one which then uses a pixelization.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits `Interferometer` dataset of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's light is omitted (and is not present in the simulated data).\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's light is an `Overlay` image-mesh, `Delaunay` mesh and `Constant` regularization.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We define the \u2018real_space_mask\u2019 which defines the grid the image the strong lens is evaluated using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "real_space_mask = al.Mask2D.circular(\n",
        "    shape_native=(800, 800),\n",
        "    pixel_scales=0.05,\n",
        "    radius=3.0,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the strong lens `Interferometer` dataset `simple` from .fits files , which we will fit \n",
        "with the lens model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple\"\n",
        "dataset_path = path.join(\"dataset\", \"interferometer\", dataset_name)\n",
        "\n",
        "dataset = al.Interferometer.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    uv_wavelengths_path=path.join(dataset_path, \"uv_wavelengths.fits\"),\n",
        "    real_space_mask=real_space_mask,\n",
        "    transformer_class=al.TransformerDFT,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Times (Inversion Settings)__\n",
        "\n",
        "The run times of an interferometer pixelization reconstruction (called an `Inversion`) depend significantly \n",
        "on how the reconstruction is performed, specifically the transformer used and way the linear algebra is performed.\n",
        "\n",
        "The transformer maps the inversion's image from real-space to Fourier space, with two options available that have\n",
        "optimal run-times depending on the number of visibilities in the dataset:\n",
        "\n",
        "- `TransformerDFT`: A discrete Fourier transform which is most efficient for < ~100 000 visibilities.\n",
        "\n",
        "- `TransformerNUFFT`: A non-uniform fast Fourier transform which is most efficient for > ~100 000 visibilities.\n",
        "\n",
        "This dataset fitted in this example has just ~200 visibilities, so we will input the \n",
        "setting `transformer_cls=TransformerDFT`.\n",
        "\n",
        "The linear algebra describes how the linear system of equations used to reconstruct a source via a pixelization is\n",
        "solved. \n",
        "\n",
        "There are with three options available that again have run-times that are optimal for datasets of different sizes \n",
        "(do not worry if you do not understand how the linear algebra works, all you need to do is ensure you choose the\n",
        "setting most appropriate for the size of your dataset):\n",
        "\n",
        "- `use_w_tilde`: If `False`, the matrices in the linear system are computed via a `mapping_matrix`, which is optimal\n",
        "  for datasets with < ~10 000 visibilities.\n",
        "\n",
        "- `use_w_tilde`: If `True`, the matrices are computed via a `w_tilde` matrix instead, which is optimal for datasets \n",
        "  with between ~10 000 and 1 000 000 visibilities.\n",
        "\n",
        "- `use_linear_operators`: A different formalism is used entirely where matrices are not computed and linear operators\n",
        "   are used instead. This is optimal for datasets with > ~1 000 000 visibilities.\n",
        "\n",
        "The dataset fitted in this example has ~200 visibilities, so we will input the settings `use_w_tilde=False` and\n",
        "`use_linear_operators=False`.\n",
        "\n",
        "The script `autolens_workspace/*/interferometer/data_preparation/examples/run_times.py` compares the run-time of an inversion for your \n",
        "interferometer dataset for different settings. \n",
        "\n",
        "I recommend you use this script to choose the optimal settings for your dataset, as the difference in run-time can be\n",
        "huge!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings_inversion = al.SettingsInversion(use_linear_operators=False, use_w_tilde=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now plot the `Interferometer` object which is used to fit the lens model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.InterferometerPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "dataset_plotter.subplot_dirty_images()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our lens model using `Model` objects, which represent the galaxies we fit to our data.  In this \n",
        "example fits a lens model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear` [7 parameters].\n",
        " \n",
        " - The source-galaxy's light uses a `Rectangular` mesh with fixed resolution 30 x 30 pixels (0 parameters).\n",
        " \n",
        " - This pixelization is regularized using a `ConstantSplit` scheme which smooths every source pixel equally [1 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=8. \n",
        " \n",
        "It is worth noting the `Pixelization`  use significantly fewer parameters (1 parameter) than \n",
        "fitting the source using `LightProfile`'s (7+ parameters). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(\n",
        "    al.Galaxy, redshift=0.5, mass=al.mp.Isothermal, shear=al.mp.ExternalShear\n",
        ")\n",
        "\n",
        "pixelization = af.Model(\n",
        "    al.Pixelization,\n",
        "    image_mesh=al.image_mesh.Overlay(shape=(30, 30)),\n",
        "    mesh=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.ConstantSplit,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using the nested sampling algorithm Nautilus (see `start.here.py` for a \n",
        "full description)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"interferometer\", \"modeling\"),\n",
        "    name=\"mass[sie]_source[pix]\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=4,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Position Likelihood__\n",
        "\n",
        "We add a penalty term ot the likelihood function, which penalizes models where the brightest multiple images of\n",
        "the lensed source galaxy do not trace close to one another in the source plane. This removes \"demagnified source\n",
        "solutions\" from the source pixelization, which one is likely to infer without this penalty.\n",
        "\n",
        "A comprehensive description of why we do this is given at the following readthedocs page. I strongly recommend you \n",
        "read this page in full if you are not familiar with the positions likelihood penalty and demagnified source reconstructions:\n",
        "\n",
        " https://pyautolens.readthedocs.io/en/latest/general/demagnified_solutions.html\n",
        "\n",
        "__Brief Description__\n",
        "\n",
        "Unlike other example scripts, we also pass the `AnalysisInterferometer` object below a `PositionsLHPenalty` object, \n",
        "whichincludes the positions we loaded above, alongside a `threshold`.\n",
        "\n",
        "This is because `Inversion`'s suffer a bias whereby they fit unphysical lens models where the source galaxy is \n",
        "reconstructed as a demagnified version of the lensed source. \n",
        "\n",
        "To prevent these solutions biasing the model-fit we specify a `position_threshold` of 0.5\", which requires that a \n",
        "mass model traces the four (y,x) coordinates specified by our positions (that correspond to the brightest regions of the \n",
        "lensed source) within 0.5\" of one another in the source-plane. If this criteria is not met, a large penalty term is\n",
        "added to likelihood that massively reduces the overall likelihood. This penalty is larger if the ``positions``\n",
        "trace further from one another.\n",
        "\n",
        "This ensures the unphysical solutions that bias a pixelization have a lower likelihood that the physical solutions\n",
        "we desire. Furthermore, the penalty term reduces as the image-plane multiple image positions trace closer in the \n",
        "source-plane, ensuring Nautilus converges towards an accurate mass model. It does this very fast, as \n",
        "ray-tracing just a few multiple image positions is computationally cheap. \n",
        "\n",
        "The threshold of 0.3\" is large. For an accurate lens model we would anticipate the positions trace within < 0.01\" of\n",
        "one another. The high threshold ensures only the initial mass models at the start of the fit are resampled.\n",
        "\n",
        "Position thresholding is described in more detail in the \n",
        "script `autolens_workspace/*/modeling/imaging/customize/positions.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = al.Grid2DIrregular(\n",
        "    al.from_json(file_path=path.join(dataset_path, \"positions.json\"))\n",
        ")\n",
        "\n",
        "\n",
        "positions_likelihood = al.PositionsLHPenalty(positions=positions, threshold=0.3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "The `AnalysisInterferometer` object defines the `log_likelihood_function` used by the non-linear search to fit the \n",
        "model to the `Interferometer`dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisInterferometer(\n",
        "    dataset=dataset,\n",
        "    positions_likelihood=positions_likelihood,\n",
        "    settings_inversion=settings_inversion,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "The discussion above described how the run-times of a pixelization using an interferometer dataset are significantly\n",
        "depending on the number of visibilities in the dataset. The discussion below is a more generic description of how\n",
        "the run-time of a pixelization scales, which applies to other datasets (e.g. imaging) as well.\n",
        "\n",
        "The log likelihood evaluation time given below is relatively fast (), because we above chose a suitable transformer\n",
        "and method to solve the linear equations for the number of visibilities in the dataset.\n",
        "\n",
        "The run time of a pixelization is longer than many other features, with the estimate below coming out at around ~0.5 \n",
        "seconds per likelihood evaluation. This is because the fit has a lot of linear algebra to perform in order to\n",
        "reconstruct the source on the pixel-grid.\n",
        "\n",
        "Nevertheless, this is still fast enough for most use-cases. If run-time is an issue, the following factors determine\n",
        "the run-time of a a pixelization and can be changed to speed it up (at the expense of accuracy):\n",
        "\n",
        " - The number of unmasked pixels in the image data. By making the mask smaller (e.g. using an annular mask), the \n",
        "   run-time will decrease.\n",
        "\n",
        " - The number of source pixels in the pixelization. By reducing the `shape` from (30, 30) the run-time will decrease.\n",
        "\n",
        "This also serves to highlight why the positions threshold likelihood is so powerful. The likelihood evaluation time\n",
        "of this step is below 0.001 seconds, meaning that the initial parameter space sampling is extremely efficient even\n",
        "for a pixelization (this is not accounted for in the run-time estimate below)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")\n",
        "\n",
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")\n",
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the maximum likelihood fit, tracer images and posteriors inferred via Nautilus.\n",
        "\n",
        "Checkout `autolens_workspace/*/imaging/results` for a full description of analysing results in **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer,\n",
        "    grid=real_space_mask.derive_grid.unmasked,\n",
        ")\n",
        "tracer_plotter.subplot_tracer()\n",
        "\n",
        "fit_plotter = aplt.FitInterferometerPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()\n",
        "fit_plotter.subplot_fit_dirty_images()\n",
        "\n",
        "plotter = aplt.NestPlotter(samples=result.samples)\n",
        "plotter.corner_anesthetic()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autolens_workspace/*/imaging/results` for a full description of analysing results in **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}