{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling: Customize\n",
    "===================\n",
    "\n",
    "This script gives a run through of all the different ways the analysis can be customized for lens modeling, with\n",
    "reasons explaining why each customization is useful.\n",
    "\n",
    "__Contents__\n",
    "\n",
    "**Dataset**: Load a dataset which is used to illustrate the customizations.\n",
    "**Mask:** Apply a custom mask to the dataset, which can be used to remove regions of the image that contain no emission.\n",
    "**Over Sampling:** Change the over sampling used to compute the surface brightness of every image-pixel.\n",
    "**Positions:** Specify the positions of the lensed source's multiple images, which can be used to discard unphysical mass models.\n",
    "\n",
    "__Start Here Notebook__\n",
    "\n",
    "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "%matplotlib inline\n",
    "from pyprojroot import here\n",
    "workspace_path = str(here())\n",
    "%cd $workspace_path\n",
    "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
    "\n",
    "from pathlib import Path\n",
    "import autofit as af\n",
    "import autolens as al\n",
    "import autolens.plot as aplt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Dataset__\n",
    "\n",
    "All customizations in this script are applied to the strong lens dataset `simple__no_lens_light`, which is a\n",
    "simple strong lens with no lens light emission.\n",
    "\n",
    "We therefore load and plot the strong lens dataset `simple__no_lens_light` via .fits files."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataset_name = \"simple__no_lens_light\"\n",
    "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
    "\n",
    "dataset = al.Imaging.from_fits(\n",
    "    data_path=dataset_path / \"data.fits\",\n",
    "    psf_path=dataset_path / \"psf.fits\",\n",
    "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
    "    pixel_scales=0.1,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Mask__\n",
    "\n",
    "All example default scritps use a circular mask to model a lens, which contains the lens and source emission.\n",
    "However, the mask can be customized to better suit the lens and source emission, for example by using an annular\n",
    "mask to only contain the emission of the Einstein ring itelf.\n",
    "\n",
    "Advantages: Strong lenses with complex and difficult-to-subtract foreground lens galaxies can leave residuals that\n",
    "bias the mass and source models, which this custom mask can remove from the model-fit. The custom mask can also provide\n",
    "faster run times, as the removal of large large regions of the image (which contain no signal) no longer need to be\n",
    "processed and fitted.\n",
    "\n",
    "Disadvantages: Pixels containing no source emission may still constrain the lens model, if a mass model incorrectly\n",
    "predicts that flux will appear in these image pixels. By using a custom mask, the model-fit will not be penalized for\n",
    "incorrectly predicting flux in these image-pixels (As the mask has removed them from the fit).\n",
    "\n",
    "We first show an example using an annular masks, which because the data does not contain lens light can be\n",
    "used to remove the central pixels containing no emission and thus only fit the source."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mask = al.Mask2D.circular_annular(\n",
    "    shape_native=dataset.shape_native,\n",
    "    pixel_scales=dataset.pixel_scales,\n",
    "    inner_radius=0.5,\n",
    "    outer_radius=2.5,\n",
    ")\n",
    "\n",
    "dataset = dataset.apply_mask(mask=mask)  # <----- The custom mask is used here!\n",
    "\n",
    "visuals = aplt.Visuals2D(mask=mask)\n",
    "\n",
    "dataset_plotter = aplt.ImagingPlotter(dataset=dataset, visuals_2d=visuals)\n",
    "dataset_plotter.subplot_dataset()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load the mask from a .fits file, which could have been produced in a way which is even more customized\n",
    "to the source emission than the annular masks above.. \n",
    "\n",
    "To create the .fits file of a mask, we use a GUI tool which is described in the following script:\n",
    "\n",
    " `autolens_workspace/*/data_preparation/imaging/gui/mask.py`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mask = al.Mask2D.from_fits(\n",
    "    file_path=Path(dataset_path, \"mask_gui.fits\"),\n",
    "    hdu=0,\n",
    "    pixel_scales=dataset.pixel_scales,\n",
    ")\n",
    "\n",
    "dataset = dataset.apply_mask(mask=mask)  # <----- The custom mask is used here!\n",
    "\n",
    "visuals = aplt.Visuals2D(mask=mask)\n",
    "\n",
    "dataset_plotter = aplt.ImagingPlotter(dataset=dataset, visuals_2d=visuals)\n",
    "dataset_plotter.subplot_dataset()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Over Sampling__\n",
    "\n",
    "Over sampling is a numerical technique where the images of light profiles and galaxies are evaluated\n",
    "on a higher resolution grid than the image data to ensure the calculation is accurate.\n",
    "\n",
    "For lensing calculations, the high magnification regions of a lensed source galaxy require especially high levels of\n",
    "over sampling to ensure the lensed images are evaluated accurately.\n",
    "\n",
    "This is why throughout the workspace the cored Sersic profile is used, instead of the regular Sersic profile which\n",
    "you may be more familiar with from the literature. In this example we will increase the over sampling level and\n",
    "therefore fit a regular Sersic profile to the data, instead of a cored Sersic profile.\n",
    "\n",
    "This example demonstrates how to change the over sampling used to compute the surface brightness of every image-pixel,\n",
    "whereby a higher sub-grid resolution better oversamples the image of the light profile so as to provide a more accurate\n",
    "model of its image.\n",
    "\n",
    "**Benefit**: Higher level of over sampling provide a more accurate estimate of the surface brightness in every image-pixel.\n",
    "**Downside**: Higher levels of over sampling require longer calculations and higher memory usage.\n",
    "\n",
    "Over sampling is applied separately to the light profiles which compute the surface brightness of the lens galaxy,\n",
    "which are on a `uniform` grid, and the light profiles which compute the surface brightness of the source galaxy,\n",
    "which are on a `non-uniform` grid.\n",
    "\n",
    "Prequisites: You should read `autolens_workspace/*/guides/advanced/over_sampling.ipynb` before running this script, which\n",
    "introduces the concept of over sampling in PyAutoLens and explains why the lens and source galaxy are evaluated\n",
    "on different grids.\n",
    "\n",
    "\n",
    "\n",
    "The over sampling used to fit the data is customized using the `apply_over_sampling` method, which you may have\n",
    "seen in example `modeling` scripts.\n",
    "\n",
    "To apply uniform over sampling of degree 4x4, we simply input the integer 4.\n",
    "\n",
    "The grid this is applied to is called `lp`, to indicate that it is the grid used to evaluate the emission of light\n",
    "profiles for which this over sampling scheme is applied."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataset = dataset.apply_over_sampling(over_sample_size_lp=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the `over_sample_size` input has been an integer, however it can also be an `ndarray` of values corresponding\n",
    "to each pixel. \n",
    "\n",
    "We create an `ndarray` of values which are high in the centre, but reduce to 2 at the outskirts, therefore\n",
    "providing high levels of over sampling where we need it whilst using lower values which are computationally fast to \n",
    "evaluate at the outskirts.\n",
    "\n",
    "Specifically, we define a 24 x 24 sub-grid within the central 0.3\" of pixels, uses a 8 x 8 grid between\n",
    "0.3\" and 0.6\" and a 2 x 2 grid beyond that. \n",
    "\n",
    "This will provide high levels of over sampling for the lens galaxy, whose emission peaks at the centre of the\n",
    "image near (0.0\", 0.0\"), but will not produce high levels of over sampling for the lensed source."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "over_sample_size = al.util.over_sample.over_sample_size_via_radial_bins_from(\n",
    "    grid=dataset.grid,\n",
    "    sub_size_list=[24, 8, 2],\n",
    "    radial_list=[0.3, 0.6],\n",
    "    centre_list=[(0.0, 0.0)],\n",
    ")\n",
    "\n",
    "dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By assuming the lens galaxy is near (0.0\", 0.0\"), it was simple to set up an adaptive over sampling grid which is\n",
    "applicable to all strong lens dataset.\n",
    "\n",
    "There is no analogous define an adaptive over sampling grid for the lensed source, because for every dataset the\n",
    "source's light will appear in different regions of the image plane.\n",
    "\n",
    "This is why the majority of workspace examples use cored light profiles for the source galaxy. A cored light profile\n",
    "does not rapidly change in its central regions, and therefore can be evaluated accurately without over-sampling.\n",
    "\n",
    "There is a way to set up an adaptive over sampling grid for a lensed source, however it requries one to use and\n",
    "understanding the advanced lens modeling feature search chaining.\n",
    "\n",
    "An example of how to use search chaining to over sample sources efficient is provided in \n",
    "the `autolens_workspace/*/imaging/advanced/chaining/over_sampling.ipynb` example."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# %%\n",
    "'''\n",
    "__Positions__\n",
    "\n",
    "Before fitting a strong lens, we can manually specify a grid of image-plane coordinates corresponding to the multiple\n",
    "images of the lensed source-galaxy(s). During the model-fit, **PyAutoLens** will check that these coordinates trace\n",
    "within a specified arc-second threshold of one another in the source-plane. If they do not meet this threshold, the\n",
    "mass model is discarded and a new sample is generated by the non-linear search.\n",
    "\n",
    "Advantages: The model-fit is faster, as the non-linear search avoids regions of parameter space where the mass-model\n",
    "is clearly not accurate. Removing these unphysical solutions may also mean that the global-maximum solution is inferred\n",
    "instead of a local-maxima, given that removing unphysical mass models makes non-linear parameter space less complex.\n",
    "\n",
    "Disadvantages: If the positions are inaccurate or threshold is set too low, one may inadvertantly remove the correct\n",
    "mass model!\n",
    "\n",
    "The positions are associated with the and they are loaded from a `positions.json` file which is in the same folder as \n",
    "the dataset itself. \n",
    "\n",
    "To create this file, we used a GUI to `draw on` the positions with our mouse. This GUI can be found in the script:\n",
    "\n",
    " `autolens_workspace/*/data_preparation/imaging/gui/positions.py`\n",
    "\n",
    "If you wish to use positions for modeling your own lens data, you should use this script to draw on the positions of\n",
    "every lens in you dataset.\n",
    "'''"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "positions = al.Grid2DIrregular(\n",
    "    al.from_json(file_path=Path(dataset_path, \"positions.json\"))\n",
    ")\n",
    "\n",
    "visuals = aplt.Visuals2D(mask=mask, positions=positions)\n",
    "dataset_plotter = aplt.ImagingPlotter(dataset=dataset, visuals_2d=visuals)\n",
    "dataset_plotter.subplot_dataset()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the positions can be specified manually in the modeling script script using the `Grid2DIrregular`object.\n",
    "\n",
    "Below, we specify a list of (y,x) coordinates (that are not on a uniform or regular grid) which correspond to the \n",
    "arc-second (y,x) coordinates ot he lensed source's brightest pixels."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "positions = al.Grid2DIrregular(\n",
    "    [(0.4, 1.6), (1.58, -0.35), (-0.43, -1.59), (-1.45, 0.2)]\n",
    ")\n",
    "\n",
    "visuals = aplt.Visuals2D(mask=mask, positions=positions)\n",
    "dataset_plotter = aplt.ImagingPlotter(dataset=dataset, visuals_2d=visuals)\n",
    "dataset_plotter.subplot_dataset()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use positions in lens modeling, we pass the `AnalysisImaging` object a `PositionsLH` object, which includes the \n",
    "positions we loaded above, alongside a `threshold`.\n",
    "\n",
    "The threshold of 0.3\" is large. For an accurate lens model we would anticipate the positions trace within < 0.01\" of\n",
    "one another. The high threshold ensures only the initial mass models at the start of the fit are penalized."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "positions_likelihood = al.PositionsLH(positions=positions, threshold=0.3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis receives a list of `PositionsLH` objects, which allows us to use multiple sets of positions to apply this \n",
    "penalty, for example if there source has multiple sets of multiple images which we know how they map to one another."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "analysis = al.AnalysisImaging(\n",
    "    dataset=dataset, positions_likelihood_list=[positions_likelihood]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
