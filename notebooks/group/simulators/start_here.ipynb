{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulator: Group\n",
        "================\n",
        "\n",
        "This script simulates `Imaging` and a `PointDataset` of a 'group-scale' strong lens where:\n",
        "\n",
        " - The group consists of three lens galaxies whose ligth distributions are `SersicSph` profiles and\n",
        " total mass distributions are `IsothermalSph` profiles.\n",
        " - A single source galaxy is observed whose `LightProfile` is an `Sersic`.\n",
        "\n",
        "The brightest pixels of the source in the image-plane are used to create a point-source dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset Paths__\n",
        "\n",
        "The `dataset_type` describes the type of data being simulated (in this case, `Imaging` data) and `dataset_name`\n",
        "gives it a descriptive name. They define the folder the dataset is output to on your hard-disk:\n",
        "\n",
        " - The image will be output to `/autolens_workspace/dataset/dataset_type/dataset_name/image.fits`.\n",
        " - The noise-map will be output to `/autolens_workspace/dataset/dataset_type/dataset_name/noise_map.fits`.\n",
        " - The psf will be output to `/autolens_workspace/dataset/dataset_type/dataset_name/psf.fits`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"group\"\n",
        "dataset_name = \"lens_x3__source_x1\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The path where the dataset will be output, which in this case is:\n",
        "`/autolens_workspace/output/group`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = path.join(\"dataset\", dataset_type, dataset_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Simulate__\n",
        "\n",
        "When simulating the amount of emission in each image pixel from the lens and source galaxies, a two dimensional\n",
        "line integral of all of the emission within the area of that pixel should be performed. However, for complex lens\n",
        "models this can be difficult to analytically compute and can lead to slow run times.\n",
        "\n",
        "Instead, an iterative ray-tracing algorithm is used to approximate the line integral. Grids of increasing resolution\n",
        "are used to evaluate the flux in each pixel from the lens and source galaxies. Grids of higher resolution are used\n",
        "until the fractional accuracy of the flux in each pixel meets a certain threshold, which we set below to 99.99%\n",
        "\n",
        "This uses the `OverSamplingIterate` object, which is input into to the `Grid2D` object you may have seen in other \n",
        "example scripts, however it make sit perform the iterative ray-tracing described above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(250, 250),\n",
        "    pixel_scales=0.1,\n",
        "    over_sampling=al.OverSamplingIterate(\n",
        "        fractional_accuracy=0.9999, sub_steps=[2, 4, 8, 16]\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulate a simple Gaussian PSF for the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "psf = al.Kernel2D.from_gaussian(\n",
        "    shape_native=(11, 11), sigma=0.1, pixel_scales=grid.pixel_scales\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To simulate the `Imaging` dataset we first create a simulator, which defines the exposure time, background sky,\n",
        "noise levels and psf of the dataset that is simulated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "simulator = al.SimulatorImaging(\n",
        "    exposure_time=300.0, psf=psf, background_sky_level=0.1, add_poisson_noise=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Ray Tracing__\n",
        "\n",
        "Setup the mass models of the three lens galaxies using the `IsothermalSph` model and the source galaxy light using \n",
        "an elliptical Sersic for this simulated lens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy_0 = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    bulge=al.lp.SersicSph(\n",
        "        centre=(0.0, 0.0), intensity=0.7, effective_radius=2.0, sersic_index=4.0\n",
        "    ),\n",
        "    mass=al.mp.IsothermalSph(centre=(0.0, 0.0), einstein_radius=4.0),\n",
        ")\n",
        "\n",
        "lens_galaxy_1 = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    bulge=al.lp.SersicSph(\n",
        "        centre=(3.5, 2.5), intensity=0.9, effective_radius=0.8, sersic_index=3.0\n",
        "    ),\n",
        "    mass=al.mp.IsothermalSph(centre=(3.5, 2.5), einstein_radius=0.8),\n",
        ")\n",
        "\n",
        "lens_galaxy_2 = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    bulge=al.lp.SersicSph(\n",
        "        centre=(-4.4, -5.0), intensity=0.9, effective_radius=0.8, sersic_index=3.0\n",
        "    ),\n",
        "    mass=al.mp.IsothermalSph(centre=(-4.4, -5.0), einstein_radius=1.0),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp.Sersic(\n",
        "        centre=(0.0, 0.1),\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.8, angle=60.0),\n",
        "        intensity=3.0,\n",
        "        effective_radius=0.4,\n",
        "        sersic_index=1.0,\n",
        "    ),\n",
        "    point_0=al.ps.Point(centre=(0.0, 0.1)),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use these galaxies to setup a tracer, which will generate the image for the simulated `Imaging` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = al.Tracer(\n",
        "    galaxies=[lens_galaxy_0, lens_galaxy_1, lens_galaxy_2, source_galaxy]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets look at the tracer`s image, this is the image we'll be simulating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=grid)\n",
        "tracer_plotter.figures_2d(image=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Source__\n",
        "\n",
        "It is common for group-scale strong lens datasets to be modeled assuming that the source is a point-source. Even if \n",
        "it isn't, this can be necessary due to computational run-time making it unfeasible to fit the imaging dataset outright.\n",
        "\n",
        "A `PointSolver` determines the multiple-images of the mass model for a point source at location (y,x) in the source \n",
        "plane. It does this by iteratively ray-tracing light rays from the image-plane to the source-plane, until it finds \n",
        "the image-plane coordinate that rays converge at for a given  source-plane (y,x).\n",
        "\n",
        "For the lens mass model defined above, it computes the multiple images of the source galaxy\n",
        "at the (y,x) source-plane coordinates (0.0\", 0.0\") of the point source.\n",
        "\n",
        "The `PointSolver` requires a starting grid of (y,x) coordinates in the image-plane, which are iteratively traced \n",
        "and refined to locate the image-plane coordinates that map directly to the source-plane coordinate.\n",
        "\n",
        "The `pixel_scale_precision` is the resolution up to which the multiple images are computed. The lower the value, the\n",
        "longer the calculation, with a value of 0.001 being efficient but more than sufficient for most point-source datasets.\n",
        "\n",
        "Strong lens mass models have a multiple image called the \"central image\", which is located at the centre of the lens.\n",
        "However, the image is nearly always demagnified due to the mass model, and is therefore not observed and not\n",
        "something we want to be included in the simulated dataset. The `maginification_threshold` removes this image, by\n",
        "discarding any image with a magnification below the threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(300, 300),\n",
        "    pixel_scales=0.05,  # <- The pixel-scale describes the conversion from pixel units to arc-seconds.\n",
        ")\n",
        "\n",
        "solver = al.PointSolver.for_grid(\n",
        "    grid=grid, pixel_scale_precision=0.001, magnification_threshold=0.1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now pass the `Tracer` to the solver. This will then find the image-plane coordinates that map directly to the\n",
        "source-plane coordinate (0.0\", 0.0\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = solver.solve(\n",
        "    tracer=tracer, source_plane_coordinate=source_galaxy.point_0.centre\n",
        ")\n",
        "\n",
        "print(positions)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the positions to compute the magnification of the `Tracer` at every position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "magnifications = tracer.magnification_2d_via_hessian_from(grid=positions)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now compute the observed fluxes of the `Point`, give we know how much each is magnified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "flux = 1.0\n",
        "fluxes = [flux * np.abs(magnification) for magnification in magnifications]\n",
        "fluxes = al.ArrayIrregular(values=fluxes)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Datasets__\n",
        "\n",
        "All of the quantities computed above are input into a `PointDataset` object, which collates all information\n",
        "about the multiple images of a point-source strong lens system.\n",
        "\n",
        "In this example, it contains the image-plane coordinates of the multiple images, the fluxes of the multiple images,\n",
        "and their associated noise-map values.\n",
        "\n",
        "It also contains the name `point_0`, which is a label given to the dataset to indicate that it is a dataset of a single\n",
        "point-source. This label is important, it is used for lens modeling in order to associate the dataset with the correct\n",
        "point-source in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.PointDataset(\n",
        "    name=\"point_0\",\n",
        "    positions=positions,\n",
        "    positions_noise_map=grid.pixel_scale,\n",
        "    fluxes=fluxes,\n",
        "    fluxes_noise_map=al.ArrayIrregular(\n",
        "        values=[np.sqrt(flux) for _ in range(len(fluxes))]\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now output the point dataset to the dataset path as a .json file, which is loaded in the point source modeling\n",
        "examples.\n",
        "\n",
        "In this example, there is just one point source dataset. However, for group and cluster strong lenses there\n",
        "can be many point source datasets in a single dataset, and separate .json files are output for each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "al.output_to_json(\n",
        "    obj=dataset,\n",
        "    file_path=path.join(dataset_path, \"point_dataset.json\"),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Visualize__\n",
        "\n",
        "Output a subplot of the simulated point source dataset as a .png file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mat_plot_1d = aplt.MatPlot1D(output=aplt.Output(path=dataset_path, format=\"png\"))\n",
        "mat_plot_2d = aplt.MatPlot2D(output=aplt.Output(path=dataset_path, format=\"png\"))\n",
        "\n",
        "point_dataset_plotter = aplt.PointDatasetPlotter(\n",
        "    dataset=dataset, mat_plot_1d=mat_plot_1d, mat_plot_2d=mat_plot_2d\n",
        ")\n",
        "point_dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Pass the simulator a tracer, which creates the image which is simulated as an imaging dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = simulator.via_tracer_from(tracer=tracer, grid=grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets plot the simulated `Imaging` dataset before we output it to fits, including the (y,x) coordinates of the multiple\n",
        "images in the image-plane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(multiple_images=positions)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(\n",
        "    dataset=dataset, visuals_2d=visuals, mat_plot_2d=aplt.MatPlot2D()\n",
        ")\n",
        "dataset_plotter.subplot_dataset()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output the simulated dataset to the dataset path as .fits files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset.output_to_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    overwrite=True,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Visualize__\n",
        "\n",
        "Output a subplot of the simulated dataset, the image and the tracer's quantities to the dataset path as .png files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mat_plot = aplt.MatPlot2D(output=aplt.Output(path=dataset_path, format=\"png\"))\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset, mat_plot_2d=mat_plot)\n",
        "dataset_plotter.subplot_dataset()\n",
        "dataset_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Tracer json__\n",
        "\n",
        "Save the `Tracer` in the dataset folder as a .json file, ensuring the true light profiles, mass profiles and galaxies\n",
        "are safely stored and available to check how the dataset was simulated in the future. \n",
        "\n",
        "This can be loaded via the method `tracer = al.from_json()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "al.output_to_json(\n",
        "    obj=tracer,\n",
        "    file_path=path.join(dataset_path, \"tracer.json\"),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}