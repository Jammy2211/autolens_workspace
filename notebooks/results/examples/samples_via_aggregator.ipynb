{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results: Samples via Aggregator\n",
        "===============================\n",
        "\n",
        "In the script `autogalaxy_workspace/*/imaging/results/examples/samples.py` we show how to inspect the non-linear\n",
        "search samples from a result.\n",
        "\n",
        "We have also shown how to use the `Aggregator` to load the samples of a non-linear search from hard-disk or a\n",
        ".sqllite database file.\n",
        "\n",
        "In this example, we'll load results via the aggregator and inspect the samples of the non-linear search. The\n",
        "attributes we inspect are the same as those shown in the `samples.py` script.\n",
        "\n",
        "This script is simply an API cheat sheet for accessing the results of a non-linear search via the `Aggregator`, so you\n",
        "can copy and paste the code to use in your own scripts!\n",
        "\n",
        "__Samples via Result__\n",
        "\n",
        "A fraction of this example repeats the API for manipulating samples given in the\n",
        "`autogalaxy_workspace/*/results/examples/samples.py` example.\n",
        "\n",
        "This is done so users can directly copy and paste Python code which loads results from the database and manipulates\n",
        "the samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Files__\n",
        "\n",
        "In the `start_here.py` script, we discussed the `files` that are output by the non-linear search. The \n",
        "following files correspond to the information loaded when loading the non-linear search samples from the database:\n",
        "\n",
        " - `model`: The `model` defined above and used in the model-fit (`model.json`).\n",
        " - `search`: The non-linear search settings (`search.json`).\n",
        " - `samples`: The non-linear search samples (`samples.csv`).\n",
        " - `samples_info`: Additional information about the samples (`samples_info.json`).\n",
        " - `samples_summary`: A summary of key results of the samples (`samples_summary.json`).\n",
        " - `info`: The info dictionary passed to the search (`info.json`).\n",
        " - `covariance`: The inferred covariance matrix (`covariance.csv`).\n",
        " - `cosmology`: The cosmology used by the fit (`cosmology.json`).\n",
        " - `settings_inversion`: The settings associated with a inversion if used (`settings_inversion.json`).\n",
        " - `dataset/data`: The data that is fitted (`data.fits`).\n",
        " - `dataset/noise_map`: The noise-map (`noise_map.fits`).\n",
        " - `dataset/psf`: The Point Spread Function (`psf.fits`).\n",
        " - `dataset/mask`: The mask applied to the data (`mask.fits`).\n",
        " - `dataset/settings`: The settings associated with the dataset (`settings.json`).\n",
        "\n",
        "The `samples` and `samples_summary` results contain a lot of repeated information. The `samples` result contains\n",
        "the full non-linear search samples, for example every parameter sample and its log likelihood. The `samples_summary`\n",
        "contains a summary of the results, for example the maximum log likelihood model and error estimates on parameters\n",
        "at 1 and 3 sigma confidence.\n",
        "\n",
        "Accessing results via the `samples_summary` is much faster, because as it does reperform calculations using the full \n",
        "list of samples. Therefore, if the result you want is accessible via the `samples_summary` you should use it\n",
        "but if not you can revert to the `samples.\n",
        "\n",
        "__Aggregator__\n",
        "\n",
        "First, set up the aggregator as shown in `start_here.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autofit.aggregator.aggregator import Aggregator\n",
        "\n",
        "agg = Aggregator.from_directory(\n",
        "    directory=path.join(\"output\", \"results_folder\"),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Generators__\n",
        "\n",
        "The `start_here.py` database example gives an explanation of what Python generators are and why and how they are used.\n",
        "Refer back to that example if you are unsure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples_gen = agg.values(\"samples\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Samples__\n",
        "\n",
        "The result contains a `Samples` object, which contains all samples of the non-linear search, which is accessible\n",
        "via the database and aggregator.\n",
        "\n",
        "Each sample corresponds to a set of model parameters that were evaluated and accepted by the non linear search, \n",
        "in this example `Nautilus`. \n",
        "\n",
        "This includes their log likelihoods, which are used for computing additional information about the model-fit,\n",
        "for example the error on every parameter. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Samples: \\n\")\n",
        "print(agg.values(\"samples\"))\n",
        "print()\n",
        "print(\"Total Samples Objects = \", len(agg), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Parameters__\n",
        "\n",
        "The parameters are stored as a list of lists, where:\n",
        "\n",
        " - The outer list is the size of the total number of samples.\n",
        " - The inner list is the size of the number of free parameters in the fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    print(\"All parameters of the very first sample\")\n",
        "    print(samples.parameter_lists[0])\n",
        "    print(\"The third parameter of the tenth sample\")\n",
        "    print(samples.parameter_lists[9][2])\n",
        "    print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Samples Info__\n",
        "\n",
        "The samples info contains additional information on the samples, which depends on the non-linear search used. \n",
        "\n",
        "For example, for a nested sampling algorithm it contains information on the number of live points, for a MCMC\n",
        "algorithm it contains information on the number of steps, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples_info in agg.values(\"samples_info\"):\n",
        "    print(samples_info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Figures of Merit__\n",
        "\n",
        "The `Samples` class contains the log likelihood, log prior, log posterior and weight_list of every accepted sample, where:\n",
        "\n",
        "- The `log_likelihood` is the value evaluated in the `log_likelihood_function`.\n",
        "\n",
        "- The `log_prior` encodes information on how parameter priors map log likelihood values to log posterior values.\n",
        "\n",
        "- The `log_posterior` is `log_likelihood + log_prior`.\n",
        "\n",
        "- The `weight` gives information on how samples are combined to estimate the posterior, which depends on type of search\n",
        "  used (for `Nautilus` they are all non-zero values which sum to 1).\n",
        "\n",
        "Lets inspect these values for the tenth sample of each of the 3 model-fits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    print(\"log(likelihood), log(prior), log(posterior) and weight of the tenth sample.\")\n",
        "    print(samples.log_likelihood_list[9])\n",
        "    print(samples.log_prior_list[9])\n",
        "    print(samples.log_posterior_list[9])\n",
        "    print(samples.weight_list[9])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Samples Summary__\n",
        "\n",
        "The samples summary contains a subset of results access via the `Samples`, for example the maximum likelihood model\n",
        "and parameter error estimates.\n",
        "\n",
        "Using the samples method above can be slow, as the quantities have to be computed from all non-linear search samples\n",
        "(e.g. computing errors requires that all samples are marginalized over). This information is stored directly in the\n",
        "samples summary and can therefore be accessed instantly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples_summary in agg.values(\"samples_summary\"):\n",
        "    instance = samples_summary.max_log_likelihood()\n",
        "\n",
        "    print(\"Max Log Likelihood Instance:\")\n",
        "    print(\"Centre = \", instance.galaxies.lens.mass.centre)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Maximum Likelihood Model__\n",
        "\n",
        "We can use the outputs to create a list of the maximum log likelihood model of each fit to our three images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_list = [\n",
        "    samps.max_log_likelihood(as_instance=False) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "print(\"Max Log Likelihood Model Parameter Lists: \\n\")\n",
        "print(ml_list, \"\\n\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Parameter Names__\n",
        "\n",
        "Vectors return a lists of all model parameters, but do not tell us which values correspond to which parameters.\n",
        "\n",
        "The following quantities are available in the `Model`, where the order of their entries correspond to the parameters \n",
        "in the `ml_list` above:\n",
        "\n",
        " - `paths`: a list of tuples which give the path of every parameter in the `Model`.\n",
        " - `parameter_names`: a list of shorthand parameter names derived from the `paths`.\n",
        " - `parameter_labels`: a list of parameter labels used when visualizing non-linear search results (see below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    model = samples.model\n",
        "    print(model)\n",
        "    print(model.paths)\n",
        "    print(model.parameter_names)\n",
        "    print(model.parameter_labels)\n",
        "    print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These lists will be used later for visualization, how it is often more useful to create the model instance of every fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_instances = [samps.max_log_likelihood() for samps in agg.values(\"samples\")]\n",
        "print(\"Maximum Log Likelihood Model Instances: \\n\")\n",
        "print(ml_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Instances__\n",
        "\n",
        "We can use the `Aggregator` to create a list of instances of the model, using the Python class structure of the \n",
        "model composition.\n",
        "\n",
        "For example, we can return a list of the model instances corresponding to the maximum log likelihood sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies)\n",
        "# print(ml_instances[1].galaxies)\n",
        "# print(ml_instances[2].galaxies)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These galaxies will be named according to the model composed and fitted by the search (in this case `lens` and `source`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies.lens)\n",
        "print()\n",
        "# print(ml_instances[1].galaxies.source)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Their light and mass profiles are also named according to model composition allowing individual parameters to be \n",
        "printed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies.lens.mass.einstein_radius)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Posterior / PDF__\n",
        "\n",
        "The result contains the full posterior information of our non-linear search, which can be used for parameter \n",
        "estimation. \n",
        "\n",
        "PDF stands for \"Probability Density Function\" and it quantifies probability of each model parameter having values\n",
        "that are sampled. It therefore enables error estimation via a process called marginalization.\n",
        "\n",
        "The median pdf vector is available, which estimates every parameter via 1D marginalization of their PDFs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mp_instances = [samps.median_pdf() for samps in agg.values(\"samples\")]\n",
        "\n",
        "print(\"Median PDF Model Instances: \\n\")\n",
        "print(mp_instances, \"\\n\")\n",
        "print(mp_instances[0].galaxies.lens.mass)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Errors__\n",
        "\n",
        "Methods for computing error estimates on all parameters are provided. \n",
        "\n",
        "This again uses 1D marginalization, now at an input sigma confidence limit. \n",
        "\n",
        "By inputting `sigma=3.0` margnialization find the values spanning 99.7% of 1D PDF. Changing this to `sigma=1.0`\n",
        "would give the errors at the 68.3% confidence limit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "uv3_lists = [samps.values_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")]\n",
        "\n",
        "uv3_instances = [\n",
        "    samps.values_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "lv3_lists = [samps.values_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")]\n",
        "\n",
        "lv3_instances = [\n",
        "    samps.values_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "print(\"Errors Lists: \\n\")\n",
        "print(uv3_lists, \"\\n\")\n",
        "print(lv3_lists, \"\\n\")\n",
        "print(\"Errors Instances: \\n\")\n",
        "print(uv3_instances, \"\\n\")\n",
        "print(lv3_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute the upper and lower errors on each parameter at a given sigma limit.\n",
        "\n",
        "The `ue3` below signifies the upper error at 3 sigma. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ue3_lists = [samps.errors_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")]\n",
        "\n",
        "# ue3_instances = [\n",
        "#     samps.errors_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "# ]\n",
        "\n",
        "le3_lists = [samps.errors_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")]\n",
        "# le3_instances = [\n",
        "#     samps.errors_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "# ]\n",
        "\n",
        "print(\"Errors Lists: \\n\")\n",
        "print(ue3_lists, \"\\n\")\n",
        "print(le3_lists, \"\\n\")\n",
        "print(\"Errors Instances: \\n\")\n",
        "# print(ue3_instances, \"\\n\")\n",
        "# print(le3_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Sample Instance__\n",
        "\n",
        "A non-linear search retains every model that is accepted during the model-fit.\n",
        "\n",
        "We can create an instance of any model -- below we create an instance of the last accepted model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    instance = samples.from_sample_index(sample_index=-1)\n",
        "\n",
        "    print(instance.galaxies.source.bulge)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search Plots__\n",
        "\n",
        "The Probability Density Functions (PDF's) of the results can be plotted using the non-linear search in-built \n",
        "visualization tools.\n",
        "\n",
        "This fit used `Nautilus` therefore we use the `NestPlotter` for visualization, which wraps `Nautilus`'s in-built\n",
        "visualization tools.\n",
        "\n",
        "The `autofit_workspace/*/plots` folder illustrates other packages that can be used to make these plots using\n",
        "the standard output results formats (e.g. `GetDist.py`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    plotter = aplt.NestPlotter(samples=samples)\n",
        "#  plotter.corner_anesthetic()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Maximum Likelihood__\n",
        "\n",
        "The maximum log likelihood value of the model-fit can be estimated by simple taking the maximum of all log\n",
        "likelihoods of the samples.\n",
        "\n",
        "If different models are fitted to the same dataset, this value can be compared to determine which model provides\n",
        "the best fit (e.g. which model has the highest maximum likelihood)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print([max(samps.log_likelihood_list) for samps in agg.values(\"samples\")])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Bayesian Evidence__\n",
        "\n",
        "Nested sampling algorithms like Nautilus also estimate the Bayesian evidence (estimated via the nested sampling \n",
        "algorithm).\n",
        "\n",
        "The Bayesian evidence accounts for \"Occam's Razor\", whereby it penalizes models for being more complex (e.g. if a model\n",
        "has more parameters it needs to fit the da\n",
        "\n",
        "The Bayesian evidence is a better quantity to use to compare models, because it penalizes models with more parameters\n",
        "for being more complex (\"Occam's Razor\"). Comparisons using the maximum likelihood value do not account for this and\n",
        "therefore may unjustly favour more complex models.\n",
        "\n",
        "Using the Bayesian evidence for model comparison is well documented on the internet, for example the following\n",
        "wikipedia page: https://en.wikipedia.org/wiki/Bayes_factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Log Evidences: \\n\")\n",
        "print([samps.log_evidence for samps in agg.values(\"samples\")])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Lists__\n",
        "\n",
        "All results can alternatively be returned as a 1D list of values, by passing `as_instance=False`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    max_lh_list = samples.max_log_likelihood(as_instance=False)\n",
        "    print(\"Max Log Likelihood Model Parameters: \\n\")\n",
        "    print(max_lh_list, \"\\n\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The list above does not tell us which values correspond to which parameters.\n",
        "\n",
        "The following quantities are available in the `Model`, where the order of their entries correspond to the parameters \n",
        "in the `ml_vector` above:\n",
        "\n",
        " - `paths`: a list of tuples which give the path of every parameter in the `Model`.\n",
        " - `parameter_names`: a list of shorthand parameter names derived from the `paths`.\n",
        " - `parameter_labels`: a list of parameter labels used when visualizing non-linear search results (see below).\n",
        "\n",
        "For simple models like the one fitted in this tutorial, the quantities below are somewhat redundant. For the\n",
        "more complex models they are important for tracking the parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for model in agg.values(\"model\"):\n",
        "    print(model.paths)\n",
        "    print(model.parameter_names)\n",
        "    print(model.parameter_labels)\n",
        "    print(model.model_component_and_parameter_names)\n",
        "    print(\"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Latex__\n",
        "\n",
        "If you are writing modeling results up in a paper, you can use inbuilt latex tools to create latex table code which \n",
        "you can copy to your .tex document.\n",
        "\n",
        "By combining this with the filtering tools below, specific parameters can be included or removed from the latex.\n",
        "\n",
        "Remember that the superscripts of a parameter are loaded from the config file `notation/label.yaml`, providing high\n",
        "levels of customization for how the parameter names appear in the latex table. This is especially useful if your model\n",
        "uses the same model components with the same parameter, which therefore need to be distinguished via superscripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    latex = af.text.Samples.latex(\n",
        "        samples=samples,\n",
        "        median_pdf_model=True,\n",
        "        sigma=3.0,\n",
        "        name_to_label=True,\n",
        "        include_name=True,\n",
        "        include_quickmath=True,\n",
        "        prefix=\"Example Prefix \",\n",
        "        suffix=r\"\\\\[-2pt]\",\n",
        "    )\n",
        "\n",
        "    print(latex)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Ordering__\n",
        "\n",
        "The default ordering of the results can be a bit random, as it depends on how the sqlite database is built. \n",
        "\n",
        "The `order_by` method can be used to order by a property of the database that is a string, for example by ordering \n",
        "using the `unique_tag` (which we set up in the search as the `dataset_name`) the database orders results alphabetically\n",
        "according to dataset name.\n",
        "\n",
        "# agg = agg.order_by(agg.search.unique_tag)\n",
        "\n",
        "We can also order by a bool, for example making it so all completed results are at the front of the aggregator.\n",
        "\n",
        "# agg = agg.order_by(agg.search.is_complete)\n",
        "\n",
        "__Samples Filtering__\n",
        "\n",
        "The samples object has the results for all model parameter. It can be filtered to contain the results of specific \n",
        "parameters of interest.\n",
        "\n",
        "The basic form of filtering specifies parameters via their path, which was printed above via the model and is printed \n",
        "again below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = list(agg.values(\"samples\"))[0]\n",
        "\n",
        "print(\"Parameter paths in the model which are used for filtering:\")\n",
        "print(samples.model.paths)\n",
        "\n",
        "print(\"All parameters of the very first sample\")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "samples = samples.with_paths(\n",
        "    [\n",
        "        (\"galaxies\", \"lens\", \"mass\", \"einstein_radius\"),\n",
        "        (\"galaxies\", \"source\", \"bulge\", \"sersic_index\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"All parameters of the very first sample (containing only the lens mass's einstein radius and \"\n",
        "    \"source bulge's sersic index).\"\n",
        ")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "print(\n",
        "    \"Maximum Log Likelihood Model Instances (containing only the lens mass's einstein radius and \"\n",
        "    \"source bulge's sersic index):\\n\"\n",
        ")\n",
        "print(samples.max_log_likelihood(as_instance=False))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above, we specified each path as a list of tuples of strings. \n",
        "\n",
        "This is how the source code internally stores the path to different components of the model, but it is not in-line \n",
        "with the PyAutoLens API used to compose a model.\n",
        "\n",
        "We can alternatively use the following API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = list(agg.values(\"samples\"))[0]\n",
        "\n",
        "samples = samples.with_paths(\n",
        "    [\"galaxies.lens.mass.einstein_radius\", \"galaxies.source.bulge.sersic_index\"]\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"All parameters of the very first sample (containing only the lens mass's einstein radius and \"\n",
        "    \"source bulge's sersic index).\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above, we filtered the `Samples` but asking for all parameters which included the\n",
        "path (\"galaxies\", \"lens\", \"mass\", \"einstein_radius\").\n",
        "\n",
        "We can alternatively filter the `Samples` object by removing all parameters with a certain path. Below, we remove\n",
        "the centres of the mass model to be left with 10 parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = list(agg.values(\"samples\"))[0]\n",
        "\n",
        "print(\"Parameter paths in the model which are used for filtering:\")\n",
        "print(samples.model.paths)\n",
        "\n",
        "print(\"Parameters of first sample\")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "print(samples.model.total_free_parameters)\n",
        "\n",
        "samples = samples.without_paths(\n",
        "    [\n",
        "        # \"galaxies.lens.mass.centre\"),\n",
        "        \"galaxies.lens.mass.centre.centre_0\",\n",
        "        # \"galaxies.lens.mass.centre.centre_1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Parameters of first sample without the lens mass centre.\")\n",
        "print(samples.parameter_lists[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can keep and remove entire paths of the samples, for example keeping only the parameters of the lens or \n",
        "removing all parameters of the source's bulge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = list(agg.values(\"samples\"))[0]\n",
        "samples = samples.with_paths([\"galaxies.lens\"])\n",
        "print(\"Parameters of the first sample of the lens galaxy\")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "samples = list(agg.values(\"samples\"))[0]\n",
        "samples = samples.with_paths([\"galaxies.source.bulge\"])\n",
        "print(\"Parameters of the first sample without the source's bulge\")\n",
        "print(samples.parameter_lists[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}