{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results: Data Fitting\n",
        "=====================\n",
        "\n",
        "In this tutorial, we use the aggregator to load models and data from a non-linear search and use them to perform\n",
        "fits to the data.\n",
        "\n",
        "We show how to use these tools to inspect the maximum log likelihood model of a fit to the data, customize things\n",
        "like its visualization and also inspect fits randomly drawm from the PDF.\n",
        "\n",
        "__Interferometer__\n",
        "\n",
        "This script can easily be adapted to analyse the results of charge injection imaging model-fits.\n",
        "\n",
        "The only entries that needs changing are:\n",
        "\n",
        " - `ImagingAgg` -> `InterferometerAgg`.\n",
        " - `FitImagingAgg` -> `FitInterferometerAgg`.\n",
        " - `Clocker1D` -> `Clocker2D`.\n",
        " - `ImagingPlotter` -> `InterferometerPlotter`.\n",
        " - `FitImagingPlotter` -> `FitInterferometerPlotter`.\n",
        "\n",
        "Quantities specific to an interfometer, for example its uv-wavelengths real space mask, are accessed using the same API\n",
        "(e.g. `values(\"dataset.uv_wavelengths\")` and `.values{\"dataset.real_space_mask\"))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import os\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Aggregator__\n",
        "\n",
        "The functionality illustrated in this example only supports results loaded via the .sqlite database.\n",
        "\n",
        "We therefore do not load results from hard-disk like other scripts, but build a .sqlite database in order\n",
        "to create the `Aggregator` object.\n",
        "\n",
        "If you have not used the .sqlite database before, the `start_here.ipynb` example describes how to set it up and the API\n",
        "for the aggregator is identical from here on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "database_name = \"results_folder\"\n",
        "\n",
        "if path.exists(path.join(\"output\", f\"{database_name}.sqlite\")):\n",
        "    os.remove(path.join(\"output\", f\"{database_name}.sqlite\"))\n",
        "\n",
        "agg = af.Aggregator.from_database(\n",
        "    filename=f\"{database_name}.sqlite\", completed_only=False\n",
        ")\n",
        "\n",
        "agg.add_directory(directory=path.join(\"output\", database_name))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The masks we used to fit the lenses is accessible via the aggregator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_gen = agg.values(\"dataset.mask\")\n",
        "print([mask for mask in mask_gen])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The info dictionary we passed is also available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Info:\")\n",
        "info_gen = agg.values(\"info\")\n",
        "print([info for info in info_gen])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fits via Aggregator__\n",
        "\n",
        "Having performed a model-fit, we now want to interpret and visualize the results. In this example, we inspect \n",
        "the `Imaging` objects that gave good fits to the data. \n",
        "\n",
        "Using the API shown in the `start_here.py` example this would require us to create a `Samples` object and manually \n",
        "compose our own `Imaging` object. For large datasets, this would require us to use generators to ensure it is \n",
        "memory-light, which are cumbersome to write.\n",
        "\n",
        "This example therefore uses the `ImagingAgg` object, which conveniently loads the `Imaging` objects of every fit via \n",
        "generators for us. \n",
        "\n",
        "We get a dataset generator via the `al.agg.ImagingAgg` object, where this `dataset_gen` contains the maximum log\n",
        "likelihood `Imaging `object of every model-fit.\n",
        "\n",
        "The `dataset_gen` returns a list of `Imaging` objects, as opposed to just a single `Imaging` object. This is because\n",
        "only a single `Analysis` class was used in the model-fit, meaning there was only one `Imaging` dataset that was\n",
        "fit. \n",
        "\n",
        "The `multi` package of the workspace illustrates model-fits which fit multiple datasets \n",
        "simultaneously, (e.g. multi-wavelength imaging)  by summing `Analysis` objects together, where the `dataset_list` \n",
        "would contain multiple `Imaging` objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_agg = al.agg.ImagingAgg(aggregator=agg)\n",
        "dataset_gen = dataset_agg.dataset_gen_from()\n",
        "\n",
        "for dataset_list in dataset_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    dataset = dataset_list[0]\n",
        "\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use the aggregator to load a generator containing the fit of the maximum log likelihood model (and therefore \n",
        "fit) to each dataset.\n",
        "\n",
        "Analogous to the `dataset_gen` above returning a list with one `Imaging` object, the `fit_gen` returns a list of\n",
        "`FitImaging` objects, because only one `Analysis` was used to perform the model-fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg = al.agg.FitImagingAgg(aggregator=agg)\n",
        "fit_gen = fit_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "for fit_list in fit_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    fit = fit_list[0]\n",
        "\n",
        "    fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "    fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Modification__\n",
        "\n",
        "The `FitImagingAgg` allow us to modify the fit settings. \n",
        "\n",
        "However, we can change these settings such that the fit is performed differently. For example, what if I wanted to see \n",
        "how the fit looks where the pixelization didn`t use a border? \n",
        "\n",
        "You can do this by passing the settings objects, which overwrite the ones used by the analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg = al.agg.FitImagingAgg(\n",
        "    aggregator=agg,\n",
        "    settings_inversion=al.SettingsInversion(use_border_relocator=False),\n",
        ")\n",
        "fit_gen = fit_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "for fit_list in fit_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    fit = fit_list[0]\n",
        "\n",
        "    fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "    fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Visualization Customization__\n",
        "\n",
        "The benefit of inspecting fits using the aggregator, rather than the files outputs to the hard-disk, is that we can \n",
        "customize the plots using the `MatPlot1D` and `MatPlot2D` objects..\n",
        "\n",
        "Below, we create a new function to apply as a generator to do this. However, we use a convenience method available \n",
        "in the aggregator package to set up the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg = al.agg.FitImagingAgg(aggregator=agg)\n",
        "fit_gen = fit_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "for fit_list in fit_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    fit = fit_list[0]\n",
        "\n",
        "    mat_plot = aplt.MatPlot2D(\n",
        "        figure=aplt.Figure(figsize=(12, 12)),\n",
        "        title=aplt.Title(label=\"Custom Image\", fontsize=24),\n",
        "        yticks=aplt.YTicks(fontsize=24),\n",
        "        xticks=aplt.XTicks(fontsize=24),\n",
        "        cmap=aplt.Cmap(norm=\"log\", vmax=1.0, vmin=1.0),\n",
        "        colorbar_tickparams=aplt.ColorbarTickParams(labelsize=20),\n",
        "        units=aplt.Units(in_kpc=True),\n",
        "    )\n",
        "\n",
        "    fit_plotter = aplt.FitImagingPlotter(fit=fit, mat_plot_2d=mat_plot)\n",
        "    fit_plotter.figures_2d(normalized_residual_map=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Making this plot for a paper? You can output it to hard disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg = al.agg.FitImagingAgg(aggregator=agg)\n",
        "fit_gen = fit_agg.max_log_likelihood_gen_from()\n",
        "\n",
        "for fit_list in fit_gen:\n",
        "    # Only one `Analysis` so take first and only dataset.\n",
        "    fit = fit_list[0]\n",
        "\n",
        "    mat_plot = aplt.MatPlot2D(\n",
        "        title=aplt.Title(label=\"Hey\"),\n",
        "        output=aplt.Output(\n",
        "            path=path.join(\"output\", \"path\", \"of\", \"file\"),\n",
        "            filename=\"publication\",\n",
        "            format=\"png\",\n",
        "        ),\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Errors (Random draws from PDF)__\n",
        "\n",
        "In the `examples/models.py` example we showed how `Tracer objects could be randomly drawn form the Probability \n",
        "Distribution Function, in order to quantity things such as errors.\n",
        "\n",
        "The same approach can be used with `FitImaging` objects, to investigate how the properties of the fit vary within\n",
        "the errors (e.g. showing source reconstructions fot different fits consistent with the errors)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_agg = al.agg.FitImagingAgg(aggregator=agg)\n",
        "fit_gen = fit_agg.randomly_drawn_via_pdf_gen_from(total_samples=2)\n",
        "\n",
        "\n",
        "for fit_list_gen in fit_gen:  # Total samples 2 so fit_list_gen contains 2 fits.\n",
        "    for fit_list in fit_list_gen:  # Iterate over each fit of total_samples=2\n",
        "        # Only one `Analysis` so take first and only dataset.\n",
        "        fit = fit_list[0]\n",
        "\n",
        "    fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "    fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}