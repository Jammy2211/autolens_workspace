{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Written soon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"hi\")\n",
        "\n",
        "# \"\"\"\n",
        "# __Sub Gridding__\n",
        "#\n",
        "# A grid can also have a sub-grid, defined via its `sub_size`, which defines how each pixel on the 2D grid is split\n",
        "# into sub-pixels of size (`sub_size` x `sub_size`).\n",
        "#\n",
        "# These additional sub-pixels are used to perform calculations more accurately. For example, for the 2D image the\n",
        "# values can be computed at every sub-pixel coordinate and binned-up, as opposed to computing the image only at the\n",
        "# centre of each image pixel.\n",
        "#\n",
        "# This approximates more closely how light is observed on a telescope, where it is the full surface brightness\n",
        "# distribution of the source over the pixel that is observed.\n",
        "#\n",
        "# The `sub_shape_native` and `sub_shape_slim` properties of the grid show that it has many additional coordinates\n",
        "# corresponding to the 4x4 grid of sub-pixels in each image pixel.\n",
        "# \"\"\"\n",
        "# grid_sub = al.Grid2D.uniform(shape_native=(3, 3), pixel_scales=0.1, sub_size=2)\n",
        "#\n",
        "# print(grid_sub.sub_shape_native)\n",
        "# print(grid_sub.sub_shape_slim)\n",
        "#\n",
        "# \"\"\"\n",
        "# The image computed using this grid does not have a `native` shape (5,5), but instead shape (20, 20). This is because\n",
        "# each image pixel has been split into a 4x4 sub pixel (e.g. 4 * 5 = 20):\n",
        "# \"\"\"\n",
        "# image = tracer.image_2d_from(grid=grid_sub)\n",
        "#\n",
        "# print(image.native.shape)\n",
        "# print(image.shape)\n",
        "#\n",
        "# \"\"\"\n",
        "# To estimate the image on our original 5x5 grid, we can use the `binned` property which bins up every 4x4 grid\n",
        "# of sub-pixels in each image pixel.\n",
        "# \"\"\"\n",
        "# print(image.binned.slim)\n",
        "# print(image.binned.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorial: Sub-Grids (Optional)\n",
        "==============================\n",
        "\n",
        "Throughout chapter 1, we used two dimensional grids of $(y,x)$ coordinates to calculate properties of light and mass\n",
        "profiles and perform lensing ray-tracing calculations.\n",
        "\n",
        "Sub-grids perform these calculations on an up-sampled grid containing multiple 'sub-pixels' for each pixel on the grid.\n",
        "Light profiles and mass profiles are then evaluated on every $(y,x)$ sub-coordinate and 'binned up' as the mean of\n",
        "these values, ensuring their properties are calculated accurately.\n",
        "\n",
        "This tutorial describes sub-grids. It is considered optional as the default sub-grid options of **PyAutoLens** are\n",
        "sufficient for the majority of calculations to be performed accurately without customization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To create a `Grid2D` with a sub-grid we input a `sub_size`, which defines how each pixel on the 2D grid is split \n",
        "into sub-pixels of size (`sub_size` x `sub_size`). \n",
        "\n",
        "These additional pixels are used to perform calculations more accurately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(shape_native=(100, 100), pixel_scales=0.05, sub_size=2)\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=grid)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We specified a `sub_size` of 2 above, therefore we expect 4 (2 x 2) times more sub-pixels than pixels. We can see this \n",
        "is the case by inspecting the `Grid2D` `sub_shape_native` and `sub_shape_slim` attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(grid.sub_shape_native)\n",
        "print(grid.sub_shape_slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first four pixels of this sub-grid correspond to the first four sub-pixels in the first pixel of the grid. These\n",
        "four pixels for a sub-grid inside this image pixel as follows:\n",
        "\n",
        "pixel 1\n",
        "\n",
        "                 ______\n",
        "\n",
        "              I         I\n",
        "\n",
        "              I         I  o = $(y,x)$ centre of\n",
        "\n",
        " y = 2.475\"   I    o    I       Grid2D coordinate.\n",
        "\n",
        "              I         I\n",
        "\n",
        "              I_________I\n",
        "\n",
        "              x = -2.475\n",
        "\n",
        "\n",
        "Sub-pixels 1, 2, 3 & 4\n",
        "\n",
        "                 ______\n",
        "\n",
        "              I         I\n",
        "\n",
        "              I  o   o  I  o = $(y,x)$ centre of sub\n",
        "\n",
        " y = 2.475\"   I         I       Grid2D coordinates.\n",
        "\n",
        "              I  o   o  I\n",
        "\n",
        "              I_________I\n",
        "\n",
        "              x = -2.475\n",
        "\n",
        "The sub-pixels coordinates are spaced uniformly between the pixel's edges (which are at y = (2.45\", 2.5\") and \n",
        "x = (-2.5\". -2.45\") )\n",
        "\n",
        "We can access the sub-pixel coordinates via the `native` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"(y,x) sub-pixel 0 (of pixel 0):\")\n",
        "print(grid.native[0, 0])\n",
        "print(\"(y,x) sub-pixel 1 (of pixel 0):\")\n",
        "print(grid.native[0, 1])\n",
        "print(\"(y,x) sub-pixel 2 (of pixel 0):\")\n",
        "print(grid.native[1, 0])\n",
        "print(\"(y,x) sub-pixel 3 (of pixel 0):\")\n",
        "print(grid.native[1, 1])\n",
        "print(\"(y,x) sub-pixel 0 (of pixel 1):\")\n",
        "print(grid.native[0, 2])\n",
        "print(\"etc.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The sub-pixels can also be accessed via `slim`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"(y,x) sub-pixel 0 (of pixel 0):\")\n",
        "print(grid.slim[0])\n",
        "print(\"(y,x) sub-pixel 1 (of pixel 0):\")\n",
        "print(grid.slim[1])\n",
        "print(\"(y,x) sub-pixel 2 (of pixel 0):\")\n",
        "print(grid.slim[2])\n",
        "print(\"(y,x) sub-pixel 3 (of pixel 0):\")\n",
        "print(grid.slim[3])\n",
        "print(\"(y,x) sub-pixel 0 (of pixel 1):\")\n",
        "print(grid.slim[4])\n",
        "print(\"etc.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From a sub-grid, we can compute the binned grid, which is the mean of all $(y, x)$ sub-coordinates in a sub-pixel. \n",
        "This therefore reduces to the native grid without sub-gridding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"(t,x) of pixel 0 via mean of its 4 sub-pixel coordinates\")\n",
        "print(grid.binned.native[0, 0])\n",
        "print(\"(t,x) of pixel 1 via mean of its 4 sub-pixel coordinates\")\n",
        "print(grid.binned.slim[1])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The values computed when we call a `_from_grid` method (e.g. the image intensities) are calculated on this sub-grid. \n",
        "The `Array2D` containing the values therefore has the same `sub_shape_native` and `sub_shape_slim` dimensions as the \n",
        "sub-grid, which in this case is a 200 x 200 grid.\n",
        "\n",
        "The example below shows this for the `image_2d_from` of a light profile."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "sersic_light_profile = al.lp.Sersic(\n",
        "    centre=(0.0, 0.0),\n",
        "    ell_comps=(0.0, 0.111111),\n",
        "    intensity=1.0,\n",
        "    effective_radius=1.0,\n",
        "    sersic_index=2.5,\n",
        ")\n",
        "\n",
        "image = sersic_light_profile.image_2d_from(grid=grid)\n",
        "\n",
        "print(image.sub_shape_native)\n",
        "print(image.sub_shape_slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we have seen, this can be accessed via the `native` and `slim` attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Intensity of sub-pixel 0 (of pixel 0):\")\n",
        "print(image.native[0, 0])\n",
        "print(\"Intensity of sub-pixel 1 (of pixel 0):\")\n",
        "print(image.slim[1])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The benefit of calculating all values on a sub-grid is that we can now bin them up to the native resolution of the\n",
        "`Grid2D`, using the same `binned` attribute introduced above.\n",
        "\n",
        "The benefit of binning is now clear: binning will compute the mean of all intensity values of the sub-pixels in each \n",
        "pixel. If, within a pixel, the intensity values of the light profile are rapidly changing, this will give a more \n",
        "accurate estimate of the average intensity within that pixel compared to using a `sub_size=1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Intensity of pixel 0 via mean of its 4 sub-pixels\")\n",
        "print(image.binned.native[0, 0])\n",
        "print(\"Intensity of pixel 1 via mean of its 4 sub-pixels\")\n",
        "print(image.binned.slim[1])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sub-grids can also be used for all the quantities output by a mass profile, albeit we will omit showing this here.\n",
        "\n",
        "The purpose of sub-gridding is therefore now clear, it allows us to precisely estimate the intensity of light of a \n",
        "light profile in an image pixel. When an image-pixel is far away from the centre of a light profile, sub-gridding\n",
        "is not important, because within a pixel the change in intensity negligible and evaluating it at its centre is \n",
        "sufficiently accurate.\n",
        "\n",
        "There are two circumstances where sub-gridding because important:\n",
        "\n",
        " - When an image pixel is near the centre of a light profile, because the intensity of the light profile may now \n",
        " rapidly change over the area of the image-pixel.\n",
        "\n",
        " - When a mass profile ray-traces many light rays near the centre of a light profile in the source plane, creating a\n",
        " region of high magnification. The intensity values in the image pixel will again trace over regions of the source\n",
        "where the evaluated intensity rapidly changes. \n",
        "\n",
        "**PyAutoLens** also provides a `OverSamplingIterate` input to a grid, which uses iteratively higher and higher levels \n",
        "of sub gridding to evaluate a `from_grid_` method until a threshold level of accuracy is met. This is used in many of \n",
        "the example `simulator` scripts to ensure that the images of simulated lenses are evaluated accurately. \n",
        "\n",
        "This grid is not used by default in the majority of example scripts and a `sub_size=1` is assumed to ensure faster \n",
        "**PyAutoLens** run times. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}