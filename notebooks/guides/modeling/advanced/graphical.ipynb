{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling: Graphical\n",
        "===================\n",
        "\n",
        "The example scripts throughout the workspace have focused on modeling **individual strong lens datasets**.\n",
        "From each fit, you may have inspected lens properties (e.g., Einstein radius) and source properties\n",
        "(e.g., magnification). You may even have analyzed many lenses one-by-one and combined their results to study\n",
        "global trends in galaxy formation or cosmology.\n",
        "\n",
        "However, fitting each lens independently does **not** make full use of the information contained in a large\n",
        "sample. Many properties are expected to be **shared across lenses** (e.g., population-level mass slopes,\n",
        "cosmological parameters), and treating them independently ignores this shared structure.\n",
        "\n",
        "In this example, we demonstrate how to fit **multiple lenses simultaneously** using a **graphical model**.\n",
        "A graphical model links parameters across separate lens fits, explicitly defining which parameters are unique\n",
        "to each dataset and which are shared. These links can be arbitrarily complex, enabling joint analysis across\n",
        "diverse datasets with structured relationships between model components.\n",
        "\n",
        "Here, we illustrate a cosmological application: inferring the **Hubble constant (H0)** from time-delay lenses.\n",
        "A graphical model links the mass models across multiple lenses and includes a **shared H0 parameter**, allowing\n",
        "a joint inference that improves cosmological constraints compared to individual fits.\n",
        "\n",
        "Graphical models form the foundation of **hierarchical modeling**, where the parameters of individual lenses are\n",
        "assumed to be drawn from a parent distribution (see `guides/modeling/hierarchical`). Hierarchical approaches can\n",
        "extract significantly more information from large samples than fitting each dataset independently. The example\n",
        "shows how the power-law `slope` of each lens's mass distribution is modeled as being drawn from a shared parent\n",
        "Gaussian distribution, whose hyper-parameters (mean and variance) are inferred from the data.\n",
        "\n",
        "This example illustrates graphical models using point-source datasets and the Hubble Constant, but it is a clear\n",
        "and intuitive model whereby a single shared parameter (H0) links multiple lenses. The API and concepts demonstrated\n",
        "here can be directly applied to imaging and interferometer datasets, and more complex models with many shared can\n",
        "be composed and fitted using the same framework."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from pathlib import Path\n",
        "import autolens as al\n",
        "import autofit as af"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Initialization__\n",
        "\n",
        "Load 3 simulated time-delay lens datasets which are all simulated with different mass models but \n",
        "the same Hubble constant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_label = \"samples\"\n",
        "dataset_type = \"point_source\"\n",
        "dataset_sample_name = \"hubble_constant_time_delays\"\n",
        "\n",
        "dataset_path = Path(\"dataset\") / dataset_type / dataset_label / dataset_sample_name\n",
        "\n",
        "total_datasets = 3\n",
        "\n",
        "dataset_list = []\n",
        "\n",
        "for dataset_index in range(total_datasets):\n",
        "    dataset_sample_path = dataset_path / f\"dataset_{dataset_index}\"\n",
        "\n",
        "    dataset = al.from_json(\n",
        "        file_path=dataset_sample_path / \"point_dataset_with_time_delays.json\",\n",
        "    )\n",
        "\n",
        "    dataset_list.append(dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Solver__\n",
        "\n",
        "We set up the `PointSolver`, which is used to compute the multiple images of the point source in the image-plane.\n",
        "\n",
        "There are no special settings or inputs for the fitting of time_delays, therefore the `PointSolver` is set up in the same way\n",
        "as in the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(100, 100),\n",
        "    pixel_scales=0.2,  # <- The pixel-scale describes the conversion from pixel units to arc-seconds.\n",
        ")\n",
        "\n",
        "solver = al.PointSolver.for_grid(\n",
        "    grid=grid, pixel_scale_precision=0.001, magnification_threshold=0.1, xp=np\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our model using `Model` objects, which represent the lenses we fit to our data.\n",
        "\n",
        "This graphical model creates a non-linear parameter space that has parameters for every lens mass and source galaxy point\n",
        "source in our sample. In this example, there are 3 lenses each with their own model, therefore:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` with fixec centre [3 parameters].\n",
        "\n",
        " - The source galaxy's light is a point `Point` [2 parameters].\n",
        "\n",
        " - There is a single cosmological shared free parameter, `H0` [1 parameter]\n",
        "\n",
        " - There are 3 strong lenses in our graphical model [(3 x 5) + 1 = 16 parameters]. \n",
        "\n",
        "The overall dimensionality of parameter space is therefore N=16."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cosmology = af.Model(al.cosmo.FlatwCDMWrap)\n",
        "\n",
        "cosmology.H0 = af.UniformPrior(lower_limit=0.0, upper_limit=150.0)\n",
        "\n",
        "model_list = []\n",
        "\n",
        "for model_index in range(total_datasets):\n",
        "    # Lens:\n",
        "\n",
        "    mass = af.Model(al.mp.Isothermal)\n",
        "    mass.centre.centre_0 = 0.0\n",
        "    mass.centre.centre_1 = 0.0\n",
        "\n",
        "    lens = af.Model(al.Galaxy, redshift=0.5, mass=mass)\n",
        "\n",
        "    # Source:\n",
        "\n",
        "    point_0 = af.Model(al.ps.Point)\n",
        "\n",
        "    source = af.Model(al.Galaxy, redshift=1.0, point_0=point_0)\n",
        "\n",
        "    # Overall Lens Model:\n",
        "\n",
        "    model = af.Collection(\n",
        "        galaxies=af.Collection(lens=lens, source=source),\n",
        "        cosmology=cosmology,\n",
        "    )\n",
        "\n",
        "    model_list.append(model)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "For each dataset we now create a corresponding `AnalysisPoint` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = []\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    analysis = al.AnalysisPoint(dataset=dataset, solver=solver)\n",
        "\n",
        "    analysis_list.append(analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis Factors__\n",
        "\n",
        "Above, we created a `model_list` containing three lens models, each sharing the same prior on `H0`.  \n",
        "We also loaded three datasets and assigned each one an `Analysis` class, which defines how a model\n",
        "is evaluated against that dataset.\n",
        "\n",
        "We now pair each model with its corresponding `Analysis` object, telling **PyAutoLens** that:\n",
        "\n",
        "- `model_list[0]` is fit to `dataset_list[0]` using `analysis_list[0]`\n",
        "- `model_list[1]` is fit to `dataset_list[1]` using `analysis_list[1]`\n",
        "- `model_list[2]` is fit to `dataset_list[2]` using `analysis_list[2]`\n",
        "\n",
        "The point where a `Model` and an `Analysis` meet is called an **`AnalysisFactor`**.\n",
        "\n",
        "This terminology reflects that we are building a **factor graph**:  \n",
        "each *factor* corresponds to a node that contains (i) a dataset, (ii) a model for that dataset, and (iii) the\n",
        "process that fits them together. The links between these nodes define the global structure of the graphical model\n",
        "we are fitting, including shared parameters such as `H0`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_factor_list = []\n",
        "\n",
        "for model, analysis in zip(model_list, analysis_list):\n",
        "\n",
        "    analysis_factor = af.AnalysisFactor(prior_model=model, analysis=analysis)\n",
        "\n",
        "    analysis_factor_list.append(analysis_factor)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Factor Graph__\n",
        "\n",
        "We now combine our `AnalysisFactor` objects to form a **factor graph**.\n",
        "\n",
        "What is a factor graph?  \n",
        "A factor graph is the explicit representation of our graphical model. It defines:\n",
        "\n",
        "- the individual model components used to fit each dataset (e.g., the three `Collection` lens + source models), and\n",
        "- how their parameters are linked or shared (e.g., each lens has its own mass distribution, but all share the same\n",
        "  cosmological parameter `H0`).\n",
        "\n",
        "Although PyAutoFit does not yet visualize factor graphs, the conceptual structure is straightforward. A factor graph\n",
        "consists of:\n",
        "\n",
        "- **Nodes** \u2014 each node corresponds to an `AnalysisFactor`, meaning a specific dataset paired with a model used to fit it.\n",
        "\n",
        "- **Links** \u2014 these represent shared model components or parameters across nodes (e.g., a single `H0` value shared\n",
        "  across all lenses), ensuring they retain the same value when fitting multiple datasets.\n",
        "\n",
        "Together, the nodes and links define the full, coupled model that is fit across all datasets simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "factor_graph = af.FactorGraphModel(*analysis_factor_list, use_jax=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit will use the factor graph's `global_prior_model`, which uses the models contained in every analysis factor \n",
        "to contrast the overall global model that is fitted.\n",
        "\n",
        "Printing the `info` attribute of this model reveals the overall structure of the model, which is grouped in terms\n",
        "of the analysis factors and therefore datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph.global_prior_model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We can now create a non-linear search and used it to the fit the factor graph, using its `global_prior_model` property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"modeling\"),\n",
        "    name=\"graphical\",\n",
        "    n_live=150,\n",
        ")\n",
        "\n",
        "result = search.fit(model=factor_graph.global_prior_model, analysis=factor_graph)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result's `info` attribute shows that the result is expressed following the same struture of analysis factors\n",
        "that the `global_prior_model.info` attribute revealed above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "The graphical model estimated the Hubble constant by fitting all three lenses **simultaneously**, making full use of\n",
        "the information shared across the sample.\n",
        "\n",
        "If you instead fit each lens independently and compute `H0` manually from each result, the combined uncertainty on\n",
        "`H0` will be larger than the uncertainty from the graphical model. This demonstrates the power of **joint inference**\n",
        "using graphical models.\n",
        "\n",
        "Even if you tried to combine the independent fits using importance sampling, you would still not recover the same\n",
        "precision or accuracy. In addition, the prior on `H0` would be applied three times (once per lens), biasing the\n",
        "inference.\n",
        "\n",
        "This example used a simple shared parameter (the Hubble constant) across multiple lenses. The same framework can be\n",
        "extended to far more complex models, with many shared or linked parameters, enabling powerful hierarchical and\n",
        "population-level inference for large lens samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}