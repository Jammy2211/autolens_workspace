{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling: Hierarchical\n",
        "======================\n",
        "\n",
        "A hierarchical model assumes that certain model parameters are drawn from a **shared parent distribution**\n",
        "(e.g. a Gaussian). When we fit such a model, the parameters of this parent distribution (such as its `mean` and\n",
        "`sigma`) become explicit free parameters in the inference. Scientifically, these parent-distribution parameters\n",
        "are often of greatest interest because they describe **population-level trends**, rather than the properties of\n",
        "individual lenses.\n",
        "\n",
        "In this example, we fit a hierarchical model to a sample of three strong gravitational lenses. We assume that\n",
        "the **power-law slope** of each lens\u2019s mass distribution is drawn from a shared Gaussian distribution. This is\n",
        "well motivated: observational studies find that the slopes of early-type lens galaxies are well approximated by\n",
        "a Gaussian with mean \u2248 2.06 and sigma \u2248 0.20.\n",
        "\n",
        "To perform this fit, we use a graphical model (see `guides/modeling/advanced/graphical`). The model-composition\n",
        "API makes it straightforward to fit multiple datasets simultaneously while linking parameters via a shared\n",
        "parent distribution.\n",
        "\n",
        "Note that hierarchical models **do not have to be fit through graphical models**\u2014the same API can be applied to\n",
        "single-object problems where multiple components of a lens share a parent distribution. For example, a single\n",
        "lens could contain multiple mass components whose parameters are drawn from a common parent distribution. While\n",
        "no such example is included in the current workspace, the structure shown here could be adapted easily for that case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import autolens as al\n",
        "import autofit as af\n",
        "from pathlib import Path"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "For each lens dataset in our sample we set up the correct path and load it by iterating over a for loop. \n",
        "\n",
        "We are loading a different dataset to the previous tutorials, where the lenses only have a single bulge component\n",
        "which each have different Sersic indexes which are drawn from a parent Gaussian distribution with a mean value \n",
        "of 2.0 and sigma of 0.5.\n",
        "\n",
        "This data is not automatically provided with the autolens workspace, and must be first simulated by running the \n",
        "script `autolens_workspace/scripts/advanced/graphical/simulator/samples/advanced/mass_power_law.py`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_label = \"samples\"\n",
        "dataset_type = \"imaging\"\n",
        "dataset_sample_name = \"mass_power_law\"\n",
        "\n",
        "dataset_path = Path(\"dataset\", dataset_type, dataset_label, dataset_sample_name)\n",
        "\n",
        "total_datasets = 3\n",
        "\n",
        "dataset_list = []\n",
        "\n",
        "for dataset_index in range(total_datasets):\n",
        "    dataset_sample_path = Path(dataset_path, f\"dataset_{dataset_index}\")\n",
        "\n",
        "    dataset_list.append(\n",
        "        al.Imaging.from_fits(\n",
        "            data_path=Path(dataset_sample_path, \"data.fits\"),\n",
        "            psf_path=Path(dataset_sample_path, \"psf.fits\"),\n",
        "            noise_map_path=Path(dataset_sample_path, \"noise_map.fits\"),\n",
        "            pixel_scales=0.1,\n",
        "        )\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "masked_imaging_list = []\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    mask = al.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "    over_sample_size = al.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "        grid=dataset.grid,\n",
        "        sub_size_list=[4, 2, 1],\n",
        "        radial_list=[0.3, 0.6],\n",
        "        centre_list=[(0.0, 0.0)],\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)\n",
        "\n",
        "    masked_imaging_list.append(dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "For each dataset we now create a corresponding `AnalysisImaging` class, as we are used to doing for `Imaging` data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = []\n",
        "\n",
        "for masked_dataset in masked_imaging_list:\n",
        "    analysis = al.AnalysisImaging(dataset=masked_dataset)\n",
        "\n",
        "    analysis_list.append(analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Individual Factors__\n",
        "\n",
        "We first set up a model for each lens, with an `PowerLawSph` mass and `ExponentialSph` bulge, which we will use to \n",
        "fit the hierarchical model.\n",
        "\n",
        "Note that the `PowerLawSph` mass model has a `slope` parameter, which we will assume is drawn from a shared parent\n",
        "Gaussian distribution, albeit building this into the model is done later in this script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_list = []\n",
        "\n",
        "for dataset_index in range(total_datasets):\n",
        "    lens = af.Model(al.Galaxy, redshift=0.5, mass=al.mp.PowerLawSph)\n",
        "    lens.mass.centre = (0.0, 0.0)\n",
        "\n",
        "    source = af.Model(al.Galaxy, redshift=1.0, bulge=al.lp_linear.ExponentialCoreSph)\n",
        "\n",
        "    model = af.Collection(galaxies=af.Collection(lens=lens, source=source))\n",
        "\n",
        "    model_list.append(model)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis Factors__\n",
        "\n",
        "Now we have our `Analysis` classes and model components, we can compose our `AnalysisFactor`'s.\n",
        "\n",
        "These are composed in the same way as for the graphical model and are described in detail in the\n",
        "`guides/modeling/advanced/graphical` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_factor_list = []\n",
        "\n",
        "for model, analysis in zip(model_list, analysis_list):\n",
        "    analysis_factor = af.AnalysisFactor(prior_model=model, analysis=analysis)\n",
        "\n",
        "    analysis_factor_list.append(analysis_factor)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We now compose the hierarchical model that we fit, using the individual model components created above.\n",
        "\n",
        "We first create a `HierarchicalFactor`, which represents the parent Gaussian distribution from which we will assume \n",
        "that the `slope` of each individual lens mass model is drawn. \n",
        "\n",
        "For this parent `Gaussian`, we have to place priors on its `mean` and `sigma`, given that they are parameters in our\n",
        "model we are ultimately fitting for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "hierarchical_factor = af.HierarchicalFactor(\n",
        "    af.GaussianPrior,\n",
        "    mean=af.TruncatedGaussianPrior(\n",
        "        mean=2.0, sigma=1.0, lower_limit=0.0, upper_limit=100.0\n",
        "    ),\n",
        "    sigma=af.TruncatedGaussianPrior(\n",
        "        mean=0.5, sigma=0.5, lower_limit=0.0, upper_limit=100.0\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now add each of the individual mass `slope` parameters to the `hierarchical_factor`.\n",
        "\n",
        "This composes the hierarchical model whereby the individual `slope` of every light model in our dataset is now \n",
        "assumed to be drawn from a shared parent distribution. It is the `mean` and `sigma` of this distribution we are hoping \n",
        "to estimate.\n",
        "\n",
        "The code below is not specific to graphical models and could be applied to any model where certain parameters are\n",
        "assumed to be drawn from a shared parent distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for model in model_list:\n",
        "    hierarchical_factor.add_drawn_variable(model.galaxies.lens.mass.slope)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Factor Graph__\n",
        "\n",
        "We now create the factor graph for this model, using the list of `AnalysisFactor`'s and the hierarchical factor.\n",
        "\n",
        "Again, this code is described in detail in the `guides/modeling/advanced/graphical` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "factor_graph = af.FactorGraphModel(\n",
        "    *analysis_factor_list, hierarchical_factor, use_jax=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The factor graph model `info` attribute shows that the hierarchical factor's parameters are included in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(factor_graph.global_prior_model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We can now create a non-linear search and used it to the fit the factor graph, using its `global_prior_model` property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"modeling\"),\n",
        "    name=\"hierarchical\",\n",
        "    n_live=150,\n",
        ")\n",
        "\n",
        "result = search.fit(model=factor_graph.global_prior_model, analysis=factor_graph)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result's `info` attribute shows the result, including the hierarchical factor's parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now inspect the inferred value of hierarchical factor's mean and sigma.\n",
        "\n",
        "We see that they are consistent with the input values of `mean=2.0` and `sigma=0.2`, which are\n",
        "the values used to simulate the lens dataset sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "\n",
        "mean = samples.median_pdf(as_instance=False)[-2]\n",
        "\n",
        "u1_error = samples.values_at_upper_sigma(sigma=1.0)[-2]\n",
        "l1_error = samples.values_at_lower_sigma(sigma=1.0)[-2]\n",
        "\n",
        "u3_error = samples.values_at_upper_sigma(sigma=3.0)[-2]\n",
        "l3_error = samples.values_at_lower_sigma(sigma=3.0)[-2]\n",
        "\n",
        "print(\n",
        "    \"Inferred value of the mean of the parent hierarchical distribution for the mass model slopes: \\n\"\n",
        ")\n",
        "print(f\"{mean} ({l1_error} {u1_error}) [1.0 sigma confidence intervals]\")\n",
        "print(f\"{mean} ({l3_error} {u3_error}) [3.0 sigma confidence intervals]\")\n",
        "\n",
        "scatter = samples.median_pdf(as_instance=False)[-2]\n",
        "\n",
        "u1_error = samples.values_at_upper_sigma(sigma=1.0)[-1]\n",
        "l1_error = samples.values_at_lower_sigma(sigma=1.0)[-1]\n",
        "\n",
        "u3_error = samples.values_at_upper_sigma(sigma=3.0)[-1]\n",
        "l3_error = samples.values_at_lower_sigma(sigma=3.0)[-1]\n",
        "\n",
        "print(\n",
        "    \"Inferred value of the scatter (the sigma value of the Gassuain) of the parent hierarchical distribution for the mass model slopes: \\n\"\n",
        ")\n",
        "print(f\"{scatter} ({l1_error} {u1_error}) [1.0 sigma confidence intervals]\")\n",
        "print(f\"{scatter} ({l3_error} {u3_error}) [3.0 sigma confidence intervals]\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Concept__\n",
        "\n",
        "A hierarchical model yields more precise and accurate estimates of the parent distribution\u2019s parameters, but also\n",
        "the individual parameters fit to each lens. \n",
        "\n",
        "This happens because **each dataset informs the shared distribution**, and the distribution in turn constrains \n",
        "each individual dataset. This can be described as **\u201cthe datasets talking to one another.\u201d**\n",
        "\n",
        "For example, suppose that when fit alone, `dataset_0` yields a weak constraint on the mass\u2013slope parameter, spanning\n",
        "1.3 \u2192 2.7 (1\u03c3). Now imagine that, when we include the other datasets, the hierarchical distribution is well constrained\n",
        "to `mean = 2.0 \u00b1 0.1` and `sigma = 0.10 \u00b1 0.05`. This shared information tells us that values far from ~2.0 are unlikely,\n",
        "so `dataset_0` will be **forced toward physically plausible solutions**, even though it could not infer this on its own.\n",
        "\n",
        "In large hierarchical fits with many lenses, this \u201ccommunication\u201d between datasets can break degeneracies and extract\n",
        "substantially more information from the sample than independent fits ever could. For inference on parameters like\n",
        "cosmology, this shrinkage of uncertainties on lens mass model parameters can lead to significantly tighter constraints\n",
        "on the cosmological parameters themselves.\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "Hierarchical models enable us to infer **population-level trends** from large lens samples. Using graphical modeling,\n",
        "we can easily compose complex models with shared parameters and hierarchical structure across many datasets.\n",
        "\n",
        "However, scaling to large graphs introduces challenges. As models grow in size, poor sampling can lead to local maxima,\n",
        "and fitting many datasets simultaneously can become computationally expensive (in both CPU time and memory).\n",
        "\n",
        "The next tutorial introduces **Expectation Propagation (EP)**, a framework that partitions the graphical model into\n",
        "many small sub-fits\u2014one for each node in the factor graph. Each node fit passes information to its neighbors, allowing\n",
        "us to fit graphs with hundreds of components and tens of thousands of parameters as a series of manageable, low-dimensional\n",
        "optimizations.\n",
        "\n",
        "This makes hierarchical graphical modeling **scalable to the largest datasets and most complex models.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}