{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Structures\n",
        "===============\n",
        "\n",
        "This tutorial illustrates the data structure objects which data and results quantities are stored using, which are\n",
        "extensions of NumPy arrays.\n",
        "\n",
        "These data structures are used because for different lensing calculations it is convenient to store the data in\n",
        "different formats. For example, when ray-tracing a uniform grid of image-plane (y,x) coordinates, to an irregular\n",
        "grid of source-plane (y,x) coordinates, the image-plane coordinates can be stored in 2D (because the grid is uniform)\n",
        "whereas the source-plane coordinates must be stored in 1D (because after lensing it is irregular).\n",
        "\n",
        "These data structures use the `slim` and `native` data representations API to make it simple to map quantities from\n",
        "1D dimensions to their native dimensions.\n",
        "\n",
        "__Plot Module__\n",
        "\n",
        "This example uses the plot module to plot the results, including `Plotter` objects that make\n",
        "the figures and `MatPlot` objects that wrap matplotlib to customize the figures.\n",
        "\n",
        "The visualization API is straightforward but is explained in the `autolens_workspace/*/plot` package in full.\n",
        "This includes detailed guides on how to customize every aspect of the figures, which can easily be combined with the\n",
        "code outlined in this tutorial.\n",
        "\n",
        "__Units__\n",
        "\n",
        "In this example, all quantities are **PyAutoLens**'s internal unit coordinates, with spatial coordinates in\n",
        "arc seconds, luminosities in electrons per second and mass quantities (e.g. convergence) are dimensionless.\n",
        "\n",
        "The guide `units_and_cosmology.ipynb` illustrates how to convert these quantities to physical units like\n",
        "kiloparsecs, magnitudes and solar masses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__API__\n",
        "\n",
        "We discuss in detail why these data structures and illustrate their functionality below.\n",
        "\n",
        "However, we first create the three data structures we'll use in this example, to set expectations for what they do.\n",
        "\n",
        "We create three data structures:\n",
        "\n",
        " - `Array2D`: A 2D array of data, which is used for storing an image, a noise-map, etc. \n",
        "\n",
        " - `Grid2D`: A 2D array of (y,x) coordinates, which is used for ray-tracing.\n",
        "\n",
        " -`VectorYX2D`: A 2D array of vector values, which is used for deflection angles, shear and other vector fields.\n",
        "\n",
        "All data structures are defined according to a uniform grid of coordinates and therefore they have a `pixel_scales`\n",
        "input defining the pixel-to-arcssecond conversion factor of its grid. \n",
        "\n",
        "For example, for an image stored as an `Array2D`, it has a grid where each coordinate is the centre of each image pixel\n",
        "and the pixel-scale is therefore the resolution of the image.\n",
        "\n",
        "We first create each data structure without a mask using the `no_mask` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "arr = al.Array2D.no_mask(\n",
        "    values=[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]], pixel_scales=1.0\n",
        ")\n",
        "\n",
        "print(arr)\n",
        "\n",
        "grid = al.Grid2D.no_mask(\n",
        "    values=[\n",
        "        [[-1.0, -1.0], [-1.0, 0.0], [-1.0, 1.0]],\n",
        "        [[0.0, -1.0], [0.0, 0.0], [0.0, 1.0]],\n",
        "        [\n",
        "            [1.0, -1.0],\n",
        "            [1.0, 0.0],\n",
        "            [1.0, 1.0],\n",
        "        ],\n",
        "    ],\n",
        "    pixel_scales=1.0,\n",
        ")\n",
        "\n",
        "print(grid)\n",
        "\n",
        "vector_yx = al.VectorYX2D.no_mask(\n",
        "    values=[\n",
        "        [[5.0, -5.0], [5.0, 0.0], [5.0, 5.0]],\n",
        "        [[0.0, -5.0], [0.0, 0.0], [0.0, 5.0]],\n",
        "        [\n",
        "            [-5.0, -5.0],\n",
        "            [-5.0, 0.0],\n",
        "            [-5.0, 5.0],\n",
        "        ],\n",
        "    ],\n",
        "    pixel_scales=1.0,\n",
        ")\n",
        "\n",
        "print(vector_yx)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Grids__\n",
        "\n",
        "We now illustrate data structures using a `Grid2D` object, which is a set of two-dimensional $(y,x)$ coordinates\n",
        "(in arc-seconds) that are deflected and traced by a strong lensing system.\n",
        "\n",
        "These are fundamental to all lensing calculations and drive why data structures are used in **PyAutoLens**.\n",
        "\n",
        "First, lets make a uniform 100 x 100 grid of (y,x) coordinates and plot it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(shape_native=(100, 100), pixel_scales=0.05)\n",
        "\n",
        "mat_plot = aplt.MatPlot2D(title=aplt.Title(label=\"Uniform 100 x 100 Grid2D\"))\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=grid, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Native__\n",
        "\n",
        "This plot shows the grid in its `native` format, that is in 2D dimensions where the y and x coordinates are plotted\n",
        "where we expect them to be on the grid.\n",
        "\n",
        "We can print values from the grid's `native` property to confirm this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"(y,x) pixel 0:\")\n",
        "print(grid.native[0, 0])\n",
        "print(\"(y,x) pixel 1:\")\n",
        "print(grid.native[0, 1])\n",
        "print(\"(y,x) pixel 2:\")\n",
        "print(grid.native[0, 2])\n",
        "print(\"(y,x) pixel 100:\")\n",
        "print(grid.native[1, 0])\n",
        "print(\"etc.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Slim__\n",
        "\n",
        "Every `Grid2D` object is accessible via two attributes, `native` and `slim`, which store the grid as NumPy ndarrays \n",
        "of two different shapes:\n",
        " \n",
        " - `native`: an ndarray of shape [total_y_image_pixels, total_x_image_pixels, 2] which is the native shape of the \n",
        " 2D grid and corresponds to the resolution of the image datasets we pair with a grid.\n",
        " \n",
        " - `slim`: an ndarray of shape [total_y_image_pixels*total_x_image_pixels, 2] which is a slimmed-down representation \n",
        " the grid which collapses the inner two dimensions of the native ndarray to a single dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"(y,x) pixel 0 (accessed via native):\")\n",
        "print(grid.native[0, 0])\n",
        "print(\"(y,x) pixel 0 (accessed via slim 1D):\")\n",
        "print(grid.slim[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As discussed above, the reason we need the slim representation is because when we ray-trace a grid of (y,x) coordinates\n",
        "from the image-plane to the source-plane, the source-plane grid will be irregular.\n",
        "\n",
        "The shapes of the `Grid2D` in its `native` and `slim` formats are also available, confirming that this grid has a \n",
        "`native` resolution of (100 x 100) and a `slim` resolution of 10000 coordinates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(grid.shape_native)\n",
        "print(grid.shape_slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Neither shape above include the third index of the `Grid` which has dimensions 2 (corresponding to the y and x \n",
        "coordinates). \n",
        "\n",
        "This is accessible by using the standard numpy `shape` method on each grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(grid.native.shape)\n",
        "print(grid.slim.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can print the entire `Grid2D` in its `slim` or `native` form. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(grid.native)\n",
        "print(grid.slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Masked Data Structures__\n",
        "\n",
        "When a mask is applied to a grid or other data structure, this changes the `slim` and `native` representations as \n",
        "follows:\n",
        "\n",
        " - `slim`: only contains image-pixels that are not masked, removing all masked pixels from the 1D array.\n",
        " \n",
        " - `native`: retains the dimensions [total_y_image_pixels, total_x_image_pixels], but the masked pixels have values\n",
        "    of 0.0 or (0.0, 0.0).\n",
        "\n",
        "This can be seen by computing a grid via a mask and comparing the its`shape_slim` attribute to the `pixels_in_mask` of \n",
        "the mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(shape_native=(100, 100), pixel_scales=0.05, radius=3.0)\n",
        "\n",
        "grid = al.Grid2D.from_mask(mask=mask)\n",
        "\n",
        "print(\"The shape_slim and number of unmasked pixels\")\n",
        "print(grid.shape_slim)\n",
        "print(mask.pixels_in_mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can use the `slim` attribute to print unmasked values of the grid:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"First unmasked image value:\")\n",
        "print(grid.slim[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `native` representation of the `Grid2D` retains the dimensions [total_y_image_pixels, total_x_image_pixels], \n",
        "however the exterior pixels have values of 0.0 indicating that they have been masked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Example masked pixels in the grid native representation:\")\n",
        "print(grid.shape_native)\n",
        "print(grid.native[0, 0])\n",
        "print(grid.native[2, 2])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data__\n",
        "\n",
        "Two dimensional arrays of data are stored using the `Array2D` object, which has `slim` and `native` representations\n",
        "analogous to the `Grid2D` object and described as follows:\n",
        "\n",
        " - `slim`: an ndarray of shape [total_unmasked_pixels] which is a slimmed-down representation of the data in 1D that \n",
        "    contains only the unmasked data points (where this mask is the one used by the model-fit above).\n",
        "\n",
        " - `native`: an ndarray of shape [total_y_image_pixels, total_x_image_pixels], which is the native shape of the \n",
        "    masked 2D grid used to fit the lens model. All masked pixels are assigned a value 0.0 in the `native` array.\n",
        "\n",
        "For example, the `data` and `noise_map` in an `Imaging` object are stored as `Array2D` objects.\n",
        "\n",
        "We load an imaging dataset and illustrate its data structures below.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"lens_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "data = dataset.data"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is what `slim` and `native` representations of the data's first pixel look like for the `data` before masking:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"First unmasked data value:\")\n",
        "print(data.slim[0])\n",
        "print(data.native[0, 0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, all arrays in **PyAutoLens** are stored as their `slim` 1D numpy array, meaning we don't need to use the\n",
        "`slim` attribute to access the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(data[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By applying a mask the first value in `slim` changes and the native value becomes 0.0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "data = dataset.data\n",
        "\n",
        "print(\"First unmasked data value:\")\n",
        "print(data.slim[0])\n",
        "print(data.native[0, 0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Tracer__\n",
        "\n",
        "The `Tracer` produces many lensing quantities all of which use the `slim` and `native` data structures.\n",
        "\n",
        "For example, by passing it a 2D grid of (y,x) coordinates we can return a numpy array containing its 2D image. \n",
        "This includes the lens light and lensed source images.\n",
        "\n",
        "Below, we use the grid that is aligned with the imaging data (e.g. where each grid coordinate is at the centre of each\n",
        "image pixel) to compute the galaxy image and show its data structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = al.Galaxy(\n",
        "    redshift=0.5, mass=al.mp.IsothermalSph(centre=(0.0, 0.0), einstein_radius=1.6)\n",
        ")\n",
        "\n",
        "source = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    light=al.lp.SersicCoreSph(\n",
        "        centre=(0.0, 0.0),\n",
        "        intensity=0.2,\n",
        "        effective_radius=0.2,\n",
        "        sersic_index=1.0,\n",
        "        radius_break=0.025,\n",
        "    ),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens, source])\n",
        "\n",
        "image = tracer.image_2d_from(grid=dataset.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we print the type of the `image` we note that it is an `Array2D`, which is a data structure that inherits \n",
        "from a numpy array but is extended to include specific functionality discussed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(type(image))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the image is a numpy array, we can print its shape and see that it is 1D."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(image.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Irregular Structures__\n",
        "\n",
        "We may want to perform calculations at specific (y,x) coordinates which are not tied to a uniform grid.\n",
        "\n",
        "We can use an irregular 2D (y,x) grid of coordinates for this. The grid below evaluates the image at:\n",
        "\n",
        "- y = 1.0, x = 1.0.\n",
        "- y = 1.0, x = 2.0.\n",
        "- y = 2.0, x = 2.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_irregular = al.Grid2DIrregular(values=[[1.0, 1.0], [1.0, 2.0], [2.0, 2.0]])\n",
        "\n",
        "image = tracer.image_2d_from(grid=grid_irregular)\n",
        "\n",
        "print(image)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result is stored using an `ArrayIrregular` object, which is a data structure that handles irregular arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(type(image))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Vector Quantities__\n",
        "\n",
        "Many lensing quantities are vectors. That is, they are (y,x) coordinates that have 2 values representing their\n",
        "magnitudes in both the y and x directions.\n",
        "\n",
        "The most obvious of these is the deflection angles, which are used throughout lens modeling to ray-trace grids\n",
        "from the image-plane to the source-plane via a lens galaxy mass model.\n",
        "\n",
        "To indicate that a quantities is a vector, **PyAutoLens** uses the label `_yx`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "deflections_yx_2d = tracer.deflections_yx_2d_from(grid=dataset.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we print the type of the `deflections_yx` we note that it is a `VectorYX2D`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(type(deflections_yx_2d))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unlike the scalar quantities above, which were a 1D numpy array in the `slim` representation and a 2D numpy array in \n",
        "the `native` representation, vectors are 2D in `slim` and 3D in `native`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(deflections_yx_2d.slim.shape)\n",
        "print(deflections_yx_2d.native.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For vector quantities the has shape `2`, corresponding to the y and x vectors respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(deflections_yx_2d.slim[0, :])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The role of the terms `slim` and `native` can be thought of in the same way as for scalar quantities. \n",
        "\n",
        "For a scalar, the `slim` property gives every scalar value as a 1D ndarray for every unmasked pixel. For a vector we \n",
        "still get an ndarray of every unmasked pixel, however each entry now contains two entries: the vector of (y,x) values. \n",
        "\n",
        "For a `native` property these vectors are shown on an image-plane 2D grid where again each pixel\n",
        "contains a (y,x) vector.\n",
        "\n",
        "Like we did for the convergence, we can use whatever grid we want to compute a vector and use sub-gridding to estimate\n",
        "values more precisely:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(shape_native=(3, 3), pixel_scales=0.1)\n",
        "\n",
        "deflections_yx_2d = tracer.deflections_yx_2d_from(grid=grid)\n",
        "\n",
        "print(deflections_yx_2d.slim)\n",
        "print(deflections_yx_2d.native)\n",
        "\n",
        "grid_irregular = al.Grid2DIrregular(values=[[1.0, 1.0], [1.0, 2.0], [2.0, 2.0]])\n",
        "\n",
        "deflections_yx_2d = tracer.deflections_yx_2d_from(grid=grid_irregular)\n",
        "\n",
        "print(deflections_yx_2d)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}