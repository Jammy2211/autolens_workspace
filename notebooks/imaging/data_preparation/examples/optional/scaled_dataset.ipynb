{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Preparation: Scaled Dataset (Optional)\n",
        "===========================================\n",
        "\n",
        "There may be regions of an image that have signal near the lens and source that is from other sources (e.g. foreground\n",
        "stars, background galaxies not associated with the strong lens). The emission from these images will impact our\n",
        "model fitting and needs to be removed from the analysis.\n",
        "\n",
        "This script marks these regions of the image and scales their image values to zero and increases their corresponding\n",
        "noise-map to large values. This means that the model-fit will ignore these regions.\n",
        "\n",
        "Why not just mask these regions instead? For fits using light profiles for the source (e.g. `Sersic`'s, shapelets\n",
        "or a multi gaussian expansion) masking does not make a significant difference.\n",
        "\n",
        "However, for fits using a `Pixelization` for the source, masking these regions can have a significant impact on the\n",
        "reconstruction. Masking regions of the image removes them entirely from the fitting procedure. This means\n",
        "their deflection angles are not computed, they are not traced to the source-plane and their corresponding\n",
        "Delaunay / Voronoi cells do not form.\n",
        "\n",
        "This means there are discontinuities in the source `Pixelization`'s mesh which can degrade the quality of the\n",
        "reconstruction and negatively impact the `Regularization` scheme.\n",
        "\n",
        "Therefore, by retaining them in the mask but scaling their values these source-mesh discontinuities are not\n",
        "created and regularization still occurs over these regions of the source reconstruction.\n",
        "\n",
        "Links / Resources:\n",
        "\n",
        "The script `data_prepration/gui/scaled_data.ipynb` shows how to use a Graphical User Interface (GUI) to scale\n",
        "the data in this way.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `data_preparation/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "%matplotlib inline\n",
        "from os import path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The path where the dataset we scale is loaded from, which \n",
        "is `dataset/imaging/clumps`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"imaging\"\n",
        "dataset_name = \"clumps\"\n",
        "dataset_path = path.join(\"dataset\", dataset_type, dataset_name)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you use this tool for your own dataset, you *must* double check this pixel scale is correct!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixel_scales = 0.1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, load the dataset image, so that the location of galaxies is clear when scaling the noise-map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = al.Array2D.from_fits(\n",
        "    file_path=path.join(dataset_path, \"data.fits\"), pixel_scales=pixel_scales\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, load the noise-map, which we will use the scale the noise-map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "noise_map = al.Array2D.from_fits(\n",
        "    file_path=path.join(dataset_path, \"noise_map.fits\"), pixel_scales=pixel_scales\n",
        ")\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=noise_map)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now lets plot the signal to noise-map, which will be reduced to nearly zero one we scale the noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "array_plotter = aplt.Array2DPlotter(array=data / noise_map)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we manually define a mask corresponding to the regions of the image we will scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.all_false(\n",
        "    shape_native=data.shape_native, pixel_scales=data.pixel_scales\n",
        ")\n",
        "mask[25:55, 77:96] = True\n",
        "mask[55:85, 3:27] = True"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are going to change the image flux values to low values. Not zeros, but values consistent with the background\n",
        "signa in the image, which we can estimate from the image itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "background_level = al.preprocess.background_noise_map_via_edges_from(\n",
        "    image=data, no_edges=2\n",
        ")[0]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function uses the mask to scale the appropriate regions of the image to the background level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = np.where(mask, background_level, data.native)\n",
        "data = al.Array2D.no_mask(values=data, pixel_scales=pixel_scales)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To make our scaled image look as realistic as possible, we can optionally included some noise drawn from a Gaussian\n",
        "distribution to replicate the noise-pattern in the image. This requires us to choose a `gaussian_sigma` value \n",
        "representative of the data, which you should choose via `trial and error` until you get a noise pattern that is\n",
        "visually hard to discern from the rest of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# gaussian_sigma = None\n",
        "gaussian_sigma = 0.03\n",
        "\n",
        "if gaussian_sigma is not None:\n",
        "    random_noise = np.random.normal(\n",
        "        loc=background_level, scale=gaussian_sigma, size=data.shape_native\n",
        "    )\n",
        "    data = np.where(mask, random_noise, data.native)\n",
        "    data = al.Array2D.no_mask(values=data, pixel_scales=pixel_scales)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The new image is plotted for inspection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "array_plotter = aplt.Array2DPlotter(array=data)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we`re happy with the image, lets output it to the dataset folder of the lens, so that we can load it from a .fits\n",
        "file in our pipelines!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data.output_to_fits(\n",
        "    file_path=path.join(dataset_path, \"data_scaled.fits\"), overwrite=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we manually increase the noise values at these points in the mask to extremely large values, such that the \n",
        "analysis essentially omits them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "noise_map = noise_map.native\n",
        "noise_map[mask == True] = 1.0e8"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The noise-map and signal to noise-map show the noise-map being scaled in the correct regions of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "array_plotter = aplt.Array2DPlotter(array=noise_map)\n",
        "array_plotter.figure_2d()\n",
        "\n",
        "array_plotter = aplt.Array2DPlotter(array=data / noise_map.slim)\n",
        "array_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we`re happy with the mask, lets output it to the dataset folder of the lens, so that we can load it from a .fits\n",
        "file in our pipelines!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "noise_map.output_to_fits(\n",
        "    file_path=path.join(dataset_path, \"noise_map_scaled.fits\"), overwrite=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can output the scaled mask encase we need it in the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask.output_to_fits(\n",
        "    file_path=path.join(dataset_path, \"mask_scaled.fits\"), overwrite=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The workspace also includes a GUI for image and noise-map scaling, which can be found at \n",
        "`autolens_workspace/*/data_preparation/imaging/gui/scaled_dataset.py`. This tools allows you `spray paint` on the image where \n",
        "an you want to scale, allow irregular patterns (i.e. not rectangles) to be scaled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}