{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GUI Preprocessing: Positions\n",
        "============================\n",
        "\n",
        "This tool allows one to input the positions of strong lenses via a GUI, which can be used to penalize inaccurate\n",
        "mass models during lensing modeling.\n",
        "\n",
        "This GUI is adapted from the following code: https://gist.github.com/brikeats/4f63f867fd8ea0f196c78e9b835150ab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from pathlib import Path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Setup the path the datasets we'll use to illustrate preprocessing, which is the \n",
        "folder `dataset/imaging/simple__no_lens_light`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pixel scale of the imaging dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixel_scales = 0.1"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the image which we will use to mark the positions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data = al.Array2D.from_fits(\n",
        "    file_path=dataset_path / \"data.fits\", pixel_scales=pixel_scales\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search Box__\n",
        "\n",
        "When you click on a pixel to mark a position, the search box looks around this click and finds the pixel with\n",
        "the highest flux to mark the position.\n",
        "\n",
        "The `search_box_size` is the number of pixels around your click this search takes place."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_box_size = 5"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Clicker__\n",
        "\n",
        "Set up the `Clicker` object from the `clicker.py` module, which monitors your mouse clicks in order to determine\n",
        "the positions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "clicker = al.Clicker(\n",
        "    image=data, pixel_scales=pixel_scales, search_box_size=search_box_size\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For lenses with bright lens light emission, it can be difficult to get the source light to show. The normalization\n",
        "below uses a log-scale with a capped maximum, which better contrasts the lens and source emission."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cmap = aplt.Cmap(norm=\"linear\", vmin=1.0e-4, vmax=np.max(data))\n",
        "\n",
        "norm = cmap.norm_from(array=None)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up the clicker canvas and load the GUI which you can now click on to mark the positionss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "n_y, n_x = data.shape_native\n",
        "hw = int(n_x / 2) * pixel_scales\n",
        "ext = [-hw, hw, -hw, hw]\n",
        "fig = plt.figure(figsize=(14, 14))\n",
        "plt.imshow(data.native, cmap=\"jet\", extent=ext)\n",
        "plt.colorbar()\n",
        "cid = fig.canvas.mpl_connect(\"button_press_event\", clicker.onclick)\n",
        "plt.show()\n",
        "fig.canvas.mpl_disconnect(cid)\n",
        "plt.close(fig)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the results of the Clicker GUI to create the list of the positions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = al.Grid2DIrregular(values=clicker.click_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Output__\n",
        "\n",
        "Now lets plot the image and positions,, so we can check that the positions overlap the brightest pixels in the\n",
        "lensed source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(mass_profile_centres=positions)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(\n",
        "    array=data, visuals_2d=visuals, mat_plot_2d=aplt.MatPlot2D()\n",
        ")\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output this image of the positions to a .png file in the dataset folder for future reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "array_2d_plotter = aplt.Array2DPlotter(\n",
        "    array=data,\n",
        "    visuals_2d=visuals,\n",
        "    mat_plot_2d=aplt.MatPlot2D(\n",
        "        output=aplt.Output(path=dataset_path, filename=\"positions\", format=\"png\")\n",
        "    ),\n",
        ")\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output the positions to a .json file in the dataset folder, so we can load them in modeling scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "al.output_to_json(\n",
        "    obj=positions,\n",
        "    file_path=Path(dataset_path, \"positions.json\"),\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}