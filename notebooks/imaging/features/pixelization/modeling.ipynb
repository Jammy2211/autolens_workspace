{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Features: Pixelization Modeling\n",
        "===============================\n",
        "\n",
        "A pixelization reconstructs the source's light using a pixel-grid, which is regularized using a prior that forces\n",
        "the solution to have a degree of smoothness.\n",
        "\n",
        "This script fits a source galaxy model which uses a pixelization to reconstruct the source's light.\n",
        "\n",
        "A Rectangular mesh and constant regularization scheme are used, which are the simplest forms of mesh and regularization\n",
        "with provide computationally fast and accurate solutions.\n",
        "\n",
        "For simplicity, the lens galaxy\u2019s light is omitted from both the simulated data and the model. Including the lens\n",
        "galaxy\u2019s light is straightforward and can be done in exactly the same framework.\n",
        "\n",
        "You may wish to first read the pixelization/fit.py example, which demonstrates how a pixelized source reconstruction\n",
        "is applied to a single dataset.\n",
        "\n",
        "Pixelizations are covered in detail in chapter 4 of the **HowToLens** lectures.\n",
        "\n",
        "__Run Time Overview__\n",
        "\n",
        "Pixelized source reconstructions are computed using either GPU acceleration via JAX or CPU acceleration via `numba`.\n",
        "\n",
        "The faster option depends on two crucial factors:\n",
        "\n",
        "#### **1. GPU VRAM Limitations**\n",
        "JAX only provides significant acceleration on GPUs with **large VRAM (\u226516 GB)**.\n",
        "To avoid excessive VRAM usage, examples often restrict pixelization meshes (e.g. 20 \u00d7 20).\n",
        "On consumer GPUs with limited memory, **JAX may be slower than CPU execution**.\n",
        "\n",
        "#### **2. Sparse Matrix Performance**\n",
        "\n",
        "Pixelized inversions require operations on **very large, highly sparse matrices**.\n",
        "\n",
        "- JAX currently lacks sparse-matrix support and must compute using **dense matrices**, which scale poorly.\n",
        "- PyAutoLens\u2019s CPU implementation (via `numba`) fully exploits sparsity, providing large speed gains\n",
        "  at **high image resolution** (e.g. `pixel_scales <= 0.03`).\n",
        "\n",
        "As a result, CPU execution can outperform JAX even on powerful GPUs for high-resolution datasets.\n",
        "\n",
        "The example `pixelization/cpu_fast_modeling` shows how to set up a pixelization to use efficient CPU calculations\n",
        "via the library `numba`.\n",
        "\n",
        "__Rule of Thumb__\n",
        "\n",
        "For **low-resolution imaging** (for example, datasets with `pixel_scales > 0.05`), modeling is generally faster using\n",
        "**JAX with a GPU**, because the computations involve fewer sparse operations and do not require large amounts of VRAM.\n",
        "\n",
        "For **high-resolution imaging** (for example, `pixel_scales <= 0.03`), modeling can be faster using a **CPU with numba**\n",
        "and multiple cores. At high resolution, the linear algebra is dominated by sparse matrix operations, and the CPU\n",
        "implementation exploits sparsity more effectively, especially on systems with many CPU cores (e.g. HPC clusters).\n",
        "\n",
        "**Recommendation:** The best choice depends on your hardware and dataset. If your data has resolution of 0.1\" per pixel\n",
        " (e.g. Euclid imaging) or lower, JAX will be the most efficient. For higher resolution imaging (e.g. HST, JWST) it is\n",
        " worth benchmarking both approaches (GPU+JAX vs CPU+numba) to determine which performs fastest for your case.\n",
        "\n",
        "__Contents__\n",
        "\n",
        "**Advantages & Disadvantages:** Benefits and drawbacks of using a pixelization to model a source galaxy.\n",
        "**Positive Only Solver:** How a positive solution to the reconstructed source pixel fluxes is ensured.\n",
        "**Dataset & Mask:** Standard set up of imaging dataset that is fitted.\n",
        "**Pixelization:** How to create a pixelization, including a description of its inputs.\n",
        "**Model:** Composing a model using a pixelization and how it changes the number of free parameters.\n",
        "**Search & Analysis:** Standard set up of non-linear search and analysis.\n",
        "**Positions Likelihood:** Removing unphysical pixelized source solutions using a likelihood penalty using the lensed multiple images.\n",
        "**Run Time:** Profiling of pixelization run times and discussion of how they compare to standard light profiles.\n",
        "**Model-Fit:** Performs the model fit using standard API.\n",
        "**Result:** Pixelization results and visualizaiton.\n",
        "**Chaining:** How the advanced modeling feature, non-linear search chaining, can significantly improve lens modeling with pixelizaitons.\n",
        "**Result (Advanced):** API for various pixelization outputs (magnifications, mappings) which requires some polishing.\n",
        "**Simulate (Advanced):** Simulating a strong lens dataset with the inferred pixelized source.\n",
        "\n",
        "__Advantages__\n",
        "\n",
        "Many strongly lensed source galaxies exhibit complex, asymmetric, and irregular morphologies. Such structures\n",
        "cannot be well approximated by analytic light profiles such as a S\u00e9rsic profile, or even combinations of multiple\n",
        "S\u00e9rsic components. pixelizations are therefore required to accurately reconstruct this irregular source-plane light.\n",
        "\n",
        "Even alternative basis-function approaches, such as shapelets or multi-Gaussian expansions, struggle to accurately\n",
        "reconstruct sources with highly complex morphologies or multiple distinct source galaxies.\n",
        "\n",
        "Pixelized source models are also essential for robustly constraining detailed components of the lens mass\n",
        "distribution (e.g. the mass density slope or the presence of dark matter substructure). By fitting all of the lensed\n",
        "source light, they reduce degeneracies between the source and lens mass model.\n",
        "\n",
        "Finally, many science applications aim to study the highly magnified source galaxy itself, in order to learn about\n",
        "distant and intrinsically faint galaxies. pixelizations reconstruct the unlensed source emission, enabling detailed\n",
        "studies of the source-plane structure.\n",
        "\n",
        "__Disadvantages__\n",
        "\n",
        "Pixelized source reconstructions are computationally more expensive than analytic source models. For high-resolution\n",
        "imaging data (e.g. Hubble Space Telescope observations), it is common for lens models using pixelizations to require\n",
        "hours or even days to fit.\n",
        "\n",
        "Lens modeling with pixelizations is also conceptually more complex. There are additional failure modes, such as\n",
        "solutions where the source is reconstructed in a highly demagnified configuration due to an unphysical lens mass\n",
        "model (e.g. too little or too much mass). These issues are discussed in detail later in the workspace.\n",
        "\n",
        "As a result, learning to successfully fit lens models with pixelizations typically requires more time and experience\n",
        "than the simpler modeling approaches introduced elsewhere in the workspace.\n",
        "\n",
        "__Positive Only Solver__\n",
        "\n",
        "Many codes which use linear algebra typically rely on a linear algabra solver which allows for positive and negative\n",
        "values of the solution (e.g. `np.linalg.solve`), because they are computationally fast.\n",
        "\n",
        "This is problematic, as it means that negative surface brightnesses values can be computed to represent a galaxy's\n",
        "light, which is clearly unphysical. For a pixelizaiton, this often produces negative source pixels which over-fit\n",
        "the data, producing unphysical solutions.\n",
        "\n",
        "All pixelized source reconstructions use a positive-only solver, meaning that every source-pixel is only allowed\n",
        "to reconstruct positive flux values. This ensures that the source reconstruction is physical and that we don't\n",
        "reconstruct negative flux values that don't exist in the real source galaxy (a common systematic solution in lens\n",
        "analysis).\n",
        "\n",
        "It may be surprising to hear that this is a feature worth pointing out, but it turns out setting up the linear algebra\n",
        "to enforce positive reconstructions is difficult to make efficient. A lot of development time went into making this\n",
        "possible, where a bespoke fast non-negative linear solver was developed to achieve this.\n",
        "\n",
        "Other methods in the literature often do not use a positive only solver, and therefore suffer from these\n",
        "unphysical solutions, which can degrade the results of lens model in general.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits an `Imaging` dataset of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's light is omitted (and is not present in the simulated data).\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's surface-brightness is reconstructed using a `RectangularAdaptDensity` mesh\n",
        "   and `Constant` regularization scheme.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the strong lens dataset `simple__no_lens_light` via .fits files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Over Sampling__\n",
        "\n",
        "A pixelization uses a separate grid for ray tracing, with its own over sampling scheme, which below we set to a \n",
        "uniform grid of values of 2. \n",
        "\n",
        "The pixelization only reconstructs the source galaxy, therefore the adaptive over sampling used for the lens galaxy's \n",
        "light in other examples is not applied to the pixelization. \n",
        "\n",
        "This example does not model lens light, for examples which combine lens light and a pixelization both over sampling \n",
        "schemes should be used, with the lens light adaptive and the pixelization uniform.\n",
        "\n",
        "Note that the over sampling is input into the `over_sample_size_pixelization` because we are using a `Pixelization`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = dataset.apply_over_sampling(\n",
        "    over_sample_size_pixelization=4,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__JAX & Preloads__\n",
        "\n",
        "In JAX, calculations must use static shaped arrays with known and fixed indexes. For certain calculations in the\n",
        "pixelization, this information has to be passed in before the pixelization is performed. Below, we do this for 3\n",
        "inputs:\n",
        "\n",
        "- `total_linear_light_profiles`: The number of linear light profiles in the model. This is 0 because we are not\n",
        "  fitting any linear light profiles to the data, primarily because the lens light is omitted.\n",
        "\n",
        "- `total_mapper_pixels`: The number of source pixels in the rectangular pixelization mesh. This is required to set up \n",
        "  the arrays that perform the linear algebra of the pixelization.\n",
        "\n",
        "- `source_pixel_zeroed_indices`: The indices of source pixels on its edge, which when the source is reconstructed \n",
        "  are forced to values of zero, a technique tests have shown are required to give accruate lens models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh_shape = (20, 20)\n",
        "total_mapper_pixels = mesh_shape[0] * mesh_shape[1]\n",
        "\n",
        "total_linear_light_profiles = 0\n",
        "\n",
        "preloads = al.Preloads(\n",
        "    mapper_indices=al.mapper_indices_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        total_mapper_pixels=total_mapper_pixels,\n",
        "    ),\n",
        "    source_pixel_zeroed_indices=al.util.mesh.rectangular_edge_pixel_list_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        shape_native=mesh_shape,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our lens model using `Model` objects, which represent the galaxies we fit to our data.  In this \n",
        "example fits a lens model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear` [7 parameters].\n",
        "\n",
        " - The source-galaxy's light uses a 20 x 20 `RectangularAdaptDensity` mesh [0 parameters].\n",
        "\n",
        " - This pixelization is regularized using a `Constant` scheme which smooths every source pixel equally [1 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=6. \n",
        "\n",
        "It is worth noting the pixelization fits the source using significantly fewer parameters (1 parameter for \n",
        "regularization) than fitting the source using light profiles or an MGE (4+ parameters). \n",
        "\n",
        "The lens model therefore includes a mesh and regularization scheme, which are used together to create the \n",
        "pixelization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.PowerLaw)\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=mass, shear=shear)\n",
        "\n",
        "# Source:\n",
        "mesh = af.Model(al.mesh.RectangularAdaptDensity, shape=mesh_shape)\n",
        "regularization = af.Model(al.reg.Constant)\n",
        "\n",
        "pixelization = af.Model(al.Pixelization, mesh=mesh, regularization=regularization)\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format (if this does not display clearly on your screen refer to\n",
        "`start_here.ipynb` for a description of how to fix this).\n",
        "\n",
        "This confirms that the source galaxy's has a mesh and regularization scheme, which are combined into a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using the nested sampling algorithm Nautilus (see `start.here.py` for a \n",
        "full description)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"imaging\"),\n",
        "    name=\"pixelization\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    n_batch=50,  # GPU lens model fits are batched and run simultaneously, see VRAM section below.\n",
        "    iterations_per_quick_update=50000,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Position Likelihood__\n",
        "\n",
        "We add a penalty term ot the likelihood function, which penalizes models where the brightest multiple images of\n",
        "the lensed source galaxy do not trace close to one another in the source plane. This removes \"demagnified source\n",
        "solutions\" from the source pixelization, which one is likely to infer without this penalty.\n",
        "\n",
        "A comprehensive description of why we do this is given at the following readthedocs page. I strongly recommend you \n",
        "read this page in full if you are not familiar with the positions likelihood penalty and demagnified source \n",
        "reconstructions:\n",
        "\n",
        " https://pyautolens.readthedocs.io/en/latest/general/demagnified_solutions.html\n",
        "\n",
        "__Brief Description__\n",
        "\n",
        "Unlike other example scripts, we also pass the `AnalysisImaging` object below a `PositionsLH` object, which\n",
        "includes the positions we loaded above, alongside a `threshold`.\n",
        "\n",
        "This is because `Inversion`'s suffer a bias whereby they fit unphysical lens models where the source galaxy is \n",
        "reconstructed as a demagnified version of the lensed source. \n",
        "\n",
        "To prevent these solutions biasing the model-fit we specify a `position_threshold` of 0.5\", which requires that a \n",
        "mass model traces the four (y,x) coordinates specified by our positions (that correspond to the brightest regions of the \n",
        "lensed source) within 0.5\" of one another in the source-plane. If this criteria is not met, a large penalty term is\n",
        "added to likelihood that massively reduces the overall likelihood. This penalty is larger if the ``positions``\n",
        "trace further from one another.\n",
        "\n",
        "This ensures the unphysical solutions that bias a pixelization have a lower likelihood that the physical solutions\n",
        "we desire. Furthermore, the penalty term reduces as the image-plane multiple image positions trace closer in the \n",
        "source-plane, ensuring Nautilus converges towards an accurate mass model. It does this very fast, as \n",
        "ray-tracing just a few multiple image positions is computationally cheap. \n",
        "\n",
        "The threshold of 0.3\" is large. For an accurate lens model we would anticipate the positions trace within < 0.01\" of\n",
        "one another. The high threshold ensures only the initial mass models at the start of the fit are penalized.\n",
        "\n",
        "Position thresholding is described in more detail in the \n",
        "script `autolens_workspace/*/guides/modeling/customize`\n",
        "\n",
        "The arc-second positions of the multiply imaged lensed source galaxy were drawn onto the\n",
        "image via the GUI described in the file `autolens_workspace/*/imaging/data_preparation/gui/positions.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = al.Grid2DIrregular(\n",
        "    al.from_json(file_path=Path(dataset_path, \"positions.json\"))\n",
        ")\n",
        "\n",
        "positions_likelihood = al.PositionsLH(positions=positions, threshold=0.3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the `AnalysisImaging` object defining how the via Nautilus the model is fitted to the data. \n",
        "\n",
        "The `positions_likelihood_list` is passed to the analysis, which applies the likelihood penalty described above\n",
        "for everyone lens mass model.\n",
        "\n",
        "The `preloads` are passed to the analysis, which contain the static array information JAX needs to perform\n",
        "the pixelization calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset, positions_likelihood_list=[positions_likelihood], preloads=preloads\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__VRAM__\n",
        "\n",
        "The `modeling` example explains how VRAM is used during GPU-based fitting and how to print the estimated VRAM \n",
        "required by a model.\n",
        "\n",
        "pixelizations use a lot more VRAM than light profile-only models, with the amount required depending on the size of\n",
        "dataset and the number of source pixels in the pixelization's mesh. For 400 source pixels, around 0.05 GB per batched\n",
        "likelihood of VRAM is used. \n",
        "\n",
        "This is why the `batch_size` above is 20, lower than other examples, because reducing the batch size ensures a more \n",
        "modest amount of VRAM is used. If you have a GPU with more VRAM, increasing the batch size will lead to faster run times.\n",
        "\n",
        "Given VRAM use is an important consideration, we print out the estimated VRAM required for this \n",
        "model-fit and advise you do this for your own pixelization model-fits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis.print_vram_use(model=model, batch_size=search.batch_size)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "The run time of a pixelization are fast provided that the GPU VRAM exceeds the amount of memory required to perform\n",
        "a likelihood evaluation.\n",
        "\n",
        "Assuming the use of a 20 x 20 mesh grid above means this is the case, the run times of this model-fit on a GPU\n",
        "should take under 10 minutes. If VRAM is exceeded, the run time will be significantly longer (3+ hours). CPU run\n",
        "times are also of order hours, but can be sped up using the `numba` library (see the `pixelization/cpu` example).\n",
        "\n",
        "The run times of pixelizations slow down as the data becomes higher resolution. In this example, data with a pixel\n",
        "scale of 0.1\" gives of order 10 minute run times (when VRAM is under control), for a pixel scale of 0.05\" this\n",
        "becomes around 30 minutes, and an hour for 0.03\".\n",
        "\n",
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format (if this\n",
        "does not display clearly on your screen refer to `start_here.ipynb` for a description of how to fix this):\n",
        "\n",
        "This confirms that the source galaxy's has a mesh and regularization scheme, which are combined into a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the maximum likelihood fit, tracer images and posteriors inferred via Nautilus.\n",
        "\n",
        "The end of this example provides a detailed description of all result options for a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=result.grids.lp\n",
        ")\n",
        "tracer_plotter.subplot_tracer()\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "plotter = aplt.NestPlotter(samples=result.samples)\n",
        "plotter.corner_anesthetic()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The example `pixelization/fit` provides a full description of the different calculations that can be performed\n",
        "with the result of a pixelization model-fit.\n",
        "\n",
        "__Mask Extra Galaxies__\n",
        "\n",
        "There may be extra galaxies nearby the lens and source galaxies, whose emission blends with the lens and source.\n",
        "\n",
        "If their emission is significant, and close enough to the lens and source, we may simply remove it from the data\n",
        "to ensure it does not impact the model-fit. A standard masking approach would be to remove the image pixels containing\n",
        "the emission of these galaxies altogether. This is analogous to what the circular masks used throughout the examples\n",
        "does.\n",
        "\n",
        "For fits using a pixelization, masking regions of the image in a way that removes their image pixels entirely from\n",
        "the fit. This can produce discontinuities in the pixelixation used to reconstruct the source and produce unexpected\n",
        "systematics and unsatisfactory results. In this case, applying the mask in a way where the image pixels are not\n",
        "removed from the fit, but their data and noise-map values are scaled such that they contribute negligibly to the fit,\n",
        "is a better approach.\n",
        "\n",
        "We illustrate the API for doing this below, using the `extra_galaxies` dataset which has extra galaxies whose emission\n",
        "needs to be removed via scaling in this way. We apply the scaling and show the subplot imaging where the extra\n",
        "galaxies mask has scaled the data values to zeros, increasing the noise-map values to large values and in turn made\n",
        "the signal to noise of its pixels effectively zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"extra_galaxies\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask_extra_galaxies = al.Mask2D.from_fits(\n",
        "    file_path=Path(dataset_path, \"mask_extra_galaxies.fits\"),\n",
        "    pixel_scales=0.1,\n",
        "    invert=True,  # Note that we invert the mask here as `True` means a pixel is scaled.\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_noise_scaling(mask=mask_extra_galaxies)\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=0.1, centre=(0.0, 0.0), radius=6.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do not explictly fit this data, for the sake of brevity, however if your data has these nearby galaxies you should\n",
        "apply the mask as above before fitting the data.\n",
        "\n",
        "__Result Use__\n",
        "\n",
        "There are many things you can do with the result of a pixelixaiton, including analysing the reconstructed source, \n",
        "magnification calculations of the source and much more.\n",
        "\n",
        "These are documented in the `fit.py` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion = result.max_log_likelihood_fit.inversion"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "Pixelizations are the most complex but also the most powerful way to model a galaxy\u2019s light.\n",
        "\n",
        "Whether you need to use them depends on the science you are doing. If you are only interested in measuring simple\n",
        "global quantities (for example, total flux, size, or axis ratio), analytic light profiles such as a S\u00e9rsic, MGE, or\n",
        "shapelets are often sufficient. For low-resolution data, pixelizations are also unnecessary, as the complex\n",
        "structure of the galaxy is not resolved.\n",
        "\n",
        "However, modeling galaxies with complex, irregular, or highly structured light distributions requires this level of\n",
        "flexibility. Furthermore, if you are interested in studying the detailed morphology of a galaxy itself, there is no\n",
        "better approach than using a pixelization.\n",
        "\n",
        "__Chaining__\n",
        "\n",
        "Modeling with a pixelization can be made more efficient, robust, and automated using the non-linear chaining feature\n",
        "to compose a pipeline that begins by fitting a simpler model using parametric light profiles.\n",
        "\n",
        "More information on chaining is provided in the\n",
        "`autogalaxy_workspace/notebooks/guides/modeling/chaining` folder and in chapter 3 of the **HowToGalaxy** lectures.\n",
        "\n",
        "__HowToGalaxy__\n",
        "\n",
        "A full description of how pixelizations work\u2014which relies heavily on linear algebra, Bayesian statistics, and\n",
        "2D geometry\u2014is provided in chapter 4 of the **HowToGalaxy** lectures.\n",
        "\n",
        "__Future Ideas / Contributions__\n",
        "\n",
        "Here are a list of things I would like to add to this tutorial but haven't found the time. If you are interested\n",
        "in having a go at adding them contact me on SLACK! :)\n",
        "\n",
        "- More diagnostic quantities for reconstructed galaxy light.\n",
        "- Gradient calculations of the reconstructed light distribution.\n",
        "- Quantifying spatial variations in galaxy structure across the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}