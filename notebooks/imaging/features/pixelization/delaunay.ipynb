{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pixelization: Delaunay\n",
        "======================\n",
        "\n",
        "The majority of pixelized source reconstructions in the workspace use a rectangular mesh to reconstruct\n",
        "the source's surface brightness.\n",
        "\n",
        "This example illustrates an alternative pixelization that uses a Delaunay triangulation mesh to reconstruct the\n",
        "source.\n",
        "\n",
        "The approach is distinct from the rectangular mesh and has a number of traits which are unique to it:\n",
        "\n",
        "- `Adaptive Mesh`: In the source plane, the Delaunay mesh uses irregularly shaped triangles to reconstruct the\n",
        "  source, as opposed to uniform rectangular pixels. This allows the mesh to better adapt to irregular and\n",
        "  asymmetric source morphologies and change the distribution of source pixels to better match the source's\n",
        "  surface brightness.\n",
        "\n",
        "- `Image Mesh`: The vertexes of the Delaunay triangles are computed by overlaying a coarse uniform grid in the\n",
        "  image-plane and ray-tracing these coordinates to the source-plane. This is unlike the rectangular mesh, which\n",
        "  simply overlays a uniform grid in the source-plane. This again helps the Delaunay mesh to better adapt to the\n",
        "  source's surface brightness.\n",
        "\n",
        "- `Interpolation`: The Delaunay mesh uses a different interpolation scheme to the rectangular mesh, which is\n",
        "  barycentric interpolation within each triangle. This is different to the rectangular mesh, which uses bilinear\n",
        "  interpolation within each rectangular pixel.\n",
        "\n",
        "- `Regularization`: The Delaunay mesh provides different approaches to regularization, with the default being\n",
        "  one which uses the barycentric coordinates of the triangles to compute how source pixels are regularized with\n",
        "  their neighbors.\n",
        "\n",
        "Currently it is not expected that the Delaunay is better or worse than the rectangular mesh, it is simply a different\n",
        "approach to pixelization that may work better for certain datasets.\n",
        "\n",
        "__JAX + GPU__\n",
        "\n",
        "Generating a Delaunay mesh currently does not support JAX and GPU acceleration. This script therefore runs exclusively\n",
        "using CPU, and follows the fast CPU method described in example `imaging/features/pixelization/cpu_fast_modeling`.\n",
        "\n",
        "You should read this script before using the Delaunay mesh for your own modeling, but the key point are:\n",
        "\n",
        "- The library `numba` must be installed for fast likelihood evaluations.\n",
        "\n",
        "- Python multiprocessing is used to parallelize model-fits over many CPU cores.\n",
        "\n",
        "- CPU pixelization calculations fully exploit sparsity and therefore for high resolution datasets (around\n",
        "a `pixel_scale` of 0.03\" or below) begin to run as fast or faster than GPU computations using JAX. They also use\n",
        "significantly less memory and are therefore able to model datasets that are infeasible using JAX."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "try:\n",
        "    import numba\n",
        "except ModuleNotFoundError:\n",
        "    input(\n",
        "        \"##################\\n\"\n",
        "        \"##### NUMBA ######\\n\"\n",
        "        \"##################\\n\\n\"\n",
        "        \"\"\"\n",
        "        Numba is not currently installed.\n",
        "\n",
        "        Numba is a library which makes PyAutoLens run a lot faster. Certain functionality is disabled without numba\n",
        "        and will raise an exception if it is used.\n",
        "\n",
        "        If you have not tried installing numba, I recommend you try and do so now by running the following \n",
        "        commands in your command line / bash terminal now:\n",
        "\n",
        "        pip install --upgrade pip\n",
        "        pip install numba\n",
        "\n",
        "        If your numba installation raises an error and fails, you should go ahead and use PyAutoLens without numba to \n",
        "        decide if it is the right software for you. If it is, you should then commit time to bug-fixing the numba\n",
        "        installation. Feel free to raise an issue on GitHub for support with installing numba.\n",
        "\n",
        "        A warning will crop up throughout your *PyAutoLens** use until you install numba, to remind you to do so.\n",
        "\n",
        "        [Press Enter to continue]\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset + Masking + Positions__ \n",
        "\n",
        "Load, plot and mask the `Imaging` data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "over_sample_size = al.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "    grid=dataset.grid,\n",
        "    sub_size_list=[4, 2, 1],\n",
        "    radial_list=[0.3, 0.6],\n",
        "    centre_list=[(0.0, 0.0)],\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "\n",
        "positions = al.Grid2DIrregular(\n",
        "    al.from_json(file_path=Path(dataset_path, \"positions.json\"))\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__W_Tilde__\n",
        "\n",
        "Use the `w_tilde` function to pre-compute matrices which enable fast linear algebra for pixelized source by\n",
        "exploiting sparsity, as described in the `imaging/features/pixelization/cpu_fast_modeling.py` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = dataset.apply_w_tilde()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__JAX & Preloads__\n",
        "\n",
        "The example in `autolens_workspace/*/imaging/features/pixelization/modeling` explains why JAX requires certain\n",
        "arrays to be **preloaded** before the fit begins. JAX must know the shape of arrays in advance so it can compile\n",
        "functions for them.\n",
        "\n",
        "For a Delaunay mesh, the vertices of the triangles are defined by (y, x) coordinates in the image-plane. These\n",
        "coordinates are then ray-traced into the source-plane for each mass model sampled during the non-linear search.\n",
        "Because this ray-tracing happens repeatedly, the `image_plane_mesh_grid` must be computed once at the start and\n",
        "passed into a `Preloads` object.\n",
        "\n",
        "Below, we compute this `image_plane_mesh_grid` using an **Overlay image-mesh**, which places a regular grid of\n",
        "(y, x) points across the image-plane. This has a mild adaptive effect: regions of high lens magnification receive\n",
        "more source pixels once they are ray-traced. Later in this example, we switch to a **Hilbert mesh**, which adapts\n",
        "the pixel distribution more strongly to the source\u2019s surface brightness.\n",
        "\n",
        "Unlike regular pixelizations, which define a `mesh_shape` to set the total number of source pixels, Delaunay\n",
        "meshes instead use an `image_mesh_shape`, because the triangulation comes from the overlaid image-plane grid.\n",
        "\n",
        "Another feature of pixelizations is that all pixels at the edge of the mesh in the source-plane are forced to\n",
        "solutions of zero brightness by the linear algebra solver. This prevents unphysical solutions where pixels at the\n",
        "# edge of the mesh reconstruct bright surface brightnesses, often because they fit residuals from the lens\n",
        "light subtraction.\n",
        "\n",
        "This requires us to input the `source_pixel_zeroed_indices` into the `Preloads` object, which for rectangular meshes\n",
        "was simply the edge pixels of the rectangular grid which could be computed via their 2D indices. \n",
        "\n",
        "For an image-plane mesh, we simply add a circle of edge points to the image-plane mesh-grid after it has been computed.\n",
        "We pass the indices of these edge points to the `Preloads` object so that the linear algebra solver knows to force these\n",
        "pixels to zero during the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_mesh = al.image_mesh.Overlay(shape=(26, 26))\n",
        "\n",
        "image_plane_mesh_grid = image_mesh.image_plane_mesh_grid_from(\n",
        "    mask=dataset.mask,\n",
        ")\n",
        "\n",
        "image_plane_mesh_grid_edge_pixels = 30\n",
        "\n",
        "image_plane_mesh_grid = al.image_mesh.append_with_circle_edge_points(\n",
        "    image_plane_mesh_grid=image_plane_mesh_grid,\n",
        "    centre=mask.mask_centre,\n",
        "    radius=3.0 + mask.pixel_scale / 2.0,\n",
        "    n_points=image_plane_mesh_grid_edge_pixels,\n",
        ")\n",
        "\n",
        "total_mapper_pixels = image_plane_mesh_grid.shape[0]\n",
        "\n",
        "total_linear_light_profiles = 0\n",
        "\n",
        "mapper_indices = al.mapper_indices_from(\n",
        "    total_linear_light_profiles=total_linear_light_profiles,\n",
        "    total_mapper_pixels=total_mapper_pixels,\n",
        ")\n",
        "\n",
        "# Extract the last `image_plane_mesh_grid_edge_pixels` indices, which correspond to the circle edge points we added\n",
        "\n",
        "source_pixel_zeroed_indices = mapper_indices[-image_plane_mesh_grid_edge_pixels:]\n",
        "\n",
        "preloads = al.Preloads(\n",
        "    mapper_indices=mapper_indices,\n",
        "    source_pixel_zeroed_indices=source_pixel_zeroed_indices,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "In the example `imaging/features/pixelization/fit.py`, we illustrate how to use a pixelized source\n",
        "with a rectangular mesh to fit imaging data.\n",
        "\n",
        "Below, we use a Delaunay mesh to perform a fit using the Delaunay source reconstruction.\n",
        "\n",
        "The API is nearly identical to the rectangular mesh example, noting that the use of \n",
        "preloads with an `image_plane_mesh_grid` and the `Delaunay` mesh changes the \n",
        "calculation internally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh = al.mesh.Delaunay()\n",
        "regularization = al.reg.Constant(coefficient=1.0)\n",
        "\n",
        "pixelization = al.Pixelization(mesh=mesh, regularization=regularization)\n",
        "\n",
        "lens = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.0, 0.0),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        "    shear=al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05),\n",
        ")\n",
        "\n",
        "source = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens, source])\n",
        "\n",
        "adapt_images = al.AdaptImages(\n",
        "    galaxy_image_plane_mesh_grid_dict={source: image_plane_mesh_grid}\n",
        ")\n",
        "\n",
        "fit = al.FitImaging(\n",
        "    dataset=dataset,\n",
        "    tracer=tracer,\n",
        "    preloads=preloads,\n",
        "    adapt_images=adapt_images,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting the fit, we see that the Delaunay source does a good job at capturing the appearance of the source galaxy\n",
        "using adaptive triangular pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We now perform lens modeling using the Delaunay pixelization with the Overlay image-mesh.\n",
        "\n",
        "The code below is a simple adaptive modeling example using the Delaunay mesh, which mirrors the\n",
        "API used in other pixelization modeling examples.\n",
        "\n",
        "The example `imaging/features/pixelization/adaptive.py` illustrates how to use adaptive features to\n",
        "adapt the rectangular mesh and its regularization to the source's surface brightness. In particular, an image\n",
        "of the lensed source is passed to the modeling via the `AdaptImages` object, in order to adapt\n",
        "the mesh and regularization during the model-fit.\n",
        "\n",
        "The same object is used to pass the `image_plane_mesh_grid` to the modeling. Above, this image-plane mesh grid\n",
        "is an `Overlay` mesh and does not specifically adapt to the source's surface brightness, thus pairing it with\n",
        "the source as done below seems redundant. However, in a moment we will switch to a `Hilbert` image-mesh, which\n",
        "does adapt to the source's surface brightness, meaning this pairing is necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "adapt_images = al.AdaptImages(\n",
        "    galaxy_name_image_plane_mesh_grid_dict={\n",
        "        \"('galaxies', 'source')\": image_plane_mesh_grid\n",
        "    },\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ", the `number_of_cores` is specified in the non-linear search.\n",
        "\n",
        "We therefore compose our lens model using `Model` objects, which represent the galaxies we fit to our data. In the first\n",
        "search our lens model is:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` with `ExternalShear` [7 parameters].\n",
        " \n",
        " - The source galaxy's light uses an `Overlay` image-mesh with fixed resolution 30 x 30 pixels [0 parameters].\n",
        " \n",
        " - The source-galaxy's light uses a `Delaunay` mesh [0 parameters].\n",
        "\n",
        " - This pixelization is regularized using a `Constant` scheme [1 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(\n",
        "    al.Galaxy, redshift=0.5, mass=al.mp.Isothermal, shear=al.mp.ExternalShear\n",
        ")\n",
        "\n",
        "pixelization = af.Model(\n",
        "    al.Pixelization,\n",
        "    mesh=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.Constant,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "model_1 = af.Collection(galaxies=af.Collection(lens=lens, source=source))\n",
        "\n",
        "search_1 = af.Nautilus(\n",
        "    path_prefix=Path(\"features\"),\n",
        "    name=\"delaunay\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=2,\n",
        ")\n",
        "\n",
        "analysis_1 = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_images=adapt_images,\n",
        "    positions_likelihood_list=[al.PositionsLH(positions=positions, threshold=0.3)],\n",
        "    preloads=preloads,\n",
        "    use_jax=False,\n",
        ")\n",
        "\n",
        "result_1 = search_1.fit(model=model_1, analysis=analysis_1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Adaptive Delaunay__\n",
        "\n",
        "The example `imaging/features/pixelization/adaptive.py` illustrates how to use adaptive features to\n",
        "adapt the rectangular mesh and its regularization to the source's surface brightness.\n",
        "\n",
        "The image-mesh has a special adaptive variant called the `Hilbert` image-mesh, which adapts the distribution \n",
        "of source-pixels to the source's unlensed morphology. This means that the source's brightest regions are \n",
        "reconstructed using significantly more source pixels than seen for the `Overlay` image mesh. \n",
        "Conversely, the source's faintest regions are reconstructed using significantly fewer source pixels.\n",
        "\n",
        "Unlike the adaptive rectangular mesh, the Hilbert image-plane mesh is computed before modeling, passed\n",
        "to the `AdaptImages` object, and remains fixed during the model-fit.\n",
        "\n",
        "It is recommend that the parameters governing these features are always fitted from using a fixed lens light and\n",
        "mass model. This ensures the adaptation is performed quickly, and removes degeneracies in the lens model that\n",
        "are difficult to sample. Given the Hilbert mesh is fixed, this modeling only fits for the regularization coefficients\n",
        "of the adaptive regularization scheme.\n",
        "\n",
        "For this reason, search 2 fixes the lens galaxy's light and mass model to the best-fit model of search 1. A third\n",
        "search will then fit for the lens galaxy's light and mass model using these adaptive features.\n",
        "\n",
        "The details of how the above features work is not provided here, but is given at the end of chapter 4 of the HowToLens\n",
        "lecture series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy_image_name_dict = al.galaxy_name_image_dict_via_result_from(result=result_1)\n",
        "\n",
        "image_mesh = al.image_mesh.Hilbert(pixels=1000)\n",
        "\n",
        "image_plane_mesh_grid = image_mesh.image_plane_mesh_grid_from(\n",
        "    mask=dataset.mask, adapt_data=galaxy_image_name_dict[\"('galaxies', 'source')\"]\n",
        ")\n",
        "\n",
        "image_plane_mesh_grid_edge_pixels = 30\n",
        "\n",
        "image_plane_mesh_grid = al.image_mesh.append_with_circle_edge_points(\n",
        "    image_plane_mesh_grid=image_plane_mesh_grid,\n",
        "    centre=mask.mask_centre,\n",
        "    radius=3.0 + mask.pixel_scale / 2.0,\n",
        "    n_points=image_plane_mesh_grid_edge_pixels,\n",
        ")\n",
        "\n",
        "total_mapper_pixels = image_plane_mesh_grid.shape[0]\n",
        "\n",
        "total_linear_light_profiles = 0\n",
        "\n",
        "mapper_indices = al.mapper_indices_from(\n",
        "    total_linear_light_profiles=total_linear_light_profiles,\n",
        "    total_mapper_pixels=total_mapper_pixels,\n",
        ")\n",
        "\n",
        "source_pixel_zeroed_indices = mapper_indices[-image_plane_mesh_grid_edge_pixels:]\n",
        "\n",
        "preloads = al.Preloads(\n",
        "    mapper_indices=mapper_indices,\n",
        "    source_pixel_zeroed_indices=source_pixel_zeroed_indices,\n",
        ")\n",
        "\n",
        "adapt_images = al.AdaptImages(\n",
        "    galaxy_name_image_dict=galaxy_image_name_dict,\n",
        "    galaxy_name_image_plane_mesh_grid_dict={\n",
        "        \"('galaxies', 'source')\": image_plane_mesh_grid\n",
        "    },\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model (Search 2)__\n",
        "\n",
        "We therefore compose our lens model using `Model` objects, which represent the galaxies we fit to our data. In \n",
        "the second search our lens model is:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` with `ExternalShear` with fixed parameters from \n",
        "   search 1 [0 parameters].\n",
        " \n",
        " - The source galaxy's light uses a `Hilbert` image-mesh with fixed resolution 1000 pixels [2 parameters].\n",
        " \n",
        " - The source-galaxy's light uses a `Delaunay` mesh [0 parameters].\n",
        "\n",
        " - This pixelization is regularized using a `AdaptiveBrightnessSplit` scheme [2 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = af.Model(\n",
        "    al.Pixelization,\n",
        "    mesh=al.mesh.Delaunay,\n",
        "    regularization=al.reg.AdaptiveBrightnessSplit,\n",
        ")\n",
        "\n",
        "source = af.Model(\n",
        "    al.Galaxy,\n",
        "    redshift=1.0,\n",
        "    pixelization=pixelization,\n",
        ")\n",
        "\n",
        "model_2 = af.Collection(\n",
        "    galaxies=af.Collection(lens=result_1.instance.galaxies.lens, source=source)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis (Search 2)__\n",
        "\n",
        "We now create the analysis for the second search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_2 = al.AnalysisImaging(\n",
        "    dataset=dataset, adapt_images=adapt_images, preloads=preloads, use_jax=False\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search + Model-Fit (Search 2)__\n",
        "\n",
        "We now create the non-linear search and perform the model-fit using this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_2 = af.Nautilus(\n",
        "    path_prefix=Path(\"features\"),\n",
        "    name=\"delaunay_adapt\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=75,\n",
        "    number_of_cores=2,  # CPU specific code\n",
        ")\n",
        "\n",
        "result_2 = search_2.fit(model=model_2, analysis=analysis_2)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We could perform a third fit where we free all lens model parameters and fit them using the adaptive \n",
        "image mesh and regularization.\n",
        "\n",
        "However, it is better to use all of these features with the Delaunay via the\n",
        "SLaM pipelines, which we jump to immediately below.\n",
        "\n",
        "__SLaM Pipelines__\n",
        "\n",
        "The API above allows you to use adaptive features yourself, and you should go ahead an explore them on datasets you\n",
        "are familiar with.\n",
        "\n",
        "However, you may also wish to use the Source, Light and Mass (SLaM) pipelines, which are pipelines that\n",
        "have been carefully crafted to automate lens modeling of large samples whilst ensuring models of the highest\n",
        "complexity can be reliably fitted.\n",
        "\n",
        "These pipelines are built around the use of adaptive features -- for example the Source pipeline comes first so that\n",
        "these features are set up robustly before more complex lens light and mass models are fitted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, os.getcwd())\n",
        "import slam_pipeline\n",
        "\n",
        "dataset_name = \"simple\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "over_sample_size = al.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "    grid=dataset.grid,\n",
        "    sub_size_list=[4, 2, 1],\n",
        "    radial_list=[0.3, 0.6],\n",
        "    centre_list=[(0.0, 0.0)],\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)\n",
        "\n",
        "dataset = dataset.apply_w_tilde()\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Settings AutoFit__\n",
        "\n",
        "The settings of autofit, which controls the output paths, parallelization, database use, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings_search = af.SettingsSearch(\n",
        "    path_prefix=Path(\"imaging\") / \"slam_delaunay\",\n",
        "    unique_tag=dataset_name,\n",
        "    info=None,\n",
        "    session=None,\n",
        "    number_of_cores=2,  # CPU specific code\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Redshifts__\n",
        "\n",
        "The redshifts of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "redshift_lens = 0.5\n",
        "redshift_source = 1.0\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE LP PIPELINE__\n",
        "\n",
        "The SOURCE LP PIPELINE is identical to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(dataset=dataset, use_jax=False)\n",
        "\n",
        "# Lens Light\n",
        "\n",
        "lens_bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius,\n",
        "    total_gaussians=20,\n",
        "    gaussian_per_basis=2,\n",
        "    centre_prior_is_uniform=True,\n",
        ")\n",
        "\n",
        "# Source Light\n",
        "\n",
        "source_bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius, total_gaussians=20, centre_prior_is_uniform=False\n",
        ")\n",
        "\n",
        "source_lp_result = slam_pipeline.source_lp.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    lens_bulge=lens_bulge,\n",
        "    lens_disk=None,\n",
        "    mass=af.Model(al.mp.Isothermal),\n",
        "    shear=af.Model(al.mp.ExternalShear),\n",
        "    source_bulge=source_bulge,\n",
        "    mass_centre=(0.0, 0.0),\n",
        "    redshift_lens=redshift_lens,\n",
        "    redshift_source=redshift_source,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__JAX & Preloads__\n",
        "\n",
        "Setup the Overlay image-mesh and preloads for the SOURCE PIX PIPELINE, following the same\n",
        "code as earlier in this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_mesh = al.image_mesh.Overlay(shape=(26, 26))\n",
        "\n",
        "image_plane_mesh_grid = image_mesh.image_plane_mesh_grid_from(\n",
        "    mask=dataset.mask,\n",
        ")\n",
        "\n",
        "image_plane_mesh_grid_edge_pixels = 30\n",
        "\n",
        "image_plane_mesh_grid = al.image_mesh.append_with_circle_edge_points(\n",
        "    image_plane_mesh_grid=image_plane_mesh_grid,\n",
        "    centre=mask.mask_centre,\n",
        "    radius=3.0 + mask.pixel_scale / 2.0,\n",
        "    n_points=image_plane_mesh_grid_edge_pixels,\n",
        ")\n",
        "\n",
        "total_mapper_pixels = image_plane_mesh_grid.shape[0]\n",
        "\n",
        "total_linear_light_profiles = 40\n",
        "\n",
        "mapper_indices = al.mapper_indices_from(\n",
        "    total_linear_light_profiles=total_linear_light_profiles,\n",
        "    total_mapper_pixels=total_mapper_pixels,\n",
        ")\n",
        "\n",
        "# Extract the last `image_plane_mesh_grid_edge_pixels` indices, which correspond to the circle edge points we added\n",
        "\n",
        "source_pixel_zeroed_indices = mapper_indices[-image_plane_mesh_grid_edge_pixels:]\n",
        "\n",
        "preloads = al.Preloads(\n",
        "    mapper_indices=mapper_indices,\n",
        "    source_pixel_zeroed_indices=source_pixel_zeroed_indices,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE PIX PIPELINE__\n",
        "\n",
        "The SOURCE PIX PIPELINE is identical to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy_image_name_dict = al.galaxy_name_image_dict_via_result_from(\n",
        "    result=source_lp_result\n",
        ")\n",
        "\n",
        "adapt_images = al.AdaptImages(\n",
        "    galaxy_name_image_dict=galaxy_image_name_dict,\n",
        "    galaxy_name_image_plane_mesh_grid_dict={\n",
        "        \"('galaxies', 'source')\": image_plane_mesh_grid\n",
        "    },\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_images=adapt_images,\n",
        "    positions_likelihood_list=[\n",
        "        source_lp_result.positions_likelihood_from(factor=3.0, minimum_threshold=0.2)\n",
        "    ],\n",
        "    preloads=preloads,\n",
        "    use_jax=False,\n",
        ")\n",
        "\n",
        "source_pix_result_1 = slam_pipeline.source_pix.run_1(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_lp_result=source_lp_result,\n",
        "    mesh_init=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.AdaptiveBrightness,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE PIX PIPELINE 2__\n",
        "\n",
        "The SOURCE PIX PIPELINE 2 is identical to the `slam_start_here.ipynb` example.\n",
        "\n",
        "This sets up the Hilbert image-mesh and preloads for the second source pixelization\n",
        "using the same code as earlier in this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy_image_name_dict = al.galaxy_name_image_dict_via_result_from(\n",
        "    result=source_pix_result_1\n",
        ")\n",
        "\n",
        "image_mesh = al.image_mesh.Hilbert(pixels=1000)\n",
        "\n",
        "image_plane_mesh_grid = image_mesh.image_plane_mesh_grid_from(\n",
        "    mask=dataset.mask, adapt_data=galaxy_image_name_dict[\"('galaxies', 'source')\"]\n",
        ")\n",
        "\n",
        "image_plane_mesh_grid_edge_pixels = 30\n",
        "\n",
        "image_plane_mesh_grid = al.image_mesh.append_with_circle_edge_points(\n",
        "    image_plane_mesh_grid=image_plane_mesh_grid,\n",
        "    centre=mask.mask_centre,\n",
        "    radius=3.0 + mask.pixel_scale / 2.0,\n",
        "    n_points=image_plane_mesh_grid_edge_pixels,\n",
        ")\n",
        "\n",
        "total_mapper_pixels = image_plane_mesh_grid.shape[0]\n",
        "\n",
        "total_linear_light_profiles = 40\n",
        "\n",
        "mapper_indices = al.mapper_indices_from(\n",
        "    total_linear_light_profiles=total_linear_light_profiles,\n",
        "    total_mapper_pixels=total_mapper_pixels,\n",
        ")\n",
        "\n",
        "source_pixel_zeroed_indices = mapper_indices[-image_plane_mesh_grid_edge_pixels:]\n",
        "\n",
        "preloads = al.Preloads(\n",
        "    mapper_indices=mapper_indices,\n",
        "    source_pixel_zeroed_indices=source_pixel_zeroed_indices,\n",
        ")\n",
        "\n",
        "adapt_images = al.AdaptImages(\n",
        "    galaxy_name_image_dict=galaxy_image_name_dict,\n",
        "    galaxy_name_image_plane_mesh_grid_dict={\n",
        "        \"('galaxies', 'source')\": image_plane_mesh_grid\n",
        "    },\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_images=adapt_images,\n",
        "    preloads=preloads,\n",
        "    use_jax=False,\n",
        ")\n",
        "\n",
        "source_pix_result_2 = slam_pipeline.source_pix.run_2(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_lp_result=source_lp_result,\n",
        "    source_pix_result_1=source_pix_result_1,\n",
        "    mesh=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.AdaptiveBrightness,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__LIGHT LP PIPELINE__\n",
        "\n",
        "The LIGHT LP PIPELINE is setup identically to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_images=adapt_images,\n",
        "    preloads=preloads,\n",
        "    use_jax=False,\n",
        ")\n",
        "\n",
        "lens_bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius,\n",
        "    total_gaussians=20,\n",
        "    gaussian_per_basis=2,\n",
        "    centre_prior_is_uniform=True,\n",
        ")\n",
        "\n",
        "light_result = slam_pipeline.light_lp.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_result_for_lens=source_pix_result_1,\n",
        "    source_result_for_source=source_pix_result_2,\n",
        "    lens_bulge=lens_bulge,\n",
        "    lens_disk=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__MASS TOTAL PIPELINE__\n",
        "\n",
        "The MASS TOTAL PIPELINE is identical to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_images=adapt_images,\n",
        "    positions_likelihood_list=[\n",
        "        source_pix_result_2.positions_likelihood_from(factor=3.0, minimum_threshold=0.2)\n",
        "    ],\n",
        "    preloads=preloads,\n",
        "    use_jax=False,\n",
        ")\n",
        "\n",
        "mass_result = slam_pipeline.mass_total.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_result_for_lens=source_pix_result_1,\n",
        "    source_result_for_source=source_pix_result_2,\n",
        "    light_result=light_result,\n",
        "    mass=af.Model(al.mp.PowerLaw),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Function__\n",
        "\n",
        "The example `imaging/features/pixelization/likelihood_function.py` provides a step-by-step description of how\n",
        "a likelihood evaluation is performed for imaging data using a pixelized source reconstruction with a rectangular\n",
        "mesh.\n",
        "\n",
        "We now give the same step-by-step description for a pixelized source reconstruction using a Delaunay mesh and\n",
        "adaptive features.\n",
        "\n",
        "We only describe code which is specific to Delaunay meshes and adaptive features -- for all other aspects of the likelihood\n",
        "evaluation, refer to rectangular mesh example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = Path(\"dataset\", \"imaging\", \"simple\")\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "\n",
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "masked_dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=masked_dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "\n",
        "masked_dataset = masked_dataset.apply_over_sampling(\n",
        "    over_sample_size_lp=1,\n",
        "    over_sample_size_pixelization=1,\n",
        ")\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=masked_dataset.grids.pixelization)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "bulge = al.lp.Sersic(\n",
        "    centre=(0.0, 0.0),\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    intensity=2.0,\n",
        "    effective_radius=0.6,\n",
        "    sersic_index=3.0,\n",
        ")\n",
        "\n",
        "mass = al.mp.Isothermal(\n",
        "    centre=(0.0, 0.0),\n",
        "    einstein_radius=1.6,\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        ")\n",
        "\n",
        "shear = al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05)\n",
        "\n",
        "lens_galaxy = al.Galaxy(redshift=0.5, bulge=bulge, mass=mass, shear=shear)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Source Galaxy Pixelization and Regularization__\n",
        "\n",
        "The source galaxy is reconstructed using a pixel-grid, in this example a Delaunay mesh, which accounts for \n",
        "irregularities and asymmetries in the source's surface brightness. \n",
        "\n",
        "A constant regularization scheme is applied which applies a smoothness prior on the reconstruction. \n",
        "\n",
        "One of the biggest differences between a Delaunay mesh and rectangular mesh is how the centres of the mesh pixels\n",
        "in the source-plane are computed. \n",
        "\n",
        "For the rectangular mesh, the pixel centres are computed by overlaying a uniform grid over the source-plane.\n",
        "\n",
        "For a Delaunay mesh, the uniform grid is instead laid over the image-plane to create a course grid of (y,x) coordinates.\n",
        "These are then ray-traced to the source-plane and are used as the vertexes of the Delaunay triangles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    image_mesh=al.image_mesh.Overlay(shape=(30, 30)),  # Specific to Delaunay\n",
        "    mesh=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(redshift=1.0, pixelization=pixelization)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Lens Light__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image = lens_galaxy.image_2d_from(grid=masked_dataset.grid)\n",
        "\n",
        "galaxy_plotter = aplt.GalaxyPlotter(galaxy=lens_galaxy, grid=masked_dataset.grid)\n",
        "galaxy_plotter.figures_2d(image=True)\n",
        "\n",
        "blurring_image_2d = lens_galaxy.image_2d_from(grid=masked_dataset.grids.blurring)\n",
        "\n",
        "galaxy_plotter = aplt.GalaxyPlotter(\n",
        "    galaxy=lens_galaxy, grid=masked_dataset.grids.blurring\n",
        ")\n",
        "galaxy_plotter.figures_2d(image=True)\n",
        "\n",
        "convolved_image_2d = masked_dataset.psf.convolved_image_from(\n",
        "    image=image, blurring_image=blurring_image_2d\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=convolved_image_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "\n",
        "lens_subtracted_image_2d = masked_dataset.data - convolved_image_2d\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=lens_subtracted_image_2d)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Source Pixel Centre Calculation__\n",
        "\n",
        "In order to reconstruct the source galaxy using a Delaunay mesh, we need to determine the centres of the Delaunay\n",
        "source pixels.\n",
        "\n",
        "The image-mesh `Overlay` object computes the source-pixel centres in the image-plane (which are ray-traced to the\n",
        "source-plane below). The source pixelization therefore adapts to the lens model magnification, because more\n",
        "source pixels will congregate in higher magnification regions.\n",
        "\n",
        "This calculation is performed by overlaying a uniform regular grid with an `pixelization_shape_2d` over the image\n",
        "mask and retaining all pixels that fall within the mask. This uses a `Grid2DSparse` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_plane_mesh_grid = pixelization.image_mesh.image_plane_mesh_grid_from(\n",
        "    mask=masked_dataset.mask,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting this grid shows a sparse grid of (y,x) coordinates within the mask, which will form our source pixel centres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(grid=image_plane_mesh_grid)\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=masked_dataset, visuals_2d=visuals)\n",
        "dataset_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Ray Tracing__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The source code gets quite complex when handling grids for a pixelization, but it is all handled in\n",
        "the `TracerToInversion` objects.\n",
        "\n",
        "The plots at the bottom of this cell show the traced grids used by the source pixelization, showing\n",
        "how the Delaunay mesh and traced image pixels are constructed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_to_inversion = al.TracerToInversion(tracer=tracer, dataset=masked_dataset)\n",
        "\n",
        "# A list of every grid (e.g. image-plane, source-plane) however we only need the source plane grid with index -1.\n",
        "traced_grid_pixelization = tracer.traced_grid_2d_list_from(\n",
        "    grid=masked_dataset.grids.pixelization\n",
        ")[-1]\n",
        "\n",
        "# This functions a bit weird - it returns a list of lists of ndarrays. Best not to worry about it for now!\n",
        "traced_mesh_grid = tracer_to_inversion.traced_mesh_grid_pg_list[-1][-1]\n",
        "\n",
        "mat_plot = aplt.MatPlot2D(axis=aplt.Axis(extent=[-1.5, 1.5, -1.5, 1.5]))\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=traced_grid_pixelization, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have also ray-traced the coarse grid of image-pixel coordinates used to form the source pixelization's\n",
        "Delaunay mesh, which we can also plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_plotter = aplt.Grid2DPlotter(grid=traced_mesh_grid, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Border Relocation__\n",
        "\n",
        "Coordinates that are ray-traced near the mass profile centres are heavily demagnified and may trace to far outskirts of\n",
        "the source-plane. \n",
        "\n",
        "Border relocation is performed on both the traced image-pixel grid and traced mesh pixels, therefore ensuring that\n",
        "the vertexes of the Delaunay triangles are not at the extreme outskirts of the source-plane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoarray.inversion.pixelization.border_relocator import BorderRelocator\n",
        "\n",
        "border_relocator = BorderRelocator(mask=masked_dataset.mask, sub_size=1)\n",
        "\n",
        "relocated_grid = border_relocator.relocated_grid_from(grid=traced_grid_pixelization)\n",
        "\n",
        "relocated_mesh_grid = border_relocator.relocated_mesh_grid_from(\n",
        "    grid=traced_mesh_grid, mesh_grid=traced_mesh_grid\n",
        ")\n",
        "\n",
        "mat_plot = aplt.MatPlot2D(axis=aplt.Axis(extent=[-1.5, 1.5, -1.5, 1.5]))\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=relocated_grid, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=relocated_mesh_grid, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Delaunay Mesh__\n",
        "\n",
        "The relocated mesh grid is used to create the `Pixelization`'s Delaunay mesh using the `scipy.spatial` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_delaunay = al.Mesh2DDelaunay(\n",
        "    values=relocated_mesh_grid,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the Delaunay mesh shows that the source-plane and been discretized into a grid of irregular Delaunay pixels.\n",
        "\n",
        "(To plot the Delaunay mesh, we have to convert it to a `Mapper` object, which is described in the next likelihood step).\n",
        "\n",
        "Below, we plot the Delaunay mesh without the traced image-grid pixels (for clarity) and with them as black dots in order\n",
        "to show how each set of image-pixels fall within a Delaunay pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_grids = al.MapperGrids(\n",
        "    mask=mask,\n",
        "    source_plane_data_grid=relocated_grid,\n",
        "    source_plane_mesh_grid=grid_delaunay,\n",
        "    image_plane_mesh_grid=image_plane_mesh_grid,\n",
        ")\n",
        "\n",
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "mapper_plotter.figure_2d(interpolate_to_uniform=False)\n",
        "\n",
        "\n",
        "visuals = aplt.Visuals2D(\n",
        "    grid=mapper_grids.source_plane_data_grid,\n",
        ")\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper, visuals_2d=visuals)\n",
        "mapper_plotter.figure_2d(interpolate_to_uniform=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Image-Source Mapping__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "pix_indexes_for_sub_slim_index = mapper.pix_indexes_for_sub_slim_index\n",
        "\n",
        "print(pix_indexes_for_sub_slim_index[0:9])\n",
        "\n",
        "visuals = aplt.Visuals2D(indexes=[list(range(2050, 2090))])\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(\n",
        "    mapper=mapper,\n",
        "    visuals_2d=visuals,\n",
        ")\n",
        "mapper_plotter.subplot_image_and_mapper(\n",
        "    image=lens_subtracted_image_2d, interpolate_to_uniform=False\n",
        ")\n",
        "\n",
        "pix_indexes = [[200]]\n",
        "\n",
        "indexes = mapper.slim_indexes_for_pix_indexes(pix_indexes=pix_indexes)\n",
        "\n",
        "visuals = aplt.Visuals2D(indexes=indexes)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(\n",
        "    mapper=mapper,\n",
        "    visuals_2d=visuals,\n",
        ")\n",
        "\n",
        "mapper_plotter.subplot_image_and_mapper(\n",
        "    image=lens_subtracted_image_2d, interpolate_to_uniform=False\n",
        ")\n",
        "\n",
        "mapping_matrix = al.util.mapper.mapping_matrix_from(\n",
        "    pix_indexes_for_sub_slim_index=pix_indexes_for_sub_slim_index,\n",
        "    pix_size_for_sub_slim_index=mapper.pix_sizes_for_sub_slim_index,  # unused for Delaunay\n",
        "    pix_weights_for_sub_slim_index=mapper.pix_weights_for_sub_slim_index,  # unused for Delaunay\n",
        "    pixels=mapper.pixels,\n",
        "    total_mask_pixels=mapper.source_plane_data_grid.mask.pixels_in_mask,\n",
        "    slim_index_for_sub_slim_index=mapper.slim_index_for_sub_slim_index,\n",
        "    sub_fraction=np.array(mapper.over_sampler.sub_fraction),\n",
        ")\n",
        "\n",
        "plt.imshow(mapping_matrix, aspect=(mapping_matrix.shape[1] / mapping_matrix.shape[0]))\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "indexes_source_pix_200 = np.nonzero(mapping_matrix[:, 200])\n",
        "\n",
        "print(indexes_source_pix_200[0])\n",
        "\n",
        "array_2d = al.Array2D(values=mapping_matrix[:, 200], mask=masked_dataset.mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "blurred_mapping_matrix = masked_dataset.psf.convolved_mapping_matrix_from(\n",
        "    mapping_matrix=mapping_matrix, mask=masked_dataset.mask\n",
        ")\n",
        "\n",
        "plt.imshow(\n",
        "    blurred_mapping_matrix,\n",
        "    aspect=(blurred_mapping_matrix.shape[1] / blurred_mapping_matrix.shape[0]),\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "indexes_source_pix_200 = np.nonzero(blurred_mapping_matrix[:, 200])\n",
        "\n",
        "print(indexes_source_pix_200[0])\n",
        "\n",
        "array_2d = al.Array2D(values=blurred_mapping_matrix[:, 200], mask=masked_dataset.mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "print(f\"Mapping between image pixel 0 and source pixel 2 = {mapping_matrix[0, 2]}\")\n",
        "\n",
        "data_vector = al.util.inversion_imaging.data_vector_via_blurred_mapping_matrix_from(\n",
        "    blurred_mapping_matrix=blurred_mapping_matrix,\n",
        "    image=np.array(lens_subtracted_image_2d),\n",
        "    noise_map=np.array(masked_dataset.noise_map),\n",
        ")\n",
        "\n",
        "plt.imshow(\n",
        "    data_vector.reshape(data_vector.shape[0], 1), aspect=10.0 / data_vector.shape[0]\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "curvature_matrix = al.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=blurred_mapping_matrix, noise_map=masked_dataset.noise_map\n",
        ")\n",
        "\n",
        "plt.imshow(curvature_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "source_pixel_0 = 0\n",
        "source_pixel_1 = 1\n",
        "\n",
        "print(curvature_matrix[source_pixel_0, source_pixel_1])\n",
        "\n",
        "array_2d = al.Array2D(\n",
        "    values=blurred_mapping_matrix[:, source_pixel_0], mask=masked_dataset.mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "array_2d = al.Array2D(\n",
        "    values=blurred_mapping_matrix[:, source_pixel_1], mask=masked_dataset.mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "regularization_matrix = al.util.regularization.constant_regularization_matrix_from(\n",
        "    coefficient=source_galaxy.pixelization.regularization.coefficient,\n",
        "    neighbors=mapper.source_plane_mesh_grid.neighbors,\n",
        "    neighbors_sizes=mapper.source_plane_mesh_grid.neighbors.sizes,\n",
        ")\n",
        "\n",
        "plt.imshow(regularization_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "curvature_reg_matrix = np.add(curvature_matrix, regularization_matrix)\n",
        "\n",
        "reconstruction = np.linalg.solve(curvature_reg_matrix, data_vector)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "\n",
        "mapper_plotter.figure_2d(solution_vector=reconstruction, interpolate_to_uniform=False)\n",
        "\n",
        "mapped_reconstructed_image_2d = (\n",
        "    al.util.inversion.mapped_reconstructed_data_via_mapping_matrix_from(\n",
        "        mapping_matrix=blurred_mapping_matrix, reconstruction=reconstruction\n",
        "    )\n",
        ")\n",
        "\n",
        "mapped_reconstructed_image_2d = al.Array2D(\n",
        "    values=mapped_reconstructed_image_2d, mask=mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=mapped_reconstructed_image_2d)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Function__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_image = convolved_image_2d + mapped_reconstructed_image_2d\n",
        "\n",
        "residual_map = masked_dataset.data - model_image\n",
        "normalized_residual_map = residual_map / masked_dataset.noise_map\n",
        "chi_squared_map = normalized_residual_map**2.0\n",
        "\n",
        "chi_squared = np.sum(chi_squared_map)\n",
        "\n",
        "print(chi_squared)\n",
        "\n",
        "chi_squared_map = al.Array2D(values=chi_squared_map, mask=mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=chi_squared_map)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "regularization_term = np.matmul(\n",
        "    reconstruction.T, np.matmul(regularization_matrix, reconstruction)\n",
        ")\n",
        "\n",
        "print(regularization_term)\n",
        "\n",
        "log_curvature_reg_matrix_term = np.linalg.slogdet(curvature_reg_matrix)[1]\n",
        "log_regularization_matrix_term = np.linalg.slogdet(regularization_matrix)[1]\n",
        "\n",
        "print(log_curvature_reg_matrix_term)\n",
        "print(log_regularization_matrix_term)\n",
        "\n",
        "noise_normalization = float(np.sum(np.log(2 * np.pi * masked_dataset.noise_map**2.0)))\n",
        "\n",
        "log_evidence = float(\n",
        "    -0.5\n",
        "    * (\n",
        "        chi_squared\n",
        "        + regularization_term\n",
        "        + log_curvature_reg_matrix_term\n",
        "        - log_regularization_matrix_term\n",
        "        + noise_normalization\n",
        "    )\n",
        ")\n",
        "\n",
        "print(log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "This process to perform a likelihood function evaluation is what is performed in the `FitImaging` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = al.FitImaging(\n",
        "    dataset=masked_dataset,\n",
        "    tracer=tracer,\n",
        "    settings_inversion=al.SettingsInversion(use_border_relocator=True),\n",
        "    preloads=preloads,\n",
        ")\n",
        "fit_log_evidence = fit.log_evidence\n",
        "print(fit_log_evidence)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Lens Modeling__\n",
        "\n",
        "To fit a lens model to data, the likelihood function illustrated in this tutorial is sampled using a\n",
        "non-linear search algorithm.\n",
        "\n",
        "The default sampler is the nested sampling algorithm `Nautilus` (https://github.com/joshspeagle/Nautilus)\n",
        "but **PyAutoLens** supports multiple MCMC and optimization algorithms. \n",
        "\n",
        "__Sub Gridding__\n",
        "\n",
        "The calculation above uses a `Grid2D` object, with a `sub-size=1`, meaning it does not perform oversampling to\n",
        "evaluate the light profile flux at every image pixel.\n",
        "\n",
        "**PyAutoLens** has alternative methods of computing the lens galaxy images above, which uses a grid whose sub-size\n",
        "adaptively increases depending on a required fractional accuracy of the light profile.\n",
        "\n",
        " https://github.com/Jammy2211/PyAutoArray/blob/main/autoarray/structures/grids/two_d/grid_iterate.py\n",
        "\n",
        "__Sourrce Plane Interpolation__\n",
        "\n",
        "For the `Delaunay` mesh used in this example, every image-sub pixel maps to a single source Voronoi\n",
        "pixel. Therefore, the plural use of `pix_indexes` is not required. However, for other pixelizations each sub-pixel\n",
        "can map to multiple source pixels with an interpolation weight (e.g. `Delaunay` triangulation or a `Voronoi` mesh\n",
        "which uses natural neighbor interpolation).\n",
        "\n",
        "`MapperVoronoiNoInterp.pix_index_for_sub_slim_index`:\n",
        "https://github.com/Jammy2211/PyAutoArray/blob/main/autoarray/inversion/mappers/voronoi.py\n",
        "\n",
        "`pixelization_index_for_voronoi_sub_slim_index_from`:\n",
        " https://github.com/Jammy2211/PyAutoArray/blob/main/autoarray/util/mapper_util.py\n",
        "\n",
        "The number of pixels that each sub-pixel maps too is also stored and extracted. This is used for speeding up\n",
        "the calculation of the `mapping_matrix` described next.\n",
        "\n",
        "As discussed above, because for the `VoronoiNoInterp` pixelization where every sub-pixel maps to one source pixel,\n",
        "every entry of this array will be equal to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# pix_sizes_for_sub_slim_index = mapper.pix_sizes_for_sub_slim_index"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When each sub-pixel maps to multiple source pixels, the mappings are described via an interpolation weight. For \n",
        "example, for a `Delaunay` triangulation, every sub-pixel maps to 3 Delaunay triangles based on which triangle\n",
        "it lands in.\n",
        "\n",
        "For the `VoronoiNoInterp` pixelization where every sub-pixel maps to a single source pixel without inteprolation,\n",
        "every entry of this weight array is 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# pix_weights_for_sub_slim_index = mapper.pix_weights_for_sub_slim_index"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "We have presented a visual step-by-step guide to the **PyAutoLens** likelihood function, which uses a pixelization, \n",
        "regularization scheme and inversion to reconstruct the source galaxy.\n",
        "\n",
        "There are a number of other inputs features which slightly change the behaviour of this likelihood function, which\n",
        "are described in additional notebooks found in this package. In brief, these describe:\n",
        "\n",
        " - **Sub-gridding**: Oversampling the image grid into a finer grid of sub-pixels, which are all individually \n",
        " ray-traced to the source-plane and paired fractionally with each source pixel.\n",
        " \n",
        " - **Source-plane Interpolation**: Using a Delaunay triangulation or Delaunay mesh with natural neighbor interpolation\n",
        " to pair each image (sub-)pixel to multiple source-plane pixels with interpolation weights.\n",
        " \n",
        " - **Source Morphology Pixelization Adaption**: Adapting the pixelization such that is congregates source pixels around\n",
        " the source's brightest regions, as opposed to the magnification-based pixelization used here.\n",
        " \n",
        " - **Luminosity Weighted Regularization**: Using an adaptive regularization coefficient which adapts the level of \n",
        " regularization applied to the source based on its luminosity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}