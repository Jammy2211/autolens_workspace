{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pixelization: CPU Fast Modeling\n",
        "===============================\n",
        "\n",
        "This example demonstrates how to achieve **fast pixelization performance on a CPU without JAX**, by combining:\n",
        "\n",
        "- `numba` for optimized numerical routines, and\n",
        "- Python `multiprocessing` to exploit multiple CPU cores.\n",
        "\n",
        "On machines with many CPU cores (e.g. HPC clusters with >10 CPUs), this method can **outperform JAX GPU acceleration**\n",
        "for pixelized source modeling. The advantage arises because pixelizations rely heavily on **sparse linear algebra**,\n",
        "which is not currently optimized in JAX.\n",
        "\n",
        "> Note: This performance advantage applies **only to pixelized sources**.\n",
        "> For parametric sources or multi-Gaussian models, JAX (especially with a GPU) is significantly faster, and even JAX\n",
        "> on a CPU outperforms the `numba` approach shown here.\n",
        "\n",
        "__Run Time Overview__\n",
        "\n",
        "Pixelized source reconstructions can be computed using either GPU acceleration via JAX or CPU acceleration via `numba`.\n",
        "The faster option depends on two crucial factors:\n",
        "\n",
        "#### **1. GPU VRAM Limitations**\n",
        "JAX only provides significant acceleration on GPUs with **large VRAM (\u226516 GB)**.\n",
        "To avoid excessive VRAM usage, examples often restrict pixelization meshes (e.g. 20 \u00d7 20).\n",
        "On consumer GPUs with limited memory, **JAX may be slower than CPU execution**.\n",
        "\n",
        "#### **2. Sparse Matrix Performance**\n",
        "\n",
        "Pixelized source reconstructions require operations on **very large, highly sparse matrices**.\n",
        "\n",
        "- JAX currently lacks sparse-matrix support and must compute using **dense matrices**, which scale poorly.\n",
        "- PyAutoLens\u2019s CPU implementation (via `numba`) fully exploits sparsity, providing large speed gains\n",
        "  at **high image resolution** (e.g. `pixel_scales <= 0.03`).\n",
        "\n",
        "As a result, CPU execution can outperform JAX even on powerful GPUs for high-resolution datasets.\n",
        "\n",
        "__Rule of Thumb__\n",
        "\n",
        "For **low-resolution imaging** (for example, datasets with `pixel_scales > 0.05`), modeling is generally faster using\n",
        "**JAX with a GPU**, because the computations involve fewer sparse operations and do not require large amounts of VRAM.\n",
        "\n",
        "For **high-resolution imaging** (for example, `pixel_scales <= 0.03`), modeling can be faster using a **CPU with numba**\n",
        "and multiple cores. At high resolution, the linear algebra is dominated by sparse matrix operations, and the CPU\n",
        "implementation exploits sparsity more effectively, especially on systems with many CPU cores (e.g. HPC clusters).\n",
        "\n",
        "**Recommendation:** The best choice depends on your hardware and dataset, so it is always worth benchmarking both\n",
        "approaches (GPU+JAX vs CPU+numba) to determine which performs fastest for your case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "try:\n",
        "    import numba\n",
        "except ModuleNotFoundError:\n",
        "    input(\n",
        "        \"##################\\n\"\n",
        "        \"##### NUMBA ######\\n\"\n",
        "        \"##################\\n\\n\"\n",
        "        \"\"\"\n",
        "        Numba is not currently installed.\n",
        "\n",
        "        Numba is a library which makes PyAutoLens run a lot faster. Certain functionality is disabled without numba\n",
        "        and will raise an exception if it is used.\n",
        "\n",
        "        If you have not tried installing numba, I recommend you try and do so now by running the following \n",
        "        commands in your command line / bash terminal now:\n",
        "\n",
        "        pip install --upgrade pip\n",
        "        pip install numba\n",
        "\n",
        "        If your numba installation raises an error and fails, you should go ahead and use PyAutoLens without numba to \n",
        "        decide if it is the right software for you. If it is, you should then commit time to bug-fixing the numba\n",
        "        installation. Feel free to raise an issue on GitHub for support with installing numba.\n",
        "\n",
        "        A warning will crop up throughout your *PyAutoLens** use until you install numba, to remind you to do so.\n",
        "\n",
        "        [Press Enter to continue]\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset + Masking + Positions__ \n",
        "\n",
        "Load, plot and mask the `Imaging` data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "over_sample_size = al.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "    grid=dataset.grid,\n",
        "    sub_size_list=[4, 2, 1],\n",
        "    radial_list=[0.3, 0.6],\n",
        "    centre_list=[(0.0, 0.0)],\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "\n",
        "positions = al.Grid2DIrregular(\n",
        "    al.from_json(file_path=Path(dataset_path, \"positions.json\"))\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__W_Tilde__\n",
        "\n",
        "Pixelized source modeling requires heavy linear algebra operations. These calculations can be greatly accelerated\n",
        "using an alternative mathematical approach called the **`w_tilde` formalism**.\n",
        "\n",
        "You do not need to understand the full details of the method, but the key point is:\n",
        "\n",
        "- `w_tilde` exploits the **sparsity** of the matrices used in pixelized source reconstruction.\n",
        "- This leads to a **significant speed-up on CPUs**.\n",
        "- The current implementation does **not support JAX**, and therefore does not benefit from GPU acceleration.\n",
        "\n",
        "To enable this feature, we call `apply_w_tilde()` on the `Imaging` dataset. This computes and stores a `w_tilde`\n",
        "matrix, which is then reused in all subsequent pixelized source fits.\n",
        "\n",
        "- Computing `w_tilde` takes anywhere from a few seconds to a few minutes, depending on the dataset size.\n",
        "- After it is computed once, every model-fit using pixelization becomes substantially faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_w_tilde = dataset.apply_w_tilde()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__JAX & Preloads__\n",
        "\n",
        "In earlier examples (`imaging/features/pixelization/modeling`), we used JAX, which requires *preloading* array shapes\n",
        "before compilation. In contrast, CPU modeling with `w_tilde` does **not** require JAX, allowing us to use larger meshes.\n",
        "\n",
        "Below, notice how the `mesh_shape` is increased to **30 \u00d7 30**. Because CPU computation exploits sparse matrices and\n",
        "benefits from larger system memory, we can now use higher-resolution pixelizations than were practical with JAX GPU\n",
        "acceleration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh_shape = (30, 30)\n",
        "total_mapper_pixels = mesh_shape[0] * mesh_shape[1]\n",
        "\n",
        "total_linear_light_profiles = 0\n",
        "\n",
        "preloads = al.Preloads(\n",
        "    mapper_indices=al.mapper_indices_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        total_mapper_pixels=total_mapper_pixels,\n",
        "    ),\n",
        "    source_pixel_zeroed_indices=al.util.mesh.rectangular_edge_pixel_list_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        shape_native=mesh_shape,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "In the example `imaging/features/pixelization/fit.py`, we demonstrated fitting imaging data using a\n",
        "pixelized source with a rectangular mesh.\n",
        "\n",
        "Below, we perform a similar fit using the **same pixelization**, but this time accelerated on the **CPU**\n",
        "using `numba` and sparse operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh = al.mesh.RectangularMagnification(shape=mesh_shape)\n",
        "regularization = al.reg.Constant(coefficient=1.0)\n",
        "\n",
        "pixelization = al.Pixelization(mesh=mesh, regularization=regularization)\n",
        "\n",
        "lens = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.0, 0.0),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        "    shear=al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05),\n",
        ")\n",
        "\n",
        "source = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens, source])\n",
        "\n",
        "fit = al.FitImaging(\n",
        "    dataset=dataset,\n",
        "    tracer=tracer,\n",
        "    preloads=preloads,\n",
        ")\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We now perform a full model-fit using the `w_tilde` formalism on the CPU.\n",
        "\n",
        "There are two key differences from the earlier JAX-based pixelization examples:\n",
        "\n",
        "- **JAX is disabled**  \n",
        "  The `AnalysisImaging` class is created with `use_jax=False`, preventing JAX compilation and ensuring\n",
        "  that all computations run on the CPU.\n",
        "\n",
        "- **CPU parallelization**  \n",
        "  The non-linear search is given a `number_of_cores` parameter, which parallelizes likelihood evaluations\n",
        "  using Python's `multiprocessing`.  \n",
        "  In practice, this provides a speed-up of roughly half the number of CPU cores used  \n",
        "  (e.g., 4 cores \u2192 ~2\u00d7 speed-up, 8 cores \u2192 ~4\u00d7 speed-up)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(\n",
        "    al.Galaxy, redshift=0.5, mass=al.mp.Isothermal, shear=al.mp.ExternalShear\n",
        ")\n",
        "\n",
        "pixelization = af.Model(\n",
        "    al.Pixelization,\n",
        "    mesh=al.mesh.RectangularMagnification(shape=mesh_shape),\n",
        "    regularization=al.reg.Constant,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"features\"),\n",
        "    name=\"cpu_fast_modeling\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=2,  # CPU specific code\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset_w_tilde, preloads=preloads, use_jax=False  # CPU specific code\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SLaM Pipeline__\n",
        "\n",
        "The example `guides/modeling//slam_start_here.ipynb` introduces the SLaM (Source, Light and Mass) pipelines for\n",
        "automated lens modeling of large samples of strong lenses.\n",
        "\n",
        "We finish this example by showing how to run the SLaM pipelines using CPU acceleration with `w_tilde`, similar to the\n",
        "model-fit above.\n",
        "\n",
        "Note that the first pipeline, SOURCE LP, uses JAX acceleration as in previous examples and therefore does not \n",
        "pass `use_jax=False` or a `number_of_cores` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, os.getcwd())\n",
        "import slam_pipeline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Settings AutoFit__\n",
        "\n",
        "The settings of autofit, which controls the output paths, parallelization, database use, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings_search = af.SettingsSearch(\n",
        "    path_prefix=Path(\"imaging\") / \"slam_cpu_fast\",\n",
        "    unique_tag=dataset_name,\n",
        "    info=None,\n",
        "    session=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Redshifts__\n",
        "\n",
        "The redshifts of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "redshift_lens = 0.5\n",
        "redshift_source = 1.0\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE LP PIPELINE__\n",
        "\n",
        "The SOURCE LP PIPELINE is identical to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(dataset=dataset, use_jax=False)\n",
        "\n",
        "# Lens Light\n",
        "\n",
        "lens_bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius,\n",
        "    total_gaussians=20,\n",
        "    gaussian_per_basis=2,\n",
        "    centre_prior_is_uniform=True,\n",
        ")\n",
        "\n",
        "# Source Light\n",
        "\n",
        "source_bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius, total_gaussians=20, centre_prior_is_uniform=False\n",
        ")\n",
        "\n",
        "source_lp_result = slam_pipeline.source_lp.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    lens_bulge=lens_bulge,\n",
        "    lens_disk=None,\n",
        "    mass=af.Model(al.mp.Isothermal),\n",
        "    shear=af.Model(al.mp.ExternalShear),\n",
        "    source_bulge=source_bulge,\n",
        "    mass_centre=(0.0, 0.0),\n",
        "    redshift_lens=redshift_lens,\n",
        "    redshift_source=redshift_source,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__CPU Fast SLaM Pipelines__\n",
        "\n",
        "The SLaM pipeline is mostly identical to other examples, but via the `SettingsSearch` it\n",
        "uses a `number_of_cores` parameter to parallelize the likelihood evaluations on the CPU\n",
        "and disables JAX compilation for each `AnalysisImaging` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings_search = af.SettingsSearch(\n",
        "    path_prefix=Path(\"imaging\") / \"slam_cpu_fast\",\n",
        "    unique_tag=dataset_name,\n",
        "    info=None,\n",
        "    session=None,\n",
        "    number_of_cores=2,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE PIX PIPELINE__\n",
        "\n",
        "The SOURCE PIX PIPELINE is identical to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy_image_name_dict = al.galaxy_name_image_dict_via_result_from(\n",
        "    result=source_lp_result\n",
        ")\n",
        "\n",
        "adapt_images = al.AdaptImages(galaxy_name_image_dict=galaxy_image_name_dict)\n",
        "\n",
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_images=adapt_images,\n",
        "    positions_likelihood_list=[\n",
        "        source_lp_result.positions_likelihood_from(factor=3.0, minimum_threshold=0.2)\n",
        "    ],\n",
        "    preloads=preloads,\n",
        "    use_jax=False,  # CPU specific code\n",
        ")\n",
        "\n",
        "source_pix_result_1 = slam_pipeline.source_pix.run_1(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_lp_result=source_lp_result,\n",
        "    mesh_init=af.Model(al.mesh.RectangularMagnification, shape=mesh_shape),\n",
        "    regularization_init=al.reg.AdaptiveBrightness,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE PIX PIPELINE 2__\n",
        "\n",
        "The SOURCE PIX PIPELINE 2 is identical to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "galaxy_image_name_dict = al.galaxy_name_image_dict_via_result_from(\n",
        "    result=source_pix_result_1\n",
        ")\n",
        "\n",
        "adapt_images = al.AdaptImages(galaxy_name_image_dict=galaxy_image_name_dict)\n",
        "\n",
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_images=adapt_images,\n",
        "    preloads=preloads,\n",
        "    use_jax=False,  # CPU specific code\n",
        ")\n",
        "\n",
        "source_pix_result_2 = slam_pipeline.source_pix.run_2(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_lp_result=source_lp_result,\n",
        "    source_pix_result_1=source_pix_result_1,\n",
        "    mesh=af.Model(al.mesh.RectangularSource, shape=mesh_shape),\n",
        "    regularization=al.reg.AdaptiveBrightness,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__LIGHT LP PIPELINE__\n",
        "\n",
        "The LIGHT LP PIPELINE is setup identically to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_images=adapt_images,\n",
        "    preloads=preloads,\n",
        "    use_jax=False,  # CPU specific code\n",
        ")\n",
        "\n",
        "lens_bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius,\n",
        "    total_gaussians=20,\n",
        "    gaussian_per_basis=2,\n",
        "    centre_prior_is_uniform=True,\n",
        ")\n",
        "\n",
        "light_result = slam_pipeline.light_lp.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_result_for_lens=source_pix_result_1,\n",
        "    source_result_for_source=source_pix_result_2,\n",
        "    lens_bulge=lens_bulge,\n",
        "    lens_disk=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__MASS TOTAL PIPELINE__\n",
        "\n",
        "The MASS TOTAL PIPELINE is identical to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_images=adapt_images,\n",
        "    positions_likelihood_list=[\n",
        "        source_pix_result_2.positions_likelihood_from(factor=3.0, minimum_threshold=0.2)\n",
        "    ],\n",
        "    preloads=preloads,\n",
        "    use_jax=False,  # CPU specific code\n",
        ")\n",
        "\n",
        "mass_result = slam_pipeline.mass_total.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis=analysis,\n",
        "    source_result_for_lens=source_pix_result_1,\n",
        "    source_result_for_source=source_pix_result_2,\n",
        "    light_result=light_result,\n",
        "    mass=af.Model(al.mp.PowerLaw),\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "This example has demonstrated how to perform fast pixelized source modeling on a CPU without JAX, by combining\n",
        "`numba` and Python `multiprocessing`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}