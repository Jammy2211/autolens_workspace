{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pixelization: CPU Fast Modeling\n",
        "===============================\n",
        "\n",
        "Pixelization examples have used JAX to speed up computations via GPU acceleration.\n",
        "\n",
        "However, for pixelizations there are a number of situations where JAX and GPU acceleration will not provide fast\n",
        "run times:\n",
        "\n",
        "- `VRAM`: JAX acceleration only provides significant speed up when the GPU VRAM is large, with examples using a\n",
        "  rectangular   mesh of shape 20 x 20 to keep VRAM requirements low. If you do not have access to a modern GPU with >16GB\n",
        "  VRAM, JAX GPU calculations will often be slow.\n",
        "\n",
        "- `Sparsity`: Pixelization calculations use large, but very sparse matrices. JAX does not currently support sparse\n",
        "  matrix operations, meaning that many calculations are performed on large dense matrices which are slow. In a nutshell,\n",
        "  this means for high resolution data (e.g. `pixel_scales=0.03` or smaller), JAX often becomes slower than CPU\n",
        "  computations, even when large VRAM GPUs are used.\n",
        "\n",
        "This example illustrates how to perform fast pixelization modeling on a CPU without JAX. Instead it combines\n",
        "`the library `numba` with Python `multiprocessing` to perform fast pixelization modeling on a CPU. If you have access\n",
        "to a HPC with many CPU cores (e.g. > 10), this method can often outperform JAX GPU acceleration for high resolution\n",
        "imaging data where exploiting matrix sparsity is important."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "try:\n",
        "    import numba\n",
        "except ModuleNotFoundError:\n",
        "    input(\n",
        "        \"##################\\n\"\n",
        "        \"##### NUMBA ######\\n\"\n",
        "        \"##################\\n\\n\"\n",
        "        \"\"\"\n",
        "        Numba is not currently installed.\n",
        "\n",
        "        Numba is a library which makes PyAutoLens run a lot faster. Certain functionality is disabled without numba\n",
        "        and will raise an exception if it is used.\n",
        "\n",
        "        If you have not tried installing numba, I recommend you try and do so now by running the following \n",
        "        commands in your command line / bash terminal now:\n",
        "\n",
        "        pip install --upgrade pip\n",
        "        pip install numba\n",
        "\n",
        "        If your numba installation raises an error and fails, you should go ahead and use PyAutoLens without numba to \n",
        "        decide if it is the right software for you. If it is, you should then commit time to bug-fixing the numba\n",
        "        installation. Feel free to raise an issue on GitHub for support with installing numba.\n",
        "\n",
        "        A warning will crop up throughout your *PyAutoLens** use until you install numba, to remind you to do so.\n",
        "\n",
        "        [Press Enter to continue]\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset + Masking + Positions__ \n",
        "\n",
        "Load, plot and mask the `Imaging` data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "over_sample_size = al.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "    grid=dataset.grid,\n",
        "    sub_size_list=[4, 2, 1],\n",
        "    radial_list=[0.3, 0.6],\n",
        "    centre_list=[(0.0, 0.0)],\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "\n",
        "positions = al.Grid2DIrregular(\n",
        "    al.from_json(file_path=Path(dataset_path, \"positions.json\"))\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__W_Tilde__\n",
        "\n",
        "The linear algebra calculations performed to fit a pixelized source to imaging data can use an alternative \n",
        "mathetical formalism called the `w_tilde` formalism.\n",
        "\n",
        "The details of how this work are not important, but the key point is that it significantly speeds up calculations\n",
        "when using a pixelized source by exploiting the sparsity of matrices involved in the calculations. The way\n",
        "this is achieved does not currently support JAX and therefore does not support GPU acceleration.\n",
        "\n",
        "To activate the `w_tilde` formalism, we use the `apply_w_tilde()` method of the `Imaging` dataset, which calculates\n",
        "and stores a matrix called the `w_tilde` matrix in the dataset, which is used when a pixelized source is fitted to the \n",
        "data. \n",
        "\n",
        "Computing this matrix takes between a few seconds to a few minutes depending on the size of the dataset, but once \n",
        "computed it reused for every model-fit, meaning that for modeling using a pixelized source it provides a significant \n",
        "speed up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = dataset.apply_w_tilde()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__JAX & Preloads__\n",
        "\n",
        "The `autolens_workspace/*/imaging/features/pixelization/modeling` example describes how JAX required preloads in\n",
        "advance so it knows the shape of arrays it must compile functions for.\n",
        "\n",
        "The code below is the same as in that example, but note how the `mesh_shape` is now (30 x 30) because the exploitation\n",
        "of matrix sparsity by CPU calculations combined with more abundent CPU RAM means we can now use higher resolution meshes\n",
        "than when using JAX GPU acceleration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_mesh = None\n",
        "mesh_shape = (30, 30)\n",
        "total_mapper_pixels = mesh_shape[0] * mesh_shape[1]\n",
        "\n",
        "total_linear_light_profiles = 0\n",
        "\n",
        "preloads = al.Preloads(\n",
        "    mapper_indices=al.mapper_indices_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        total_mapper_pixels=total_mapper_pixels,\n",
        "    ),\n",
        "    source_pixel_zeroed_indices=al.util.mesh.rectangular_edge_pixel_list_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        shape_native=mesh_shape,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "In the example `imaging/features/pixelization/fit.py`, we illustrate how to use a pixelized source\n",
        "with a rectangular mesh to fit imaging data.\n",
        "\n",
        "Below, we illustrate a fit using the same pixelization, but now using fast CPU calculations with numba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh = al.mesh.RectangularMagnification(shape=mesh_shape)\n",
        "regularization = al.reg.Constant(coefficient=1.0)\n",
        "\n",
        "pixelization = al.Pixelization(mesh=mesh, regularization=regularization)\n",
        "\n",
        "lens = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.0, 0.0),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        "    shear=al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05),\n",
        ")\n",
        "\n",
        "source = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens, source])\n",
        "\n",
        "fit = al.FitImaging(\n",
        "    dataset=dataset,\n",
        "    tracer=tracer,\n",
        "    preloads=preloads,\n",
        ")\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()\n",
        "ffff"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "Using a Del"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(\n",
        "    al.Galaxy, redshift=0.5, mass=al.mp.Isothermal, shear=al.mp.ExternalShear\n",
        ")\n",
        "\n",
        "pixelization = af.Model(\n",
        "    al.Pixelization,\n",
        "    image_mesh=al.image_mesh.Overlay(shape=(30, 30)),\n",
        "    mesh=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.Constant,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "model_1 = af.Collection(galaxies=af.Collection(lens=lens, source=source))\n",
        "\n",
        "search_1 = af.Nautilus(\n",
        "    path_prefix=Path(\"features\"),\n",
        "    name=\"delaunay\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=2,\n",
        "    preloads=preloads,\n",
        ")\n",
        "\n",
        "analysis_1 = al.AnalysisImaging(dataset=dataset)\n",
        "\n",
        "result_1 = search_1.fit(model=model_1, analysis=analysis_1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model (Search 1)__\n",
        "\n",
        "To use adapt features, we require a model image of the lensed source galaxy, which is what the code will adapt the\n",
        "analysis too.\n",
        "\n",
        "When we begin a fit, we do not have such an image, and thus cannot use the adapt features. This is why search chaining\n",
        "is important -- it allows us to perform an initial model-fit which gives us the source image, which we can then use to\n",
        "perform a subsequent model-fit which adapts the analysis to the source's properties.\n",
        "\n",
        "We therefore compose our lens model using `Model` objects, which represent the galaxies we fit to our data. In the first\n",
        "search our lens model is:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` with `ExternalShear` [7 parameters].\n",
        "\n",
        " - The source galaxy's light uses an `Overlay` image-mesh with fixed resolution 30 x 30 pixels [0 parameters].\n",
        "\n",
        " - The source-galaxy's light uses a `Delaunay` mesh [0 parameters].\n",
        "\n",
        " - This pixelization is regularized using a `Constant` scheme [1 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(\n",
        "    al.Galaxy, redshift=0.5, mass=al.mp.Isothermal, shear=al.mp.ExternalShear\n",
        ")\n",
        "\n",
        "pixelization = af.Model(\n",
        "    al.Pixelization,\n",
        "    image_mesh=al.image_mesh.Overlay(shape=(30, 30)),\n",
        "    mesh=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.Constant,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "model_1 = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search + Analysis + Model-Fit (Search 1)__\n",
        "\n",
        "We now create the non-linear search, analysis and perform the model-fit using this model.\n",
        "\n",
        "You may wish to inspect the results of the search 1 model-fit to ensure a fast non-linear search has been provided that \n",
        "provides a reasonably accurate lens model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_1 = af.Nautilus(\n",
        "    path_prefix=path_prefix,\n",
        "    name=\"search[1]__adapt\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=2,\n",
        "    preloads=preloads,\n",
        ")\n",
        "\n",
        "analysis_1 = al.AnalysisImaging(dataset=dataset)\n",
        "\n",
        "result_1 = search_1.fit(model=model_1, analysis=analysis_1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Adaptive Pixelization__\n",
        "\n",
        "Search 2 is going to use two adaptive pixelization features that have not been used elsewhere in the workspace:\n",
        "\n",
        " - The `Hilbert` image-mesh, which adapts the distribution of source-pixels to the source's unlensed morphology. This\n",
        " means that the source's brightest regions are reconstructed using significantly more source pixels than seen for\n",
        " the `Overlay` image mesh. Conversely, the source's faintest regions are reconstructed using significantly fewer\n",
        " source pixels.\n",
        "\n",
        " - The `AdaptiveBrightness` regularization scheme, which adapts the regularization coefficient to the source's\n",
        " unlensed morphology. This means that the source's brightest regions are regularized less than its faintest regions, \n",
        " ensuring that the bright central regions of the source are not over-smoothed.\n",
        "\n",
        "Both of these features produce a significantly better lens analysis and reconstruction of the source galaxy than\n",
        "other image-meshs and regularization schemes used throughout the workspace. Now you are familiar with them, you should\n",
        "never use anything else!\n",
        "\n",
        "It is recommend that the parameters governing these features are always fitted from using a fixed lens light and\n",
        "mass model. This ensures the adaptation is performed quickly, and removes degeneracies in the lens model that\n",
        "are difficult to sample. Extensive testing has shown that this does not reduce the accuracy of the lens model.\n",
        "\n",
        "For this reason, search 2 fixes the lens galaxy's light and mass model to the best-fit model of search 1. A third\n",
        "search will then fit for the lens galaxy's light and mass model using these adaptive features.\n",
        "\n",
        "The details of how the above features work is not provided here, but is given at the end of chapter 4 of the HowToLens\n",
        "lecture series.\n",
        "\n",
        "__Model (Search 2)__\n",
        "\n",
        "We therefore compose our lens model using `Model` objects, which represent the galaxies we fit to our data. In \n",
        "the second search our lens model is:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` with `ExternalShear` with fixed parameters from \n",
        "   search 1 [0 parameters].\n",
        "\n",
        " - The source galaxy's light uses a `Hilbert` image-mesh with fixed resolution 1000 pixels [2 parameters].\n",
        "\n",
        " - The source-galaxy's light uses a `Delaunay` mesh [0 parameters].\n",
        "\n",
        " - This pixelization is regularized using a `AdaptiveBrightnessSplit` scheme [2 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = result_1.instance.galaxies.lens\n",
        "\n",
        "pixelization = af.Model(\n",
        "    al.Pixelization,\n",
        "    image_mesh=al.image_mesh.Hilbert(pixels=1000),\n",
        "    mesh=al.mesh.Delaunay,\n",
        "    regularization=al.reg.AdaptiveBrightnessSplit,\n",
        ")\n",
        "\n",
        "source = af.Model(\n",
        "    al.Galaxy,\n",
        "    redshift=1.0,\n",
        "    pixelization=pixelization,\n",
        ")\n",
        "\n",
        "model_2 = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis (Search 2)__\n",
        "\n",
        "We now create the analysis for the second search.\n",
        "\n",
        "__Adapt Images__\n",
        "\n",
        "When we create the analysis, we pass it a `adapt_images`, which contains the lens subtracted image of the source galaxy from \n",
        "the result of search 1. \n",
        "\n",
        "This is telling the `Analysis` class to use the lens subtracted images of this fit to aid the fitting of the `Hilbert` \n",
        "image-mesh and `AdaptiveBrightness` regularization for the source galaxy. Specifically, it uses the model image \n",
        "of the lensed source in order to adapt the location of the source-pixels to the source's brightest regions and lower\n",
        "the regularization coefficient in these regions.\n",
        "\n",
        "__Image Mesh Settings__\n",
        "\n",
        "The `Hilbert` image-mesh may not fully adapt to the data in a satisfactory way. Often, it does not place enough\n",
        "pixels in the source's brightest regions and it may place too few pixels further out where the source is not observed.\n",
        "To address this, we use the `settings_inversion` input of the `Analysis` class to specify that we require the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_2 = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_image_maker=al.AdaptImageMaker(result=result_1),\n",
        "    preloads=preloads,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search + Model-Fit (Search 2)__\n",
        "\n",
        "We now create the non-linear search and perform the model-fit using this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_2 = af.Nautilus(\n",
        "    path_prefix=path_prefix, name=\"search[2]__adapt\", unique_tag=dataset_name, n_live=75\n",
        ")\n",
        "\n",
        "result_2 = search_2.fit(model=model_2, analysis=analysis_2)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result (Search 2)__\n",
        "\n",
        "If you inspect and compare the results of searches 1 and 2, you'll note how the model-fits of search 2 have a much\n",
        "higher likelihood than search 1 and how the source reconstruction has congregated it pixels to the bright central\n",
        "regions of the source. This indicates that a much better result has been achieved.\n",
        "\n",
        "__Model + Search + Analysis + Model-Fit (Search 3)__\n",
        "\n",
        "We now perform a final search which uses the `Hilbert` image-mesh and `AdaptiveBrightness` regularization with their\n",
        "parameter fixed to the results of search 2.\n",
        "\n",
        "The lens mass model is free to vary.\n",
        "\n",
        "The analysis class still uses the adapt images from search 1, because this is what the adaptive features adapted\n",
        "to in search 2.\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = af.Model(\n",
        "    al.Galaxy, redshift=0.5, mass=al.mp.Isothermal, shear=al.mp.ExternalShear\n",
        ")\n",
        "\n",
        "source = af.Model(\n",
        "    al.Galaxy,\n",
        "    redshift=1.0,\n",
        "    pixelization=result_2.instance.galaxies.source.pixelization,\n",
        ")\n",
        "\n",
        "model_3 = af.Collection(galaxies=af.Collection(lens=lens, source=source))\n",
        "\n",
        "search_3 = af.Nautilus(\n",
        "    path_prefix=path_prefix,\n",
        "    name=\"search[3]__adapt\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        ")\n",
        "\n",
        "analysis_3 = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    adapt_image_maker=al.AdaptImageMaker(result=result_1),\n",
        "    preloads=preloads,\n",
        ")\n",
        "\n",
        "result_3 = search_3.fit(model=model_3, analysis=analysis_3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SLaM Pipelines__\n",
        "\n",
        "The API above allows you to use adaptive features yourself, and you should go ahead an explore them on datasets you\n",
        "are familiar with.\n",
        "\n",
        "However, you may also wish to use the Source, Light and Mass (SLaM) pipelines, which are pipelines that\n",
        "have been carefully crafted to automate lens modeling of large samples whilst ensuring models of the highest\n",
        "complexity can be reliably fitted.\n",
        "\n",
        "These pipelines are built around the use of adaptive features -- for example the Source pipeline comes first so that\n",
        "these features are set up robustly before more complex lens light and mass models are fitted.\n",
        "\n",
        "Below, we detail a few convenience functions that make using adaptive features in the SLaM pipelines straight forward.\n",
        "\n",
        "__Likelihood Function__\n",
        "\n",
        "The example `imaging/features/pixelization/likelihood_function.py` provides a step-by-step description of how\n",
        "a likelihood evaluation is performed for imaging data using a pixelized source reconstruction with a rectangular\n",
        "mesh.\n",
        "\n",
        "We now give the same step-by-step description for a pixelized source reconstruction using a Delaunay mesh and\n",
        "adaptive features.\n",
        "\n",
        "We only describe code which is specific to Delaunay meshes and adaptive features -- for all other aspects of the likelihood\n",
        "evaluation, refer to rectangular mesh example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = Path(\"dataset\", \"imaging\", \"simple\")\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "\n",
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "masked_dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=masked_dataset)\n",
        "dataset_plotter.subplot_dataset()\n",
        "\n",
        "masked_dataset = masked_dataset.apply_over_sampling(\n",
        "    over_sample_size_lp=1,\n",
        "    over_sample_size_pixelization=1,\n",
        ")\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=masked_dataset.grids.pixelization)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "bulge = al.lp.Sersic(\n",
        "    centre=(0.0, 0.0),\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    intensity=2.0,\n",
        "    effective_radius=0.6,\n",
        "    sersic_index=3.0,\n",
        ")\n",
        "\n",
        "mass = al.mp.Isothermal(\n",
        "    centre=(0.0, 0.0),\n",
        "    einstein_radius=1.6,\n",
        "    ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        ")\n",
        "\n",
        "shear = al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05)\n",
        "\n",
        "lens_galaxy = al.Galaxy(redshift=0.5, bulge=bulge, mass=mass, shear=shear)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Source Galaxy Pixelization and Regularization__\n",
        "\n",
        "The source galaxy is reconstructed using a pixel-grid, in this example a Delaunay mesh, which accounts for \n",
        "irregularities and asymmetries in the source's surface brightness. \n",
        "\n",
        "A constant regularization scheme is applied which applies a smoothness prior on the reconstruction. \n",
        "\n",
        "One of the biggest differences between a Delaunay mesh and rectangular mesh is how the centres of the mesh pixels\n",
        "in the source-plane are computed. \n",
        "\n",
        "For the rectangular mesh, the pixel centres are computed by overlaying a uniform grid over the source-plane.\n",
        "\n",
        "For a Delaunay mesh, the uniform grid is instead laid over the image-plane to create a course grid of (y,x) coordinates.\n",
        "These are then ray-traced to the source-plane and are used as the vertexes of the Delaunay triangles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixelization = al.Pixelization(\n",
        "    image_mesh=al.image_mesh.Overlay(shape=(30, 30)),  # Specific to Delaunay\n",
        "    mesh=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(redshift=1.0, pixelization=pixelization)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Lens Light__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image = lens_galaxy.image_2d_from(grid=masked_dataset.grid)\n",
        "\n",
        "galaxy_plotter = aplt.GalaxyPlotter(galaxy=lens_galaxy, grid=masked_dataset.grid)\n",
        "galaxy_plotter.figures_2d(image=True)\n",
        "\n",
        "blurring_image_2d = lens_galaxy.image_2d_from(grid=masked_dataset.grids.blurring)\n",
        "\n",
        "galaxy_plotter = aplt.GalaxyPlotter(\n",
        "    galaxy=lens_galaxy, grid=masked_dataset.grids.blurring\n",
        ")\n",
        "galaxy_plotter.figures_2d(image=True)\n",
        "\n",
        "convolved_image_2d = masked_dataset.psf.convolved_image_from(\n",
        "    image=image, blurring_image=blurring_image_2d\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=convolved_image_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "lens_subtracted_image_2d = masked_dataset.data - convolved_image_2d\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=lens_subtracted_image_2d)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Source Pixel Centre Calculation__\n",
        "\n",
        "In order to reconstruct the source galaxy using a Delaunay mesh, we need to determine the centres of the Delaunay\n",
        "source pixels.\n",
        "\n",
        "The image-mesh `Overlay` object computes the source-pixel centres in the image-plane (which are ray-traced to the\n",
        "source-plane below). The source pixelization therefore adapts to the lens model magnification, because more\n",
        "source pixels will congregate in higher magnification regions.\n",
        "\n",
        "This calculation is performed by overlaying a uniform regular grid with an `pixelization_shape_2d` over the image\n",
        "mask and retaining all pixels that fall within the mask. This uses a `Grid2DSparse` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_plane_mesh_grid = pixelization.image_mesh.image_plane_mesh_grid_from(\n",
        "    mask=masked_dataset.mask,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting this grid shows a sparse grid of (y,x) coordinates within the mask, which will form our source pixel centres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(grid=image_plane_mesh_grid)\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=masked_dataset, visuals_2d=visuals)\n",
        "dataset_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Ray Tracing__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The source code gets quite complex when handling grids for a pixelization, but it is all handled in\n",
        "the `TracerToInversion` objects.\n",
        "\n",
        "The plots at the bottom of this cell show the traced grids used by the source pixelization, showing\n",
        "how the Delaunay mesh and traced image pixels are constructed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_to_inversion = al.TracerToInversion(tracer=tracer, dataset=masked_dataset)\n",
        "\n",
        "# A list of every grid (e.g. image-plane, source-plane) however we only need the source plane grid with index -1.\n",
        "traced_grid_pixelization = tracer.traced_grid_2d_list_from(\n",
        "    grid=masked_dataset.grids.pixelization\n",
        ")[-1]\n",
        "\n",
        "# This functions a bit weird - it returns a list of lists of ndarrays. Best not to worry about it for now!\n",
        "traced_mesh_grid = tracer_to_inversion.traced_mesh_grid_pg_list[-1][-1]\n",
        "\n",
        "mat_plot = aplt.MatPlot2D(axis=aplt.Axis(extent=[-1.5, 1.5, -1.5, 1.5]))\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=traced_grid_pixelization, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have also ray-traced the coarse grid of image-pixel coordinates used to form the source pixelization's\n",
        "Delaunay mesh, which we can also plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_plotter = aplt.Grid2DPlotter(grid=traced_mesh_grid, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Border Relocation__\n",
        "\n",
        "Coordinates that are ray-traced near the mass profile centres are heavily demagnified and may trace to far outskirts of\n",
        "the source-plane. \n",
        "\n",
        "Border relocation is performed on both the traced image-pixel grid and traced mesh pixels, therefore ensuring that\n",
        "the vertexes of the Delaunay triangles are not at the extreme outskirts of the source-plane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoarray.inversion.pixelization.border_relocator import BorderRelocator\n",
        "\n",
        "border_relocator = BorderRelocator(mask=masked_dataset.mask, sub_size=1)\n",
        "\n",
        "relocated_grid = border_relocator.relocated_grid_from(grid=traced_grid_pixelization)\n",
        "\n",
        "relocated_mesh_grid = border_relocator.relocated_mesh_grid_from(\n",
        "    grid=traced_mesh_grid, mesh_grid=traced_mesh_grid\n",
        ")\n",
        "\n",
        "mat_plot = aplt.MatPlot2D(axis=aplt.Axis(extent=[-1.5, 1.5, -1.5, 1.5]))\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=relocated_grid, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()\n",
        "\n",
        "grid_plotter = aplt.Grid2DPlotter(grid=relocated_mesh_grid, mat_plot_2d=mat_plot)\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Delaunay Mesh__\n",
        "\n",
        "The relocated mesh grid is used to create the `Pixelization`'s Delaunay mesh using the `scipy.spatial` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_delaunay = al.Mesh2DDelaunay(\n",
        "    values=relocated_mesh_grid,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting the Delaunay mesh shows that the source-plane and been discretized into a grid of irregular Delaunay pixels.\n",
        "\n",
        "(To plot the Delaunay mesh, we have to convert it to a `Mapper` object, which is described in the next likelihood step).\n",
        "\n",
        "Below, we plot the Delaunay mesh without the traced image-grid pixels (for clarity) and with them as black dots in order\n",
        "to show how each set of image-pixels fall within a Delaunay pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_grids = al.MapperGrids(\n",
        "    mask=mask,\n",
        "    source_plane_data_grid=relocated_grid,\n",
        "    source_plane_mesh_grid=grid_delaunay,\n",
        "    image_plane_mesh_grid=image_plane_mesh_grid,\n",
        ")\n",
        "\n",
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "mapper_plotter.figure_2d(interpolate_to_uniform=False)\n",
        "\n",
        "visuals = aplt.Visuals2D(\n",
        "    grid=mapper_grids.source_plane_data_grid,\n",
        ")\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper, visuals_2d=visuals)\n",
        "mapper_plotter.figure_2d(interpolate_to_uniform=False)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Image-Source Mapping__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=None,\n",
        ")\n",
        "\n",
        "pix_indexes_for_sub_slim_index = mapper.pix_indexes_for_sub_slim_index\n",
        "\n",
        "print(pix_indexes_for_sub_slim_index[0:9])\n",
        "\n",
        "visuals = aplt.Visuals2D(indexes=[list(range(2050, 2090))])\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(\n",
        "    mapper=mapper,\n",
        "    visuals_2d=visuals,\n",
        ")\n",
        "mapper_plotter.subplot_image_and_mapper(\n",
        "    image=lens_subtracted_image_2d, interpolate_to_uniform=False\n",
        ")\n",
        "\n",
        "pix_indexes = [[200]]\n",
        "\n",
        "indexes = mapper.slim_indexes_for_pix_indexes(pix_indexes=pix_indexes)\n",
        "\n",
        "visuals = aplt.Visuals2D(indexes=indexes)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(\n",
        "    mapper=mapper,\n",
        "    visuals_2d=visuals,\n",
        ")\n",
        "\n",
        "mapper_plotter.subplot_image_and_mapper(\n",
        "    image=lens_subtracted_image_2d, interpolate_to_uniform=False\n",
        ")\n",
        "\n",
        "mapping_matrix = al.util.mapper.mapping_matrix_from(\n",
        "    pix_indexes_for_sub_slim_index=pix_indexes_for_sub_slim_index,\n",
        "    pix_size_for_sub_slim_index=mapper.pix_sizes_for_sub_slim_index,  # unused for Delaunay\n",
        "    pix_weights_for_sub_slim_index=mapper.pix_weights_for_sub_slim_index,  # unused for Delaunay\n",
        "    pixels=mapper.pixels,\n",
        "    total_mask_pixels=mapper.source_plane_data_grid.mask.pixels_in_mask,\n",
        "    slim_index_for_sub_slim_index=mapper.slim_index_for_sub_slim_index,\n",
        "    sub_fraction=np.array(mapper.over_sampler.sub_fraction),\n",
        ")\n",
        "\n",
        "plt.imshow(mapping_matrix, aspect=(mapping_matrix.shape[1] / mapping_matrix.shape[0]))\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "indexes_source_pix_200 = np.nonzero(mapping_matrix[:, 200])\n",
        "\n",
        "print(indexes_source_pix_200[0])\n",
        "\n",
        "array_2d = al.Array2D(values=mapping_matrix[:, 200], mask=masked_dataset.mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "blurred_mapping_matrix = masked_dataset.psf.convolved_mapping_matrix_from(\n",
        "    mapping_matrix=mapping_matrix, mask=masked_dataset.mask\n",
        ")\n",
        "\n",
        "plt.imshow(\n",
        "    blurred_mapping_matrix,\n",
        "    aspect=(blurred_mapping_matrix.shape[1] / blurred_mapping_matrix.shape[0]),\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "indexes_source_pix_200 = np.nonzero(blurred_mapping_matrix[:, 200])\n",
        "\n",
        "print(indexes_source_pix_200[0])\n",
        "\n",
        "array_2d = al.Array2D(values=blurred_mapping_matrix[:, 200], mask=masked_dataset.mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "print(f\"Mapping between image pixel 0 and source pixel 2 = {mapping_matrix[0, 2]}\")\n",
        "\n",
        "data_vector = al.util.inversion_imaging.data_vector_via_blurred_mapping_matrix_from(\n",
        "    blurred_mapping_matrix=blurred_mapping_matrix,\n",
        "    image=np.array(lens_subtracted_image_2d),\n",
        "    noise_map=np.array(masked_dataset.noise_map),\n",
        ")\n",
        "\n",
        "plt.imshow(\n",
        "    data_vector.reshape(data_vector.shape[0], 1), aspect=10.0 / data_vector.shape[0]\n",
        ")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "curvature_matrix = al.util.inversion.curvature_matrix_via_mapping_matrix_from(\n",
        "    mapping_matrix=blurred_mapping_matrix, noise_map=masked_dataset.noise_map\n",
        ")\n",
        "\n",
        "plt.imshow(curvature_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "source_pixel_0 = 0\n",
        "source_pixel_1 = 1\n",
        "\n",
        "print(curvature_matrix[source_pixel_0, source_pixel_1])\n",
        "\n",
        "array_2d = al.Array2D(\n",
        "    values=blurred_mapping_matrix[:, source_pixel_0], mask=masked_dataset.mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "array_2d = al.Array2D(\n",
        "    values=blurred_mapping_matrix[:, source_pixel_1], mask=masked_dataset.mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=array_2d)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "regularization_matrix = al.util.regularization.constant_regularization_matrix_from(\n",
        "    coefficient=source_galaxy.pixelization.regularization.coefficient,\n",
        "    neighbors=mapper.source_plane_mesh_grid.neighbors,\n",
        "    neighbors_sizes=mapper.source_plane_mesh_grid.neighbors.sizes,\n",
        ")\n",
        "\n",
        "plt.imshow(regularization_matrix)\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "curvature_reg_matrix = np.add(curvature_matrix, regularization_matrix)\n",
        "\n",
        "reconstruction = np.linalg.solve(curvature_reg_matrix, data_vector)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "\n",
        "mapper_plotter.figure_2d(solution_vector=reconstruction, interpolate_to_uniform=False)\n",
        "\n",
        "mapped_reconstructed_image_2d = (\n",
        "    al.util.inversion.mapped_reconstructed_data_via_mapping_matrix_from(\n",
        "        mapping_matrix=blurred_mapping_matrix, reconstruction=reconstruction\n",
        "    )\n",
        ")\n",
        "\n",
        "mapped_reconstructed_image_2d = al.Array2D(\n",
        "    values=mapped_reconstructed_image_2d, mask=mask\n",
        ")\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=mapped_reconstructed_image_2d)\n",
        "array_2d_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Likelihood Function__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_image = convolved_image_2d + mapped_reconstructed_image_2d\n",
        "\n",
        "residual_map = masked_dataset.data - model_image\n",
        "normalized_residual_map = residual_map / masked_dataset.noise_map\n",
        "chi_squared_map = normalized_residual_map**2.0\n",
        "\n",
        "chi_squared = np.sum(chi_squared_map)\n",
        "\n",
        "print(chi_squared)\n",
        "\n",
        "chi_squared_map = al.Array2D(values=chi_squared_map, mask=mask)\n",
        "\n",
        "array_2d_plotter = aplt.Array2DPlotter(array=chi_squared_map)\n",
        "array_2d_plotter.figure_2d()\n",
        "\n",
        "regularization_term = np.matmul(\n",
        "    reconstruction.T, np.matmul(regularization_matrix, reconstruction)\n",
        ")\n",
        "\n",
        "print(regularization_term)\n",
        "\n",
        "log_curvature_reg_matrix_term = np.linalg.slogdet(curvature_reg_matrix)[1]\n",
        "log_regularization_matrix_term = np.linalg.slogdet(regularization_matrix)[1]\n",
        "\n",
        "print(log_curvature_reg_matrix_term)\n",
        "print(log_regularization_matrix_term)\n",
        "\n",
        "noise_normalization = float(np.sum(np.log(2 * np.pi * masked_dataset.noise_map**2.0)))\n",
        "\n",
        "log_evidence = float(\n",
        "    -0.5\n",
        "    * (\n",
        "        chi_squared\n",
        "        + regularization_term\n",
        "        + log_curvature_reg_matrix_term\n",
        "        - log_regularization_matrix_term\n",
        "        + noise_normalization\n",
        "    )\n",
        ")\n",
        "\n",
        "print(log_evidence)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "This process to perform a likelihood function evaluation is what is performed in the `FitImaging` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = al.FitImaging(\n",
        "    dataset=masked_dataset,\n",
        "    tracer=tracer,\n",
        "    settings_inversion=al.SettingsInversion(use_border_relocator=True),\n",
        "    preloads=preloads,\n",
        ")\n",
        "fit_log_evidence = fit.log_evidence\n",
        "print(fit_log_evidence)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Lens Modeling__\n",
        "\n",
        "To fit a lens model to data, the likelihood function illustrated in this tutorial is sampled using a\n",
        "non-linear search algorithm.\n",
        "\n",
        "The default sampler is the nested sampling algorithm `Nautilus` (https://github.com/joshspeagle/Nautilus)\n",
        "but **PyAutoLens** supports multiple MCMC and optimization algorithms. \n",
        "\n",
        "__Sub Gridding__\n",
        "\n",
        "The calculation above uses a `Grid2D` object, with a `sub-size=1`, meaning it does not perform oversampling to\n",
        "evaluate the light profile flux at every image pixel.\n",
        "\n",
        "**PyAutoLens** has alternative methods of computing the lens galaxy images above, which uses a grid whose sub-size\n",
        "adaptively increases depending on a required fractional accuracy of the light profile.\n",
        "\n",
        " https://github.com/Jammy2211/PyAutoArray/blob/main/autoarray/structures/grids/two_d/grid_iterate.py\n",
        "\n",
        "__Sourrce Plane Interpolation__\n",
        "\n",
        "For the `Delaunay` mesh used in this example, every image-sub pixel maps to a single source Voronoi\n",
        "pixel. Therefore, the plural use of `pix_indexes` is not required. However, for other pixelizations each sub-pixel\n",
        "can map to multiple source pixels with an interpolation weight (e.g. `Delaunay` triangulation or a `Voronoi` mesh\n",
        "which uses natural neighbor interpolation).\n",
        "\n",
        "`MapperVoronoiNoInterp.pix_index_for_sub_slim_index`:\n",
        "https://github.com/Jammy2211/PyAutoArray/blob/main/autoarray/inversion/mappers/voronoi.py\n",
        "\n",
        "`pixelization_index_for_voronoi_sub_slim_index_from`:\n",
        " https://github.com/Jammy2211/PyAutoArray/blob/main/autoarray/util/mapper_util.py\n",
        "\n",
        "The number of pixels that each sub-pixel maps too is also stored and extracted. This is used for speeding up\n",
        "the calculation of the `mapping_matrix` described next.\n",
        "\n",
        "As discussed above, because for the `VoronoiNoInterp` pixelization where every sub-pixel maps to one source pixel,\n",
        "every entry of this array will be equal to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# pix_sizes_for_sub_slim_index = mapper.pix_sizes_for_sub_slim_index"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When each sub-pixel maps to multiple source pixels, the mappings are described via an interpolation weight. For \n",
        "example, for a `Delaunay` triangulation, every sub-pixel maps to 3 Delaunay triangles based on which triangle\n",
        "it lands in.\n",
        "\n",
        "For the `VoronoiNoInterp` pixelization where every sub-pixel maps to a single source pixel without inteprolation,\n",
        "every entry of this weight array is 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# pix_weights_for_sub_slim_index = mapper.pix_weights_for_sub_slim_index"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "We have presented a visual step-by-step guide to the **PyAutoLens** likelihood function, which uses a pixelization, \n",
        "regularization scheme and inversion to reconstruct the source galaxy.\n",
        "\n",
        "There are a number of other inputs features which slightly change the behaviour of this likelihood function, which\n",
        "are described in additional notebooks found in this package. In brief, these describe:\n",
        "\n",
        " - **Sub-gridding**: Oversampling the image grid into a finer grid of sub-pixels, which are all individually \n",
        " ray-traced to the source-plane and paired fractionally with each source pixel.\n",
        "\n",
        " - **Source-plane Interpolation**: Using a Delaunay triangulation or Delaunay mesh with natural neighbor interpolation\n",
        " to pair each image (sub-)pixel to multiple source-plane pixels with interpolation weights.\n",
        "\n",
        " - **Source Morphology Pixelization Adaption**: Adapting the pixelization such that is congregates source pixels around\n",
        " the source's brightest regions, as opposed to the magnification-based pixelization used here.\n",
        "\n",
        " - **Luminosity Weighted Regularization**: Using an adaptive regularization coefficient which adapts the level of \n",
        " regularization applied to the source based on its luminosity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}