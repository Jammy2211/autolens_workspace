{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Database: Samples\n",
        "=================\n",
        "\n",
        "After fitting a large suite of data, we can use the aggregator to load the database's results. We can then\n",
        "manipulate, interpret and visualize them using a Python script or Jupyter notebook.\n",
        "\n",
        "This script uses the results generated by the script `/autolens_workspace/database/tutorial_1_introduction.py`, which\n",
        "fitted 3 simulated datasets with:\n",
        "\n",
        " - An `Isothermal` `MassProfile` for the lens galaxy's mass.\n",
        " - An `Sersic` `LightProfile` representing a bulge for the source galaxy's light.\n",
        "\n",
        "__Samples__\n",
        "\n",
        "This script covers how to manipulate the `Samples` object returned from a *PyAutoLens* model-fit, which you have most\n",
        "likely already encountered when analysing the results of a model-fit.\n",
        "\n",
        "We'll learn how to use the database and `Aggregator`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Database File__\n",
        "\n",
        "The results are not contained in the `output` folder after each search completes. Instead, they are\n",
        "contained in the `database.sqlite` file, which we can load using the `Aggregator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "database_file = \"database.sqlite\"\n",
        "agg = af.Aggregator.from_database(filename=database_file)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Generators__\n",
        "\n",
        "The `start_here.py` database example gives an explanation of what Python generators are and why and how they are used.\n",
        "Refer back to that example if you are unsure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples_gen = agg.values(\"samples\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Samples__\n",
        "\n",
        "The `Samples` class contains all the parameter samples, which is a list of lists where:\n",
        " \n",
        " - The outer list is the size of the total number of samples.\n",
        " - The inner list is the size of the number of free parameters in the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    print(\"All parameters of the very first sample\")\n",
        "    print(samples.parameter_lists[0])\n",
        "    print(\"The third parameter of the tenth sample\")\n",
        "    print(samples.parameter_lists[9][2])\n",
        "    print()\n",
        "\n",
        "print(\"Samples: \\n\")\n",
        "print(agg.values(\"samples\"))\n",
        "print()\n",
        "print(\"Total Samples Objects = \", len(agg), \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Samples` class contains the log likelihood, log prior, log posterior and weight_list of every sample, where:\n",
        "\n",
        " - The log likelihood is the value evaluated from the likelihood function (e.g. -0.5 * chi_squared + the noise  \n",
        " normalization).\n",
        "    \n",
        " - The log prior encodes information on how the priors on the parameters maps the log likelihood value to the log\n",
        " posterior value.\n",
        "      \n",
        " - The log posterior is log_likelihood + log_prior.\n",
        "    \n",
        " - The weight gives information on how samples should be combined to estimate the posterior. The weight values \n",
        " depend on the sampler used, for example for MCMC they will all be 1`s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    print(\"log(likelihood), log(prior), log(posterior) and weight of the tenth sample.\")\n",
        "    print(samples.log_likelihood_list[9])\n",
        "    print(samples.log_prior_list[9])\n",
        "    print(samples.log_posterior_list[9])\n",
        "    print(samples.weight_list[9])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Maximum Likelihood Model__\n",
        "\n",
        "We can use the outputs to create a list of the maximum log likelihood model of each fit to our three images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_vector = [\n",
        "    samps.max_log_likelihood(as_instance=False) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "print(\"Max Log Likelihood Model Parameter Lists: \\n\")\n",
        "print(ml_vector, \"\\n\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Parameter Names__\n",
        "\n",
        "Vectors return a lists of all model parameters, but do not tell us which values correspond to which parameters.\n",
        "\n",
        "The following quantities are available in the `Model`, where the order of their entries correspond to the parameters \n",
        "in the `ml_vector` above:\n",
        " \n",
        " - `paths`: a list of tuples which give the path of every parameter in the `Model`.\n",
        " - `parameter_names`: a list of shorthand parameter names derived from the `paths`.\n",
        " - `parameter_labels`: a list of parameter labels used when visualizing non-linear search results (see below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    model = samples.model\n",
        "    print(model)\n",
        "    print(model.paths)\n",
        "    print(model.parameter_names)\n",
        "    print(model.parameter_labels)\n",
        "    print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These lists will be used later for visualization, how it is often more useful to create the model instance of every fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_instances = [samps.max_log_likelihood() for samps in agg.values(\"samples\")]\n",
        "print(\"Maximum Log Likelihood Model Instances: \\n\")\n",
        "print(ml_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Instances__\n",
        "\n",
        "A model instance contains all the model components of our fit, for example the list of galaxies we specified during \n",
        "model composition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies)\n",
        "print(ml_instances[1].galaxies)\n",
        "print(ml_instances[2].galaxies)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These galaxies will be named according to the search (in this case, `lens` and `source`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies.lens)\n",
        "print()\n",
        "print(ml_instances[1].galaxies.source)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Their `LightProfile`'s and `MassProfile`'s are also named according to the search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ml_instances[0].galaxies.lens.mass)\n",
        "print(ml_instances[1].galaxies.source.bulge)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Median PDF__\n",
        "\n",
        "We can access the `median pdf` model, which is the model computed by marginalizing over the samples of every parameter \n",
        "in 1D and taking the median of this PDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mp_instances = [samps.median_pdf() for samps in agg.values(\"samples\")]\n",
        "\n",
        "print(\"Median PDF Model Instances: \\n\")\n",
        "print(mp_instances, \"\\n\")\n",
        "print(mp_instances[0].galaxies.lens.mass)\n",
        "print()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Ordering__\n",
        "\n",
        "The default ordering of the results can be a bit random, as it depends on how the sqlite database is built. \n",
        "\n",
        "The `order_by` method can be used to order by a property of the database that is a string, for example by ordering \n",
        "using the `unique_tag` (which we set up in the search as the `dataset_name`) the database orders results alphabetically\n",
        "according to dataset name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg = agg.order_by(agg.search.unique_tag)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also order by a bool, for example making it so all completed results are at the front of the aggregator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "agg = agg.order_by(agg.search.is_complete)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Errors__\n",
        "\n",
        "We can compute the model parameters at a given sigma value (e.g. at 3.0 sigma limits).\n",
        "\n",
        "These parameter values do not account for covariance between the model. For example if two parameters are degenerate \n",
        "this will find their values from the degeneracy in the `same direction` (e.g. both will be positive). we'll cover\n",
        "how to handle covariance in a later tutorial.\n",
        "\n",
        "The `uv3` below signifies this is an upper value at 3 sigma confidence, with `lv3` indicating a the lower value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "uv3_vectors = [\n",
        "    samps.values_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "uv3_instances = [\n",
        "    samps.values_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "lv3_vectors = [\n",
        "    samps.values_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "lv3_instances = [\n",
        "    samps.values_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "print(\"Errors Lists: \\n\")\n",
        "print(uv3_vectors, \"\\n\")\n",
        "print(lv3_vectors, \"\\n\")\n",
        "print(\"Errors Instances: \\n\")\n",
        "print(uv3_instances, \"\\n\")\n",
        "print(lv3_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute the upper and lower errors on each parameter at a given sigma limit.\n",
        "\n",
        "The `ue3` below signifies the upper error at 3 sigma. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ue3_vectors = [\n",
        "    samps.errors_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "\n",
        "# ue3_instances = [\n",
        "#     samps.errors_at_upper_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "# ]\n",
        "\n",
        "le3_vectors = [\n",
        "    samps.errors_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "]\n",
        "# le3_instances = [\n",
        "#     samps.errors_at_lower_sigma(sigma=3.0) for samps in agg.values(\"samples\")\n",
        "# ]\n",
        "\n",
        "print(\"Errors Lists: \\n\")\n",
        "print(ue3_vectors, \"\\n\")\n",
        "print(le3_vectors, \"\\n\")\n",
        "print(\"Errors Instances: \\n\")\n",
        "# print(ue3_instances, \"\\n\")\n",
        "# print(le3_instances, \"\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Bayesian Evidence__\n",
        "\n",
        "The maximum log likelihood of each model fit and its Bayesian log evidence (estimated via the nested sampling \n",
        "algorithm) are also available.\n",
        "\n",
        "Given each fit is to a different image, these are not very useful. However, in a later tutorial we'll look at using \n",
        "the aggregator for images that we fit with many different models and many different pipelines, in which case comparing \n",
        "the evidences allows us to perform Bayesian model comparison!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"Maximum Log Likelihoods and Log Evidences: \\n\")\n",
        "print([max(samps.log_likelihood_list) for samps in agg.values(\"samples\")])\n",
        "print([samps.log_evidence for samps in agg.values(\"samples\")])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__PDFs__\n",
        "\n",
        "The Probability Density Functions (PDF's) of the every model-fit can be plotted using Dynesty's in-built visualization \n",
        "tools, which are wrapped via the `DynestyPlotter` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for samples in agg.values(\"samples\"):\n",
        "    search_plotter = aplt.DynestyPlotter(samples=samples)\n",
        "#  search_plotter.cornerplot()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Samples Filtering__\n",
        "\n",
        "The samples object has the results for all model parameter. It can be filtered to contain the results of specific \n",
        "parameters of interest.\n",
        "\n",
        "The basic form of filtering specifies parameters via their path, which was printed above via the model and is printed \n",
        "again below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = list(agg.values(\"samples\"))[0]\n",
        "\n",
        "print(\"Parameter paths in the model which are used for filtering:\")\n",
        "print(samples.model.paths)\n",
        "\n",
        "print(\"All parameters of the very first sample\")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "samples = samples.with_paths(\n",
        "    [\n",
        "        (\"galaxies\", \"lens\", \"mass\", \"einstein_radius\"),\n",
        "        (\"galaxies\", \"source\", \"bulge\", \"sersic_index\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"All parameters of the very first sample (containing only the lens mass's einstein radius and \"\n",
        "    \"source bulge's sersic index).\"\n",
        ")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "print(\n",
        "    \"Maximum Log Likelihood Model Instances (containing only the lens mass's einstein radius and \"\n",
        "    \"source bulge's sersic index):\\n\"\n",
        ")\n",
        "print(samples.max_log_likelihood(as_instance=False))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above, we specified each path as a list of tuples of strings. \n",
        "\n",
        "This is how the PyAutoFit source code stores the path to different components of the model, but it is not in-line \n",
        "with the PyAutoLens API used to compose a model.\n",
        "\n",
        "We can alternatively use the following API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = list(agg.values(\"samples\"))[0]\n",
        "\n",
        "samples = samples.with_paths(\n",
        "    [\"galaxies.lens.mass.einstein_radius\", \"galaxies.source.bulge.sersic_index\"]\n",
        ")\n",
        "\n",
        "print(\n",
        "    \"All parameters of the very first sample (containing only the lens mass's einstein radius and \"\n",
        "    \"source bulge's sersic index).\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above, we filtered the `Samples` but asking for all parameters which included the\n",
        "path (\"galaxies\", \"lens\", \"mass\", \"einstein_radius\").\n",
        "\n",
        "We can alternatively filter the `Samples` object by removing all parameters with a certain path. Below, we remove\n",
        "the centres of the mass model to be left with 10 parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = list(agg.values(\"samples\"))[0]\n",
        "\n",
        "print(\"Parameter paths in the model which are used for filtering:\")\n",
        "print(samples.model.paths)\n",
        "\n",
        "print(\"Parameters of first sample\")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "print(samples.model.total_free_parameters)\n",
        "\n",
        "samples = samples.without_paths(\n",
        "    [\n",
        "        # \"galaxies.lens.mass.centre\"),\n",
        "        \"galaxies.lens.mass.centre.centre_0\",\n",
        "        # \"galaxies.lens.mass.centre.centre_1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Parameters of first sample without the lens mass centre.\")\n",
        "print(samples.parameter_lists[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can keep and remove entire paths of the samples, for example keeping only the parameters of the lens or \n",
        "removing all parameters of the source's bulge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = list(agg.values(\"samples\"))[0]\n",
        "samples = samples.with_paths([\"galaxies.lens\"])\n",
        "print(\"Parameters of the first sample of the lens galaxy\")\n",
        "print(samples.parameter_lists[0])\n",
        "\n",
        "samples = list(agg.values(\"samples\"))[0]\n",
        "samples = samples.with_paths([\"galaxies.source.bulge\"])\n",
        "print(\"Parameters of the first sample without the source's bulge\")\n",
        "print(samples.parameter_lists[0])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Latex__\n",
        "\n",
        "If you are writing results up in a paper, you can use PyAutoFit's inbuilt latex tools to create latex \n",
        "table code which you can copy to your .tex document.\n",
        "\n",
        "By combining this with the filtering tools below, specific parameters can be included or removed from the latex.\n",
        "\n",
        "Remember that the superscripts of a parameter are loaded from the config file `notation/label.yaml`, providing high\n",
        "levels of customization for how the parameter names appear in the latex table. This is especially useful if your \n",
        "model uses the same model components with the same parameter, which therefore need to be distinguished via superscripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "latex = af.text.Samples.latex(\n",
        "    samples=list(agg.values(\"samples\"))[0],\n",
        "    median_pdf_model=True,\n",
        "    sigma=3.0,\n",
        "    name_to_label=True,\n",
        "    include_name=True,\n",
        "    include_quickmath=True,\n",
        "    prefix=\"Example Prefix \",\n",
        "    suffix=r\"\\\\[-2pt]\",\n",
        ")\n",
        "print(latex)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}