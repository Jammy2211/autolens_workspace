{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Searches: PySwarms\n",
        "==================\n",
        "\n",
        "PySwarms is a  particle swarm optimization (PSO) algorithm.\n",
        "\n",
        "Information about PySwarms can be found at the following links:\n",
        "\n",
        " - https://github.com/ljvmiranda921/pyswarms\n",
        " - https://pyswarms.readthedocs.io/en/latest/index.html\n",
        " - https://pyswarms.readthedocs.io/en/latest/api/pyswarms.single.html#module-pyswarms.single.global_best\n",
        "\n",
        "An PSO algorithm only seeks to only find the maximum likelihood lens model, unlike MCMC or nested sampling algorithms \n",
        "like Zzeus and Nautilus, which aims to map-out parameter space and infer errors on the parameters.Therefore, in \n",
        "principle, a PSO like PySwarm should fit a lens model very fast.\n",
        "\n",
        "In our experience, the parameter spaces fitted by lens models are too complex for `PySwarms` to be used without a lot\n",
        "of user attention and care.  Nevertheless, we encourage you to give it a go yourself, and let us know on the PyAutoLens \n",
        "GitHub if you find an example of a problem where `PySwarms` outperforms Nautilus!\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import numpy as np\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset + Masking__\n",
        "\n",
        "Load and plot the strong lens dataset `simple__no_lens_light` via .fits files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__ \n",
        "\n",
        "In our experience, pyswarms is ineffective at initializing a lens model and therefore needs a the initial swarm of\n",
        "particles to surround the highest likelihood lens models. We set this starting point up below by manually inputting \n",
        "`GaussianPriors` on every parameter, where the centre of these priors is near the true values of the simulated lens data.\n",
        "\n",
        "Given this need for a robust starting point, PySwarms is only suited to model-fits where we have this information. It may\n",
        "therefore be useful when performing lens modeling search chaining (see HowToLens chapter 3). However, even in such\n",
        "circumstances, we have found that is often unrealible and often infers a local maxima."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "mass.centre.centre_0 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "mass.centre.centre_1 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "mass.ell_comps.ell_comps_0 = af.GaussianPrior(mean=0.0, sigma=0.3)\n",
        "mass.ell_comps.ell_comps_1 = af.GaussianPrior(mean=0.0, sigma=0.3)\n",
        "mass.einstein_radius = af.GaussianPrior(mean=1.4, sigma=0.4)\n",
        "\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "shear.gamma_1 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "shear.gamma_2 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=mass, shear=shear)\n",
        "\n",
        "# Source:\n",
        "\n",
        "bulge = af.Model(al.lp_linear.SersicCore)\n",
        "bulge.centre.centre_0 = af.GaussianPrior(mean=0.0, sigma=0.3)\n",
        "bulge.centre.centre_1 = af.GaussianPrior(mean=0.0, sigma=0.3)\n",
        "bulge.ell_comps.ell_comps_0 = af.GaussianPrior(mean=0.0, sigma=0.3)\n",
        "bulge.ell_comps.ell_comps_1 = af.GaussianPrior(mean=0.0, sigma=0.3)\n",
        "bulge.intensity = af.GaussianPrior(mean=0.3, sigma=0.3)\n",
        "bulge.effective_radius = af.GaussianPrior(mean=0.2, sigma=0.2)\n",
        "bulge.sersic_index = af.GaussianPrior(mean=1.0, sigma=1.0)\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=bulge)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__ \n",
        "\n",
        "We create the Analysis as per using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(dataset=dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "Below we use `PySwarmsGlobal` to fit the lens model, using the model where the particles start as described above. \n",
        "See the PySwarms docs for a description of what the input parameters below do and what the `Global` search technique is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.PySwarmsGlobal(\n",
        "    path_prefix=path.join(\"imaging\", \"searches\"),\n",
        "    name=\"PySwarmsGlobal\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_particles=30,\n",
        "    iters=300,\n",
        "    cognitive=0.5,\n",
        "    social=0.3,\n",
        "    inertia=0.9,\n",
        "    ftol=-np.inf,\n",
        "    iterations_per_update=1000,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "We can use an `MLEPlotter` to create a corner plot, which shows the probability density function (PDF) of every\n",
        "parameter in 1D and 2D."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pyswarms_plotter = aplt.MLEPlotter(samples=result.samples)\n",
        "pyswarms_plotter.cost_history()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "We can also use a `PySwarmsLocal` to fit the lens model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.PySwarmsLocal(\n",
        "    path_prefix=path.join(\"imaging\", \"searches\"),\n",
        "    name=\"PySwarmsLocal\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_particles=30,\n",
        "    iters=300,\n",
        "    cognitive=0.5,\n",
        "    social=0.3,\n",
        "    inertia=0.9,\n",
        "    ftol=-np.inf,\n",
        "    iterations_per_update=1000,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)\n",
        "\n",
        "pyswarms_plotter = aplt.MLEPlotter(samples=result.samples)\n",
        "pyswarms_plotter.cost_history()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}