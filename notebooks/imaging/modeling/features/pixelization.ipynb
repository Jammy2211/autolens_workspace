{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling Features: Pixelization\n",
        "===============================\n",
        "\n",
        "A pixelization reconstructs the source's light using a pixel-grid, which is regularized using a prior that forces\n",
        "the solution to have a degree of smoothness.\n",
        "\n",
        "This script fits a source galaxy model which uses a pixelization to reconstruct the source's light. A Delaunay\n",
        "mesh and constant regularization scheme are used, which are the simplest forms of mesh and regularization\n",
        "with provide computationally fast and accurate solutions in **PyAutoLens**.\n",
        "\n",
        "For simplicity, the lens galaxy's light is omitted from the model and is not present in the simulated data. It is\n",
        "straightforward to include the lens galaxy's light in the model.\n",
        "\n",
        "Pixelizations are covered in detail in chapter 4 of the **HowToLens** lectures.\n",
        "\n",
        "__Advantages__\n",
        "\n",
        "Many strongly lensed source galaxies are complex, and have asymmetric and irregular morphologies. These morphologies\n",
        "cannot be well approximated by a parametric light profiles like a Sersic, or many Sersics, and thus a pixelization\n",
        "is required to reconstruct the source's irregular light.\n",
        "\n",
        "Even basis functions like shapelets or a multi-Gaussian expansion cannot reconstruct a source-plane accurately\n",
        "if there are multiple source galaxies, or if the source galaxy has a very complex morphology.\n",
        "\n",
        "To infer detailed components of a lens mass model (e.g. its density slope, whether there's a dark matter subhalo, etc.)\n",
        "then pixelized source models are required, to ensure the mass model is fitting all of the lensed source light.\n",
        "\n",
        "There are also many science cases where one wants to study the highly magnified light of the source galaxy in detail,\n",
        "to learnt about distant and faint galaxies. A pixelization reconstructs the source's unlensed emission and thus\n",
        "enables this.\n",
        "\n",
        "__Disadvantages__\n",
        "\n",
        "Pixelizations are computationally slow, and thus the run times will be much longer than a parametric source model.\n",
        "It is not uncommon for a pixelization to take hours or even days to fit high resolution imaging data (e.g. Hubble Space\n",
        "Telescope imaging).\n",
        "\n",
        "Lens modeling with pixelizations is also more complex than parametric source models, with there being more things\n",
        "that can go wrong. For example, there are solutions where a demagnified version of the lensed source galaxy is\n",
        "reconstructed, using a mass model which effectively has no mass or too much mass. These are described in detail below,\n",
        "the point for now is that it may take you a longer time to learn how to fit lens models with a pixelization successfully!\n",
        "\n",
        "__Positive Only Solver__\n",
        "\n",
        "Many codes which use linear algebra typically rely on a linear algabra solver which allows for positive and negative\n",
        "values of the solution (e.g. `np.linalg.solve`), because they are computationally fast.\n",
        "\n",
        "This is problematic, as it means that negative surface brightnesses values can be computed to represent a galaxy's\n",
        "light, which is clearly unphysical. For a pixelizaiton, this often produces negative source pixels which over-fit\n",
        "the data, producing unphysical solutions.\n",
        "\n",
        "**PyAutoLens** uses a positive only linear algebra solver which has been extensively optimized to ensure it is as fast\n",
        "as positive-negative solvers. This ensures that all light profile intensities are positive and therefore physical.\n",
        "\n",
        "__Positive Only Solver__\n",
        "\n",
        "All pixelized source reconstructions use a positive-only solver, meaning that every source-pixel is only allowed\n",
        "to reconstruct positive flux values. This ensures that the source reconstruction is physical and that we don't\n",
        "reconstruct negative flux values that don't exist in the real source galaxy (a common systematic solution in lens\n",
        "analysis).\n",
        "\n",
        "It may be surprising to hear that this is a feature worth pointing out, but it turns out setting up the linear algebra\n",
        "to enforce positive reconstructions is difficult to make efficient. A lot of development time went into making this\n",
        "possible, where a bespoke fast non-negative linear solver was developed to achieve this.\n",
        "\n",
        "Other methods in the literature often do not use a positive only solver, and therefore suffer from these\n",
        "unphysical solutions, which can degrade the results of lens model in general.\n",
        "\n",
        "__Chaining__\n",
        "\n",
        "Due to the complexity of fitting with a pixelization, it is often best to use **PyAutoLens**'s non-linear chaining\n",
        "feature to compose a pipeline which begins by fitting a simpler model using a parametric source.\n",
        "\n",
        "More information on chaining is provided in the `autolens_workspace/notebooks/imaging/advanced/chaining` folder,\n",
        "chapter 3 of the **HowToLens** lectures.\n",
        "\n",
        "The script `autolens_workspace/scripts/imaging/advanced/chaining/parametric_to_pixelization.py` explitly uses chaining\n",
        "to link a lens model using a light profile source to one which then uses a pixelization.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits an `Imaging` dataset of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's light is omitted (and is not present in the simulated data).\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's surface-brightness is reconstructed using a `DelaunayMagnification` mesh and `Constant`\n",
        "   regularization scheme.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the modeling `start_here.ipynb` notebook for more detailed comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the strong lens dataset `simple__no_lens_light` via .fits files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We define a 3.0\" circular mask, which includes the emission of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Positions__\n",
        "\n",
        "This fit also uses the arc-second positions of the multiply imaged lensed source galaxy, which were drawn onto the\n",
        "image via the GUI described in the file `autolens_workspace/*/imaging/data_preparation/gui/positions.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = al.Grid2DIrregular.from_json(\n",
        "    file_path=path.join(dataset_path, \"positions.json\")\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our lens model using `Model` objects, which represent the galaxies we fit to our data.  In this \n",
        "example fits a lens model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear` [7 parameters].\n",
        " \n",
        " - The source-galaxy's light uses a `DelaunayMagnification` mesh with fixed resolution 30 x 30 pixels (0 parameters).\n",
        " \n",
        " - This pixelization is regularized using a `ConstantSplit` scheme which smooths every source pixel equally [1 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=6. \n",
        " \n",
        "It is worth noting the `Pixelization`  use significantly fewer parameters (1 parameter) than \n",
        "fitting the source using `LightProfile`'s (7+ parameters). \n",
        "\n",
        "The lens model therefore includes a mesh and regularization scheme, which are used together to create the \n",
        "pixelization. \n",
        "\n",
        "__Model Cookbook__\n",
        "\n",
        "A full description of model composition, including lens model customization, is provided by the model cookbook: \n",
        "\n",
        "https://pyautolens.readthedocs.io/en/latest/general/model_cookbook.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.PowerLaw)\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=mass, shear=shear)\n",
        "\n",
        "# Source:\n",
        "\n",
        "mesh = af.Model(al.mesh.DelaunayMagnification)\n",
        "mesh.shape = (30, 30)\n",
        "\n",
        "regularization = af.Model(al.reg.ConstantSplit)\n",
        "\n",
        "pixelization = af.Model(al.Pixelization, mesh=mesh, regularization=regularization)\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format (if this does not display clearly on your screen refer to\n",
        "`start_here.ipynb` for a description of how to fix this).\n",
        "\n",
        "This confirms that the source galaxy's has a mesh and regularization scheme, which are combined into a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using the nested sampling algorithm Nautilus (see `start.here.py` for a \n",
        "full description)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"imaging\", \"modeling\"),\n",
        "    name=\"pixelization\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Position Likelihood__\n",
        "\n",
        "We add a penalty term ot the likelihood function, which penalizes models where the brightest multiple images of\n",
        "the lensed source galaxy do not trace close to one another in the source plane. This removes \"demagnified source\n",
        "solutions\" from the source pixelization, which one is likely to infer without this penalty.\n",
        "\n",
        "A comprehensive description of why we do this is given at the following readthedocs page. I strongly recommend you \n",
        "read this page in full if you are not familiar with the positions likelihood penalty and demagnified source reconstructions:\n",
        "\n",
        " https://pyautolens.readthedocs.io/en/latest/general/demagnified_solutions.html\n",
        "\n",
        "__Brief Description__\n",
        "\n",
        "Unlike other example scripts, we also pass the `AnalysisImaging` object below a `PositionsLHPenalty` object, which\n",
        "includes the positions we loaded above, alongside a `threshold`.\n",
        "\n",
        "This is because `Inversion`'s suffer a bias whereby they fit unphysical lens models where the source galaxy is \n",
        "reconstructed as a demagnified version of the lensed source. These are covered in more detail in chapter 4 \n",
        "of **HowToLens**. \n",
        "\n",
        "To prevent these solutions biasing the model-fit we specify a `position_threshold` of 0.5\", which requires that a \n",
        "mass model traces the four (y,x) coordinates specified by our positions (that correspond to the brightest regions of the \n",
        "lensed source) within 0.5\" of one another in the source-plane. If this criteria is not met, a large penalty term is\n",
        "added to likelihood that massively reduces the overall likelihood. This penalty is larger if the ``positions``\n",
        "trace further from one another.\n",
        "\n",
        "This ensures the unphysical solutions that bias an `Inversion` have much lower likelihood that the physical solutions\n",
        "we desire. Furthermore, the penalty term reduces as the image-plane multiple image positions trace closer in the \n",
        "source-plane, ensuring Nautilus converges towards an accurate mass model. It does this very fast, as \n",
        "ray-tracing just a few multiple image positions is computationally cheap. \n",
        "\n",
        "The threshold of 0.3\" is large. For an accurate lens model we would anticipate the positions trace within < 0.01\" of\n",
        "one another. However, we only want the threshold to aid the non-linear with the choice of mass model in the intiial fit.\n",
        "\n",
        "Position thresholding is described in more detail in the \n",
        "script `autolens_workspace/*/imaging/modeling/customize/positions.py`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions_likelihood = al.PositionsLHPenalty(positions=positions, threshold=0.3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the `AnalysisImaging` object defining how the via Nautilus the model is fitted to the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    positions_likelihood=positions_likelihood,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "The run time of a pixelization is longer than many other features, with the estimate below coming out at around ~0.5 \n",
        "seconds per likelihood evaluation. This is because the fit has a lot of linear algebra to perform in order to\n",
        "reconstruct the source on the pixel-grid.\n",
        "\n",
        "Nevertheless, this is still fast enough for most use-cases. If run-time is an issue, the following factors determine\n",
        "the run-time of a a pixelization and can be changed to speed it up (at the expense of accuracy):\n",
        "\n",
        " - The number of unmasked pixels in the image data. By making the mask smaller (e.g. using an annular mask), the \n",
        "   run-time will decrease.\n",
        " \n",
        " - The number of source pixels in the pixelization. By reducing the `shape` from (30, 30) the run-time will decrease.\n",
        "\n",
        "This also serves to highlight why the positions threshold likelihood is so powerful. The likelihood evaluation time\n",
        "of this step is below 0.001 seconds, meaning that the initial parameter space sampling is extremely efficient even\n",
        "for a pixelization (this is not accounted for in the run-time estimate below)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")\n",
        "\n",
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")\n",
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format (if this \n",
        "does not display clearly on your screen refer to `start_here.ipynb` for a description of how to fix this):\n",
        "\n",
        "This confirms that the source galaxy's has a mesh and regularization scheme, which are combined into a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the maximum likelihood fit, tracer images and posteriors inferred via Nautilus.\n",
        "\n",
        "Checkout `autolens_workspace/*/imaging/results` for a full description of analysing results in **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=result.grid\n",
        ")\n",
        "tracer_plotter.subplot_tracer()\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "search_plotter = aplt.NautilusPlotter(samples=result.samples)\n",
        "search_plotter.cornerplot()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Voronoi__\n",
        "\n",
        "The pixelization mesh which tests have revealed performs best is the `VoronoiNN` object, which uses a Voronoi\n",
        "mesh with a technique called natural neighbour interpolation (full details are provided in the **HowToLens**\n",
        "tutorials).\n",
        "\n",
        "I recommend users always use these pixelizations, however they require a c library to be installed, thus they are\n",
        "not the default pixelization used in this tutorial.\n",
        "\n",
        "If you want to use this pixelization, checkout the installation instructions here:\n",
        "\n",
        "https://github.com/Jammy2211/PyAutoArray/tree/main/autoarray/util/nn\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "Pixelizations are the most complex but also most powerful way to model a source galaxy.\n",
        "\n",
        "Whether you need to use them or not depends on the science you are doing. If you are only interested in measuring a\n",
        "simple quantity like the Einstein radius of a lens, you can get away with using light profiles like a Sersic, MGE or \n",
        "shapelets to model the source. Low resolution data also means that using a pixelization is not necessary, as the\n",
        "complex structure of the source galaxy is not resolved anyway.\n",
        "\n",
        "However, fitting complex mass models (e.g. a power-law, stellar / dark model or dark matter substructure) requires \n",
        "this level of complexity in the source model. Furthermore, if you are interested in studying the properties of the\n",
        "source itself, you won't find a better way to do this than using a pixelization.\n",
        "\n",
        "Having read this script, you are probably now in a position to fit your own lens model using a pixelization. If you are\n",
        "able to do this, and get a fit that is sufficiently good, you are done.\n",
        "\n",
        "__Chaining__\n",
        "\n",
        "If your pixelization fit does not go well, or you want for faster computational run-times, you may wish to use\n",
        "search chaining which breaks the model-fit into multiple Nautilus runs. This is described for the specific case of \n",
        "linking a (computationally fast) light profile fit to a pixelization in the script:\n",
        "\n",
        "`autolens_workspace/scripts/imaging/advanced/chaining/parametric_to_pixelization.py`\n",
        "\n",
        "__HowToLens__\n",
        "\n",
        "You probably also don't have a good understanding of how pixelizations actually work, which comes down to a lot of\n",
        "linear algebra, Bayesian statistics and geometry. If you want to understand this, you should checkout chapter 4 of\n",
        "**HowToLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}