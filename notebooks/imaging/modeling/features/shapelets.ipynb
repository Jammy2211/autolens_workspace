{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling Features: Shapelets\n",
        "============================\n",
        "\n",
        "A shapelet is a basis function that is appropriate for capturing the exponential / disk-like features of a galaxy. It\n",
        "has been employed in many strong lensing studies too model the light of the lensed source galaxy, as it can represent\n",
        "features of disky star forming galaxies that a single Sersic function cannot.\n",
        "\n",
        "- https://ui.adsabs.harvard.edu/abs/2016MNRAS.457.3066T\n",
        "- https://iopscience.iop.org/article/10.1088/0004-637X/813/2/102 t\n",
        "\n",
        "Shapelets are described in full in the following paper:\n",
        "\n",
        " https://arxiv.org/abs/astro-ph/0105178\n",
        "\n",
        "This script performs a model-fit using shapelet, where it decomposes the source light into a super positive of ~200\n",
        "Shapelets. The `intensity` of every Shapelet is solved for via an inversion (see the `light_parametric_linear.py`\n",
        "feature).\n",
        "\n",
        "__Advantages__\n",
        "\n",
        "Symmetric light profiles (e.g. elliptical Sersics) may leave significant residuals, because they fail to capture\n",
        "irregular and asymmetric morphological of galaxies (e.g. isophotal twists, an ellipticity which varies radially).\n",
        "Shapelets can capture these features and can therefore much better represent the emission of complex source galaxies.\n",
        "\n",
        "The shapelet model can be composed in a way that has fewer non-linear parameters than an elliptical Sersic. In this\n",
        "example, the ~200 shapelets which represent the `bulge` of the source are composed in a model corresponding to just\n",
        "N=3 non-linear parameters (a `bulge` comprising a linear Sersic would give N=6).\n",
        "\n",
        "Therefore, not only does a shapelet fit more complex source galaxy morphologies, it does so using fewer non-linear\n",
        "parameters than the standard light profile models!\n",
        "\n",
        "__Disadvantages__\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits an `Imaging` dataset of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's light is omitted (and is not present in the simulated data).\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        "This script fits an `Imaging` dataset of a galaxy with a model where:\n",
        "\n",
        " - The source galaxy's bulge is a super position of `ShapeletCartesian`` profiles.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the modeling `start_here.ipynb` notebook for more detailed comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the galaxy dataset `light_basis` via .fits files, which we will fit with \n",
        "the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "The model-fit requires a `Mask2D` defining the regions of the image we fit the model to the data, which we define\n",
        "and use to set up the `Imaging` object that the model fits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our model using `Model` objects, which represent the galaxies we fit to our data. In this \n",
        "example we fit a model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear` [7 parameters].\n",
        " - The source galaxy's bulge is a superposition of 10 parametric linear `ShapeletCartesian` profiles [3 parameters]. \n",
        " - The centres of the Shapelets are all linked together.\n",
        " - The size of the Shapelet basis is controlled by a `beta` parameter, which is the same for all Shapelet basis \n",
        "   functions.\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=10.\n",
        "\n",
        "Note how this Shapelet model can capture features more complex than a Sersic, but has fewer non-linear parameters\n",
        "(N=3 compared to N=7 for a `Sersic`).\n",
        "\n",
        "__Model Cookbook__\n",
        "\n",
        "A full description of model composition, including lens model customization, is provided by the model cookbook: \n",
        "\n",
        "https://pyautolens.readthedocs.io/en/latest/general/model_cookbook.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=mass, shear=shear)\n",
        "\n",
        "# Source:\n",
        "\n",
        "total_n = 10\n",
        "total_m = sum(range(2, total_n + 1)) + 1\n",
        "\n",
        "shapelets_bulge_list = af.Collection(\n",
        "    af.Model(al.lp_shapelets.ShapeletPolar) for _ in range(total_n + total_m)\n",
        ")\n",
        "\n",
        "n_count = 1\n",
        "m_count = -1\n",
        "\n",
        "for i, shapelet in enumerate(shapelets_bulge_list):\n",
        "    shapelet.n = n_count\n",
        "    shapelet.m = m_count\n",
        "\n",
        "    m_count += 2\n",
        "\n",
        "    if m_count > n_count:\n",
        "        n_count += 1\n",
        "        m_count = -n_count\n",
        "\n",
        "    shapelet.centre = shapelets_bulge_list[0].centre\n",
        "    shapelet.beta = shapelets_bulge_list[0].beta\n",
        "\n",
        "bulge = af.Model(\n",
        "    al.lp_basis.Basis,\n",
        "    light_profile_list=shapelets_bulge_list,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=bulge)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format (if this does not display clearly on your screen refer to\n",
        "`start_here.ipynb` for a description of how to fix this)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using the nested sampling algorithm Nautilus (see `start.here.py` for a \n",
        "full description). We make the following changes to the Nautilus settings:\n",
        "\n",
        " - Increase the number of live points, `n_live`, from the default value of 50 to 100. \n",
        "\n",
        "These changes are motivated by the higher dimensionality non-linear parameter space that including the lens light \n",
        "creates, which requires more thorough sampling by the non-linear search.\n",
        "\n",
        "The folders: \n",
        "\n",
        " - `autolens_workspace/*/imaging/modeling/searches`.\n",
        " - `autolens_workspace/*/imaging/modeling/customize`\n",
        "\n",
        "Give overviews of the non-linear searches **Pyautolens** supports and more details on how to customize the\n",
        "model-fit, including the priors on the model. \n",
        "\n",
        "If you are unclear of what a non-linear search is, checkout chapter 2 of the **HowToGalaxy** lectures.\n",
        "\n",
        "The `name` and `path_prefix` below specify the path where results ae stored in the output folder:  \n",
        "\n",
        " `/autolens_workspace/output/imaging/light_sersic/mass[sie]/unique_identifier`.\n",
        "\n",
        "__Unique Identifier__\n",
        "\n",
        "In the path above, the `unique_identifier` appears as a collection of characters, where this identifier is generated \n",
        "based on the model, search and dataset that are used in the fit.\n",
        "\n",
        "An identical combination of model and search generates the same identifier, meaning that rerunning the script will use \n",
        "the existing results to resume the model-fit. In contrast, if you change the model or search, a new unique identifier \n",
        "will be generated, ensuring that the model-fit results are output into a separate folder.\n",
        "\n",
        "We additionally want the unique identifier to be specific to the dataset fitted, so that if we fit different datasets\n",
        "with the same model and search results are output to a different folder. We achieve this below by passing \n",
        "the `dataset_name` to the search's `unique_tag`.\n",
        "\n",
        "__Number Of Cores__\n",
        "\n",
        "We include an input `number_of_cores`, which when above 1 means that Nautilus uses parallel processing to sample multiple \n",
        "models at once on your CPU. When `number_of_cores=2` the search will run roughly two times as\n",
        "fast, for `number_of_cores=3` three times as fast, and so on. The downside is more cores on your CPU will be in-use\n",
        "which may hurt the general performance of your computer.\n",
        "\n",
        "You should experiment to figure out the highest value which does not give a noticeable loss in performance of your \n",
        "computer. If you know that your processor is a quad-core processor you should be able to use `number_of_cores=4`. \n",
        "\n",
        "Above `number_of_cores=4` the speed-up from parallelization diminishes greatly. We therefore recommend you do not\n",
        "use a value above this.\n",
        "\n",
        "For users on a Windows Operating system, using `number_of_cores>1` may lead to an error, in which case it should be \n",
        "reduced back to 1 to fix it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"imaging\", \"modeling\"),\n",
        "    name=\"shapelets\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=150,\n",
        "    number_of_cores=4,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the `AnalysisImaging` object defining how the via Nautilus the model is fitted to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset, settings_inversion=al.SettingsInversion(use_w_tilde=False)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "The likelihood evaluation time for a shapelets is significantly slower than standard light profiles.\n",
        "This is because the image of every shapelets must be computed and evaluated, and each must be blurred with the PSF.\n",
        "In this example, the evaluation time is ~0.37s, compared to ~0.01 seconds for standard light profiles.\n",
        "\n",
        "Gains in the overall run-time however are made thanks to the models reduced complexity and lower\n",
        "number of free parameters. The source is modeled with 3 free parameters, compared to 6+ for a linear light profile \n",
        "Sersic.\n",
        "\n",
        "However, the multi-gaussian expansion (MGE) approachj is even faster than shapelets. It uses fewer Gaussian basis\n",
        "functions (speed up the likelihood evaluation) and has fewer free parameters (speeding up the non-linear search).\n",
        "Furthermore, non of the free parameters scale the size of the source galaxy, which means the non-linear search\n",
        "can converge faster.\n",
        "\n",
        "I recommend you try using an MGE approach alongside shapelets. For many science cases, the MGE approach will be\n",
        "faster and give higher quality results. Shapelets may perform better for irregular sources, but this is not\n",
        "guaranteed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")\n",
        "\n",
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")\n",
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The `info` attribute shows the model in a readable format (if this does not display clearly on your screen refer to\n",
        "`start_here.ipynb` for a description of how to fix this)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the maximum likelihood fit, tracer images and posteriors inferred via Nautilus.\n",
        "\n",
        "Checkout `autolens_workspace/*/imaging/results` for a full description of analysing results in **PyAutoLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "plane_plotter = aplt.PlanePlotter(\n",
        "    plane=result.max_log_likelihood_plane, grid=result.grid\n",
        ")\n",
        "plane_plotter.subplot()\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "search_plotter = aplt.DynestyPlotter(samples=result.samples)\n",
        "search_plotter.cornerplot()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Lens Shapelets__\n",
        "\n",
        "A model where the lens is modeled as shapelets can be composed and fitted as shown below.\n",
        "\n",
        "I have not seen this model used in the literature, and am not clear on its advantages over a standard light profile\n",
        "model. However, it is worth trying if you are fitting a lens galaxy with a complex morphology.\n",
        "\n",
        "For most massive early-type galaxies, an MGE model will be faster and give higher quality results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "bulge = af.Model(\n",
        "    al.lp_basis.Basis,\n",
        "    light_profile_list=shapelets_bulge_list,\n",
        ")\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, bulge=bulge, mass=mass, shear=shear)\n",
        "\n",
        "# Source:\n",
        "\n",
        "bulge = af.Model(\n",
        "    al.lp_basis.Basis,\n",
        "    light_profile_list=shapelets_bulge_list,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=bulge)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autolens_workspace/*/imaging/results` for a full description of analysing results in **Pyautolens**, which \n",
        "includes a dedicated tutorial for linear objects like basis functions.\n",
        "\n",
        "__Regularization__\n",
        "\n",
        "There is one downside to `Basis` functions, we may compose a model with too much freedom. The `Basis` (e.g. our 20\n",
        "Gaussians) may overfit noise in the data, or possible the lensed source galaxy emission -- neither of which we \n",
        "want to happen! \n",
        "\n",
        "To circumvent this issue, we have the option of adding regularization to a `Basis`. Regularization penalizes\n",
        "solutions which are not smooth -- it is essentially a prior that says we expect the component the `Basis` represents\n",
        "(e.g. a bulge or disk) to be smooth, in that its light changes smoothly as a function of radius.\n",
        "\n",
        "Below, we compose and fit a model using Basis functions which includes regularization, which adds one addition \n",
        "parameter to the fit, the `coefficient`, which controls the degree of smoothing applied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = af.Model(\n",
        "    al.lp_basis.Basis,\n",
        "    light_profile_list=shapelets_bulge_list,\n",
        "    regularization=al.reg.Constant,\n",
        ")\n",
        "galaxy = af.Model(al.Galaxy, redshift=0.5, bulge=bulge)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(galaxy=galaxy))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model, which has addition priors now associated with regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"imaging\", \"modeling\"),\n",
        "    name=\"shapelets_regularized\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=150,\n",
        "    number_of_cores=1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "Regularization has a small impact on the run-time of the model-fit, as the likelihood evaluation time does not\n",
        "change and it adds only 1 additional parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")\n",
        "\n",
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")\n",
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To learn more about Basis functions, regularization and when you should use them, checkout the \n",
        "following **HowToGalaxy** tutorials:\n",
        "\n",
        " - `howtogalaxy/chapter_2_lens_modeling/tutorial_5_linear_profiles.ipynb`.\n",
        " - `howtogalaxy/chapter_4_pixelizations/tutorial_4_bayesian_regularization.ipynb."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}