{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fits\n",
        "====\n",
        "\n",
        "This guide shows how to fit data using the `FitImaging` object, including visualizing and interpreting its results.\n",
        "\n",
        "References\n",
        "----------\n",
        "\n",
        "This example uses functionality described fully in other examples in the `guides` package:\n",
        "\n",
        "- `guides/plot`: Using Plotter objects to plot and customize figures.\n",
        "- `guides/units`: The source code unit conventions (e.g. arc seconds for distances and how to convert to physical units).\n",
        "- `guides/data_structures`: The bespoke data structures used to store 1D and 2d arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Loading Data__\n",
        "\n",
        "We we begin by loading the strong lens dataset `simple__no_lens_light` from .fits files, which is the dataset \n",
        "we will use to demonstrate fitting.\n",
        "\n",
        "This dataset was simulated using the `imaging/simulator` example, read through that to have a better\n",
        "understanding of how the data this exam fits was generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `ImagingPlotter` contains a subplot which plots all the key properties of the dataset simultaneously.\n",
        "\n",
        "This includes the observed image data, RMS noise map, Point Spread Function and other information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We now mask the data, so that regions where there is no signal (e.g. the edges) are omitted from the fit.\n",
        "\n",
        "We use a ``Mask2D`` object, which for this example is a 3.0\" circular mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now combine the imaging dataset with the mask."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = dataset.apply_mask(mask=mask)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now plot the image with the mask applied, where the image automatically zooms around the mask to make the lensed \n",
        "source appear bigger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.set_title(\"Image Data With Mask Applied\")\n",
        "dataset_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mask is also used to compute a `Grid2D`, where the (y,x) arc-second coordinates are only computed in unmasked \n",
        "pixels within the masks' circle. \n",
        "\n",
        "As shown in the previous overview example, this grid will be used to perform lensing calculations when fitting the\n",
        "data below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_plotter = aplt.Grid2DPlotter(grid=dataset.grid)\n",
        "grid_plotter.set_title(\"Grid2D of Masked Dataset\")\n",
        "grid_plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fitting__\n",
        "\n",
        "Following the previous overview example, we can make a tracer from a collection of light profiles, mass profiles\n",
        "and galaxies.\n",
        "\n",
        "The combination of light and mass profiels below is the same as those used to generate the simulated \n",
        "dataset we loaded above.\n",
        "\n",
        "It therefore produces a tracer whose image looks exactly like the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.0, 0.0),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        "    shear=al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp.Sersic(\n",
        "        centre=(0.0, 0.0),\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.8, angle=60.0),\n",
        "        intensity=4.0,\n",
        "        effective_radius=0.1,\n",
        "        sersic_index=1.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the tracer's light and mass profiles are the same used to make the dataset, its image is nearly the same as the\n",
        "observed image.\n",
        "\n",
        "However, the tracer's image does appear different to the data, in that its ring appears a bit thinner. This is\n",
        "because its image has not been blurred with the telescope optics PSF, which the data has.\n",
        "\n",
        "[For those not familiar with Astronomy data, the PSF describes how the observed emission of the galaxy is blurred by\n",
        "the telescope optics when it is observed. It mimicks this blurring effect via a 2D convolution operation]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=dataset.grid)\n",
        "tracer_plotter.set_title(\"Tracer  Image\")\n",
        "tracer_plotter.figures_2d(image=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now use a `FitImaging` object to fit this tracer to the dataset. \n",
        "\n",
        "The fit creates a `model_image` which we fit the data with, which includes performing the step of blurring the tracer`s \n",
        "image with the imaging dataset's PSF. We can see this by comparing the tracer`s image (which isn't PSF convolved) and \n",
        "the fit`s model image (which is)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = al.FitImaging(dataset=dataset, tracer=tracer)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.figures_2d(model_image=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit does a lot more than just blur the tracer's image with the PSF, it also creates the following:\n",
        "\n",
        " - The `residual_map`: The `model_image` subtracted from the observed dataset`s `data`.\n",
        " - The `normalized_residual_map`: The `residual_map `divided by the observed dataset's `noise_map`.\n",
        " - The `chi_squared_map`: The `normalized_residual_map` squared.\n",
        "\n",
        "For a good lens model where the model image and tracer are representative of the strong lens system the\n",
        "residuals, normalized residuals and chi-squareds are minimized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter.figures_2d(\n",
        "    residual_map=True, normalized_residual_map=True, chi_squared_map=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A subplot can be plotted which contains all of the above quantities, as well as other information contained in the\n",
        "tracer such as the source-plane image, a zoom in of the source-plane and a normalized residual map where the colorbar\n",
        "goes from 1.0 sigma to -1.0 sigma, to highlight regions where the fit is poor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The fit also provides us with a ``log_likelihood``, a single value quantifying how good the tracer fitted the dataset.\n",
        "\n",
        "Lens modeling, describe in the next overview example, effectively tries to maximize this log likelihood value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.log_likelihood)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Bad Fit__\n",
        "\n",
        "A bad lens model will show features in the residual-map and chi-squared map.\n",
        "\n",
        "We can produce such an image by creating a tracer with different lens and source galaxies. In the example below, we \n",
        "change the centre of the source galaxy from (0.0, 0.0) to (0.05, 0.05), which leads to residuals appearing\n",
        "in the fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.1, 0.1),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        "    shear=al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    bulge=al.lp.Sersic(\n",
        "        centre=(0.1, 0.1),\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.8, angle=60.0),\n",
        "        intensity=0.3,\n",
        "        effective_radius=0.1,\n",
        "        sersic_index=1.0,\n",
        "    ),\n",
        ")\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A new fit using this plane shows residuals, normalized residuals and chi-squared which are non-zero. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = al.FitImaging(dataset=dataset, tracer=tracer)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also note that its likelihood decreases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.log_likelihood)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit Quantities__\n",
        "\n",
        "The maximum log likelihood fit contains many 1D and 2D arrays showing the fit.\n",
        "\n",
        "There is a `model_image`, which is the image-plane image of the tracer we inspected in the previous tutorial\n",
        "blurred with the imaging data's PSF. \n",
        "\n",
        "This is the image that is fitted to the data in order to compute the log likelihood and therefore quantify the \n",
        "goodness-of-fit.\n",
        "\n",
        "If you are unclear on what `slim` means, refer to the section `Data Structure` at the top of this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.model_data.slim)\n",
        "\n",
        "# The native property provides quantities in 2D NumPy Arrays.\n",
        "print(fit.model_data.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are numerous ndarrays showing the goodness of fit: \n",
        "\n",
        " - `residual_map`: Residuals = (Data - Model_Data).\n",
        " - `normalized_residual_map`: Normalized_Residual = (Data - Model_Data) / Noise\n",
        " - `chi_squared_map`: Chi_Squared = ((Residuals) / (Noise)) ** 2.0 = ((Data - Model)**2.0)/(Variances)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.residual_map.slim)\n",
        "print(fit.normalized_residual_map.slim)\n",
        "print(fit.chi_squared_map.slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Figures of Merit__\n",
        "\n",
        "There are single valued floats which quantify the goodness of fit:\n",
        "\n",
        " - `chi_squared`: The sum of the `chi_squared_map`.\n",
        "\n",
        " - `noise_normalization`: The normalizing noise term in the likelihood function \n",
        "    where [Noise_Term] = sum(log(2*pi*[Noise]**2.0)).\n",
        "\n",
        " - `log_likelihood`: The log likelihood value of the fit where [LogLikelihood] = -0.5*[Chi_Squared_Term + Noise_Term]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.chi_squared)\n",
        "print(fit.noise_normalization)\n",
        "print(fit.log_likelihood)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Plane Quantities__\n",
        "\n",
        "The `FitImaging` object has specific quantities which break down each image of each plane:\n",
        "\n",
        " - `model_images_of_planes_list`: Model-images of each individual plane, which in this example is a model image of the \n",
        " lens galaxy and model image of the lensed source galaxy. Both images are convolved with the imaging's PSF.\n",
        "\n",
        " - `subtracted_images_of_planes_list`: Subtracted images of each individual plane, which are the data's image with\n",
        "   all other plane's model-images subtracted. For example, the first subtracted image has the source galaxy's model image\n",
        "   subtracted and therefore is of only the lens galaxy's emission. The second subtracted image is of the lensed source,\n",
        "   with the lens galaxy's light removed.\n",
        "\n",
        "For multi-plane lens systems these lists will be extended to provide information on every individual plane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.model_images_of_planes_list[0].slim)\n",
        "print(fit.model_images_of_planes_list[1].slim)\n",
        "\n",
        "print(fit.subtracted_images_of_planes_list[0].slim)\n",
        "print(fit.subtracted_images_of_planes_list[1].slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Unmasked Quantities__\n",
        "\n",
        "All of the quantities above are computed using the mask which was used to fit the data.\n",
        "\n",
        "The `FitImaging` can also compute the unmasked blurred image of each plane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.unmasked_blurred_image.native)\n",
        "print(fit.unmasked_blurred_image_of_planes_list[0].native)\n",
        "print(fit.unmasked_blurred_image_of_planes_list[1].native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We can use the `Mask2D` object to mask regions of one of the fit's maps and estimate quantities of it.\n",
        "\n",
        "Below, we estimate the average absolute normalized residuals within a 1.0\" circular mask, which would inform us of\n",
        "how accurate the lens light subtraction of a model fit is and if it leaves any significant residuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=fit.dataset.shape_native,\n",
        "    pixel_scales=fit.dataset.pixel_scales,\n",
        "    radius=1.0,\n",
        ")\n",
        "\n",
        "normalized_residuals = fit.normalized_residual_map.apply_mask(mask=mask)\n",
        "\n",
        "print(np.mean(np.abs(normalized_residuals.slim)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixel Counting__\n",
        "\n",
        "An alternative way to quantify residuals like the lens light residuals is pixel counting. For example, we could sum\n",
        "up the number of pixels whose chi-squared values are above 10 which indicates a poor fit to the data.\n",
        "\n",
        "Whereas computing the mean above the average level of residuals, pixel counting informs us how spatially large the\n",
        "residuals extend. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=fit.dataset.shape_native,\n",
        "    pixel_scales=fit.dataset.pixel_scales,\n",
        "    radius=1.0,\n",
        ")\n",
        "\n",
        "chi_squared_map = fit.chi_squared_map.apply_mask(mask=mask)\n",
        "\n",
        "print(np.sum(chi_squared_map > 10.0))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Outputting Results__\n",
        "\n",
        "You may wish to output certain results to .fits files for later inspection. \n",
        "\n",
        "For example, one could output the lens light subtracted image of the lensed source galaxy to a .fits file such that\n",
        "we could fit this source-only image again with an independent pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_subtracted_image = fit.subtracted_images_of_planes_list[1]\n",
        "lens_subtracted_image.output_to_fits(\n",
        "    file_path=dataset_path / \"lens_subtracted_data.fits\", overwrite=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fin."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}