{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results: Data Structures\n",
        "========================\n",
        "\n",
        "This tutorial illustrates the data structure objects which many results quantities are stored using, which are\n",
        "extensions of NumPy arrays.\n",
        "\n",
        "These data structures are used because for different lensing calculations it is convenient to store the data in\n",
        "different formats. For example, when ray-tracing a uniform grid of image-plane (y,x) coordinates, to an irregular\n",
        "grid of source-plane (y,x) coordinates, the image-plane coordinates can be stored in 2D whereas the source-plane\n",
        "coordinates must be stored in 1D.\n",
        "\n",
        "These data structures use the `slim` and `native` data representations API to make it simple to map quantities from\n",
        "1D dimensions to their native dimensions (e.g. a 2D grid).\n",
        "\n",
        "It also includes functionality necessary for performing calculations on a sub-grid, and binning this grid up to\n",
        "perform more accurate calculations.\n",
        "\n",
        "__Plot Module__\n",
        "\n",
        "This example uses the **PyAutoLens** plot module to plot the results, including `Plotter` objects that make\n",
        "the figures and `MatPlot` objects that wrap matplotlib to customize the figures.\n",
        "\n",
        "The visualization API is straightforward but is explained in the `autolens_workspace/*/plot` package in full.\n",
        "This includes detailed guides on how to customize every aspect of the figures, which can easily be combined with the\n",
        "code outlined in this tutorial.\n",
        "\n",
        "__Units__\n",
        "\n",
        "In this example, all quantities are **PyAutoLens**'s internal unit coordinates, with spatial coordinates in\n",
        "arc seconds, luminosities in electrons per second and mass quantities (e.g. convergence) are dimensionless.\n",
        "\n",
        "The results example `units_and_cosmology.ipynb` illustrates how to convert these quantities to physical units like\n",
        "kiloparsecs, magnitudes and solar masses.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `results/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__\n",
        "\n",
        "The code below performs a model-fit using Nautilus. \n",
        "\n",
        "You should be familiar with modeling already, if not read the `modeling/start_here.py` script before reading this one!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "dataset_name = \"lens_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "model = af.Collection(\n",
        "    galaxies=af.Collection(\n",
        "        lens=af.Model(\n",
        "            al.Galaxy, redshift=0.5, bulge=al.lp.Sersic, mass=al.mp.Isothermal\n",
        "        ),\n",
        "        source=af.Model(al.Galaxy, redshift=1.0, bulge=al.lp.Sersic),\n",
        "    )\n",
        ")\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"imaging\", \"modeling\"),\n",
        "    name=\"light[bulge]_mass[sie]_source[bulge]\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisImaging(dataset=dataset)\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Max Likelihood Tracer__\n",
        "\n",
        "As seen elsewhere in the workspace, the result contains a `max_log_likelihood_tracer` which we can visualize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = result.max_log_likelihood_tracer\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=tracer, grid=mask.derive_grid.all_false_sub_1\n",
        ")\n",
        "tracer_plotter.subplot_tracer()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data Structures Slim / Native__\n",
        "\n",
        "Objects like the `Tracer` allow us to produce lens modeling quantities.\n",
        "\n",
        "For example, by passing it a 2D grid of (y,x) coordinates we can return a numpy array containing its 2D image. \n",
        "This includes the lens light and lensed source images.\n",
        "\n",
        "Below, we use the grid of the `imaging` to computed the image on, which is the grid used to fit to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image = tracer.image_2d_from(grid=dataset.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we print the type of the `image` we note that it is an `Array2D`, which is a data structure that inherits \n",
        "from a numpy array but is extended to include specific functionality discussed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(type(image))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because the image is a numpy array, we can print its shape and see that it is 1D."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(image.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Data Structure__\n",
        "\n",
        "Why is the image stored as a 1D NumPy array? Is the image not a 2D quantity?\n",
        "\n",
        "Every array object returned is accessible via two attributes, `native` and `slim`:\n",
        "\n",
        " - `slim`: an ndarray of shape [total_unmasked_pixels] which is a slimmed-down representation of the data in 1D that \n",
        "    contains only the unmasked data points (where this mask is the one used by the model-fit above).\n",
        "\n",
        " - `native`: an ndarray of shape [total_y_image_pixels, total_x_image_pixels], which is the native shape of the \n",
        "    masked 2D grid used to fit the lens model. All masked pixels are assigned a value 0.0 in the `native` array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(image.native.shape)\n",
        "print(image.slim.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, all arrays in **PyAutoLens** are stored as their `slim` 1D numpy array.\n",
        "\n",
        "We can easily access them in their native format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(image[0:2])\n",
        "print(image.slim[0:2])\n",
        "print(image.native[10:12, 10:12])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Grid Choices__\n",
        "\n",
        "We can input a different grid, which is not masked, to evaluate the image anywhere of interest. We can also change\n",
        "the grid's resolution from that used in the model-fit.\n",
        "\n",
        "The examples uses a grid with `shape_native=(3,3)`. This is much lower resolution than one would typically use to \n",
        "perform ray tracing, but is chosen here so that the `print()` statements display in a concise and readable format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(shape_native=(5, 5), pixel_scales=0.1)\n",
        "\n",
        "image = tracer.image_2d_from(grid=grid)\n",
        "\n",
        "print(image.slim)\n",
        "print(image.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Sub Gridding__\n",
        "\n",
        "A grid can also have a sub-grid, defined via its `sub_size`, which defines how each pixel on the 2D grid is split \n",
        "into sub-pixels of size (`sub_size` x `sub_size`). \n",
        "\n",
        "These additional sub-pixels are used to perform calculations more accurately. For example, for the 2D image the\n",
        "values can be computed at every sub-pixel coordinate and binned-up, as opposed to computing the image only at the\n",
        "centre of each image pixel. \n",
        "\n",
        "This approximates more closely how light is observed on a telescope, where it is the full surface brightness \n",
        "distribution of the source over the pixel that is observed.\n",
        "\n",
        "The `sub_shape_native` and `sub_shape_slim` properties of the grid show that it has many additional coordinates\n",
        "corresponding to the 4x4 grid of sub-pixels in each image pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_sub = al.Grid2D.uniform(shape_native=(3, 3), pixel_scales=0.1, sub_size=2)\n",
        "\n",
        "print(grid_sub.sub_shape_native)\n",
        "print(grid_sub.sub_shape_slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The image computed using this grid does not have a `native` shape (5,5), but instead shape (20, 20). This is because \n",
        "each image pixel has been split into a 4x4 sub pixel (e.g. 4 * 5 = 20):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image = tracer.image_2d_from(grid=grid_sub)\n",
        "\n",
        "print(image.native.shape)\n",
        "print(image.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To estimate the image on our original 5x5 grid, we can use the `binned` property which bins up every 4x4 grid\n",
        "of sub-pixels in each image pixel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(image.binned.slim)\n",
        "print(image.binned.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Slim and Native Grids__\n",
        "\n",
        "Now we are familiar with `slim` and `native` datasets, it is worth noting that `Grid`'s also use this structure.\n",
        "\n",
        "They can be thought of as behaving analogously to vectors, albeit grids do not contains (y,x) vectors on a (y,x)\n",
        "grids of coordinates, but are simply the (y,x) grid of coordinates by itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_sub = al.Grid2D.uniform(shape_native=(3, 3), pixel_scales=0.1, sub_size=2)\n",
        "\n",
        "print(grid_sub.slim)\n",
        "print(grid_sub.native)\n",
        "print(grid_sub.binned.slim)\n",
        "print(grid_sub.binned.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A more detailed description of sub-gridding is provided in the optional **HowToLens** tutorial\n",
        "`autolens_workspace/*/howtolens/chapter_optional/tutorial_sub_grids.ipynb`.\n",
        "\n",
        "__Positions Grid__\n",
        "\n",
        "We may want the image at specific (y,x) coordinates.\n",
        "\n",
        "We can use an irregular 2D (y,x) grid of coordinates for this. The grid below evaluates the image at:\n",
        "\n",
        "- y = 1.0, x = 1.0.\n",
        "- y = 1.0, x = 2.0.\n",
        "- y = 2.0, x = 2.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_irregular = al.Grid2DIrregular(values=[[1.0, 1.0], [1.0, 2.0], [2.0, 2.0]])\n",
        "\n",
        "image = tracer.image_2d_from(grid=grid_irregular)\n",
        "\n",
        "print(image)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Vector Quantities__\n",
        "\n",
        "Many lensing quantities are vectors. That is, they are (y,x) coordinates that have 2 values representing their\n",
        "magnitudes in both the y and x directions.\n",
        "\n",
        "The most obvious of these is the deflection angles, which are used throughout lens modeling to ray-trace grids\n",
        "from the image-plane to the source-plane via a lens galaxy mass model.\n",
        "\n",
        "To indicate that a quantities is a vector, **PyAutoLens** uses the label `_yx`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "deflections_yx_2d = tracer.deflections_yx_2d_from(grid=dataset.grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we print the type of the `deflections_yx` we note that it is a `VectorYX2D`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(type(deflections_yx_2d))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unlike the scalar quantities above, which were a 1D numpy array in the `slim` representation and a 2D numpy array in \n",
        "the `native` representation, vectors are 2D in `slim` and 3D in `native`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(deflections_yx_2d.slim.shape)\n",
        "print(deflections_yx_2d.native.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For vector quantities the has shape `2`, corresponding to the y and x vectors respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(deflections_yx_2d.slim[0, :])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The role of the terms `slim` and `native` can be thought of in the same way as for scalar quantities. \n",
        "\n",
        "For a scalar, the `slim` property gives every scalar value as a 1D ndarray for every unmasked pixel. For a vector we \n",
        "still get an ndarray of every unmasked pixel, however each entry now contains two entries: the vector of (y,x) values. \n",
        "\n",
        "For a `native` property these vectors are shown on an image-plane 2D grid where again each pixel\n",
        "contains a (y,x) vector.\n",
        "\n",
        "Like we did for the convergence, we can use whatever grid we want to compute a vector and use sub-gridding to estimate\n",
        "values more precisely:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(shape_native=(3, 3), pixel_scales=0.1)\n",
        "\n",
        "deflections_yx_2d = tracer.deflections_yx_2d_from(grid=grid)\n",
        "\n",
        "print(deflections_yx_2d.slim)\n",
        "print(deflections_yx_2d.native)\n",
        "\n",
        "grid_sub = al.Grid2D.uniform(shape_native=(3, 3), pixel_scales=0.1, sub_size=2)\n",
        "\n",
        "deflections_yx_2d = tracer.deflections_yx_2d_from(grid=grid_sub)\n",
        "\n",
        "print(deflections_yx_2d.binned.slim)\n",
        "print(deflections_yx_2d.binned.native)\n",
        "\n",
        "grid_irregular = al.Grid2DIrregular(values=[[1.0, 1.0], [1.0, 2.0], [2.0, 2.0]])\n",
        "\n",
        "deflections_yx_2d = tracer.deflections_yx_2d_from(grid=grid_irregular)\n",
        "\n",
        "print(deflections_yx_2d)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}