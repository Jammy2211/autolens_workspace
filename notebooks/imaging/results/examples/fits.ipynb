{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results: Fits\n",
        "=============\n",
        "\n",
        "This tutorial inspects the model's fit to the data using the  `FitImaging` object inferred by the non-linear \n",
        "search, for example visualizing and interpreting its results.\n",
        "\n",
        "This includes inspecting the residuals, chi-squared and other goodness-of-fit quantities.\n",
        "\n",
        "__Plot Module__\n",
        "\n",
        "This example uses the **PyAutoLens** plot module to plot the results, including `Plotter` objects that make\n",
        "the figures and `MatPlot` objects that wrap matplotlib to customize the figures.\n",
        "\n",
        "The visualization API is straightforward but is explained in the `autolens_workspace/*/plot` package in full.\n",
        "This includes detailed guides on how to customize every aspect of the figures, which can easily be combined with the\n",
        "code outlined in this tutorial.\n",
        "\n",
        "__Units__\n",
        "\n",
        "In this example, all quantities are **PyAutoLens**'s internal unit coordinates, with spatial coordinates in\n",
        "arc seconds, luminosities in electrons per second and mass quantities (e.g. convergence) are dimensionless.\n",
        "\n",
        "The results example `units_and_cosmology.ipynb` illustrates how to convert these quantities to physical units like\n",
        "kiloparsecs, magnitudes and solar masses.\n",
        "\n",
        "__Data Structures__\n",
        "\n",
        "Quantities inspected in this example script use **PyAutoLens** bespoke data structures for storing arrays, grids,\n",
        "vectors and other 1D and 2D quantities. These use the `slim` and `native` API to toggle between representing the\n",
        "data in 1D numpy arrays or high dimension numpy arrays.\n",
        "\n",
        "This tutorial will only use the `slim` properties which show results in 1D numpy arrays of\n",
        "shape [total_unmasked_pixels]. This is a slimmed-down representation of the data in 1D that contains only the\n",
        "unmasked data points\n",
        "\n",
        "These are documented fully in the `autolens_workspace/*/guides/data_structure.ipynb` guide.\n",
        "\n",
        "__Other Models__\n",
        "\n",
        "This tutorial does not use a pixelized source reconstruction or linear light profiles, which have their own dediciated\n",
        "functionality that interfacts with the `FitImaging` object.\n",
        "\n",
        "These are described in the dedicated example scripts `results/examples/linear.py` and `results/examples/pixelizaiton.py`.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `results/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__\n",
        "\n",
        "The code below performs a model-fit using Nautilus. \n",
        "\n",
        "You should be familiar with modeling already, if not read the `modeling/start_here.py` script before reading this one!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"lens_sersic\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "model = af.Collection(\n",
        "    galaxies=af.Collection(\n",
        "        lens=af.Model(\n",
        "            al.Galaxy, redshift=0.5, bulge=al.lp.Sersic, mass=al.mp.Isothermal\n",
        "        ),\n",
        "        source=af.Model(al.Galaxy, redshift=1.0, bulge=al.lp.Sersic),\n",
        "    ),\n",
        ")\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"imaging\", \"modeling\"),\n",
        "    name=\"light[bulge]_mass[sie]_source[bulge]\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisImaging(dataset=dataset)\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Max Likelihood Fit__\n",
        "\n",
        "As seen elsewhere in the workspace, the result contains a `max_log_likelihood_fit` which we can visualize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit = result.max_log_likelihood_fit\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit Quantities__\n",
        "\n",
        "The maximum log likelihood fit contains many 1D and 2D arrays showing the fit.\n",
        "\n",
        "There is a `model_image`, which is the image-plane image of the tracer we inspected in the previous tutorial\n",
        "blurred with the imaging data's PSF. \n",
        "\n",
        "This is the image that is fitted to the data in order to compute the log likelihood and therefore quantify the \n",
        "goodness-of-fit.\n",
        "\n",
        "If you are unclear on what `slim` means, refer to the section `Data Structure` at the top of this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.model_image.slim)\n",
        "\n",
        "# The native property provides quantities in 2D NumPy Arrays.\n",
        "print(fit.model_image.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are numerous ndarrays showing the goodness of fit: \n",
        "\n",
        " - `residual_map`: Residuals = (Data - Model_Data).\n",
        " - `normalized_residual_map`: Normalized_Residual = (Data - Model_Data) / Noise\n",
        " - `chi_squared_map`: Chi_Squared = ((Residuals) / (Noise)) ** 2.0 = ((Data - Model)**2.0)/(Variances)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.residual_map.slim)\n",
        "print(fit.normalized_residual_map.slim)\n",
        "print(fit.chi_squared_map.slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Figures of Merit__\n",
        "\n",
        "There are single valued floats which quantify the goodness of fit:\n",
        "\n",
        " - `chi_squared`: The sum of the `chi_squared_map`.\n",
        " \n",
        " - `noise_normalization`: The normalizing noise term in the likelihood function \n",
        "    where [Noise_Term] = sum(log(2*pi*[Noise]**2.0)).\n",
        "\n",
        " - `log_likelihood`: The log likelihood value of the fit where [LogLikelihood] = -0.5*[Chi_Squared_Term + Noise_Term]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.chi_squared)\n",
        "print(fit.noise_normalization)\n",
        "print(fit.log_likelihood)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Plane Quantities__\n",
        "\n",
        "The `FitImaging` object has specific quantities which break down each image of each plane:\n",
        "\n",
        " - `model_images_of_planes_list`: Model-images of each individual plane, which in this example is a model image of the \n",
        " lens galaxy and model image of the lensed source galaxy. Both images are convolved with the imaging's PSF.\n",
        " \n",
        " - `subtracted_images_of_planes_list`: Subtracted images of each individual plane, which are the data's image with\n",
        "   all other plane's model-images subtracted. For example, the first subtracted image has the source galaxy's model image\n",
        "   subtracted and therefore is of only the lens galaxy's emission. The second subtracted image is of the lensed source,\n",
        "   with the lens galaxy's light removed.\n",
        " \n",
        "For multi-plane lens systems these lists will be extended to provide information on every individual plane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.model_images_of_planes_list[0].slim)\n",
        "print(fit.model_images_of_planes_list[1].slim)\n",
        "\n",
        "print(fit.subtracted_images_of_planes_list[0].slim)\n",
        "print(fit.subtracted_images_of_planes_list[1].slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Unmasked Quantities__\n",
        "\n",
        "All of the quantities above are computed using the mask which was used to fit the data.\n",
        "\n",
        "The `FitImaging` can also compute the unmasked blurred image of each plane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit.unmasked_blurred_image.native)\n",
        "print(fit.unmasked_blurred_image_of_planes_list[0].native)\n",
        "print(fit.unmasked_blurred_image_of_planes_list[1].native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "We can use the `Mask2D` object to mask regions of one of the fit's maps and estimate quantities of it.\n",
        "\n",
        "Below, we estimate the average absolute normalized residuals within a 1.0\" circular mask, which would inform us of\n",
        "how accurate the lens light subtraction of a model fit is and if it leaves any significant residuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=fit.dataset.shape_native,\n",
        "    pixel_scales=fit.dataset.pixel_scales,\n",
        "    radius=1.0,\n",
        ")\n",
        "\n",
        "normalized_residuals = fit.normalized_residual_map.apply_mask(mask=mask)\n",
        "\n",
        "print(np.mean(np.abs(normalized_residuals.slim)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixel Counting__\n",
        "\n",
        "An alternative way to quantify residuals like the lens light residuals is pixel counting. For example, we could sum\n",
        "up the number of pixels whose chi-squared values are above 10 which indicates a poor fit to the data.\n",
        "\n",
        "Whereas computing the mean above the average level of residuals, pixel counting informs us how spatially large the\n",
        "residuals extend. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=fit.dataset.shape_native,\n",
        "    pixel_scales=fit.dataset.pixel_scales,\n",
        "    radius=1.0,\n",
        ")\n",
        "\n",
        "chi_squared_map = fit.chi_squared_map.apply_mask(mask=mask)\n",
        "\n",
        "print(np.sum(chi_squared_map > 10.0))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Outputting Results__\n",
        "\n",
        "You may wish to output certain results to .fits files for later inspection. \n",
        "\n",
        "For example, one could output the lens light subtracted image of the lensed source galaxy to a .fits file such that\n",
        "we could fit this source-only image again with an independent pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_subtracted_image_2d = fit.subtracted_images_of_planes_list[1]\n",
        "lens_subtracted_image_2d.output_to_fits(\n",
        "    file_path=path.join(dataset_path, \"lens_subtracted_data.fits\"), overwrite=True\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Refitting__\n",
        "\n",
        "Using the API introduced in the first tutorial, we can also refit the data locally. \n",
        "\n",
        "This allows us to inspect how the fit changes for models with similar log likelihoods. Below, we refit and plot\n",
        "the fit of the 100th last accepted model by Nautilus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "samples = result.samples\n",
        "\n",
        "instance = samples.from_sample_index(sample_index=-10)\n",
        "\n",
        "tracer = al.Tracer(galaxies=instance.galaxies)\n",
        "\n",
        "fit = al.FitImaging(dataset=dataset, tracer=tracer)\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Wrap Up__\n",
        "\n",
        "In this tutorial, we saw how to inspect the quality of a model fit using the fit imaging object.\n",
        "\n",
        "If you are modeling strong lenses using interferometer data or a point-source dataset, we cover the\n",
        "corresponding fit objects in tutorials 6 and 7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}