{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results: Pixelization\n",
        "=====================\n",
        "\n",
        "This tutorial illustrates how to analyse the results of lens modeling where the source is modeled using an\n",
        "`Inversion` and therefore has a pixelized source reconstruction we may be interested in inspecting.\n",
        "\n",
        "This includes examples of how to output the source reconstruction to .fits files, so that a more detailed analysis\n",
        "can be performed enabling source science studies.\n",
        "\n",
        "This tutorial focuses on explaining how to use the inferred inversion to compute results as numpy arrays and only\n",
        "briefly discusses visualization.\n",
        "\n",
        "__Plot Module__\n",
        "\n",
        "This example uses the **PyAutoLens** plot module to plot the results, including `Plotter` objects that make\n",
        "the figures and `MatPlot` objects that wrap matplotlib to customize the figures.\n",
        "\n",
        "The visualization API is straightforward but is explained in the `autolens_workspace/*/plot` package in full.\n",
        "This includes detailed guides on how to customize every aspect of the figures, which can easily be combined with the\n",
        "code outlined in this tutorial.\n",
        "\n",
        "__Units__\n",
        "\n",
        "In this example, all quantities are **PyAutoLens**'s internal unit coordinates, with spatial coordinates in\n",
        "arc seconds, luminosities in electrons per second and mass quantities (e.g. convergence) are dimensionless.\n",
        "\n",
        "The results example `units_and_cosmology.ipynb` illustrates how to convert these quantities to physical units like\n",
        "kiloparsecs, magnitudes and solar masses.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `results/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__\n",
        "\n",
        "The code below (which we have omitted comments from for brevity) performs a lens model-fit using Nautilus. You should\n",
        "be familiar enough with lens modeling to understand this, if not you should go over the beginner model-fit script again!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "positions = al.Grid2DIrregular.from_json(\n",
        "    file_path=path.join(dataset_path, \"positions.json\")\n",
        ")\n",
        "\n",
        "lens = af.Model(\n",
        "    al.Galaxy, redshift=0.5, mass=al.mp.Isothermal, shear=al.mp.ExternalShear\n",
        ")\n",
        "\n",
        "pixelization = af.Model(\n",
        "    al.Pixelization,\n",
        "    image_mesh=al.image_mesh.Overlay(shape=(30, 30)),\n",
        "    mesh=al.mesh.Delaunay(),\n",
        "    regularization=al.reg.Constant,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))\n",
        "\n",
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"imaging\", \"modeling\"),\n",
        "    name=\"mass[sie]_source[pix]\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=1,\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    positions_likelihood=al.PositionsLHPenalty(positions=positions, threshold=0.5),\n",
        ")\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Max Likelihood Inversion__\n",
        "\n",
        "As seen elsewhere in the workspace, the result contains a `max_log_likelihood_fit`, which contains the\n",
        "`Inversion` object we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion = result.max_log_likelihood_fit.inversion\n",
        "\n",
        "inversion_plotter = aplt.InversionPlotter(inversion=inversion)\n",
        "inversion_plotter.figures_2d(reconstructed_image=True)\n",
        "inversion_plotter.figures_2d_of_pixelization(pixelization_index=0, reconstruction=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Linear Objects__\n",
        "\n",
        "An `Inversion` contains all of the linear objects used to reconstruct the data in its `linear_obj_list`. \n",
        "\n",
        "This list may include the following objects:\n",
        "\n",
        " - `LightProfileLinearObjFuncList`: This object contains lists of linear light profiles and the functionality used\n",
        " by them to reconstruct data in an inversion. For example it may only contain a list with a single light profile\n",
        " (e.g. `lp_linear.Sersic`) or many light profiles combined in a `Basis` (e.g. `lp_basis.Basis`).\n",
        "\n",
        "- `Mapper`: The linear objected used by a `Pixelization` to reconstruct data via an `Inversion`, where the `Mapper` \n",
        "is specific to the `Pixelization`'s `Mesh` (e.g. a `RectnagularMapper` is used for a `Delaunay` mesh).\n",
        "\n",
        "In this example, the only linear object used to fit the data was a `Pixelization`, thus the `linear_obj_list`\n",
        "contains just one entry corresponding to a `Mapper`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.linear_obj_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To extract results from an inversion many quantities will come in lists or require that we specific the linear object\n",
        "we with to use. \n",
        "\n",
        "Thus, knowing what linear objects are contained in the `linear_obj_list` and what indexes they correspond to\n",
        "is important."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Delaunay Mapper = {inversion.linear_obj_list[0]}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Grids__\n",
        "\n",
        "The role of a mapper is to map between the image-plane and source-plane. \n",
        "\n",
        "This includes mapping grids corresponding to the data grid (e.g. the centers of each image-pixel in the image and\n",
        "source plane) and the pixelization grid (e.g. the centre of the Delaunay triangulation in the image-plane and \n",
        "source-plane).\n",
        "\n",
        "All grids are available in a mapper via its `mapper_grids` property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper = inversion.linear_obj_list[0]\n",
        "\n",
        "# Centre of each masked image pixel in the image-plane.\n",
        "print(mapper.mapper_grids.image_plane_data_grid)\n",
        "\n",
        "# Centre of each source pixel in the source-plane.\n",
        "print(mapper.mapper_grids.source_plane_data_grid)\n",
        "\n",
        "# Centre of each pixelization pixel in the image-plane (the `Overlay` image_mesh computes these in the image-plane\n",
        "# and maps to the source-plane).\n",
        "print(mapper.mapper_grids.image_plane_mesh_grid)\n",
        "\n",
        "# Centre of each pixelization pixel in the source-plane.\n",
        "print(mapper.mapper_grids.source_plane_mesh_grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Interpolated Source__\n",
        "\n",
        "The pixelized source reconstruction used by an `Inversion` is often on an irregular grid (e.g. a Delaunay triangulation\n",
        "or Voronoi mesh), making it difficult to manipulate and inspect after the lens modeling has completed (although we show \n",
        "how to do this below).\n",
        "\n",
        "A simpler way to inspect the source reconstruction is to interpolate the reconstruction values from the irregular\n",
        "pixelization (e.g. a Delaunay triangulation or Voronoi mesh) to a uniform 2D grid of pixels.\n",
        "\n",
        "(if you do not know what the `slim` and `native` properties below refer too, check back to tutorial 2 of the results\n",
        "for a description).\n",
        "\n",
        "Inversions can have multiple source reconstructions (e.g. double Einstein ring strong lenses) thus the majority of\n",
        "quantities are returned as a list. It is likely you are only using one `Inversion` to reconstruction one source galaxy,\n",
        "so these lists will likely contain only one entry\n",
        "\n",
        "We interpolate the Delaunay triangulation this source is reconstructed on to a 2D grid of 401 x 401 square pixels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "interpolated_reconstruction_list = inversion.interpolated_reconstruction_list_from(\n",
        "    shape_native=(401, 401)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are unclear on what `slim` means, refer to the section `Data Structure` at the top of this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(interpolated_reconstruction_list[0].slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can alternatively input the arc-second `extent` of the source reconstruction we want, which will not use square \n",
        "pixels unless symmetric y and x arc-second extents are input.\n",
        "\n",
        "The extent is input via the notation (xmin, xmax, ymin, ymax), therefore unlike most of the **PyAutoLens** API it\n",
        "does not follow the (y,x) convention. This will be updated in a future version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "interpolated_reconstruction_list = inversion.interpolated_reconstruction_list_from(\n",
        "    shape_native=(401, 401), extent=(-1.0, 1.0, -1.0, 1.0)\n",
        ")\n",
        "\n",
        "print(interpolated_reconstruction_list[0].slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The interpolated errors on the source reconstruction can also be computed, in case you are planning to perform \n",
        "model-fitting of the source reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "interpolated_errors_list = inversion.interpolated_errors_list_from(\n",
        "    shape_native=(401, 401), extent=(-1.0, 1.0, -1.0, 1.0)\n",
        ")\n",
        "\n",
        "print(interpolated_errors_list[0].slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction__\n",
        "\n",
        "The source reconstruction is also available as a 1D numpy array of values representative of the source pixelization\n",
        "itself (in this example, the reconstructed source values at the vertexes of each Delaunay triangle)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.reconstruction)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The (y,x) grid of coordinates associated with these values is given by the `Inversion`'s `Mapper` (which are \n",
        "described in chapter 4 of **HowToLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper = inversion.linear_obj_list[0]\n",
        "print(mapper.source_plane_mesh_grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mapper also contains the (y,x) grid of coordinates that correspond to the ray-traced image sub-pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(mapper.source_plane_data_grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapped Reconstructed Images__\n",
        "\n",
        "The source reconstruction(s) are mapped to the image-plane in order to fit the lens model.\n",
        "\n",
        "These mapped reconstructed images are also accessible via the `Inversion`. \n",
        "\n",
        "Note that any parametric light profiles in the lens model (e.g. the `bulge` and `disk` of a lens galaxy) are not \n",
        "included in this image -- it only contains the source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.mapped_reconstructed_image.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapped To Source__\n",
        "\n",
        "Mapping can also go in the opposite direction, whereby we input an image-plane masked 2D array and we use \n",
        "the `Inversion` to map these values to the source-plane.\n",
        "\n",
        "This creates an array which is analogous to the `reconstruction` in that the values are on the source-plane \n",
        "pixelization grid, however it bypass the linear algebra and inversion altogether and simply computes the sum of values \n",
        "mapped to each source pixel.\n",
        "\n",
        "[CURRENTLY DOES NOT WORK, BECAUSE THE MAPPING FUNCTION NEEDS TO INCORPORATE THE VARYING VORONOI PIXEL AREA]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_list = inversion.cls_list_from(cls=al.AbstractMapper)\n",
        "\n",
        "image_to_source = mapper_list[0].mapped_to_source_from(array=dataset.data)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper_list[0])\n",
        "mapper_plotter.plot_source_from(pixel_values=image_to_source)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can create a source-plane magnification map by passed the image-plane magnification map computed via the\n",
        "tracer.\n",
        "\n",
        "[CURRENTLY DOES NOT WORK, BECAUSE THE MAPPING FUNCTION NEEDS TO INCORPORATE THE VARYING VORONOI PIXEL AREA]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = result.max_log_likelihood_tracer\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(tracer=tracer, grid=dataset.grid_pixelization)\n",
        "tracer_plotter.figures_2d(magnification=True)\n",
        "\n",
        "magnification_2d = tracer.magnification_2d_from(grid=dataset.grid_pixelization)\n",
        "\n",
        "magnification_to_source = mapper_list[0].mapped_to_source_from(array=magnification_2d)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper_list[0])\n",
        "mapper_plotter.plot_source_from(pixel_values=magnification_2d)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can interpolate these arrays to output them to fits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# %%\n",
        "'''\n",
        "Although the model-fit used a Voronoi mesh, there is no reason we need to use this pixelization to map the image-plane\n",
        "data onto a source-plane array.\n",
        "\n",
        "We can instead map the image-data onto a rectangular pixelization, which has the nice property of giving us a\n",
        "regular 2D array of data which could be output to .fits format.\n",
        "\n",
        "[NOT CLEAR IF THIS WORKS YET, IT IS UNTESTED!].\n",
        "'''"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh = al.mesh.Rectangular(shape=(50, 50))\n",
        "\n",
        "mapper_grids = mesh.mapper_grids_from(source_plane_data_grid=dataset.grid)\n",
        "\n",
        "mapper = al.Mapper(mapper_grids=mapper_grids, regularization=None)\n",
        "\n",
        "image_to_source = mapper.mapped_to_source_from(array=dataset.data)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "mapper_plotter.plot_source_from(pixel_values=image_to_source)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Magnification__\n",
        "\n",
        "The inversion includes the magnification of the lens model, which is computed as the sum of flux\n",
        "in every image-plane image pixel divided by the sum of flux values in every source-plane source pixel.\n",
        "\n",
        "[INSERT CODE HERE]\n",
        "\n",
        "__Linear Algebra Matrices (Advanced)__\n",
        "\n",
        "To perform an `Inversion` a number of matrices are constructed which use linear algebra to perform the reconstruction.\n",
        "\n",
        "These are accessible in the inversion object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.curvature_matrix)\n",
        "print(inversion.regularization_matrix)\n",
        "print(inversion.curvature_reg_matrix)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Evidence Terms (Advanced)__\n",
        "\n",
        "In **HowToLens** and the papers below, we cover how an `Inversion` uses a Bayesian evidence to quantify the goodness\n",
        "of fit:\n",
        "\n",
        "https://arxiv.org/abs/1708.07377\n",
        "https://arxiv.org/abs/astro-ph/0601493\n",
        "\n",
        "This evidence balances solutions which fit the data accurately, without using an overly complex regularization source.\n",
        "\n",
        "The individual terms of the evidence and accessed via the following properties:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.regularization_term)\n",
        "print(inversion.log_det_regularization_matrix_term)\n",
        "print(inversion.log_det_curvature_reg_matrix_term)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Future Ideas / Contributions__\n",
        "\n",
        "Here are a list of things I would like to add to this tutorial but haven't found the time. If you are interested\n",
        "in having a go at adding them contact me on SLACK! :)\n",
        "\n",
        "- More \n",
        "- Source gradient calculations.\n",
        "- A calculation which shows differential lensing effects (e.g. magnification across the source plane)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}