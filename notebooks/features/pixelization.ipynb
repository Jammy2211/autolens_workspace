{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling Features: Pixelization\n",
        "===============================\n",
        "\n",
        "A pixelization reconstructs the source's light using a pixel-grid, which is regularized using a prior that forces\n",
        "the solution to have a degree of smoothness.\n",
        "\n",
        "This script fits a source galaxy model which uses a pixelization to reconstruct the source's light. \n",
        "\n",
        "A Voronoi mesh and constant regularization scheme are used, which are the simplest forms of mesh and regularization\n",
        "with provide computationally fast and accurate solutions in **PyAutoLens**.\n",
        "\n",
        "For simplicity, the lens galaxy's light is omitted from the model and is not present in the simulated data. It is\n",
        "straightforward to include the lens galaxy's light in the model.\n",
        "\n",
        "Pixelizations are covered in detail in chapter 4 of the **HowToLens** lectures.\n",
        "\n",
        "__Contents__\n",
        "\n",
        "**Advantages & Disadvantages:** Benefits and drawbacks of using an MGE.\n",
        "**Positive Only Solver:** How a positive solution to the light profile intensities is ensured.\n",
        "**Chaining:** How the advanced modeling feature, non-linear search chaining, can significantly improve lens modeling with pixelizaitons.\n",
        "**Dataset & Mask:** Standard set up of imaging dataset that is fitted.\n",
        "**Pixelization:** How to create a pixelization, including a description of its inputs.\n",
        "**Fit:** Perform a fit to a dataset using a pixelization, and visualize its results.\n",
        "**Model:** Composing a model using a pixelization and how it changes the number of free parameters.\n",
        "**Search & Analysis:** Standard set up of non-linear search and analysis.\n",
        "**Positions Likelihood:** Removing unphysical pixelized source solutions using a likelihood penalty using the lensed multiple images.\n",
        "**Run Time:** Profiling of pixelization run times and discussion of how they compare to standard light profiles.\n",
        "**Model-Fit:** Performs the model fit using standard API.\n",
        "**Result:** Pixelization results and visualizaiton.\n",
        "**Interpolated Source:** Interpolate the source reconstruction from an irregular Voronoi mesh to a uniform square grid and output to a .fits file.\n",
        "**Voronoi:** Using a Voronoi mesh pixelizaiton (instead of Voronoi), which provides better results but requires installing an external library.\n",
        "**Result (Advanced):** API for various pixelization outputs (magnifications, mappings) which requires some polishing.\n",
        "\n",
        "__Advantages__\n",
        "\n",
        "Many strongly lensed source galaxies are complex, and have asymmetric and irregular morphologies. These morphologies\n",
        "cannot be well approximated by a parametric light profiles like a Sersic, or many Sersics, and thus a pixelization\n",
        "is required to reconstruct the source's irregular light.\n",
        "\n",
        "Even basis functions like shapelets or a multi-Gaussian expansion cannot reconstruct a source-plane accurately\n",
        "if there are multiple source galaxies, or if the source galaxy has a very complex morphology.\n",
        "\n",
        "To infer detailed components of a lens mass model (e.g. its density slope, whether there's a dark matter subhalo, etc.)\n",
        "then pixelized source models are required, to ensure the mass model is fitting all of the lensed source light.\n",
        "\n",
        "There are also many science cases where one wants to study the highly magnified light of the source galaxy in detail,\n",
        "to learnt about distant and faint galaxies. A pixelization reconstructs the source's unlensed emission and thus\n",
        "enables this.\n",
        "\n",
        "__Disadvantages__\n",
        "\n",
        "Pixelizations are computationally slow and run times are typically longer than a parametric source model. It is not\n",
        "uncommon for lens models using a pixelization to take hours or even days to fit high resolution imaging\n",
        "data (e.g. Hubble Space Telescope imaging).\n",
        "\n",
        "Lens modeling with pixelizations is also more complex than parametric source models, with there being more things\n",
        "that can go wrong. For example, there are solutions where a demagnified version of the lensed source galaxy is\n",
        "reconstructed, using a mass model which effectively has no mass or too much mass. These are described in detail below.\n",
        "\n",
        "It will take you longer to learn how to successfully fit lens models with a pixelization than other methods illustrated\n",
        "in the workspace!\n",
        "\n",
        "__Positive Only Solver__\n",
        "\n",
        "Many codes which use linear algebra typically rely on a linear algabra solver which allows for positive and negative\n",
        "values of the solution (e.g. `np.linalg.solve`), because they are computationally fast.\n",
        "\n",
        "This is problematic, as it means that negative surface brightnesses values can be computed to represent a galaxy's\n",
        "light, which is clearly unphysical. For a pixelizaiton, this often produces negative source pixels which over-fit\n",
        "the data, producing unphysical solutions.\n",
        "\n",
        "All pixelized source reconstructions use a positive-only solver, meaning that every source-pixel is only allowed\n",
        "to reconstruct positive flux values. This ensures that the source reconstruction is physical and that we don't\n",
        "reconstruct negative flux values that don't exist in the real source galaxy (a common systematic solution in lens\n",
        "analysis).\n",
        "\n",
        "It may be surprising to hear that this is a feature worth pointing out, but it turns out setting up the linear algebra\n",
        "to enforce positive reconstructions is difficult to make efficient. A lot of development time went into making this\n",
        "possible, where a bespoke fast non-negative linear solver was developed to achieve this.\n",
        "\n",
        "Other methods in the literature often do not use a positive only solver, and therefore suffer from these\n",
        "unphysical solutions, which can degrade the results of lens model in general.\n",
        "\n",
        "__Chaining__\n",
        "\n",
        "Due to the complexity of fitting with a pixelization, it is often best to use **PyAutoLens**'s non-linear chaining\n",
        "feature to compose a pipeline which begins by fitting a simpler model using a parametric source.\n",
        "\n",
        "More information on chaining is provided in the `autolens_workspace/notebooks/imaging/advanced/chaining` folder,\n",
        "chapter 3 of the **HowToLens** lectures.\n",
        "\n",
        "The script `autolens_workspace/scripts/imaging/advanced/chaining/parametric_to_pixelization.py` explitly uses chaining\n",
        "to link a lens model using a light profile source to one which then uses a pixelization.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits an `Imaging` dataset of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's light is omitted (and is not present in the simulated data).\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's surface-brightness is reconstructed using a `Voronoi` mesh, `Overlay` image-mesh\n",
        "   and `ConstantSplit` regularization scheme.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from os import path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the strong lens dataset `simple__no_lens_light` via .fits files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=dataset.pixel_scales, radius=3.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixelization__\n",
        "\n",
        "We create a `Pixelization` object to perform the pixelized source reconstruction, which is made up of three\n",
        "components:\n",
        "\n",
        "- `image_mesh:`The coordinates of the mesh used for the pixelization need to be defined. The way this is performed\n",
        "depends on pixelization used. In this example, we define the source pixel centers by overlaying a uniform regular grid\n",
        "in the image-plane and ray-tracing these coordinates to the source-plane. Where they land then make up the coordinates\n",
        "used by the mesh.\n",
        "\n",
        "- `mesh:` Different types of mesh can be used to perform the source reconstruction, where the mesh changes the\n",
        "details of how the source is reconstructed (e.g. interpolation weights). In this exmaple, we use a `Voronoi` mesh,\n",
        "where the centres computed via the `image_mesh` are the vertexes of every `Voronoi` triangle.\n",
        "\n",
        "- `regularization:` A pixelization uses many pixels to reconstructed the source, which will often lead to over fitting\n",
        "of the noise in the data and an unrealistically complex and strucutred source. Regularization smooths the source\n",
        "reconstruction solution by penalizing solutions where neighboring pixels (Voronoi triangles in this example) have\n",
        "large flux differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_mesh = al.image_mesh.Overlay(shape=(30, 30))\n",
        "mesh = al.mesh.Delaunay()\n",
        "regularization = al.reg.ConstantSplit(coefficient=1.0)\n",
        "\n",
        "pixelization = al.Pixelization(\n",
        "    image_mesh=image_mesh, mesh=mesh, regularization=regularization\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "This is to illustrate the API for performing a fit via a pixelization using standard autolens objects like \n",
        "the `Galaxy`, `Tracer` and `FitImaging` \n",
        "\n",
        "We simply create a `Pixelization` and pass it to the source galaxy, which then gets input into the tracer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.0, 0.0),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        "    shear=al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05),\n",
        ")\n",
        "\n",
        "source = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens, source])\n",
        "\n",
        "fit = al.FitImaging(dataset=dataset, tracer=tracer)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting the fit, we see that the pixelized source does a good job at capturing the appearance of the source galaxy\n",
        "and fitting the data to roughly the noise level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pixelizations have bespoke visualizations which show more details about the source-reconstruction, image-mesh\n",
        "and other quantities.\n",
        "\n",
        "These plots use an `InversionPlotter`, which gets its name from the internals of how pixelizations are performed in\n",
        "the source code, where the linear algebra process which computes the source pixel fluxes is called an inversion.\n",
        "\n",
        "The `subplot_mappings` overlays colored circles in the image and source planes that map to one another, thereby\n",
        "allowing one to assess how the mass model ray-traces image-pixels and therefore to assess how the source reconstruction\n",
        "maps to the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion_plotter = fit_plotter.inversion_plotter_of_plane(plane_index=1)\n",
        "inversion_plotter.subplot_of_mapper(mapper_index=0)\n",
        "inversion_plotter.subplot_mappings(pixelization_index=0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our lens model using `Model` objects, which represent the galaxies we fit to our data.  In this \n",
        "example fits a lens model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear` [7 parameters].\n",
        " \n",
        " - The source-galaxy's light uses a `Voronoi` mesh [0 parameters].\n",
        " \n",
        " - The mesh centres of the `Voronoi` mesh are computed using a `Overlay` image-mesh, with a fixed resolution of \n",
        "   30 x 30 pixels [0 parameters].\n",
        " \n",
        " - This pixelization is regularized using a `ConstantSplit` scheme which smooths every source pixel equally [1 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=6. \n",
        " \n",
        "It is worth noting the `Pixelization`  use significantly fewer parameters (1 parameter) than \n",
        "fitting the source using `LightProfile`'s (7+ parameters). \n",
        "\n",
        "The lens model therefore includes a mesh and regularization scheme, which are used together to create the \n",
        "pixelization. \n",
        "\n",
        "__Model Cookbook__\n",
        "\n",
        "A full description of model composition is provided by the model cookbook: \n",
        "\n",
        "https://pyautolens.readthedocs.io/en/latest/general/model_cookbook.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.PowerLaw)\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=mass, shear=shear)\n",
        "\n",
        "# Source:\n",
        "\n",
        "image_mesh = af.Model(al.image_mesh.Overlay)\n",
        "image_mesh.shape = (30, 30)\n",
        "\n",
        "mesh = af.Model(al.mesh.Delaunay)\n",
        "\n",
        "regularization = af.Model(al.reg.ConstantSplit)\n",
        "\n",
        "pixelization = af.Model(\n",
        "    al.Pixelization, image_mesh=image_mesh, mesh=mesh, regularization=regularization\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format (if this does not display clearly on your screen refer to\n",
        "`start_here.ipynb` for a description of how to fix this).\n",
        "\n",
        "This confirms that the source galaxy's has a mesh and regularization scheme, which are combined into a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using the nested sampling algorithm Nautilus (see `start.here.py` for a \n",
        "full description)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=path.join(\"imaging\", \"modeling\"),\n",
        "    name=\"pixelization\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    number_of_cores=4,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Position Likelihood__\n",
        "\n",
        "We add a penalty term ot the likelihood function, which penalizes models where the brightest multiple images of\n",
        "the lensed source galaxy do not trace close to one another in the source plane. This removes \"demagnified source\n",
        "solutions\" from the source pixelization, which one is likely to infer without this penalty.\n",
        "\n",
        "A comprehensive description of why we do this is given at the following readthedocs page. I strongly recommend you \n",
        "read this page in full if you are not familiar with the positions likelihood penalty and demagnified source \n",
        "reconstructions:\n",
        "\n",
        " https://pyautolens.readthedocs.io/en/latest/general/demagnified_solutions.html\n",
        "\n",
        "__Brief Description__\n",
        "\n",
        "Unlike other example scripts, we also pass the `AnalysisImaging` object below a `PositionsLHPenalty` object, which\n",
        "includes the positions we loaded above, alongside a `threshold`.\n",
        "\n",
        "This is because `Inversion`'s suffer a bias whereby they fit unphysical lens models where the source galaxy is \n",
        "reconstructed as a demagnified version of the lensed source. \n",
        "\n",
        "To prevent these solutions biasing the model-fit we specify a `position_threshold` of 0.5\", which requires that a \n",
        "mass model traces the four (y,x) coordinates specified by our positions (that correspond to the brightest regions of the \n",
        "lensed source) within 0.5\" of one another in the source-plane. If this criteria is not met, a large penalty term is\n",
        "added to likelihood that massively reduces the overall likelihood. This penalty is larger if the ``positions``\n",
        "trace further from one another.\n",
        "\n",
        "This ensures the unphysical solutions that bias a pixelization have a lower likelihood that the physical solutions\n",
        "we desire. Furthermore, the penalty term reduces as the image-plane multiple image positions trace closer in the \n",
        "source-plane, ensuring Nautilus converges towards an accurate mass model. It does this very fast, as \n",
        "ray-tracing just a few multiple image positions is computationally cheap. \n",
        "\n",
        "The threshold of 0.3\" is large. For an accurate lens model we would anticipate the positions trace within < 0.01\" of\n",
        "one another. The high threshold ensures only the initial mass models at the start of the fit are resampled.\n",
        "\n",
        "Position thresholding is described in more detail in the \n",
        "script `autolens_workspace/*/modeling/imaging/customize/positions.py`\n",
        "\n",
        "The arc-second positions of the multiply imaged lensed source galaxy were drawn onto the\n",
        "image via the GUI described in the file `autolens_workspace/*/data_preparation/imaging/gui/positions.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = al.Grid2DIrregular(\n",
        "    al.from_json(file_path=path.join(dataset_path, \"positions.json\"))\n",
        ")\n",
        "positions_likelihood = al.PositionsLHPenalty(positions=positions, threshold=0.3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the `AnalysisImaging` object defining how the via Nautilus the model is fitted to the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset,\n",
        "    positions_likelihood=positions_likelihood,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "The run time of a pixelization is longer than many other features, with the estimate below coming out at around ~0.5 \n",
        "seconds per likelihood evaluation. This is because the fit has a lot of linear algebra to perform in order to\n",
        "reconstruct the source on the pixel-grid.\n",
        "\n",
        "Nevertheless, this is still fast enough for most use-cases. If run-time is an issue, the following factors determine\n",
        "the run-time of a a pixelization and can be changed to speed it up (at the expense of accuracy):\n",
        "\n",
        " - The number of unmasked pixels in the image data. By making the mask smaller (e.g. using an annular mask), the \n",
        "   run-time will decrease.\n",
        " \n",
        " - The number of source pixels in the pixelization. By reducing the `shape` from (30, 30) the run-time will decrease.\n",
        "\n",
        "This also serves to highlight why the positions threshold likelihood is so powerful. The likelihood evaluation time\n",
        "of this step is below 0.001 seconds, meaning that the initial parameter space sampling is extremely efficient even\n",
        "for a pixelization (this is not accounted for in the run-time estimate below)!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "run_time_dict, info_dict = analysis.profile_log_likelihood_function(\n",
        "    instance=model.random_instance()\n",
        ")\n",
        "\n",
        "print(f\"Log Likelihood Evaluation Time (second) = {run_time_dict['fit_time']}\")\n",
        "print(\n",
        "    \"Estimated Run Time Upper Limit (seconds) = \",\n",
        "    (run_time_dict[\"fit_time\"] * model.total_free_parameters * 10000)\n",
        "    / search.number_of_cores,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format (if this \n",
        "does not display clearly on your screen refer to `start_here.ipynb` for a description of how to fix this):\n",
        "\n",
        "This confirms that the source galaxy's has a mesh and regularization scheme, which are combined into a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the maximum likelihood fit, tracer images and posteriors inferred via Nautilus.\n",
        "\n",
        "The end of this example provides a detailed description of all result options for a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=result.grids.uniform\n",
        ")\n",
        "tracer_plotter.subplot_tracer()\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "plotter = aplt.NestPlotter(samples=result.samples)\n",
        "plotter.corner_anesthetic()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask Extra Galaxies__\n",
        "\n",
        "There may be extra galaxies nearby the lens and source galaxies, whose emission blends with the lens and source.\n",
        "\n",
        "If their emission is significant, and close enough to the lens and source, we may simply remove it from the data\n",
        "to ensure it does not impact the model-fit. A standard masking approach would be to remove the image pixels containing\n",
        "the emission of these galaxies altogether. This is analogous to what the circular masks used throughout the examples \n",
        "does.\n",
        "\n",
        "For fits using a pixelization, masking regions of the image in a way that removes their image pixels entirely from \n",
        "the fit. This can produce discontinuities in the pixelixation used to reconstruct the source and produce unexpected \n",
        "systematics and unsatisfactory results. In this case, applying the mask in a way where the image pixels are not \n",
        "removed from the fit, but their data and noise-map values are scaled such that they contribute negligibly to the fit, \n",
        "is a better approach. \n",
        "\n",
        "We illustrate the API for doing this below, using the `extra_galaxies` dataset which has extra galaxies whose emission\n",
        "needs to be removed via scaling in this way. We apply the scaling and show the subplot imaging where the extra \n",
        "galaxies mask has scaled the data values to zeros, increasing the noise-map values to large values and in turn made \n",
        "the signal to noise of its pixels effectively zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"extra_galaxies\"\n",
        "dataset_path = path.join(\"dataset\", \"imaging\", dataset_name)\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=path.join(dataset_path, \"data.fits\"),\n",
        "    psf_path=path.join(dataset_path, \"psf.fits\"),\n",
        "    noise_map_path=path.join(dataset_path, \"noise_map.fits\"),\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask_extra_galaxies = al.Mask2D.from_fits(\n",
        "    file_path=path.join(dataset_path, \"mask_extra_galaxies.fits\"),\n",
        "    pixel_scales=0.1,\n",
        "    invert=True,  # Note that we invert the mask here as `True` means a pixel is scaled.\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_noise_scaling(mask=mask_extra_galaxies)\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=0.1, centre=(0.0, 0.0), radius=6.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do not explictly fit this data, for the sake of brevity, however if your data has these nearby galaxies you should\n",
        "apply the mask as above before fitting the data.\n",
        "\n",
        "__Pixelization / Mapper Calculations__\n",
        "\n",
        "The pixelized source reconstruction output by an `Inversion` is often on an irregular grid (e.g. a \n",
        "Voronoi triangulation or Voronoi mesh), making it difficult to manipulate and inspect after the lens modeling has \n",
        "completed.\n",
        "\n",
        "Internally, the inversion stores a `Mapper` object to perform these calculations, which effectively maps pixels\n",
        "between the image-plane and source-plane. \n",
        "\n",
        "After an inversion is complete, it has computed values which can be paired with the `Mapper` to perform calculations,\n",
        "most notably the `reconstruction`, which is the reconstructed source pixel values.\n",
        "\n",
        "By inputting the inversions's mapper and a set of values (e.g. the `reconstruction`) into a `MapperValued` object, we\n",
        "are provided with all the functionality we need to perform calculations on the source reconstruction.\n",
        "\n",
        "We set up the `MapperValued` object below, and illustrate how we can use it to interpolate the source reconstruction\n",
        "to a uniform grid of values, perform magnification calculations and other tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion = result.max_log_likelihood_fit.inversion\n",
        "mapper = inversion.cls_list_from(cls=al.AbstractMapper)[\n",
        "    0\n",
        "]  # Only one source-plane so only one mapper, would be a list if multiple source planes\n",
        "\n",
        "mapper_valued = al.MapperValued(\n",
        "    mapper=mapper, values=inversion.reconstruction_dict[mapper]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Interpolated Source__\n",
        "\n",
        "A simple way to inspect the source reconstruction is to interpolate its values from the irregular\n",
        "pixelization o a uniform 2D grid of pixels.\n",
        "\n",
        "(if you do not know what the `slim` and `native` properties below refer too, it \n",
        "is described in the `results/examples/data_structures.py` example.)\n",
        "\n",
        "We interpolate the Voronoi triangulation this source is reconstructed on to a 2D grid of 401 x 401 square pixels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "interpolated_reconstruction = mapper_valued.interpolated_array_from(\n",
        "    shape_native=(401, 401)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are unclear on what `slim` means, refer to the section `Data Structure` at the top of this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(interpolated_reconstruction.slim)\n",
        "\n",
        "plotter = aplt.Array2DPlotter(\n",
        "    array=interpolated_reconstruction,\n",
        ")\n",
        "plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By inputting the arc-second `extent` of the source reconstruction, the interpolated array will zoom in on only these \n",
        "regions of the source-plane. The extent is input via the notation (xmin, xmax, ymin, ymax), therefore  unlike the standard \n",
        "API it does not follow the (y,x) convention.\n",
        "\n",
        "Note that the output interpolated array will likely therefore be rectangular, with rectangular pixels, unless \n",
        "symmetric y and x arc-second extents are input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "interpolated_reconstruction = mapper_valued.interpolated_array_from(\n",
        "    shape_native=(401, 401), extent=(-1.0, 1.0, -1.0, 1.0)\n",
        ")\n",
        "\n",
        "print(interpolated_reconstruction.slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The interpolated errors on the source reconstruction can also be computed, in case you are planning to perform \n",
        "model-fitting of the source reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_valued_errors = al.MapperValued(\n",
        "    mapper=mapper, values=inversion.errors_dict[mapper]\n",
        ")\n",
        "\n",
        "interpolated_errors = mapper_valued_errors.interpolated_array_from(\n",
        "    shape_native=(401, 401), extent=(-1.0, 1.0, -1.0, 1.0)\n",
        ")\n",
        "\n",
        "print(interpolated_errors.slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Magnification__\n",
        "\n",
        "The magnification of the lens model and source reconstruction can also be computed via the `MapperValued` object,\n",
        "provided we pass it the reconstruction as the `values`.\n",
        "\n",
        "This magnification is the ratio of the surface brightness of image in the image-plane over the surface brightness \n",
        "of the source in the source-plane.\n",
        "\n",
        "In the image-plane, this is computed by mapping the reconstruction to the image, summing all reconstructed\n",
        "values and multiplying by the area of each image pixel. This image-plane image is not convolved with the\n",
        "PSF, as the source plane reconstruction is a non-convolved image.\n",
        "\n",
        "In the source-plane, this is computed by interpolating the reconstruction to a regular grid of pixels, for\n",
        "example a 2D grid of 401 x 401 pixels, and summing the reconstruction values multiplied by the area of each\n",
        "pixel. This calculation uses interpolation to compute the source-plane image.\n",
        "\n",
        "The calculation is relatively stable, but depends on subtle details like the resolution of the source-plane \n",
        "pixelization and how exactly the interpolation is performed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_valued = al.MapperValued(\n",
        "    mapper=mapper,\n",
        "    values=inversion.reconstruction_dict[mapper],\n",
        ")\n",
        "\n",
        "print(\"Magnification via Interpolation:\")\n",
        "print(mapper_valued.magnification_via_interpolation_from(shape_native=(401, 401)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The magnification calculated above used an interpolation of the source-plane reconstruction to a 2D grid of 401 x 401\n",
        "pixels. \n",
        "\n",
        "For a `Rectangular` or `Voronoi` pixelization, the magnification can also be computed using the source-plane mesh\n",
        "directly, where the areas of the mesh pixels themselves are used to compute the magnification. In certain situations\n",
        "this is more accurate than interpolation, especially when the source-plane pixelization is irregular. However,\n",
        "it does not currently work for the `Delanuay` pixelization and is commented out below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# print(\"Magnification via Mesh:\")\n",
        "# print(mapper_valued.magnification_via_mesh_from())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The magnification value computed can be impacted by faint source pixels at the edge of the source reconstruction.\n",
        "\n",
        "The input `mesh_pixel_mask` can be used to remove these pixels from the calculation, such that the magnification\n",
        "is based only on the brightest regions of the source reconstruction. \n",
        "\n",
        "Below, we create a source-plane signal-to-noise map and use this to create a mask that removes all pixels with\n",
        "a signal-to-noise < 5.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "reconstruction = inversion.reconstruction_dict[mapper]\n",
        "errors = inversion.errors_dict[mapper]\n",
        "\n",
        "signal_to_noise_map = reconstruction / errors\n",
        "\n",
        "mesh_pixel_mask = signal_to_noise_map < 5.0\n",
        "\n",
        "mapper_valued = al.MapperValued(\n",
        "    mapper=mapper,\n",
        "    values=inversion.reconstruction_dict[mapper],\n",
        "    mesh_pixel_mask=mesh_pixel_mask,\n",
        ")\n",
        "\n",
        "print(\"Magnification via Interpolation:\")\n",
        "print(mapper_valued.magnification_via_interpolation_from(shape_native=(401, 401)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Voronoi__\n",
        "\n",
        "The pixelization mesh which tests have revealed performs best is the `Voronoi` object, which uses a Voronoi\n",
        "mesh with a technique called natural neighbour interpolation (full details are provided in the **HowToLens**\n",
        "tutorials).\n",
        "\n",
        "I recommend users use this pixelization, how it requires a c library to be installed, thus it is\n",
        "not the default pixelization used in this tutorial.\n",
        "\n",
        "If you want to use this pixelization, checkout the installation instructions here:\n",
        "\n",
        "https://github.com/Jammy2211/PyAutoArray/tree/main/autoarray/util/nn\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "Pixelizations are the most complex but also most powerful way to model a source galaxy.\n",
        "\n",
        "Whether you need to use them or not depends on the science you are doing. If you are only interested in measuring a\n",
        "simple quantity like the Einstein radius of a lens, you can get away with using light profiles like a Sersic, MGE or \n",
        "shapelets to model the source. Low resolution data also means that using a pixelization is not necessary, as the\n",
        "complex structure of the source galaxy is not resolved anyway.\n",
        "\n",
        "However, fitting complex mass models (e.g. a power-law, stellar / dark model or dark matter substructure) requires \n",
        "this level of complexity in the source model. Furthermore, if you are interested in studying the properties of the\n",
        "source itself, you won't find a better way to do this than using a pixelization.\n",
        "\n",
        "__Chaining__\n",
        "\n",
        "If your pixelization fit does not go well, or you want for faster computational run-times, you may wish to use\n",
        "search chaining which breaks the model-fit into multiple Nautilus runs. This is described for the specific case of \n",
        "linking a (computationally fast) light profile fit to a pixelization in the script:\n",
        "\n",
        "`autolens_workspace/scripts/imaging/advanced/chaining/parametric_to_pixelization.py`\n",
        "\n",
        "__HowToLens__\n",
        "\n",
        "A full description of how pixelizations work, which comes down to a lot of linear algebra, Bayesian statistics and\n",
        "2D geometry, is provided in chapter 4 of the **HowToLens** lectures.\n",
        "\n",
        "__Result (Advanced)__\n",
        "\n",
        "The code belows shows all additional results that can be computed from a `Result` object following a fit with a\n",
        "pixelization.\n",
        "\n",
        "__Max Likelihood Inversion__\n",
        "\n",
        "As seen elsewhere in the workspace, the result contains a `max_log_likelihood_fit`, which contains the\n",
        "`Inversion` object we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion = result.max_log_likelihood_fit.inversion\n",
        "\n",
        "inversion_plotter = aplt.InversionPlotter(inversion=inversion)\n",
        "inversion_plotter.figures_2d(reconstructed_image=True)\n",
        "inversion_plotter.figures_2d_of_pixelization(pixelization_index=0, reconstruction=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Linear Objects__\n",
        "\n",
        "An `Inversion` contains all of the linear objects used to reconstruct the data in its `linear_obj_list`. \n",
        "\n",
        "This list may include the following objects:\n",
        "\n",
        " - `LightProfileLinearObjFuncList`: This object contains lists of linear light profiles and the functionality used\n",
        " by them to reconstruct data in an inversion. For example it may only contain a list with a single light profile\n",
        " (e.g. `lp_linear.Sersic`) or many light profiles combined in a `Basis` (e.g. `lp_basis.Basis`).\n",
        "\n",
        "- `Mapper`: The linear objected used by a `Pixelization` to reconstruct data via an `Inversion`, where the `Mapper` \n",
        "is specific to the `Pixelization`'s `Mesh` (e.g. a `RectnagularMapper` is used for a `Voronoi` mesh).\n",
        "\n",
        "In this example, the only linear object used to fit the data was a `Pixelization`, thus the `linear_obj_list`\n",
        "contains just one entry corresponding to a `Mapper`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.linear_obj_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To extract results from an inversion many quantities will come in lists or require that we specific the linear object\n",
        "we with to use. \n",
        "\n",
        "Thus, knowing what linear objects are contained in the `linear_obj_list` and what indexes they correspond to\n",
        "is important."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Voronoi Mapper = {inversion.linear_obj_list[0]}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Grids__\n",
        "\n",
        "The role of a mapper is to map between the image-plane and source-plane. \n",
        "\n",
        "This includes mapping grids corresponding to the data grid (e.g. the centers of each image-pixel in the image and\n",
        "source plane) and the pixelization grid (e.g. the centre of the Voronoi triangulation in the image-plane and \n",
        "source-plane).\n",
        "\n",
        "All grids are available in a mapper via its `mapper_grids` property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper = inversion.linear_obj_list[0]\n",
        "\n",
        "# Centre of each masked image pixel in the image-plane.\n",
        "print(mapper.mapper_grids.image_plane_data_grid)\n",
        "\n",
        "# Centre of each source pixel in the source-plane.\n",
        "print(mapper.mapper_grids.source_plane_data_grid)\n",
        "\n",
        "# Centre of each pixelization pixel in the image-plane (the `Overlay` image_mesh computes these in the image-plane\n",
        "# and maps to the source-plane).\n",
        "print(mapper.mapper_grids.image_plane_mesh_grid)\n",
        "\n",
        "# Centre of each pixelization pixel in the source-plane.\n",
        "print(mapper.mapper_grids.source_plane_mesh_grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction__\n",
        "\n",
        "The source reconstruction is also available as a 1D numpy array of values representative of the source pixelization\n",
        "itself (in this example, the reconstructed source values at the vertexes of each Voronoi triangle)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.reconstruction)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The (y,x) grid of coordinates associated with these values is given by the `Inversion`'s `Mapper` (which are \n",
        "described in chapter 4 of **HowToLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper = inversion.linear_obj_list[0]\n",
        "print(mapper.source_plane_mesh_grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mapper also contains the (y,x) grid of coordinates that correspond to the ray-traced image sub-pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(mapper.source_plane_data_grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapped Reconstructed Images__\n",
        "\n",
        "The source reconstruction(s) are mapped to the image-plane in order to fit the lens model.\n",
        "\n",
        "These mapped reconstructed images are also accessible via the `Inversion`. \n",
        "\n",
        "Note that any parametric light profiles in the lens model (e.g. the `bulge` and `disk` of a lens galaxy) are not \n",
        "included in this image -- it only contains the source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.mapped_reconstructed_image.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapped To Source__\n",
        "\n",
        "Mapping can also go in the opposite direction, whereby we input an image-plane masked 2D array and we use \n",
        "the `Inversion` to map these values to the source-plane.\n",
        "\n",
        "This creates an array which is analogous to the `reconstruction` in that the values are on the source-plane \n",
        "pixelization grid, however it bypass the linear algebra and inversion altogether and simply computes the sum of values \n",
        "mapped to each source pixel.\n",
        "\n",
        "[CURRENTLY DOES NOT WORK, BECAUSE THE MAPPING FUNCTION NEEDS TO INCORPORATE THE VARYING VORONOI PIXEL AREA]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_list = inversion.cls_list_from(cls=al.AbstractMapper)\n",
        "\n",
        "image_to_source = mapper_list[0].mapped_to_source_from(array=dataset.data)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper_list[0])\n",
        "mapper_plotter.plot_source_from(pixel_values=image_to_source)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can interpolate these arrays to output them to fits.\n",
        "\n",
        "Although the model-fit used a Voronoi mesh, there is no reason we need to use this pixelization to map the image-plane\n",
        "data onto a source-plane array.\n",
        "\n",
        "We can instead map the image-data onto a rectangular pixelization, which has the nice property of giving us a\n",
        "regular 2D array of data which could be output to .fits format.\n",
        "\n",
        "[NOT CLEAR IF THIS WORKS YET, IT IS UNTESTED!]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh = al.mesh.Rectangular(shape=(50, 50))\n",
        "\n",
        "source_plane_grid = tracer.traced_grid_2d_list_from(\n",
        "    grid=dataset.grids.pixelization.over_sampler.over_sampled_grid\n",
        ")[1]\n",
        "\n",
        "mapper_grids = mesh.mapper_grids_from(\n",
        "    mask=mask, source_plane_data_grid=source_plane_grid\n",
        ")\n",
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    over_sampler=dataset.grids.over_sampler_pixelization,\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "image_to_source = mapper.mapped_to_source_from(array=dataset.data)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "mapper_plotter.plot_source_from(pixel_values=image_to_source)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Linear Algebra Matrices (Advanced)__\n",
        "\n",
        "To perform an `Inversion` a number of matrices are constructed which use linear algebra to perform the reconstruction.\n",
        "\n",
        "These are accessible in the inversion object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.curvature_matrix)\n",
        "print(inversion.regularization_matrix)\n",
        "print(inversion.curvature_reg_matrix)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Evidence Terms (Advanced)__\n",
        "\n",
        "In **HowToLens** and the papers below, we cover how an `Inversion` uses a Bayesian evidence to quantify the goodness\n",
        "of fit:\n",
        "\n",
        "https://arxiv.org/abs/1708.07377\n",
        "https://arxiv.org/abs/astro-ph/0601493\n",
        "\n",
        "This evidence balances solutions which fit the data accurately, without using an overly complex regularization source.\n",
        "\n",
        "The individual terms of the evidence and accessed via the following properties:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.regularization_term)\n",
        "print(inversion.log_det_regularization_matrix_term)\n",
        "print(inversion.log_det_curvature_reg_matrix_term)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Future Ideas / Contributions__\n",
        "\n",
        "Here are a list of things I would like to add to this tutorial but haven't found the time. If you are interested\n",
        "in having a go at adding them contact me on SLACK! :)\n",
        "\n",
        "- More magnification calculations.\n",
        "- Source gradient calculations.\n",
        "- A calculation which shows differential lensing effects (e.g. magnification across the source plane)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}