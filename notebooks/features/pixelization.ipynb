{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling Features: Pixelization\n",
        "===============================\n",
        "\n",
        "A pixelization reconstructs the source's light using a pixel-grid, which is regularized using a prior that forces\n",
        "the solution to have a degree of smoothness.\n",
        "\n",
        "This script fits a source galaxy model which uses a pixelization to reconstruct the source's light.\n",
        "\n",
        "A Voronoi mesh and constant regularization scheme are used, which are the simplest forms of mesh and regularization\n",
        "with provide computationally fast and accurate solutions in **PyAutoLens**.\n",
        "\n",
        "For simplicity, the lens galaxy's light is omitted from the model and is not present in the simulated data. It is\n",
        "straightforward to include the lens galaxy's light in the model.\n",
        "\n",
        "Pixelizations are covered in detail in chapter 4 of the **HowToLens** lectures.\n",
        "\n",
        "__JAX Slowdown__\n",
        "\n",
        "Pixelizations currently have limited JAX support. GPU acceleration works, but fast run times are only possible on\n",
        "either very modern GPUs with large amounts of VRAM or using  low resolution pixelizations with a small memory footprint.\n",
        "\n",
        "This script therefore uses an adaptive 20 x 20 rectangular mesh, which is low resolution for a pixelization and may\n",
        "lead to unreliable lens modeling results. The mesh is adaptive -- it puts more rectangular pixels in high magnification\n",
        "source plane regions, but results will still be unreliable.\n",
        "\n",
        "If you need to use pixelizations for your science right now, and the results given in this script do not look reliable,\n",
        "you should revert to version `2025.5.10.1` which does not use JAX but has an efficient `numba` implementation which\n",
        "runs fast on CPUs but does not support GPUs.\n",
        "\n",
        "First class JAX support for pixelization, which will run over x20 faster than the `numba` CPU implementation, will be\n",
        "released mid November 2025!\n",
        "\n",
        "__Contents__\n",
        "\n",
        "**Advantages & Disadvantages:** Benefits and drawbacks of using an MGE.\n",
        "**Positive Only Solver:** How a positive solution to the light profile intensities is ensured.\n",
        "**Chaining:** How the advanced modeling feature, non-linear search chaining, can significantly improve lens modeling with pixelizaitons.\n",
        "**Dataset & Mask:** Standard set up of imaging dataset that is fitted.\n",
        "**Pixelization:** How to create a pixelization, including a description of its inputs.\n",
        "**Fit:** Perform a fit to a dataset using a pixelization, and visualize its results.\n",
        "**Model:** Composing a model using a pixelization and how it changes the number of free parameters.\n",
        "**Search & Analysis:** Standard set up of non-linear search and analysis.\n",
        "**Positions Likelihood:** Removing unphysical pixelized source solutions using a likelihood penalty using the lensed multiple images.\n",
        "**Run Time:** Profiling of pixelization run times and discussion of how they compare to standard light profiles.\n",
        "**Model-Fit:** Performs the model fit using standard API.\n",
        "**Result:** Pixelization results and visualizaiton.\n",
        "**Interpolated Source:** Interpolate the source reconstruction from an irregular Voronoi mesh to a uniform square grid and output to a .fits file.\n",
        "**Reconstruction CSV:** Output the source reconstruction to a .csv file, which can be used to perform calculations on the source reconstruction.\n",
        "**Voronoi:** Using a Voronoi mesh pixelizaiton (instead of Voronoi), which allows one to manipulate the source reconstruction without autolens installed.\n",
        "**Result (Advanced):** API for various pixelization outputs (magnifications, mappings) which requires some polishing.\n",
        "**Simulate (Advanced):** Simulating a strong lens dataset with the inferred pixelized source.\n",
        "\n",
        "__Advantages__\n",
        "\n",
        "Many strongly lensed source galaxies are complex, and have asymmetric and irregular morphologies. These morphologies\n",
        "cannot be well approximated by a parametric light profiles like a Sersic, or many Sersics, and thus a pixelization\n",
        "is required to reconstruct the source's irregular light.\n",
        "\n",
        "Even basis functions like shapelets or a multi-Gaussian expansion cannot reconstruct a source-plane accurately\n",
        "if there are multiple source galaxies, or if the source galaxy has a very complex morphology.\n",
        "\n",
        "To infer detailed components of a lens mass model (e.g. its density slope, whether there's a dark matter subhalo, etc.)\n",
        "then pixelized source models are required, to ensure the mass model is fitting all of the lensed source light.\n",
        "\n",
        "There are also many science cases where one wants to study the highly magnified light of the source galaxy in detail,\n",
        "to learnt about distant and faint galaxies. A pixelization reconstructs the source's unlensed emission and thus\n",
        "enables this.\n",
        "\n",
        "__Disadvantages__\n",
        "\n",
        "Pixelizations are computationally slow and run times are typically longer than a parametric source model. It is not\n",
        "uncommon for lens models using a pixelization to take hours or even days to fit high resolution imaging\n",
        "data (e.g. Hubble Space Telescope imaging).\n",
        "\n",
        "Lens modeling with pixelizations is also more complex than parametric source models, with there being more things\n",
        "that can go wrong. For example, there are solutions where a demagnified version of the lensed source galaxy is\n",
        "reconstructed, using a mass model which effectively has no mass or too much mass. These are described in detail below.\n",
        "\n",
        "It will take you longer to learn how to successfully fit lens models with a pixelization than other methods illustrated\n",
        "in the workspace!\n",
        "\n",
        "__Positive Only Solver__\n",
        "\n",
        "Many codes which use linear algebra typically rely on a linear algabra solver which allows for positive and negative\n",
        "values of the solution (e.g. `np.linalg.solve`), because they are computationally fast.\n",
        "\n",
        "This is problematic, as it means that negative surface brightnesses values can be computed to represent a galaxy's\n",
        "light, which is clearly unphysical. For a pixelizaiton, this often produces negative source pixels which over-fit\n",
        "the data, producing unphysical solutions.\n",
        "\n",
        "All pixelized source reconstructions use a positive-only solver, meaning that every source-pixel is only allowed\n",
        "to reconstruct positive flux values. This ensures that the source reconstruction is physical and that we don't\n",
        "reconstruct negative flux values that don't exist in the real source galaxy (a common systematic solution in lens\n",
        "analysis).\n",
        "\n",
        "It may be surprising to hear that this is a feature worth pointing out, but it turns out setting up the linear algebra\n",
        "to enforce positive reconstructions is difficult to make efficient. A lot of development time went into making this\n",
        "possible, where a bespoke fast non-negative linear solver was developed to achieve this.\n",
        "\n",
        "Other methods in the literature often do not use a positive only solver, and therefore suffer from these\n",
        "unphysical solutions, which can degrade the results of lens model in general.\n",
        "\n",
        "__Chaining__\n",
        "\n",
        "Due to the complexity of fitting with a pixelization, it is often best to use **PyAutoLens**'s non-linear chaining\n",
        "feature to compose a pipeline which begins by fitting a simpler model using a parametric source.\n",
        "\n",
        "More information on chaining is provided in the `autolens_workspace/notebooks/imaging/advanced/chaining` folder,\n",
        "chapter 3 of the **HowToLens** lectures.\n",
        "\n",
        "The script `autolens_workspace/scripts/imaging/advanced/chaining/parametric_to_pixelization.py` explitly uses chaining\n",
        "to link a lens model using a light profile source to one which then uses a pixelization.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits an `Imaging` dataset of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's light is omitted (and is not present in the simulated data).\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's surface-brightness is reconstructed using a `Voronoi` mesh, `Overlay` image-mesh\n",
        "   and `Constant` regularization scheme.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot the strong lens dataset `simple__no_lens_light` via .fits files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"simple__no_lens_light\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_radius = 3.0\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Over Sampling__\n",
        "\n",
        "A pixelization uses a separate grid for ray tracing, with its own over sampling scheme, which below we set to a \n",
        "uniform grid of values of 2. \n",
        "\n",
        "The pixelization only reconstructs the source galaxy, therefore the adaptive over sampling used for the lens galaxy's \n",
        "light in other examples is not applied to the pixelization. \n",
        "\n",
        "This example does not model lens light, for examples which combine lens light and a pixelization both over sampling \n",
        "schemes should be used, with the lens light adaptive and the pixelization uniform.\n",
        "\n",
        "Note that the over sampling is input into the `over_sample_size_pixelization` because we are using a `Pixelization`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = dataset.apply_over_sampling(\n",
        "    over_sample_size_pixelization=4,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__JAX & Preloads__\n",
        "\n",
        "In JAX, calculations must use static shaped arrays with known and fixed indexes. For certain calculations in the\n",
        "pixelization, this information has to be passed in before the pixelization is performed. Below, we do this for 3\n",
        "inputs:\n",
        "\n",
        "- `total_linear_light_profiles`: The number of linear light profiles in the model. This is 0 because we are not\n",
        "  fitting any linear light profiles to the data, primarily because the lens light is omitted.\n",
        "  \n",
        "- `total_mapper_pixels`: The number of source pixels in the rectangular pixelization mesh. This is required to set up \n",
        "  the arrays that perform the linear algebra of the pixelization.\n",
        "  \n",
        "- `source_pixel_zeroed_indices`: The indices of source pixels on its edge, which when the source is reconstructed \n",
        "  are forced to values of zero, a technique tests have shown are required to give accruate lens models.\n",
        "  \n",
        "The `image_mesh` can be ignored, it is legacy API from previous versions which may or may not be reintegrated in future\n",
        "versions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "image_mesh = None\n",
        "mesh_shape = (20, 20)\n",
        "total_mapper_pixels = mesh_shape[0] * mesh_shape[1]\n",
        "\n",
        "total_linear_light_profiles = 0\n",
        "\n",
        "preloads = al.Preloads(\n",
        "    mapper_indices=al.mapper_indices_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        total_mapper_pixels=total_mapper_pixels,\n",
        "    ),\n",
        "    source_pixel_zeroed_indices=al.util.mesh.rectangular_edge_pixel_list_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        shape_native=mesh_shape,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixelization__\n",
        "\n",
        "We create a `Pixelization` object to perform the pixelized source reconstruction, which is made up of three\n",
        "components:\n",
        "\n",
        "- `image_mesh:`The coordinates of the mesh used for the pixelization need to be defined. The way this is performed\n",
        "depends on pixelization used. In this example, we define the source pixel centers by overlaying a uniform regular grid\n",
        "in the image-plane and ray-tracing these coordinates to the source-plane. Where they land then make up the coordinates\n",
        "used by the mesh.\n",
        "\n",
        "- `mesh:` Different types of mesh can be used to perform the source reconstruction, where the mesh changes the\n",
        "details of how the source is reconstructed (e.g. interpolation weights). In this exmaple, we use a `Voronoi` mesh,\n",
        "where the centres computed via the `image_mesh` are the vertexes of every `Voronoi` triangle.\n",
        "\n",
        "- `regularization:` A pixelization uses many pixels to reconstructed the source, which will often lead to over fitting\n",
        "of the noise in the data and an unrealistically complex and strucutred source. Regularization smooths the source\n",
        "reconstruction solution by penalizing solutions where neighboring pixels (Voronoi triangles in this example) have\n",
        "large flux differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh = al.mesh.Rectangular(shape=mesh_shape)\n",
        "regularization = al.reg.Constant(coefficient=1.0)\n",
        "\n",
        "pixelization = al.Pixelization(\n",
        "    image_mesh=image_mesh, mesh=mesh, regularization=regularization\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fit__\n",
        "\n",
        "This is to illustrate the API for performing a fit via a pixelization using standard autolens objects like \n",
        "the `Galaxy`, `Tracer` and `FitImaging` \n",
        "\n",
        "We simply create a `Pixelization` and pass it to the source galaxy, which then gets input into the tracer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.0, 0.0),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        "    shear=al.mp.ExternalShear(gamma_1=0.05, gamma_2=0.05),\n",
        ")\n",
        "\n",
        "source = al.Galaxy(redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "tracer = al.Tracer(galaxies=[lens, source])\n",
        "\n",
        "fit = al.FitImaging(\n",
        "    dataset=dataset,\n",
        "    tracer=tracer,\n",
        "    preloads=preloads,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By plotting the fit, we see that the pixelized source does a good job at capturing the appearance of the source galaxy\n",
        "and fitting the data to roughly the noise level."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_plotter = aplt.FitImagingPlotter(fit=fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pixelizations have bespoke visualizations which show more details about the source-reconstruction, image-mesh\n",
        "and other quantities.\n",
        "\n",
        "These plots use an `InversionPlotter`, which gets its name from the internals of how pixelizations are performed in\n",
        "the source code, where the linear algebra process which computes the source pixel fluxes is called an inversion.\n",
        "\n",
        "The `subplot_mappings` overlays colored circles in the image and source planes that map to one another, thereby\n",
        "allowing one to assess how the mass model ray-traces image-pixels and therefore to assess how the source reconstruction\n",
        "maps to the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion_plotter = fit_plotter.inversion_plotter_of_plane(plane_index=1)\n",
        "inversion_plotter.subplot_of_mapper(mapper_index=0)\n",
        "inversion_plotter.subplot_mappings(pixelization_index=0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose our lens model using `Model` objects, which represent the galaxies we fit to our data.  In this \n",
        "example fits a lens model where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear` [7 parameters].\n",
        " \n",
        " - The source-galaxy's light uses a `Voronoi` mesh [0 parameters].\n",
        " \n",
        " - The mesh centres of the `Voronoi` mesh are computed using a `Overlay` image-mesh, with a fixed resolution of \n",
        "   30 x 30 pixels [0 parameters].\n",
        " \n",
        " - This pixelization is regularized using a `Constant` scheme which smooths every source pixel equally [1 parameter]. \n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=6. \n",
        " \n",
        "It is worth noting the `Pixelization`  use significantly fewer parameters (1 parameter) than \n",
        "fitting the source using `LightProfile`'s (7+ parameters). \n",
        "\n",
        "The lens model therefore includes a mesh and regularization scheme, which are used together to create the \n",
        "pixelization. \n",
        "\n",
        "__Model Cookbook__\n",
        "\n",
        "A full description of model composition is provided by the model cookbook: \n",
        "\n",
        "https://pyautolens.readthedocs.io/en/latest/general/model_cookbook.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Lens:\n",
        "\n",
        "mass = af.Model(al.mp.PowerLaw)\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, mass=mass, shear=shear)\n",
        "\n",
        "# Source:\n",
        "mesh = af.Model(al.mesh.Rectangular(shape=mesh_shape))\n",
        "regularization = af.Model(al.reg.Constant)\n",
        "\n",
        "pixelization = af.Model(\n",
        "    al.Pixelization, image_mesh=image_mesh, mesh=mesh, regularization=regularization\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, pixelization=pixelization)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(galaxies=af.Collection(lens=lens, source=source))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `info` attribute shows the model in a readable format (if this does not display clearly on your screen refer to\n",
        "`start_here.ipynb` for a description of how to fix this).\n",
        "\n",
        "This confirms that the source galaxy's has a mesh and regularization scheme, which are combined into a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__\n",
        "\n",
        "The model is fitted to the data using the nested sampling algorithm Nautilus (see `start.here.py` for a \n",
        "full description)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"features\"),\n",
        "    name=\"pixelization\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    n_batch=5,\n",
        "    iterations_per_quick_update=50000,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Position Likelihood__\n",
        "\n",
        "We add a penalty term ot the likelihood function, which penalizes models where the brightest multiple images of\n",
        "the lensed source galaxy do not trace close to one another in the source plane. This removes \"demagnified source\n",
        "solutions\" from the source pixelization, which one is likely to infer without this penalty.\n",
        "\n",
        "A comprehensive description of why we do this is given at the following readthedocs page. I strongly recommend you \n",
        "read this page in full if you are not familiar with the positions likelihood penalty and demagnified source \n",
        "reconstructions:\n",
        "\n",
        " https://pyautolens.readthedocs.io/en/latest/general/demagnified_solutions.html\n",
        "\n",
        "__Brief Description__\n",
        "\n",
        "Unlike other example scripts, we also pass the `AnalysisImaging` object below a `PositionsLH` object, which\n",
        "includes the positions we loaded above, alongside a `threshold`.\n",
        "\n",
        "This is because `Inversion`'s suffer a bias whereby they fit unphysical lens models where the source galaxy is \n",
        "reconstructed as a demagnified version of the lensed source. \n",
        "\n",
        "To prevent these solutions biasing the model-fit we specify a `position_threshold` of 0.5\", which requires that a \n",
        "mass model traces the four (y,x) coordinates specified by our positions (that correspond to the brightest regions of the \n",
        "lensed source) within 0.5\" of one another in the source-plane. If this criteria is not met, a large penalty term is\n",
        "added to likelihood that massively reduces the overall likelihood. This penalty is larger if the ``positions``\n",
        "trace further from one another.\n",
        "\n",
        "This ensures the unphysical solutions that bias a pixelization have a lower likelihood that the physical solutions\n",
        "we desire. Furthermore, the penalty term reduces as the image-plane multiple image positions trace closer in the \n",
        "source-plane, ensuring Nautilus converges towards an accurate mass model. It does this very fast, as \n",
        "ray-tracing just a few multiple image positions is computationally cheap. \n",
        "\n",
        "The threshold of 0.3\" is large. For an accurate lens model we would anticipate the positions trace within < 0.01\" of\n",
        "one another. The high threshold ensures only the initial mass models at the start of the fit are penalized.\n",
        "\n",
        "Position thresholding is described in more detail in the \n",
        "script `autolens_workspace/*/modeling/imaging/customize/positions.py`\n",
        "\n",
        "The arc-second positions of the multiply imaged lensed source galaxy were drawn onto the\n",
        "image via the GUI described in the file `autolens_workspace/*/data_preparation/imaging/gui/positions.py`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = al.Grid2DIrregular(\n",
        "    al.from_json(file_path=Path(dataset_path, \"positions.json\"))\n",
        ")\n",
        "positions_likelihood = al.PositionsLH(positions=positions, threshold=0.3)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "Create the `AnalysisImaging` object defining how the via Nautilus the model is fitted to the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis = al.AnalysisImaging(\n",
        "    dataset=dataset, positions_likelihood_list=[positions_likelihood], preloads=preloads\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Run Time__\n",
        "\n",
        "The run time of a pixelization is longer than many other features, with the estimate below coming out at around ~0.5 \n",
        "seconds per likelihood evaluation. This is because the fit has a lot of linear algebra to perform in order to\n",
        "reconstruct the source on the pixel-grid.\n",
        "\n",
        "Nevertheless, this is still fast enough for most use-cases. If run-time is an issue, the following factors determine\n",
        "the run-time of a a pixelization and can be changed to speed it up (at the expense of accuracy):\n",
        "\n",
        " - The number of unmasked pixels in the image data. By making the mask smaller (e.g. using an annular mask), the \n",
        "   run-time will decrease.\n",
        " \n",
        " - The number of source pixels in the pixelization. By reducing the `shape` from (30, 30) the run-time will decrease.\n",
        "\n",
        "This also serves to highlight why the positions threshold likelihood is so powerful. The likelihood evaluation time\n",
        "of this step is below 0.001 seconds, meaning that the initial parameter space sampling is extremely efficient even\n",
        "for a pixelization (this is not accounted for in the run-time estimate below)!\n",
        "\n",
        "__Model-Fit__\n",
        "\n",
        "We begin the model-fit by passing the model and analysis object to the non-linear search (checkout the output folder\n",
        "for on-the-fly visualization and results)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The search returns a result object, which whose `info` attribute shows the result in a readable format (if this\n",
        "does not display clearly on your screen refer to `start_here.ipynb` for a description of how to fix this):\n",
        "\n",
        "This confirms that the source galaxy's has a mesh and regularization scheme, which are combined into a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the maximum likelihood fit, tracer images and posteriors inferred via Nautilus.\n",
        "\n",
        "The end of this example provides a detailed description of all result options for a pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.max_log_likelihood_instance)\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=result.grids.lp\n",
        ")\n",
        "tracer_plotter.subplot_tracer()\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()\n",
        "\n",
        "plotter = aplt.NestPlotter(samples=result.samples)\n",
        "plotter.corner_anesthetic()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask Extra Galaxies__\n",
        "\n",
        "There may be extra galaxies nearby the lens and source galaxies, whose emission blends with the lens and source.\n",
        "\n",
        "If their emission is significant, and close enough to the lens and source, we may simply remove it from the data\n",
        "to ensure it does not impact the model-fit. A standard masking approach would be to remove the image pixels containing\n",
        "the emission of these galaxies altogether. This is analogous to what the circular masks used throughout the examples\n",
        "does.\n",
        "\n",
        "For fits using a pixelization, masking regions of the image in a way that removes their image pixels entirely from\n",
        "the fit. This can produce discontinuities in the pixelixation used to reconstruct the source and produce unexpected\n",
        "systematics and unsatisfactory results. In this case, applying the mask in a way where the image pixels are not\n",
        "removed from the fit, but their data and noise-map values are scaled such that they contribute negligibly to the fit,\n",
        "is a better approach.\n",
        "\n",
        "We illustrate the API for doing this below, using the `extra_galaxies` dataset which has extra galaxies whose emission\n",
        "needs to be removed via scaling in this way. We apply the scaling and show the subplot imaging where the extra\n",
        "galaxies mask has scaled the data values to zeros, increasing the noise-map values to large values and in turn made\n",
        "the signal to noise of its pixels effectively zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"extra_galaxies\"\n",
        "dataset_path = Path(\"dataset\") / \"imaging\" / dataset_name\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "mask_extra_galaxies = al.Mask2D.from_fits(\n",
        "    file_path=Path(dataset_path, \"mask_extra_galaxies.fits\"),\n",
        "    pixel_scales=0.1,\n",
        "    invert=True,  # Note that we invert the mask here as `True` means a pixel is scaled.\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_noise_scaling(mask=mask_extra_galaxies)\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native, pixel_scales=0.1, centre=(0.0, 0.0), radius=6.0\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We do not explictly fit this data, for the sake of brevity, however if your data has these nearby galaxies you should\n",
        "apply the mask as above before fitting the data.\n",
        "\n",
        "__Pixelization / Mapper Calculations__\n",
        "\n",
        "The pixelized source reconstruction output by an `Inversion` is often on an irregular grid (e.g. a\n",
        "Voronoi triangulation or Voronoi mesh), making it difficult to manipulate and inspect after the lens modeling has\n",
        "completed.\n",
        "\n",
        "Internally, the inversion stores a `Mapper` object to perform these calculations, which effectively maps pixels\n",
        "between the image-plane and source-plane.\n",
        "\n",
        "After an inversion is complete, it has computed values which can be paired with the `Mapper` to perform calculations,\n",
        "most notably the `reconstruction`, which is the reconstructed source pixel values.\n",
        "\n",
        "By inputting the inversions's mapper and a set of values (e.g. the `reconstruction`) into a `MapperValued` object, we\n",
        "are provided with all the functionality we need to perform calculations on the source reconstruction.\n",
        "\n",
        "We set up the `MapperValued` object below, and illustrate how we can use it to interpolate the source reconstruction\n",
        "to a uniform grid of values, perform magnification calculations and other tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion = result.max_log_likelihood_fit.inversion\n",
        "mapper = inversion.cls_list_from(cls=al.AbstractMapper)[\n",
        "    0\n",
        "]  # Only one source-plane so only one mapper, would be a list if multiple source planes\n",
        "\n",
        "mapper_valued = al.MapperValued(\n",
        "    mapper=mapper, values=inversion.reconstruction_dict[mapper]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Interpolated Source__\n",
        "\n",
        "A simple way to inspect the source reconstruction is to interpolate its values from the irregular\n",
        "pixelization o a uniform 2D grid of pixels.\n",
        "\n",
        "(if you do not know what the `slim` and `native` properties below refer too, it\n",
        "is described in the `results/examples/data_structures.py` example.)\n",
        "\n",
        "We interpolate the Voronoi triangulation this source is reconstructed on to a 2D grid of 401 x 401 square pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "interpolated_reconstruction = mapper_valued.interpolated_array_from(\n",
        "    shape_native=(401, 401)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are unclear on what `slim` means, refer to the section `Data Structure` at the top of this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(interpolated_reconstruction.slim)\n",
        "\n",
        "plotter = aplt.Array2DPlotter(\n",
        "    array=interpolated_reconstruction,\n",
        ")\n",
        "plotter.figure_2d()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By inputting the arc-second `extent` of the source reconstruction, the interpolated array will zoom in on only these\n",
        "regions of the source-plane. The extent is input via the notation (xmin, xmax, ymin, ymax), therefore  unlike the standard\n",
        "API it does not follow the (y,x) convention.\n",
        "\n",
        "Note that the output interpolated array will likely therefore be rectangular, with rectangular pixels, unless\n",
        "symmetric y and x arc-second extents are input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "interpolated_reconstruction = mapper_valued.interpolated_array_from(\n",
        "    shape_native=(401, 401), extent=(-1.0, 1.0, -1.0, 1.0)\n",
        ")\n",
        "\n",
        "print(interpolated_reconstruction.slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The interpolated errors on the source reconstruction can also be computed, in case you are planning to perform\n",
        "model-fitting of the source reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_valued_errors = al.MapperValued(\n",
        "    mapper=mapper, values=inversion.reconstruction_noise_map_dict[mapper]\n",
        ")\n",
        "\n",
        "interpolated_errors = mapper_valued_errors.interpolated_array_from(\n",
        "    shape_native=(401, 401), extent=(-1.0, 1.0, -1.0, 1.0)\n",
        ")\n",
        "\n",
        "print(interpolated_errors.slim)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Magnification__\n",
        "\n",
        "The magnification of the lens model and source reconstruction can also be computed via the `MapperValued` object,\n",
        "provided we pass it the reconstruction as the `values`.\n",
        "\n",
        "This magnification is the ratio of the surface brightness of image in the image-plane over the surface brightness\n",
        "of the source in the source-plane.\n",
        "\n",
        "In the image-plane, this is computed by mapping the reconstruction to the image, summing all reconstructed\n",
        "values and multiplying by the area of each image pixel. This image-plane image is not convolved with the\n",
        "PSF, as the source plane reconstruction is a non-convolved image.\n",
        "\n",
        "In the source-plane, this is computed by interpolating the reconstruction to a regular grid of pixels, for\n",
        "example a 2D grid of 401 x 401 pixels, and summing the reconstruction values multiplied by the area of each\n",
        "pixel. This calculation uses interpolation to compute the source-plane image.\n",
        "\n",
        "The calculation is relatively stable, but depends on subtle details like the resolution of the source-plane\n",
        "pixelization and how exactly the interpolation is performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_valued = al.MapperValued(\n",
        "    mapper=mapper,\n",
        "    values=inversion.reconstruction_dict[mapper],\n",
        ")\n",
        "\n",
        "print(\"Magnification via Interpolation:\")\n",
        "print(mapper_valued.magnification_via_interpolation_from(shape_native=(401, 401)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The magnification calculated above used an interpolation of the source-plane reconstruction to a 2D grid of 401 x 401\n",
        "pixels.\n",
        "\n",
        "For a `Rectangular` or `Voronoi` pixelization, the magnification can also be computed using the source-plane mesh\n",
        "directly, where the areas of the mesh pixels themselves are used to compute the magnification. In certain situations\n",
        "this is more accurate than interpolation, especially when the source-plane pixelization is irregular. However,\n",
        "it does not currently work for the `Delanuay` pixelization and is commented out below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# print(\"Magnification via Mesh:\")\n",
        "# print(mapper_valued.magnification_via_mesh_from())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The magnification value computed can be impacted by faint source pixels at the edge of the source reconstruction.\n",
        "\n",
        "The input `mesh_pixel_mask` can be used to remove these pixels from the calculation, such that the magnification\n",
        "is based only on the brightest regions of the source reconstruction.\n",
        "\n",
        "We create a source-plane signal-to-noise map and use this to create a mask that removes all pixels with\n",
        "a signal-to-noise < 5.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "reconstruction = inversion.reconstruction_dict[mapper]\n",
        "errors = inversion.reconstruction_noise_map_dict[mapper]\n",
        "\n",
        "signal_to_noise_map = reconstruction / errors\n",
        "\n",
        "mesh_pixel_mask = signal_to_noise_map < 5.0\n",
        "\n",
        "mapper_valued = al.MapperValued(\n",
        "    mapper=mapper,\n",
        "    values=inversion.reconstruction_dict[mapper],\n",
        "    mesh_pixel_mask=mesh_pixel_mask,\n",
        ")\n",
        "\n",
        "print(\"Magnification via Interpolation:\")\n",
        "print(mapper_valued.magnification_via_interpolation_from(shape_native=(401, 401)))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction CSV__\n",
        "\n",
        "In the results `image` folder there is a .csv file called `source_plane_reconstruction_0.csv` which contains the\n",
        "y and x coordinates of the pixelization mesh, the reconstruct values and the noise map of these values.\n",
        "\n",
        "This file is provides all information on the source reconstruciton in a format that does not depend autolens\n",
        "and therefore be easily loaded to create images of the source or shared collaobrations who do not have PyAutoLens\n",
        "installed.\n",
        "\n",
        "First, lets load `source_plane_reconstruction_0.csv` as a dictionary, using basic `csv` functionality in Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import csv\n",
        "\n",
        "with open(\n",
        "    search.paths.image_path / \"source_plane_reconstruction_0.csv\", mode=\"r\"\n",
        ") as file:\n",
        "    reader = csv.reader(file)\n",
        "    header_list = next(reader)  # ['y', 'x', 'reconstruction', 'noise_map']\n",
        "\n",
        "    reconstruction_dict = {header: [] for header in header_list}\n",
        "\n",
        "    for row in reader:\n",
        "        for key, value in zip(header_list, row):\n",
        "            reconstruction_dict[key].append(float(value))\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    for key in reconstruction_dict:\n",
        "        reconstruction_dict[key] = np.array(reconstruction_dict[key])\n",
        "\n",
        "print(reconstruction_dict[\"y\"])\n",
        "print(reconstruction_dict[\"x\"])\n",
        "print(reconstruction_dict[\"reconstruction\"])\n",
        "print(reconstruction_dict[\"noise_map\"])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can now use standard libraries to performed calculations with the reconstruction on the mesh, again avoiding\n",
        "the need to use autolens.\n",
        "\n",
        "For example, we can create a Rectangular mesh using the scipy.spatial library, which is a triangulation\n",
        "of the y and x coordinates of the pixelization mesh. This is useful for visualizing the pixelization\n",
        "and performing calculations on the mesh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import scipy\n",
        "\n",
        "points = np.stack(arrays=(reconstruction_dict[\"x\"], reconstruction_dict[\"y\"]), axis=-1)\n",
        "\n",
        "mesh = scipy.spatial.Rectangular(points)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interpolating the result to a uniform grid is also possible using the scipy.interpolate library, which means the result\n",
        "can be turned into a uniform 2D image which can be useful to analyse the source with tools which require an uniform grid.\n",
        "\n",
        "Below, we interpolate the result onto a 201 x 201 grid of pixels with the extent spanning -1.0\" to 1.0\", which\n",
        "capture the majority of the source reconstruction without being too high resolution.\n",
        "\n",
        "It should be noted this inteprolation may not be as optimal as the interpolation perforemd above using `MapperValued`, \n",
        "which uses specifc interpolation methods for a Rectangular mesh which are more accurate, but it should be sufficent for\n",
        "most use-cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from scipy.interpolate import griddata\n",
        "\n",
        "values = reconstruction_dict[\"reconstruction\"]\n",
        "\n",
        "interpolation_grid = al.Grid2D.from_extent(\n",
        "    extent=(-1.0, 1.0, -1.0, 1.0), shape_native=(201, 201)\n",
        ")\n",
        "\n",
        "interpolated_array = griddata(points=points, values=values, xi=interpolation_grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Voronoi__\n",
        "\n",
        "The pixelization mesh which tests have revealed performs best is the `Voronoi` object, which uses a Voronoi\n",
        "mesh with a technique called natural neighbour interpolation (full details are provided in the **HowToLens**\n",
        "tutorials).\n",
        "\n",
        "I recommend users use this pixelization, how it requires a c library to be installed, thus it is\n",
        "not the default pixelization used in this tutorial.\n",
        "\n",
        "If you want to use this pixelization, checkout the installation instructions here:\n",
        "\n",
        "https://github.com/Jammy2211/PyAutoArray/tree/main/autoarray/util/nn\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "Pixelizations are the most complex but also most powerful way to model a source galaxy.\n",
        "\n",
        "Whether you need to use them or not depends on the science you are doing. If you are only interested in measuring a\n",
        "simple quantity like the Einstein radius of a lens, you can get away with using light profiles like a Sersic, MGE or \n",
        "shapelets to model the source. Low resolution data also means that using a pixelization is not necessary, as the\n",
        "complex structure of the source galaxy is not resolved anyway.\n",
        "\n",
        "However, fitting complex mass models (e.g. a power-law, stellar / dark model or dark matter substructure) requires \n",
        "this level of complexity in the source model. Furthermore, if you are interested in studying the properties of the\n",
        "source itself, you won't find a better way to do this than using a pixelization.\n",
        "\n",
        "__Chaining__\n",
        "\n",
        "If your pixelization fit does not go well, or you want for faster computational run-times, you may wish to use\n",
        "search chaining which breaks the model-fit into multiple Nautilus runs. This is described for the specific case of \n",
        "linking a (computationally fast) light profile fit to a pixelization in the script:\n",
        "\n",
        "`autolens_workspace/scripts/imaging/advanced/chaining/parametric_to_pixelization.py`\n",
        "\n",
        "__HowToLens__\n",
        "\n",
        "A full description of how pixelizations work, which comes down to a lot of linear algebra, Bayesian statistics and\n",
        "2D geometry, is provided in chapter 4 of the **HowToLens** lectures.\n",
        "\n",
        "__Result (Advanced)__\n",
        "\n",
        "The code belows shows all additional results that can be computed from a `Result` object following a fit with a\n",
        "pixelization.\n",
        "\n",
        "__Max Likelihood Inversion__\n",
        "\n",
        "As seen elsewhere in the workspace, the result contains a `max_log_likelihood_fit`, which contains the\n",
        "`Inversion` object we need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inversion = result.max_log_likelihood_fit.inversion\n",
        "\n",
        "inversion_plotter = aplt.InversionPlotter(inversion=inversion)\n",
        "inversion_plotter.figures_2d(reconstructed_image=True)\n",
        "inversion_plotter.figures_2d_of_pixelization(pixelization_index=0, reconstruction=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Linear Objects__\n",
        "\n",
        "An `Inversion` contains all of the linear objects used to reconstruct the data in its `linear_obj_list`. \n",
        "\n",
        "This list may include the following objects:\n",
        "\n",
        " - `LightProfileLinearObjFuncList`: This object contains lists of linear light profiles and the functionality used\n",
        " by them to reconstruct data in an inversion. For example it may only contain a list with a single light profile\n",
        " (e.g. `lp_linear.Sersic`) or many light profiles combined in a `Basis` (e.g. `lp_basis.Basis`).\n",
        "\n",
        "- `Mapper`: The linear objected used by a `Pixelization` to reconstruct data via an `Inversion`, where the `Mapper` \n",
        "is specific to the `Pixelization`'s `Mesh` (e.g. a `RectnagularMapper` is used for a `Voronoi` mesh).\n",
        "\n",
        "In this example, the only linear object used to fit the data was a `Pixelization`, thus the `linear_obj_list`\n",
        "contains just one entry corresponding to a `Mapper`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.linear_obj_list)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To extract results from an inversion many quantities will come in lists or require that we specific the linear object\n",
        "we with to use. \n",
        "\n",
        "Thus, knowing what linear objects are contained in the `linear_obj_list` and what indexes they correspond to\n",
        "is important."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Voronoi Mapper = {inversion.linear_obj_list[0]}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Grids__\n",
        "\n",
        "The role of a mapper is to map between the image-plane and source-plane. \n",
        "\n",
        "This includes mapping grids corresponding to the data grid (e.g. the centers of each image-pixel in the image and\n",
        "source plane) and the pixelization grid (e.g. the centre of the Voronoi triangulation in the image-plane and \n",
        "source-plane).\n",
        "\n",
        "All grids are available in a mapper via its `mapper_grids` property."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper = inversion.linear_obj_list[0]\n",
        "\n",
        "# Centre of each masked image pixel in the image-plane.\n",
        "print(mapper.mapper_grids.image_plane_data_grid)\n",
        "\n",
        "# Centre of each source pixel in the source-plane.\n",
        "print(mapper.mapper_grids.source_plane_data_grid)\n",
        "\n",
        "# Centre of each pixelization pixel in the image-plane (the `Overlay` image_mesh computes these in the image-plane\n",
        "# and maps to the source-plane).\n",
        "print(mapper.mapper_grids.image_plane_mesh_grid)\n",
        "\n",
        "# Centre of each pixelization pixel in the source-plane.\n",
        "print(mapper.mapper_grids.source_plane_mesh_grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Reconstruction__\n",
        "\n",
        "The source reconstruction is also available as a 1D numpy array of values representative of the source pixelization\n",
        "itself (in this example, the reconstructed source values at the vertexes of each Voronoi triangle)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.reconstruction)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The (y,x) grid of coordinates associated with these values is given by the `Inversion`'s `Mapper` (which are \n",
        "described in chapter 4 of **HowToLens**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper = inversion.linear_obj_list[0]\n",
        "print(mapper.source_plane_mesh_grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The mapper also contains the (y,x) grid of coordinates that correspond to the ray-traced image sub-pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(mapper.source_plane_data_grid)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapped Reconstructed Images__\n",
        "\n",
        "The source reconstruction(s) are mapped to the image-plane in order to fit the lens model.\n",
        "\n",
        "These mapped reconstructed images are also accessible via the `Inversion`. \n",
        "\n",
        "Note that any parametric light profiles in the lens model (e.g. the `bulge` and `disk` of a lens galaxy) are not \n",
        "included in this image -- it only contains the source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.mapped_reconstructed_image.native)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mapped To Source__\n",
        "\n",
        "Mapping can also go in the opposite direction, whereby we input an image-plane masked 2D array and we use \n",
        "the `Inversion` to map these values to the source-plane.\n",
        "\n",
        "This creates an array which is analogous to the `reconstruction` in that the values are on the source-plane \n",
        "pixelization grid, however it bypass the linear algebra and inversion altogether and simply computes the sum of values \n",
        "mapped to each source pixel.\n",
        "\n",
        "[CURRENTLY DOES NOT WORK, BECAUSE THE MAPPING FUNCTION NEEDS TO INCORPORATE THE VARYING VORONOI PIXEL AREA]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper_list = inversion.cls_list_from(cls=al.AbstractMapper)\n",
        "\n",
        "image_to_source = mapper_list[0].mapped_to_source_from(array=dataset.data)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper_list[0])\n",
        "mapper_plotter.plot_source_from(pixel_values=image_to_source)\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can interpolate these arrays to output them to fits.\n",
        "\n",
        "Although the model-fit used a Voronoi mesh, there is no reason we need to use this pixelization to map the image-plane\n",
        "data onto a source-plane array.\n",
        "\n",
        "We can instead map the image-data onto a rectangular pixelization, which has the nice property of giving us a\n",
        "regular 2D array of data which could be output to .fits format.\n",
        "\n",
        "[NOT CLEAR IF THIS WORKS YET, IT IS UNTESTED!]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh = al.mesh.Rectangular(shape=(50, 50))\n",
        "\n",
        "source_plane_grid = tracer.traced_grid_2d_list_from(grid=dataset.grids.pixelization)[1]\n",
        "\n",
        "mapper_grids = mesh.mapper_grids_from(\n",
        "    mask=mask, source_plane_data_grid=source_plane_grid\n",
        ")\n",
        "mapper = al.Mapper(\n",
        "    mapper_grids=mapper_grids,\n",
        "    regularization=al.reg.Constant(coefficient=1.0),\n",
        ")\n",
        "\n",
        "image_to_source = mapper.mapped_to_source_from(array=dataset.data)\n",
        "\n",
        "mapper_plotter = aplt.MapperPlotter(mapper=mapper)\n",
        "mapper_plotter.plot_source_from(pixel_values=image_to_source)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Linear Algebra Matrices (Advanced)__\n",
        "\n",
        "To perform an `Inversion` a number of matrices are constructed which use linear algebra to perform the reconstruction.\n",
        "\n",
        "These are accessible in the inversion object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.curvature_matrix)\n",
        "print(inversion.regularization_matrix)\n",
        "print(inversion.curvature_reg_matrix)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Evidence Terms (Advanced)__\n",
        "\n",
        "In **HowToLens** and the papers below, we cover how an `Inversion` uses a Bayesian evidence to quantify the goodness\n",
        "of fit:\n",
        "\n",
        "https://arxiv.org/abs/1708.07377\n",
        "https://arxiv.org/abs/astro-ph/0601493\n",
        "\n",
        "This evidence balances solutions which fit the data accurately, without using an overly complex regularization source.\n",
        "\n",
        "The individual terms of the evidence and accessed via the following properties:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(inversion.regularization_term)\n",
        "print(inversion.log_det_regularization_matrix_term)\n",
        "print(inversion.log_det_curvature_reg_matrix_term)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Simulated Imaging__\n",
        "\n",
        "We load the source galaxy image from the pixelized inversion of a previous fit, which was performed on an irregular \n",
        "Rectangular or Voronoi mesh.  \n",
        "\n",
        "Since irregular meshes cannot be directly used to simulate lensed images, we interpolate the source onto a uniform \n",
        "grid with shape `interpolated_pixelized_shape`. This grid should have a high resolution (e.g., 1000 \u00d7 1000) to preserve \n",
        "all resolved structure from the original Rectangular or Voronoi mesh.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mapper = inversion.cls_list_from(cls=al.AbstractMapper)[0]\n",
        "\n",
        "mapper_valued = al.MapperValued(\n",
        "    mapper=mapper,\n",
        "    values=inversion.reconstruction_dict[mapper],\n",
        ")\n",
        "\n",
        "source_image = mapper_valued.interpolated_array_from(\n",
        "    shape_native=(1000, 1000),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To create the lensed image, we ray-trace image pixels to the source plane and interpolate them onto the source \n",
        "galaxy image.  \n",
        "\n",
        "This requires an image-plane grid of (y, x) coordinates. In this example, we use a grid with the same \n",
        "resolution as the `Imaging` dataset, but without applying a mask.  \n",
        "\n",
        "To ensure accurate ray-tracing, we apply an 8\u00d78 oversampling scheme. This means that for each pixel in the \n",
        "image-plane grid, an 8\u00d78 sub-pixel grid is ray-traced. This approach fully resolves how light is distributed \n",
        "across each simulated image pixel, given the source pixelization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=mask.shape_native,\n",
        "    pixel_scales=mask.pixel_scales,\n",
        "    over_sample_size=8,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a tracer to generate the lensed grid onto which we overlay the interpolated source galaxy image, \n",
        "producing the lensed source galaxy image.  \n",
        "\n",
        "The source-plane requires a source galaxy with a defined `redshift` for the tracer to function. Since the source\u2019s \n",
        "emission is entirely determined by the source galaxy image, this galaxy has no light profiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = al.Tracer(\n",
        "    galaxies=[\n",
        "        result.instance.galaxies.lens,\n",
        "        al.Galaxy(redshift=result.instance.galaxies.source.redshift),\n",
        "    ]\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the tracer, we generate the lensed source galaxy image on the image-plane grid. This process incorporates \n",
        "the `source_image`, preserving the irregular and asymmetric morphological features captured by the source reconstruction.  \n",
        "\n",
        "Next, we configure the grid, PSF, and simulator settings to match the signal-to-noise ratio (S/N) and noise properties \n",
        "of the observed data used for sensitivity mapping.  \n",
        "\n",
        "The `SimulatorImaging` takes the generated strong lens image and convolves it with the PSF before adding noise. To \n",
        "prevent edge effects, the image is padded before convolution and then trimmed to restore its original `shape_native`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "simulator = al.SimulatorImaging(\n",
        "    exposure_time=300.0,\n",
        "    psf=dataset.psf,\n",
        "    background_sky_level=0.1,\n",
        "    add_poisson_noise_to_data=False,\n",
        "    noise_seed=1,\n",
        ")\n",
        "\n",
        "over_sample_size = al.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "    grid=grid,\n",
        "    sub_size_list=[32, 8, 2],\n",
        "    radial_list=[0.3, 0.6],\n",
        "    centre_list=[(0.0, 0.0)],\n",
        ")\n",
        "\n",
        "grid = grid.apply_over_sampling(over_sample_size=over_sample_size)\n",
        "\n",
        "dataset = simulator.via_source_image_from(\n",
        "    tracer=tracer, grid=grid, source_image=source_image\n",
        ")\n",
        "\n",
        "plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "plotter.subplot_dataset()\n",
        "\n",
        "output = aplt.Output(path=\".\", filename=\"source_image\", format=\"png\")\n",
        "\n",
        "plotter = aplt.ImagingPlotter(\n",
        "    dataset=dataset, mat_plot_2d=aplt.MatPlot2D(output=output)\n",
        ")\n",
        "plotter.subplot_dataset()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Future Ideas / Contributions__\n",
        "\n",
        "Here are a list of things I would like to add to this tutorial but haven't found the time. If you are interested\n",
        "in having a go at adding them contact me on SLACK! :)\n",
        "\n",
        "- More magnification calculations.\n",
        "- Source gradient calculations.\n",
        "- A calculation which shows differential lensing effects (e.g. magnification across the source plane)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}