{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simulator: Start Here\n",
        "=====================\n",
        "\n",
        "This script is the starting point for simulating point source strong lens datasets, for example a lensed quasar\n",
        "or supernova, and it provides an overview of the lens simulation API.\n",
        "\n",
        "After reading this script, the `examples` folder provide examples for simulating more complex lenses in different ways.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script simulates `PointDataset` data of a strong lens where:\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal`.\n",
        " - The source `Galaxy` is a `Point`.\n",
        "\n",
        "__Pre-requisites__\n",
        "\n",
        "It is strongly recommended you read the `autolens_workspace/scripts/guides/point_sources.ipyn` notebook before\n",
        "running this script, as it gives a full overview of the point source modeling API and how lensing calculations\n",
        "are performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset Paths__\n",
        "\n",
        "The `dataset_type` describes the type of data being simulated (in this case, `PointDataset` data) and `dataset_name` \n",
        "gives it a descriptive name. They define the folder the dataset is output to on your hard-disk:\n",
        "\n",
        " - The image will be output to `/autolens_workspace/dataset/dataset_type/dataset_name/positions.json`.\n",
        " - The noise-map will be output to `/autolens_workspace/dataset/dataset_type/dataset_name/noise_map.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"point_source\"\n",
        "dataset_name = \"simple\""
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The path where the dataset will be output. \n",
        "\n",
        "In this example, this is: `/autolens_workspace/dataset/positions/simple`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_path = Path(\"dataset\") / dataset_type / dataset_name"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Ray Tracing__\n",
        "\n",
        "Setup the lens galaxy's mass (SIE) and source galaxy (a point source) for this simulated lens. \n",
        "\n",
        "We include a faint extended light profile for the source galaxy for visualization purposes, in order to show where \n",
        "the multiple images of the lensed source appear in the image-plane.\n",
        "\n",
        "For lens modeling, defining ellipticity in terms of the `ell_comps` improves the model-fitting procedure.\n",
        "\n",
        "However, for simulating a strong lens you may find it more intuitive to define the elliptical geometry using the \n",
        "axis-ratio of the profile (axis_ratio = semi-major axis / semi-minor axis = b/a) and position angle, where angle is\n",
        "in degrees and defined counter clockwise from the positive x-axis.\n",
        "\n",
        "We can use the `convert` module to determine the elliptical components from the axis-ratio and angle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lens_galaxy = al.Galaxy(\n",
        "    redshift=0.5,\n",
        "    mass=al.mp.Isothermal(\n",
        "        centre=(0.0, 0.0),\n",
        "        einstein_radius=1.6,\n",
        "        ell_comps=al.convert.ell_comps_from(axis_ratio=0.9, angle=45.0),\n",
        "    ),\n",
        ")\n",
        "\n",
        "source_galaxy = al.Galaxy(\n",
        "    redshift=1.0,\n",
        "    light=al.lp.ExponentialCore(\n",
        "        centre=(0.07, 0.07), intensity=0.1, effective_radius=0.02, radius_break=0.025\n",
        "    ),\n",
        "    point_0=al.ps.Point(centre=(0.07, 0.07)),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use these galaxies to setup a tracer, which will compute the multiple image positions of the simulated dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer = al.Tracer(galaxies=[lens_galaxy, source_galaxy])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Solver__\n",
        "\n",
        "For a point source, our goal is to find the (y, x) coordinates in the image plane that map directly to the center of \n",
        "the point source in the source plane\u2014these are its \"multiple images.\" This is achieved using a `PointSolver`, which \n",
        "determines the multiple images of the mass model for a point source located at a given (y, x) position in the \n",
        "source plane.\n",
        "\n",
        "The solver works by ray tracing triangles from the image plane back to the source plane and checking whether the \n",
        "source-plane (y, x) center lies inside each triangle. It iteratively refines this process by ray tracing progressively \n",
        "smaller triangles, allowing the multiple image positions to be determined with sub-pixel precision.\n",
        "\n",
        "The `PointSolver` requires an initial grid of (y, x) coordinates in the image plane, which defines the first set of \n",
        "triangles to ray trace. It also needs a `pixel_scale_precision` parameter, specifying the resolution at which the \n",
        "multiple images are computed. Smaller values increase precision but require longer computation times. The value \n",
        "of 0.001 used here balances efficiency and accuracy.\n",
        "\n",
        "Strong lens mass models often predict a \"central image,\" a multiple image that is usually heavily demagnified and thus \n",
        "not observed. Since the `PointSolver` finds all valid multiple images, it will locate this central image regardless of \n",
        "its visibility. To avoid including this unobservable image, we set a `magnification_threshold=0.1`, which discards any \n",
        "images with magnifications below this value.\n",
        "\n",
        "If your dataset does include a detectable central image, you should lower this threshold accordingly to include it in \n",
        "your analysis.\n",
        "\n",
        "We now compute the multiple image positions by creating a `PointSolver` object and passing it the tracer of our \n",
        "strong lens system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid = al.Grid2D.uniform(\n",
        "    shape_native=(200, 200),\n",
        "    pixel_scales=0.05,  # <- The pixel-scale describes the conversion from pixel units to arc-seconds.\n",
        ")\n",
        "\n",
        "solver = al.PointSolver.for_grid(\n",
        "    grid=grid, pixel_scale_precision=0.001, magnification_threshold=0.1\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now pass the tracer to the solver, to determine the image-plane multiple images for the source centre.\n",
        "\n",
        "The solver will find the image-plane coordinates that map directly to the source-plane coordinate (0.07\", 0.07\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions = solver.solve(\n",
        "    tracer=tracer, source_plane_coordinate=source_galaxy.point_0.centre\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Datasets__\n",
        "\n",
        "All the quantities computed above are stored in a `PointDataset` object, which organizes information about the multiple \n",
        "images of a point-source strong lens system.\n",
        "\n",
        "This dataset is labeled with the `name` `point_0`, identifying it as corresponding to a single point source called \n",
        "`point_0`. The name is essential for associating the dataset with the correct point source in the lens model during \n",
        "fitting.\n",
        "\n",
        "The dataset contains the image-plane coordinates of the multiple images and their corresponding noise-map values. \n",
        "Typically, the noise value for each position is set to the pixel scale of the CCD image, representing the area the \n",
        "point source occupies. Although sub-pixel accuracy can be achieved with more detailed analysis, this example does not \n",
        "cover those techniques.\n",
        "\n",
        "Note also that this dataset does not contain fluxes or time delays, which are often included in point source datasets\n",
        "and are included in a separate simulation below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.PointDataset(\n",
        "    name=\"point_0\",\n",
        "    positions=positions,\n",
        "    positions_noise_map=grid.pixel_scale,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now output the point dataset to the dataset path as a .json file, which is loaded in the point source modeling\n",
        "examples.\n",
        "\n",
        "In this example, there is just one point source dataset. However, for group and cluster strong lenses there\n",
        "can be many point source datasets in a single dataset, and separate .json files are output for each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "al.output_to_json(\n",
        "    obj=dataset,\n",
        "    file_path=dataset_path / \"point_dataset_positions_only.json\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Visualize__\n",
        "\n",
        "Output a subplot of the simulated point source dataset as a .png file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mat_plot_1d = aplt.MatPlot1D(output=aplt.Output(path=dataset_path, format=\"png\"))\n",
        "mat_plot_2d = aplt.MatPlot2D(output=aplt.Output(path=dataset_path, format=\"png\"))\n",
        "\n",
        "point_dataset_plotter = aplt.PointDatasetPlotter(\n",
        "    dataset=dataset, mat_plot_1d=mat_plot_1d, mat_plot_2d=mat_plot_2d\n",
        ")\n",
        "point_dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output subplots of the tracer's images, including the positions of the multiple images on the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "visuals = aplt.Visuals2D(multiple_images=positions)\n",
        "\n",
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=tracer, grid=grid, mat_plot_2d=mat_plot_2d, visuals_2d=visuals\n",
        ")\n",
        "tracer_plotter.subplot_tracer()\n",
        "tracer_plotter.subplot_galaxies_images()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Tracer json__\n",
        "\n",
        "Save the `Tracer` in the dataset folder as a .json file, ensuring the true light profiles, mass profiles and galaxies\n",
        "are safely stored and available to check how the dataset was simulated in the future. \n",
        "\n",
        "This can be loaded via the method `tracer = al.from_json()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "al.output_to_json(\n",
        "    obj=tracer,\n",
        "    file_path=dataset_path / \"tracer.json\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Imaging__\n",
        "\n",
        "Point-source data typically comes with imaging data of the strong lens, for example showing the 4 multiply\n",
        "imaged point-sources (e.g. the quasar images).\n",
        "\n",
        "Whilst this data may not be used for point-source modeling, it is often used to measure the locations of the point\n",
        "source multiple images in the first place, and is also useful for visually confirming the images we are using are in \n",
        "right place. It may also contain emission from the lens galaxy's light, which can be used to perform point-source \n",
        "modeling.\n",
        "\n",
        "We therefore simulate imaging dataset of this point source and output it to the dataset folder in an `imaging` folder\n",
        "as .fits and .png files. \n",
        "\n",
        "If you are not familiar with the imaging simulator API, checkout the `simulators/imaging/start_here.py` example \n",
        "in the `autolens_workspace`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "psf = al.Kernel2D.from_gaussian(\n",
        "    shape_native=(11, 11), sigma=0.1, pixel_scales=grid.pixel_scales\n",
        ")\n",
        "\n",
        "simulator = al.SimulatorImaging(\n",
        "    exposure_time=300.0,\n",
        "    psf=psf,\n",
        "    background_sky_level=0.1,\n",
        "    add_poisson_noise_to_data=True,\n",
        ")\n",
        "\n",
        "imaging = simulator.via_tracer_from(tracer=tracer, grid=grid)\n",
        "\n",
        "imaging_path = dataset_path / \"imaging\"\n",
        "\n",
        "mat_plot_2d = aplt.MatPlot2D(output=aplt.Output(path=imaging_path, format=\"png\"))\n",
        "\n",
        "imaging_plotter = aplt.ImagingPlotter(\n",
        "    dataset=imaging, mat_plot_2d=mat_plot_2d, visuals_2d=visuals\n",
        ")\n",
        "imaging_plotter.subplot_dataset()\n",
        "\n",
        "imaging.output_to_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    overwrite=True,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=imaging, mat_plot_2d=mat_plot_2d)\n",
        "dataset_plotter.subplot_dataset()\n",
        "dataset_plotter.figures_2d(data=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Fluxes__\n",
        "\n",
        "Another measurable quantity of a point source is its flux\u2014the total amount of light received from each multiple image of \n",
        "the point source (e.g., the quasar images).\n",
        "\n",
        "In practice, fluxes are often measured but not used directly when analyzing lensed point sources such as quasars or \n",
        "supernovae. This is because fluxes can be significantly affected by microlensing, which many lens models do not \n",
        "accurately capture. However, in this simulation, microlensing is not included, so the fluxes can be simulated and fitted reliably.\n",
        "\n",
        "We now simulate the fluxes of the multiple images of this point source.\n",
        "\n",
        "Given a mass model and the (y, x) image-plane coordinates of each image, the magnification at each point can be \n",
        "calculated.\n",
        "\n",
        "Below, we compute the magnification for every multiple image coordinate, which will then be used to simulate their \n",
        "fluxes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "magnifications = tracer.magnification_2d_via_hessian_from(grid=positions)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To simulate the fluxes, we assume the source galaxy point-source has a total flux of 1.0.\n",
        "\n",
        "Each observed image has a flux that is the source's flux multiplied by the magnification at that image-plane coordinate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "flux = 1.0\n",
        "fluxes = [flux * np.abs(magnification) for magnification in magnifications]\n",
        "fluxes = al.ArrayIrregular(values=fluxes)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The noise values of the fluxes are set to the square root of the flux, which is a common given that Poisson noise\n",
        "is expected to dominate the noise of the fluxes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fluxes_noise_map = al.ArrayIrregular(values=[np.sqrt(flux) for _ in range(len(fluxes))])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Dataset__\n",
        "\n",
        "The fluxes are not input a `PointDataset` object, alongside the image-plane coordinates of the multiple images\n",
        "and their associated noise-map values. \n",
        "\n",
        "We again give the dataset the name `point_0`, which is a label given to the dataset to indicate that it is a dataset \n",
        "of a single point-source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.PointDataset(\n",
        "    name=\"point_0\",\n",
        "    positions=positions,\n",
        "    positions_noise_map=grid.pixel_scale,\n",
        "    fluxes=fluxes,\n",
        "    fluxes_noise_map=fluxes_noise_map,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now output the point dataset to the dataset path as a .json file, which is loaded in the point source modeling\n",
        "examples.\n",
        "\n",
        "In this example, there is just one point source dataset. However, for group and cluster strong lenses there\n",
        "can be many point source datasets in a single dataset, and separate .json files are output for each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "al.output_to_json(\n",
        "    obj=dataset,\n",
        "    file_path=dataset_path / \"point_dataset_with_fluxes.json\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Time Delays__\n",
        "\n",
        "Another measurable quantity of a point source is its time delay\u2014the time it takes for light to travel from the\n",
        "source to the observer for each multiple image of the point source (e.g., the quasar images). This is often expressed\n",
        "as the relative time delay between each image and the image with the shortest time delay, which is often referred to as\n",
        "the \"reference image.\"\n",
        "\n",
        "Time delays are commonly used in strong lensing analyses, for example to measure the Hubble constant, since\n",
        "they are less affected by microlensing and can provide robust cosmological constraints.\n",
        "\n",
        "We now simulate the same point source dataset, but this time including the time delays of the multiple images.\n",
        "\n",
        "Given a mass model and (y, x) image-plane coordinates, the time delay at each image-plane position can be\n",
        "calculated from the mass model. It includes the contribution of both the geometric time delay (the time it takes\n",
        "different light rays to travel from the source to the observer) and the Shapiro time delay (the time it takes\n",
        "light to travel through the gravitational potential of the lens galaxy)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "time_delays = tracer.time_delays_from(grid=positions)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In real observations, times delays are measured by taking photometric measurements of the multiple images over time,\n",
        "aligning the light curves, and measuring the time delays between the images.\n",
        "\n",
        "This processes estimates with it uncertainties, which are often represented as noise-map values in the dataset.\n",
        "For simplicity, in this simulation we assume the time delays have a noise value which is a quarter of their\n",
        "measurement value, however it is not typical that the noise value is directly proportional to the time delay."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "time_delays_noise_map = al.ArrayIrregular(values=time_delays * 0.25)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Point Dataset__\n",
        "\n",
        "The time delays are input into a `PointDataset` object, alongside the image-plane coordinates of the multiple images\n",
        "and their associated noise-map values. \n",
        "\n",
        "We again give the dataset the name `point_0`, which is a label given to the dataset to indicate that it is a dataset \n",
        "of a single point-source."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.PointDataset(\n",
        "    name=\"point_0\",\n",
        "    positions=positions,\n",
        "    positions_noise_map=grid.pixel_scale,\n",
        "    time_delays=time_delays,\n",
        "    time_delays_noise_map=time_delays_noise_map,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now output the point dataset to the dataset path as a .json file, which can be loaded in point source modeling\n",
        "examples.\n",
        "\n",
        "While this example contains one point source dataset, group and cluster lenses can contain multiple datasets,\n",
        "with separate .json files saved for each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "al.output_to_json(\n",
        "    obj=dataset,\n",
        "    file_path=dataset_path / \"point_dataset_with_time_delays.json\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We output a final point source dataset containing the positions, fluxes and time delays, which could be used\n",
        "to perform lens modeling of all measurements simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = al.PointDataset(\n",
        "    name=\"point_0\",\n",
        "    positions=positions,\n",
        "    positions_noise_map=grid.pixel_scale,\n",
        "    fluxes=fluxes,\n",
        "    fluxes_noise_map=fluxes_noise_map,\n",
        "    time_delays=time_delays,\n",
        "    time_delays_noise_map=time_delays_noise_map,\n",
        ")\n",
        "\n",
        "al.output_to_json(\n",
        "    obj=dataset,\n",
        "    file_path=dataset_path / \"point_dataset_with_fluxes_and_time_delays.json\",\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}