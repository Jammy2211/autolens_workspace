{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Modeling Features: Dataset Offsets\n",
        "==================================\n",
        "\n",
        "Multi-wavelength datasets often have offsets between their images, which are due to the different telescope pointings\n",
        "during the observations.\n",
        "\n",
        "These offsets are often accounted for during the data reduction process, which aligns the images, however:\n",
        "\n",
        " - Certain data reduction pipelines may not perfectly align the images, and the scientist may be unsure what the\n",
        " true offset between the images are.\n",
        "\n",
        " - Even if the reduction process does align the images, there is still a small uncertainty in the offset due to the\n",
        "   precision of the telescope pointing which for detailed lens models must be accounted for.\n",
        "\n",
        "This script shows how to include an offset in the model, which is two free parameters, the y and x offsets, for every\n",
        "additional dataset after the first dataset. The offset therefore describes the offset of each dataset in the\n",
        "multi-wavelength dataset relative to the first dataset.\n",
        "\n",
        "To apply the offset, the code simply subtracts the offset from the grids aligned to the dataset pixels before performing\n",
        "lensing calculations. This means that the light and mass model centres do not change when the offset is applied, only\n",
        "the coordinates of the image pixels which are input into these profiles to compute the images.\n",
        "\n",
        "__Advantages__\n",
        "\n",
        "If one fits a lens model to one dataset and applies it to other datasets, it is common to see the lens model fit\n",
        "and source reconsturction degrade due to small offsets between the datasets. The same issue persists for simultaneous\n",
        "fits to multiple datasets, even when care has been taken to align the datasets.\n",
        "\n",
        "The advantage is therefore simple, for most multi-wavelength lens modeling, accounting for offsets in this way\n",
        "is the only way to ensure the lens model is accurate and the source reconstruction is reliable.\n",
        "\n",
        "__Disadvantages__\n",
        "\n",
        "Each offset introduces two additional free parameters into the model for each dataset after the first dataset. For\n",
        "4 datasets, this is 6 additional free parameters. This increases the dimensionality of the non-linear parameter space\n",
        "and therefore the computational run-time of the model-fit.\n",
        "\n",
        "__Model__\n",
        "\n",
        "This script fits an `Imaging` dataset of a 'galaxy-scale' strong lens with a model where:\n",
        "\n",
        " - The lens galaxy's light is a an MGE bulge.\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear`.\n",
        " - The source galaxy's light is a an MGE.\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `modeling/start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Colors__\n",
        "\n",
        "The colors of the multi-wavelength image, which in this case are green (g-band) and red (r-band).\n",
        "\n",
        "The strings are used for load each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "waveband_list = [\"g\", \"r\"]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Pixel Scales__\n",
        "\n",
        "Every multi-wavelength dataset can have its own unique pixel-scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pixel_scales_list = [0.08, 0.12]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "Load and plot each multi-wavelength strong lens dataset, using a list of their waveband colors.\n",
        "\n",
        "The plotted images show that the datasets have a small offset between them, half a pixel based on the resolution of\n",
        "the second image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_type = \"multi\"\n",
        "dataset_label = \"imaging\"\n",
        "dataset_name = \"dataset_offsets\"\n",
        "\n",
        "dataset_path = Path(\"dataset\") / dataset_type / dataset_label / dataset_name\n",
        "\n",
        "dataset_list = [\n",
        "    al.Imaging.from_fits(\n",
        "        data_path=Path(dataset_path) / f\"{waveband}_data.fits\",\n",
        "        psf_path=Path(dataset_path) / f\"{waveband}_psf.fits\",\n",
        "        noise_map_path=Path(dataset_path) / f\"{waveband}_noise_map.fits\",\n",
        "        pixel_scales=pixel_scales,\n",
        "    )\n",
        "    for waveband, pixel_scales in zip(waveband_list, pixel_scales_list)\n",
        "]\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Mask__\n",
        "\n",
        "Define a 3.0\" circular mask, which includes the emission of the lens and source galaxies.\n",
        "\n",
        "For multi-wavelength lens modeling, we use the same mask for every dataset whenever possible. This is not\n",
        "absolutely necessary, but provides a more reliable analysis.\n",
        "\n",
        "The small offset between datasets means that the mask may not contain the exact same area of the image for every\n",
        "dataset. \n",
        "\n",
        "For this dataset's offset of half a pixel (and anything of order a few pixels) this is fine and wont impact the analysis. \n",
        "However, for larger offsets the mask may need to be adjusted to ensure the same image area is masked out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_radius = 3.0\n",
        "\n",
        "mask_list = [\n",
        "    al.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native,\n",
        "        pixel_scales=dataset.pixel_scales,\n",
        "        radius=mask_radius,\n",
        "    )\n",
        "    for dataset in dataset_list\n",
        "]\n",
        "\n",
        "dataset_list = [\n",
        "    dataset.apply_mask(mask=mask) for imaging, mask in zip(dataset_list, mask_list)\n",
        "]\n",
        "\n",
        "for dataset in dataset_list:\n",
        "    dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "    dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Analysis__\n",
        "\n",
        "We create an `Analysis` object for every dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [al.AnalysisImaging(dataset=dataset) for dataset in dataset_list]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "We compose a lens model where:\n",
        "\n",
        " - Parameters which shift the second dataset's image (y_offset_0, x_offset_0) relative to the first dataset's image\n",
        " are included via the `DatasetModel` object [2 parameters].\n",
        "\n",
        " - The lens galaxy's light is an MGE with 1 x 20 Gaussians [6 parameters].\n",
        "\n",
        " - The lens galaxy's total mass distribution is an `Isothermal` and `ExternalShear` [7 parameters].\n",
        "\n",
        " - The source galaxy's light is an MGE with 1 x 20 Gaussians [4 parameters].\n",
        "\n",
        "The number of free parameters and therefore the dimensionality of non-linear parameter space is N=23."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius,\n",
        "    total_gaussians=20,\n",
        "    gaussian_per_basis=1,\n",
        "    centre_prior_is_uniform=True,\n",
        ")\n",
        "\n",
        "lens = af.Model(\n",
        "    al.Galaxy,\n",
        "    redshift=0.5,\n",
        "    bulge=bulge,\n",
        "    mass=al.mp.Isothermal,\n",
        "    shear=al.mp.ExternalShear,\n",
        ")\n",
        "\n",
        "bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius,\n",
        "    total_gaussians=20,\n",
        "    gaussian_per_basis=1,\n",
        "    centre_prior_is_uniform=False,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=bulge)\n",
        "\n",
        "dataset_model = af.Model(al.DatasetModel)\n",
        "\n",
        "model = af.Collection(\n",
        "    dataset_model=dataset_model, galaxies=af.Collection(lens=lens, source=source)\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `DatasetModel` can apply a shift to each dataset, however we do not want this to be applied to both\n",
        "datasets as they will then both have free parameters for the same offset, duplicating free parameters.\n",
        "\n",
        "The default prior on a `DatasetModel`'s offsets are actually not a prior, but fixed values of (0.0, 0.0),\n",
        "meaning that if we do not update the model the shift will not be applied to the datasets.\n",
        "\n",
        "We therefore update the `DatasetModel` below, to only apply a shift to the second dataset, which is the r-band image.\n",
        "\n",
        "If we add more datasets, the code will apply the shift to each one after the first dataset, which are all shifted\n",
        "relative to the first dataset, making it the reference point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_factor_list = []\n",
        "\n",
        "for i, analysis in enumerate(analysis_list):\n",
        "    model_analysis = model.copy()\n",
        "\n",
        "    if i > 0:\n",
        "        model_analysis.dataset_model.grid_offset.grid_offset_0 = af.UniformPrior(\n",
        "            lower_limit=-1.0, upper_limit=1.0\n",
        "        )\n",
        "        model_analysis.dataset_model.grid_offset.grid_offset_1 = af.UniformPrior(\n",
        "            lower_limit=-1.0, upper_limit=1.0\n",
        "        )\n",
        "\n",
        "    analysis_factor = af.AnalysisFactor(prior_model=model, analysis=analysis)\n",
        "\n",
        "    analysis_factor_list.append(analysis_factor)\n",
        "\n",
        "factor_graph = af.FactorGraphModel(*analysis_factor_list, use_jax=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Search__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"multi\", \"modeling\"),\n",
        "    name=\"dataset_offsets\",\n",
        "    unique_tag=dataset_name,\n",
        "    n_live=100,\n",
        "    n_batch=50,  # GPU lens model fits are batched and run simultaneously, see VRAM section below.\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model-Fit__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "result_list = search.fit(model=factor_graph.global_prior_model, analysis=factor_graph)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "The result object returned by this model-fit is a list of `Result` objects, because we used a factor graph.\n",
        "Each result corresponds to each analysis, and therefore corresponds to the model-fit at that wavelength."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result_list[0].max_log_likelihood_instance)\n",
        "print(result_list[1].max_log_likelihood_instance)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting each result's tracer shows that the source appears different, owning to its different intensities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for result in result_list:\n",
        "    tracer_plotter = aplt.TracerPlotter(\n",
        "        tracer=result.max_log_likelihood_tracer, grid=result.grids.lp\n",
        "    )\n",
        "    tracer_plotter.subplot_tracer()\n",
        "\n",
        "    fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "    fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `Samples` object still has the dimensions of the overall non-linear search (in this case N=15). \n",
        "\n",
        "Therefore, the samples is identical in every result object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for result in result_list:\n",
        "    plotter = aplt.NestPlotter(samples=result.samples)\n",
        "    plotter.corner_anesthetic()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checkout `autolens_workspace/*/guides/results` for a full description of analysing results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}