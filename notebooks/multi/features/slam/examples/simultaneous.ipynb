{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SLaM: Multi Wavelength Simultaneous\n",
        "===================================\n",
        "\n",
        "This example shows how to use the SLaM pipeline to fit a lens dataset at multiple wavelengths simultaneously.\n",
        "\n",
        "Simultaneous multi-dataset fits are currently built into the SLaM pipeline without user input or customization.\n",
        "Therefore, as long as lists of `Analysis` objects are created, summed and passed to the SLaM pipelines, the analysis\n",
        "will fit every dataset simultaneously and it will adapt the model as follows:\n",
        "\n",
        "- Sub-pixel offsets between the datasets are fully modeled as free parameters in each stage of the pipeline, assuming\n",
        "  broad uniform priors for every step. This is because the precision of a lens model can often be less than the\n",
        "  requirements on astrometry.\n",
        "\n",
        "- The regularization parameters are free for every dataset in the `source_pix[1]` and `source_pix[2]` stages. This is because\n",
        "  the source morphology can be different between datasets, and the regularization scheme adapts to this.\n",
        "\n",
        "- From the `light_lp` stage onwards, the regularization scheme for each dataset is different fixed to that inferred\n",
        "  for the `source_pix[2]` stage.\n",
        "\n",
        "Simultaneous fitting SLaM pipelines are not designed for customization, for example changing the model from the\n",
        "set up above. This is because we are still figuring out the best way to perform multi-wavelength modeling, but have\n",
        "so far figured the above settings are important.\n",
        "\n",
        "If you need customization of the model or pipeline, you should pick apart the SLaM pipeline and customize\n",
        "them as you see fit.\n",
        "\n",
        "__Preqrequisites__\n",
        "\n",
        "Before reading this script, you should have familiarity with the following key concepts:\n",
        "\n",
        "- **Multi**: The `autolens_workspace/*/advanced/multi` package describes many different ways that multiple datasets\n",
        "  can be modeled in a single analysis.\n",
        "\n",
        "__This Script__\n",
        "\n",
        "Using a SOURCE LP PIPELINE, SOURCE PIX PIPELINE, LIGHT LP PIPELINE and TOTAL MASS PIPELINE this SLaM modeling\n",
        "script  fits `Imaging` dataset  of a strong lens system where in the final model:\n",
        "\n",
        " - The lens galaxy's light is a bulge with Multiple Gaussian Expansion (MGE) light profile.\n",
        " - The lens galaxy's total mass distribution is an `PowerLaw` plus an `ExternalShear`.\n",
        " - The source galaxy's light is a `Pixelization`.\n",
        "\n",
        "This modeling script uses the SLaM pipelines:\n",
        "\n",
        " `source_lp`\n",
        " `source_pix`\n",
        " `light_lp`\n",
        " `mass_total`\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `guides/modeling/slam_start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "\n",
        "sys.path.insert(0, os.getcwd())\n",
        "from scripts.advanced.multi import slam_pipeline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__ \n",
        "\n",
        "Load, plot and mask the `Imaging` data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_waveband_list = [\"g\", \"r\"]\n",
        "pixel_scale_list = [0.12, 0.08]\n",
        "\n",
        "dataset_name = \"lens_sersic\"\n",
        "dataset_main_path = Path(\"dataset\", \"multi\", \"imaging\", dataset_name)\n",
        "dataset_path = Path(dataset_main_path, dataset_name)\n",
        "\n",
        "\n",
        "dataset_list = []\n",
        "\n",
        "for dataset_waveband, pixel_scale in zip(dataset_waveband_list, pixel_scale_list):\n",
        "    dataset = al.Imaging.from_fits(\n",
        "        data_path=Path(dataset_main_path, f\"{dataset_waveband}_data.fits\"),\n",
        "        noise_map_path=Path(dataset_main_path, f\"{dataset_waveband}_noise_map.fits\"),\n",
        "        psf_path=Path(dataset_main_path, f\"{dataset_waveband}_psf.fits\"),\n",
        "        pixel_scales=pixel_scale,\n",
        "    )\n",
        "\n",
        "    mask_radius = 3.0\n",
        "\n",
        "    mask = al.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native,\n",
        "        pixel_scales=dataset.pixel_scales,\n",
        "        radius=mask_radius,\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "    over_sample_size = al.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "        grid=dataset.grid,\n",
        "        sub_size_list=[4, 2, 1],\n",
        "        radial_list=[0.3, 0.6],\n",
        "        centre_list=[(0.0, 0.0)],\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)\n",
        "\n",
        "    dataset_list.append(dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Settings AutoFit__\n",
        "\n",
        "The settings of autofit, which controls the output paths, parallelization, database use, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings_search = af.SettingsSearch(\n",
        "    path_prefix=Path(\"slam\", \"multi\", \"simultaneous\"),\n",
        "    unique_tag=dataset_name,\n",
        "    info=None,\n",
        "    session=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Redshifts__\n",
        "\n",
        "The redshifts of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "redshift_lens = 0.5\n",
        "redshift_source = 1.0"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE LP PIPELINE__\n",
        "\n",
        "The SOURCE LP PIPELINE fits an identical to the `start_here.ipynb` example, except:\n",
        "\n",
        " - The model includes the (y,x) offset of each dataset relative to the first dataset, which is added to every\n",
        "  `AnalysisImaging` object such that there are 2 extra parameters fitted for each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Lens Light\n",
        "\n",
        "centre_0 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "centre_1 = af.GaussianPrior(mean=0.0, sigma=0.1)\n",
        "\n",
        "total_gaussians = 30\n",
        "gaussian_per_basis = 2\n",
        "\n",
        "log10_sigma_list = np.linspace(-2, np.log10(mask_radius), total_gaussians)\n",
        "\n",
        "bulge_gaussian_list = []\n",
        "\n",
        "for j in range(gaussian_per_basis):\n",
        "    gaussian_list = af.Collection(\n",
        "        af.Model(al.lp_linear.Gaussian) for _ in range(total_gaussians)\n",
        "    )\n",
        "\n",
        "    for i, gaussian in enumerate(gaussian_list):\n",
        "        gaussian.centre.centre_0 = centre_0\n",
        "        gaussian.centre.centre_1 = centre_1\n",
        "        gaussian.ell_comps = gaussian_list[0].ell_comps\n",
        "        gaussian.sigma = 10 ** log10_sigma_list[i]\n",
        "\n",
        "    bulge_gaussian_list += gaussian_list\n",
        "\n",
        "lens_bulge = af.Model(\n",
        "    al.lp_basis.Basis,\n",
        "    profile_list=bulge_gaussian_list,\n",
        ")\n",
        "\n",
        "# Source Light\n",
        "\n",
        "centre_0 = af.GaussianPrior(mean=0.0, sigma=0.3)\n",
        "centre_1 = af.GaussianPrior(mean=0.0, sigma=0.3)\n",
        "\n",
        "total_gaussians = 30\n",
        "gaussian_per_basis = 1\n",
        "\n",
        "log10_sigma_list = np.linspace(-3, np.log10(1.0), total_gaussians)\n",
        "\n",
        "bulge_gaussian_list = []\n",
        "\n",
        "for j in range(gaussian_per_basis):\n",
        "    gaussian_list = af.Collection(\n",
        "        af.Model(al.lp_linear.Gaussian) for _ in range(total_gaussians)\n",
        "    )\n",
        "\n",
        "    for i, gaussian in enumerate(gaussian_list):\n",
        "        gaussian.centre.centre_0 = centre_0\n",
        "        gaussian.centre.centre_1 = centre_1\n",
        "        gaussian.ell_comps = gaussian_list[0].ell_comps\n",
        "        gaussian.sigma = 10 ** log10_sigma_list[i]\n",
        "\n",
        "    bulge_gaussian_list += gaussian_list\n",
        "\n",
        "source_bulge = af.Model(\n",
        "    al.lp_basis.Basis,\n",
        "    profile_list=bulge_gaussian_list,\n",
        ")\n",
        "\n",
        "analysis_list = [\n",
        "    al.AnalysisImaging(dataset=dataset, use_jax=True) for dataset in dataset_list\n",
        "]\n",
        "\n",
        "source_lp_result = slam_pipeline.source_lp.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    lens_bulge=lens_bulge,\n",
        "    lens_disk=None,\n",
        "    mass=af.Model(al.mp.Isothermal),\n",
        "    shear=af.Model(al.mp.ExternalShear),\n",
        "    source_bulge=source_bulge,\n",
        "    mass_centre=(0.0, 0.0),\n",
        "    redshift_lens=redshift_lens,\n",
        "    redshift_source=redshift_source,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE PIX PIPELINE__\n",
        "\n",
        "The SOURCE PIX PIPELINE uses two searches to initialize a robust model for the `Pixelization` that\n",
        "reconstructs the source galaxy's light. \n",
        "\n",
        "This pixelization adapts its source pixels to the morphology of the source, placing more pixels in its \n",
        "brightest regions. To do this, an \"adapt image\" is required, which is the lens light subtracted image meaning\n",
        "only the lensed source emission is present.\n",
        "\n",
        "The SOURCE LP Pipeline result is not good enough quality to set up this adapt image (e.g. the source\n",
        "may be more complex than a simple light profile). The first step of the SOURCE PIX PIPELINE therefore fits a new\n",
        "model using a pixelization to create this adapt image.\n",
        "\n",
        "The first search, which is an initialization search, fits an `Overlay` image-mesh, `RectangularMagnification` mesh \n",
        "and `AdaptiveBrightnessSplit` regularization.\n",
        "\n",
        "__Adapt Images / Image Mesh Settings__\n",
        "\n",
        "If you are unclear what the `adapt_images` and `SettingsInversion` inputs are doing below, refer to the \n",
        "`autolens_workspace/*/guides/modeling/chaining/pix_adapt/start_here.py` example script.\n",
        "\n",
        "__Settings__:\n",
        "\n",
        " - Positions: We update the positions and positions threshold using the previous model-fitting result (as described \n",
        " in `chaining/examples/parametric_to_pixelization.py`) to remove unphysical solutions from the `Inversion` model-fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions_likelihood = source_lp_result.positions_likelihood_from(\n",
        "    factor=3.0, minimum_threshold=0.2\n",
        ")\n",
        "\n",
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_image_maker=al.AdaptImageMaker(result=result),\n",
        "        positions_likelihood_list=[positions_likelihood],\n",
        "        use_jax=True,\n",
        "    )\n",
        "    for result in source_lp_result\n",
        "]\n",
        "\n",
        "source_pix_result_1 = slam_pipeline.source_pix.run_1(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    source_lp_result=source_lp_result,\n",
        "    mesh_init=al.mesh.RectangularMagnification,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE PIX PIPELINE 2 (with lens light)__\n",
        "\n",
        "The second search, which uses the mesh and regularization used throughout the remainder of the slam_graph pipelines,\n",
        "fits the following model:\n",
        "\n",
        "- Uses a `Hilbert` image-mesh. \n",
        "\n",
        "- Uses a `RectangularMagnification` mesh.\n",
        "\n",
        " - Uses an `AdaptiveBrightnessSplit` regularization.\n",
        "\n",
        " - Carries the lens redshift, source redshift and `ExternalShear` of the SOURCE LP PIPELINE through to the\n",
        " SOURCE PIX PIPELINE.\n",
        "\n",
        "The `Hilbert` image-mesh and `AdaptiveBrightness` regularization adapt the source pixels and regularization weights\n",
        "to the source's morphology.\n",
        "\n",
        "Below, we therefore set up the adapt image using this result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_image_maker=al.AdaptImageMaker(result=result),\n",
        "        settings_inversion=al.SettingsInversion(\n",
        "            image_mesh_min_mesh_pixels_per_pixel=3,\n",
        "            image_mesh_min_mesh_number=5,\n",
        "            image_mesh_adapt_background_percent_threshold=0.1,\n",
        "            image_mesh_adapt_background_percent_check=0.8,\n",
        "        ),\n",
        "        use_jax=True,\n",
        "    )\n",
        "    for result in source_pix_result_1\n",
        "]\n",
        "\n",
        "source_pix_result_2 = slam_pipeline.source_pix.run_2(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    source_lp_result=source_lp_result,\n",
        "    source_pix_result_1=source_pix_result_1,\n",
        "    image_mesh=al.image_mesh.Hilbert,\n",
        "    mesh=al.mesh.RectangularMagnification,\n",
        "    regularization=al.reg.AdaptiveBrightnessSplit,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__LIGHT LP PIPELINE__\n",
        "\n",
        "The LIGHT LP PIPELINE uses one search to fit a complex lens light model to a high level of accuracy, using the\n",
        "lens mass model and source light model fixed to the maximum log likelihood result of the SOURCE LP PIPELINE.\n",
        "In this example it:\n",
        "\n",
        " - The lens galaxy's light is a MGE with 2 x 30 Gaussian [6 parameters] [6 Free Parameters].\n",
        "\n",
        " - Uses an `Isothermal` mass model with `ExternalShear` for the lens's total mass distribution [fixed from SOURCE PIX PIPELINE].\n",
        "\n",
        " - Uses a `Pixelization` for the source's light [fixed from SOURCE PIX PIPELINE].\n",
        "\n",
        " - Carries the lens redshift and source redshift of the SOURCE PIPELINE through to the MASS PIPELINE [fixed values].   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_image_maker=al.AdaptImageMaker(result=result),\n",
        "        raise_inversion_positions_likelihood_exception=False,\n",
        "    )\n",
        "    for result in source_pix_result_1\n",
        "]\n",
        "\n",
        "centre_0 = af.UniformPrior(lower_limit=-0.2, upper_limit=0.2)\n",
        "centre_1 = af.UniformPrior(lower_limit=-0.2, upper_limit=0.2)\n",
        "\n",
        "total_gaussians = 30\n",
        "gaussian_per_basis = 2\n",
        "\n",
        "log10_sigma_list = np.linspace(-2, np.log10(mask_radius), total_gaussians)\n",
        "\n",
        "bulge_gaussian_list = []\n",
        "\n",
        "for j in range(gaussian_per_basis):\n",
        "    gaussian_list = af.Collection(\n",
        "        af.Model(al.lp_linear.Gaussian) for _ in range(total_gaussians)\n",
        "    )\n",
        "\n",
        "    for i, gaussian in enumerate(gaussian_list):\n",
        "        gaussian.centre.centre_0 = centre_0\n",
        "        gaussian.centre.centre_1 = centre_1\n",
        "        gaussian.ell_comps = gaussian_list[0].ell_comps\n",
        "        gaussian.sigma = 10 ** log10_sigma_list[i]\n",
        "\n",
        "    bulge_gaussian_list += gaussian_list\n",
        "\n",
        "lens_bulge = af.Model(\n",
        "    al.lp_basis.Basis,\n",
        "    profile_list=bulge_gaussian_list,\n",
        ")\n",
        "\n",
        "light_result = slam_pipeline.light_lp.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    source_result_for_lens=source_pix_result_1,\n",
        "    source_result_for_source=source_pix_result_2,\n",
        "    lens_bulge=lens_bulge,\n",
        "    lens_disk=None,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__MASS TOTAL PIPELINE__\n",
        "\n",
        "The MASS TOTAL PIPELINE uses one search to fits a complex lens mass model to a high level of accuracy, \n",
        "using the lens mass model and source model of the SOURCE PIX PIPELINE to initialize the model priors and the lens \n",
        "light model of the LIGHT LP PIPELINE. \n",
        "\n",
        "In this example it:\n",
        "\n",
        " - Uses a linear Multi Gaussian Expansion bulge [fixed from LIGHT LP PIPELINE].\n",
        "\n",
        " - Uses an `PowerLaw` model for the lens's total mass distribution [priors initialized from SOURCE \n",
        " LIGHT PROFILE PIPELINE + centre unfixed from (0.0, 0.0)].\n",
        "\n",
        " - Uses a `Pixelization` for the source's light [fixed from SOURCE PIX PIPELINE].\n",
        "\n",
        " - Carries the lens redshift and source redshift of the SOURCE PIPELINE through to the MASS TOTAL PIPELINE.\n",
        "\n",
        "__Settings__:\n",
        "\n",
        " - adapt: We may be using adapt features and therefore pass the result of the SOURCE PIX PIPELINE to use as the\n",
        " hyper dataset if required.\n",
        "\n",
        " - Positions: We update the positions and positions threshold using the previous model-fitting result (as described \n",
        " in `chaining/examples/parametric_to_pixelization.py`) to remove unphysical solutions from the `Inversion` model-fitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions_likelihood = source_pix_result_1[0].positions_likelihood_from(\n",
        "    factor=3.0, minimum_threshold=0.2\n",
        ")\n",
        "\n",
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_image_maker=al.AdaptImageMaker(result=result),\n",
        "        positions_likelihood_list=[positions_likelihood],\n",
        "    )\n",
        "    for result in source_pix_result_1\n",
        "]\n",
        "\n",
        "mass_result = slam_pipeline.mass_total.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    source_result_for_lens=source_pix_result_1,\n",
        "    source_result_for_source=source_pix_result_2,\n",
        "    light_result=light_result,\n",
        "    mass=af.Model(al.mp.PowerLaw),\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SUBHALO PIPELINE (single plane detection)__\n",
        "\n",
        "The SUBHALO PIPELINE (single plane detection) consists of the following searches:\n",
        "\n",
        " 1) Refit the lens and source model, to refine the model evidence for comparing to the models fitted which include a \n",
        " subhalo. This uses the same model as fitted in the MASS PIPELINE. \n",
        " 2) Performs a grid-search of non-linear searches to attempt to detect a dark matter subhalo. \n",
        " 3) If there is a successful detection a final search is performed to refine its parameters.\n",
        "\n",
        "For this runner the SUBHALO PIPELINE customizes:\n",
        "\n",
        " - The [number_of_steps x number_of_steps] size of the grid-search, as well as the dimensions it spans in arc-seconds.\n",
        " - The `number_of_cores` used for the gridsearch, where `number_of_cores > 1` performs the model-fits in paralle using\n",
        " the Python multiprocessing module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_image_maker=al.AdaptImageMaker(result=result),\n",
        "        positions_likelihood_list=[positions_likelihood],\n",
        "    )\n",
        "    for result in source_pix_result_1\n",
        "]\n",
        "\n",
        "subhalo_result_1 = slam_pipeline.subhalo.detection.run_1_no_subhalo(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    mass_result=mass_result,\n",
        ")\n",
        "\n",
        "subhalo_grid_search_result_2 = slam_pipeline.subhalo.detection.run_2_grid_search(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    mass_result=mass_result,\n",
        "    subhalo_result_1=subhalo_result_1,\n",
        "    subhalo_mass=af.Model(al.mp.NFWMCRLudlowSph),\n",
        "    grid_dimension_arcsec=3.0,\n",
        "    number_of_steps=2,\n",
        ")\n",
        "\n",
        "subhalo_result_3 = slam_pipeline.subhalo.detection.run_3_subhalo(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    subhalo_result_1=subhalo_result_1,\n",
        "    subhalo_grid_search_result_2=subhalo_grid_search_result_2,\n",
        "    subhalo_mass=af.Model(al.mp.NFWMCRLudlowSph),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}