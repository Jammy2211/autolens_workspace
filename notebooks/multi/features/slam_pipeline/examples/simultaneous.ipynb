{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SLaM: Multi Wavelength Simultaneous\n",
        "===================================\n",
        "\n",
        "This example shows how to use the SLaM pipeline to fit a lens dataset at multiple wavelengths simultaneously.\n",
        "\n",
        "Simultaneous multi-dataset fits are currently built into the SLaM pipeline without user input or customization.\n",
        "Therefore, as long as lists of `Analysis` objects are created, summed and passed to the SLaM pipelines, the analysis\n",
        "will fit every dataset simultaneously and it will adapt the model as follows:\n",
        "\n",
        "- Sub-pixel offsets between the datasets are fully modeled as free parameters in each stage of the pipeline, assuming\n",
        "  broad uniform priors for every step. This is because the precision of a lens model can often be less than the\n",
        "  requirements on astrometry.\n",
        "\n",
        "- The regularization parameters are free for every dataset in the `source_pix[1]` and `source_pix[2]` stages. This is because\n",
        "  the source morphology can be different between datasets, and the regularization scheme adapts to this.\n",
        "\n",
        "- From the `light_lp` stage onwards, the regularization scheme for each dataset is different fixed to that inferred\n",
        "  for the `source_pix[2]` stage.\n",
        "\n",
        "Simultaneous fitting SLaM pipelines are not designed for customization, for example changing the model from the\n",
        "set up above. This is because we are still figuring out the best way to perform multi-wavelength modeling, but have\n",
        "so far figured the above settings are important.\n",
        "\n",
        "If you need customization of the model or pipeline, you should pick apart the SLaM pipeline and customize\n",
        "them as you see fit.\n",
        "\n",
        "__Preqrequisites__\n",
        "\n",
        "Before reading this script, you should have familiarity with the following key concepts:\n",
        "\n",
        "- **Multi**: The `autolens_workspace/*/advanced/multi` package describes many different ways that multiple datasets\n",
        "  can be modeled in a single analysis.\n",
        "\n",
        "__This Script__\n",
        "\n",
        "Using a SOURCE LP PIPELINE, SOURCE PIX PIPELINE, LIGHT LP PIPELINE and TOTAL MASS PIPELINE this SLaM modeling\n",
        "script  fits `Imaging` dataset  of a strong lens system where in the final model:\n",
        "\n",
        " - The lens galaxy's light is a bulge with Multiple Gaussian Expansion (MGE) light profile.\n",
        " - The lens galaxy's total mass distribution is an `PowerLaw` plus an `ExternalShear`.\n",
        " - The source galaxy's light is a `Pixelization`.\n",
        "\n",
        "This modeling script uses the SLaM pipelines:\n",
        "\n",
        " `source_lp`\n",
        " `source_pix`\n",
        " `light_lp`\n",
        " `mass_total`\n",
        "\n",
        "__Start Here Notebook__\n",
        "\n",
        "If any code in this script is unclear, refer to the `guides/modeling/slam_start_here.ipynb` notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from autoconf import jax_wrapper  # Sets JAX environment before other imports\n",
        "\n",
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt\n",
        "\n",
        "sys.path.insert(0, os.getcwd())\n",
        "from scripts.multi.features import slam_pipeline"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__ \n",
        "\n",
        "Load, plot and mask the `Imaging` data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_waveband_list = [\"g\", \"r\"]\n",
        "pixel_scale_list = [0.12, 0.08]\n",
        "\n",
        "dataset_name = \"lens_sersic\"\n",
        "dataset_main_path = Path(\"dataset\", \"multi\", \"imaging\", dataset_name)\n",
        "dataset_path = Path(dataset_main_path, dataset_name)\n",
        "\n",
        "\n",
        "dataset_list = []\n",
        "\n",
        "for dataset_waveband, pixel_scale in zip(dataset_waveband_list, pixel_scale_list):\n",
        "    dataset = al.Imaging.from_fits(\n",
        "        data_path=Path(dataset_main_path, f\"{dataset_waveband}_data.fits\"),\n",
        "        noise_map_path=Path(dataset_main_path, f\"{dataset_waveband}_noise_map.fits\"),\n",
        "        psf_path=Path(dataset_main_path, f\"{dataset_waveband}_psf.fits\"),\n",
        "        pixel_scales=pixel_scale,\n",
        "    )\n",
        "\n",
        "    mask_radius = 3.0\n",
        "\n",
        "    mask = al.Mask2D.circular(\n",
        "        shape_native=dataset.shape_native,\n",
        "        pixel_scales=dataset.pixel_scales,\n",
        "        radius=mask_radius,\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "    over_sample_size = al.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "        grid=dataset.grid,\n",
        "        sub_size_list=[4, 2, 1],\n",
        "        radial_list=[0.3, 0.6],\n",
        "        centre_list=[(0.0, 0.0)],\n",
        "    )\n",
        "\n",
        "    dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)\n",
        "\n",
        "    dataset_list.append(dataset)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Settings AutoFit__\n",
        "\n",
        "The settings of autofit, which controls the output paths, parallelization, database use, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "settings_search = af.SettingsSearch(\n",
        "    path_prefix=Path(\"slam\", \"multi\", \"simultaneous\"),\n",
        "    unique_tag=dataset_name,\n",
        "    info=None,\n",
        "    session=None,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Redshifts__\n",
        "\n",
        "The redshifts of the lens and source galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "redshift_lens = 0.5\n",
        "redshift_source = 1.0"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE LP PIPELINE__\n",
        "\n",
        "The SOURCE LP PIPELINE fits an identical to the `start_here.ipynb` example, except:\n",
        "\n",
        " - The model includes the (y,x) offset of each dataset relative to the first dataset, which is added to every\n",
        "  `AnalysisImaging` object such that there are 2 extra parameters fitted for each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# Lens Light\n",
        "\n",
        "lens_bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius,\n",
        "    total_gaussians=20,\n",
        "    gaussian_per_basis=2,\n",
        "    centre_prior_is_uniform=True,\n",
        ")\n",
        "\n",
        "# Source Light\n",
        "\n",
        "source_bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius, total_gaussians=20, centre_prior_is_uniform=False\n",
        ")\n",
        "\n",
        "analysis_list = [\n",
        "    al.AnalysisImaging(dataset=dataset, use_jax=True) for dataset in dataset_list\n",
        "]\n",
        "\n",
        "source_lp_result = slam_pipeline.source_lp.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    lens_bulge=lens_bulge,\n",
        "    lens_disk=None,\n",
        "    mass=af.Model(al.mp.Isothermal),\n",
        "    shear=af.Model(al.mp.ExternalShear),\n",
        "    source_bulge=source_bulge,\n",
        "    mass_centre=(0.0, 0.0),\n",
        "    redshift_lens=redshift_lens,\n",
        "    redshift_source=redshift_source,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__JAX & Preloads__\n",
        "\n",
        "The `autolens_workspace/*/imaging/features/pixelization/modeling` example describes how JAX required preloads in\n",
        "advance so it knows the shape of arrays it must compile functions for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mesh_shape = (20, 20)\n",
        "total_mapper_pixels = mesh_shape[0] * mesh_shape[1]\n",
        "\n",
        "total_linear_light_profiles = 40\n",
        "\n",
        "preloads = al.Preloads(\n",
        "    mapper_indices=al.mapper_indices_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        total_mapper_pixels=total_mapper_pixels,\n",
        "    ),\n",
        "    source_pixel_zeroed_indices=al.util.mesh.rectangular_edge_pixel_list_from(\n",
        "        total_linear_light_profiles=total_linear_light_profiles,\n",
        "        shape_native=mesh_shape,\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE PIX PIPELINE__\n",
        "\n",
        "The SOURCE PIX PIPELINE is identical to the `slam_start_here.ipynb` example, except:\n",
        "\n",
        "- The model includes the (y,x) dataset offsets again.\n",
        "\n",
        "- Inside the SLaM pipeline, a unique regularization scheme is set up for every source pixelization, as different\n",
        "  wavelengh datasets required different regularization schemes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions_likelihood = source_lp_result.positions_likelihood_from(\n",
        "    factor=3.0, minimum_threshold=0.2\n",
        ")\n",
        "\n",
        "adapt_images_list = []\n",
        "\n",
        "for result in source_lp_result:\n",
        "\n",
        "    galaxy_image_name_dict = al.galaxy_name_image_dict_via_result_from(result=result)\n",
        "    adapt_images = al.AdaptImages(galaxy_name_image_dict=galaxy_image_name_dict)\n",
        "\n",
        "    adapt_images_list.append(adapt_images)\n",
        "\n",
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_images=adapt_images,\n",
        "        positions_likelihood_list=[positions_likelihood],\n",
        "        preloads=preloads,\n",
        "        use_jax=True,\n",
        "    )\n",
        "    for result, adapt_images in zip(source_lp_result, adapt_images_list)\n",
        "]\n",
        "\n",
        "source_pix_result_1 = slam_pipeline.source_pix.run_1(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    source_lp_result=source_lp_result,\n",
        "    mesh_init=af.Model(al.mesh.RectangularMagnification, shape=mesh_shape),\n",
        "    regularization_init=al.reg.AdaptiveBrightness,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SOURCE PIX PIPELINE 2 (with lens light)__\n",
        "\n",
        "The SOURCE PIX PIPELINE is identical to the `slam_start_here.ipynb` example, except with the same changes\n",
        "as the SOURCE PIX PIPELINE 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "adapt_images_list = []\n",
        "\n",
        "for result in source_pix_result_1:\n",
        "\n",
        "    galaxy_image_name_dict = al.galaxy_name_image_dict_via_result_from(result=result)\n",
        "    adapt_images = al.AdaptImages(galaxy_name_image_dict=galaxy_image_name_dict)\n",
        "\n",
        "    adapt_images_list.append(adapt_images)\n",
        "\n",
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_images=adapt_images,\n",
        "        preloads=preloads,\n",
        "        use_jax=True,\n",
        "    )\n",
        "    for result, adapt_images in zip(source_pix_result_1, adapt_images_list)\n",
        "]\n",
        "\n",
        "source_pix_result_2 = slam_pipeline.source_pix.run_2(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    source_lp_result=source_lp_result,\n",
        "    source_pix_result_1=source_pix_result_1,\n",
        "    mesh=af.Model(al.mesh.RectangularSource, shape=mesh_shape),\n",
        "    regularization=al.reg.AdaptiveBrightness,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__LIGHT LP PIPELINE__\n",
        "\n",
        "The LIGHT LP PIPELINE is setup identically to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_images=adapt_images,\n",
        "        preloads=preloads,\n",
        "        raise_inversion_positions_likelihood_exception=False,\n",
        "    )\n",
        "    for result, adapt_images in zip(source_pix_result_1, adapt_images_list)\n",
        "]\n",
        "\n",
        "lens_bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius,\n",
        "    total_gaussians=20,\n",
        "    gaussian_per_basis=2,\n",
        "    centre_prior_is_uniform=True,\n",
        ")\n",
        "\n",
        "light_result = slam_pipeline.light_lp.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    source_result_for_lens=source_pix_result_1,\n",
        "    source_result_for_source=source_pix_result_2,\n",
        "    lens_bulge=lens_bulge,\n",
        "    lens_disk=None,\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__MASS TOTAL PIPELINE__\n",
        "\n",
        "The MASS TOTAL PIPELINE is identical to the `slam_start_here.ipynb` example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "positions_likelihood = source_pix_result_1[0].positions_likelihood_from(\n",
        "    factor=3.0, minimum_threshold=0.2\n",
        ")\n",
        "\n",
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_images=adapt_images,\n",
        "        preloads=preloads,\n",
        "        positions_likelihood_list=[positions_likelihood],\n",
        "    )\n",
        "    for result, adapt_images in zip(source_pix_result_1, adapt_images_list)\n",
        "]\n",
        "\n",
        "mass_result = slam_pipeline.mass_total.run(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    source_result_for_lens=source_pix_result_1,\n",
        "    source_result_for_source=source_pix_result_2,\n",
        "    light_result=light_result,\n",
        "    mass=af.Model(al.mp.PowerLaw),\n",
        "    dataset_model=af.Model(al.DatasetModel),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__SUBHALO PIPELINE__\n",
        "\n",
        "The SUBHALO pipeline is described in `imaging/features/advanced/subhalo`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "analysis_list = [\n",
        "    al.AnalysisImaging(\n",
        "        dataset=result.max_log_likelihood_fit.dataset,\n",
        "        adapt_images=adapt_images,\n",
        "        preloads=preloads,\n",
        "        positions_likelihood_list=[positions_likelihood],\n",
        "    )\n",
        "    for result, adapt_images in zip(source_pix_result_1, adapt_images_list)\n",
        "]\n",
        "\n",
        "subhalo_result_1 = slam_pipeline.subhalo.detection.run_1_no_subhalo(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    mass_result=mass_result,\n",
        ")\n",
        "\n",
        "subhalo_grid_search_result_2 = slam_pipeline.subhalo.detection.run_2_grid_search(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    mass_result=mass_result,\n",
        "    subhalo_result_1=subhalo_result_1,\n",
        "    subhalo_mass=af.Model(al.mp.NFWMCRLudlowSph),\n",
        "    grid_dimension_arcsec=3.0,\n",
        "    number_of_steps=2,\n",
        ")\n",
        "\n",
        "subhalo_result_3 = slam_pipeline.subhalo.detection.run_3_subhalo(\n",
        "    settings_search=settings_search,\n",
        "    analysis_list=analysis_list,\n",
        "    subhalo_result_1=subhalo_result_1,\n",
        "    subhalo_grid_search_result_2=subhalo_grid_search_result_2,\n",
        "    subhalo_mass=af.Model(al.mp.NFWMCRLudlowSph),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}