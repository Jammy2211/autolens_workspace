{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start Here: Group\n",
        "=================\n",
        "\n",
        "Group scale lenses typically have a single \"main\" lens galaxy and 2-10 smaller extra galaxies nearby, whose light\n",
        "may blur with the source light and whose mass contributes significantly to the ray-tracing, meaning both are\n",
        "therefore included in the analysis, Groups typically also have just one lensed source.\n",
        "\n",
        "This script shows you how to model a group lens system using **PyAutoLens** with as little setup\n",
        "as possible. In about 15 minutes you\u2019ll be able to point the code at your own FITS files and\n",
        "fit your first group-scale lens.\n",
        "\n",
        "We focus on a *group-scale* lens (a single lens galaxy with some extra galaxies nearby). If you have a single\n",
        "lens galaxy, see the `start_here_imaging.ipynb` example, if your system has many lens and sources galaxies\n",
        "see `start_here_cluster.ipynb` example.\n",
        "\n",
        "This example uses Euclid CCD imaging data, but the workflow for interferometer data on group scale lenses is similar.\n",
        "The lens has only 2 extra galaxies, so the model is not too complex, meaning this example runs in about 10 minutes on a\n",
        "good GPU. More complex groups with more extra galaxies will take longer to fit, but the workflow is identical and\n",
        "PyAutoLens can efficient scale to these more complex systems.\n",
        "\n",
        "PyAutoLens uses JAX under the hood for fast GPU/CPU acceleration. If JAX is installed with GPU\n",
        "support, your fits will run much faster (a few minutes instead of an hour). If you don\u2019t have\n",
        "a GPU locally, consider Google Colab which provides free GPUs, so your modeling runs are much faster.\n",
        "\n",
        "Finally, we also show how to simulate strong lens groups. This is useful for practice, for\n",
        "building training datasets, or for investigating lensing effects in a controlled way.\n",
        "\n",
        "__Google Colab Setup__\n",
        "\n",
        "The introduction `start_here` examples are available on Google Colab, which allows you to run them in a web browser\n",
        "without manual local PyAutoLens installation.\n",
        "\n",
        "The code below should only been run if you are using Google Colab, it will install autolens and download\n",
        "files required to run the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    in_colab = True\n",
        "except ImportError:\n",
        "    in_colab = False\n",
        "\n",
        "if in_colab:\n",
        "\n",
        "    # Install required packages\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "                           \"autoconf\", \"autofit\", \"autoarray\", \"autogalaxy\", \"autolens\",\n",
        "                           \"pyvis==0.3.2\", \"dill==0.4.0\", \"jaxnnls\",\n",
        "                           \"pyprojroot==0.2.0\", \"nautilus-sampler==1.0.4\",\n",
        "                           \"timeout_decorator==0.5.0\", \"anesthetic==2.8.14\",\n",
        "                           \"--no-deps\"])\n",
        "\n",
        "    import os\n",
        "    from autoconf import conf\n",
        "\n",
        "    os.chdir(\"/content/autolens_workspace\")\n",
        "\n",
        "    conf.instance.push(\n",
        "        new_path=\"/content/autolens_workspace/config\",\n",
        "        output_path=\"/content/autolens_workspace/output\",\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Imports__\n",
        "\n",
        "Lets first import autolens, its plotting module and the other libraries we'll need.\n",
        "\n",
        "You'll see these imports in the majority of workspace examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%matplotlib inline\n",
        "from pyprojroot import here\n",
        "workspace_path = str(here())\n",
        "%cd $workspace_path\n",
        "print(f\"Working Directory has been set to `{workspace_path}`\")\n",
        "\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import autofit as af\n",
        "import autolens as al\n",
        "import autolens.plot as aplt"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Dataset__\n",
        "\n",
        "We begin by loading the dataset. Three ingredients are needed for lens modeling:\n",
        "\n",
        "1. The image itself (CCD counts).\n",
        "2. A noise-map (per-pixel RMS noise).\n",
        "3. The PSF (Point Spread Function).\n",
        "\n",
        "Here we use HST imaging of a Euclid group-scale strong lens. Replace these FITS paths with your own to\n",
        "immediately try modeling your data.\n",
        "\n",
        "The `pixel_scales` value converts pixel units into arcseconds. It is critical you set this\n",
        "correctly for your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset_name = \"102021990_NEG650312660474055399\"\n",
        "dataset_path = Path(\"dataset\") / \"group\" / dataset_name\n",
        "\n",
        "dataset = al.Imaging.from_fits(\n",
        "    data_path=dataset_path / \"data.fits\",\n",
        "    psf_path=dataset_path / \"psf.fits\",\n",
        "    noise_map_path=dataset_path / \"noise_map.fits\",\n",
        "    pixel_scales=0.1,\n",
        ")\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Main Galaxies and Extra Galaxies__\n",
        "\n",
        "For a group-scale lens, we designate there to be two types of lens galaxies in the system:\n",
        "\n",
        " - `main_galaxy`: The main lens galaxy which likely make up the majority of light and mass in the lens system.\n",
        " These are modeled individually with a unique name for each, with their light and mass distributions modeled using \n",
        " parametric models.\n",
        " \n",
        " - `extra_galaxies`: The extra galaxies which are nearby the group lens system, whose mass contribute to the lensing \n",
        " of the source galaxy. These are modeled with a more restrictive model, for example with their are centres fixed to the \n",
        " observed centre of light. These are grouped into a single `extra_galaxies` collection.\n",
        " \n",
        "__Centres__\n",
        "\n",
        "For group-scale lenses we must manually specify the centres of the extra galaxies, which are fixed to the observed\n",
        "centres of light of the galaxies. This is integral to ensuring the lens model can be fitted accurately, without these\n",
        "centres being input there is a high chance the model will not converge to the correct solution.\n",
        "\n",
        "In this example, we simply load the centres from a .json file contained in the dataset folder. After modeling the\n",
        "data, this example will provide a GUI for you to determine the centres of the extra galaxies in your own data,\n",
        "if they are not already known."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "extra_galaxies_centres = al.from_json(\n",
        "    file_path=dataset_path / \"extra_galaxies_centres.json\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Masking__\n",
        "\n",
        "Lens modeling does not need to fit the entire image, only the region containing lens and\n",
        "source light, and the light of extra galaxies in the group. We therefore define a circular mask around all galaxies.\n",
        "\n",
        "- Make sure the mask fully encloses the lensed arcs, lens galaxy and extra galaxies.\n",
        "- Avoid masking too much empty sky, as this slows fitting without adding information.\n",
        "\n",
        "We\u2019ll also oversample the central pixels, which improves modeling accuracy without adding\n",
        "unnecessary cost far from the lens. Over sampling is also applied to the extra galaxies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mask_radius = 3.7\n",
        "\n",
        "mask = al.Mask2D.circular(\n",
        "    shape_native=dataset.shape_native,\n",
        "    pixel_scales=dataset.pixel_scales,\n",
        "    radius=mask_radius,\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_mask(mask=mask)\n",
        "\n",
        "# Over sampling is important for accurate lens modeling, but details are omitted\n",
        "# for simplicity here, so don't worry about what this code is doing yet!\n",
        "\n",
        "over_sample_size = al.util.over_sample.over_sample_size_via_radial_bins_from(\n",
        "    grid=dataset.grid,\n",
        "    sub_size_list=[4, 2, 1],\n",
        "    radial_list=[0.3, 0.6],\n",
        "    centre_list=[(0.0, 0.0)] + extra_galaxies_centres.in_list,\n",
        ")\n",
        "\n",
        "dataset = dataset.apply_over_sampling(over_sample_size_lp=over_sample_size)\n",
        "\n",
        "dataset_plotter = aplt.ImagingPlotter(dataset=dataset)\n",
        "dataset_plotter.subplot_dataset()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model__\n",
        "\n",
        "To perform lens modeling we must define a lens model, describing the light profiles of the lens and source galaxies,\n",
        "and the mass profile of the lens galaxy. This includes the mass of the groups extra galaxies.\n",
        "\n",
        "A brilliant lens model to start with is one which uses a Multi Gaussian Expansion (MGE) to model the lens and source\n",
        "light, and a Singular Isothermal Ellipsoid (SIE) plus shear to model the lens mass. \n",
        "\n",
        "Full details of why this models is so good are provided in the main workspace docs, but in a nutshell it \n",
        "provides an excellent balance of being fast to fit, flexible enough to capture complex galaxy morphologies and \n",
        "providing accurate fits to the vast majority of strong lenses. For group scale lenses, the MGE allows us to fit\n",
        "the light of extra galaxies without increasing the number of free parameters in the model.\n",
        "\n",
        "The MGE model composition API is quite long and technical, so we simply load the MGE models for the lens and source \n",
        "below via a utility function `mge_model_from` which hides the API to make the code in this introduction example ready \n",
        "to read. We then use the PyAutoLens Model API to compose the over lens model.\n",
        " \n",
        "Note how we also loop over the extra galaxy centres, creating an MGE light model and SIE mass model for each extra \n",
        "galaxy fixed to the input centre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Main Lens:\n",
        "\n",
        "bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius, total_gaussians=20, centre_prior_is_uniform=True\n",
        ")\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, bulge=bulge, mass=mass, shear=shear)\n",
        "\n",
        "# Extra Galaxies\n",
        "\n",
        "extra_galaxies_list = []\n",
        "\n",
        "for extra_galaxy_centre in extra_galaxies_centres:\n",
        "\n",
        "    # Extra Galaxy Light\n",
        "\n",
        "    bulge = al.model_util.mge_model_from(\n",
        "        mask_radius=mask_radius,\n",
        "        total_gaussians=10,\n",
        "        centre_fixed=extra_galaxy_centre,\n",
        "        use_spherical=True,\n",
        "    )\n",
        "\n",
        "    # Extra Galaxy Mass\n",
        "\n",
        "    mass = af.Model(al.mp.IsothermalSph)\n",
        "\n",
        "    mass.centre = extra_galaxy_centre\n",
        "    mass.einstein_radius = af.UniformPrior(lower_limit=0.0, upper_limit=0.5)\n",
        "\n",
        "    # Extra Galaxy\n",
        "\n",
        "    extra_galaxy = af.Model(al.Galaxy, redshift=0.5, bulge=bulge, mass=mass)\n",
        "\n",
        "    extra_galaxies_list.append(extra_galaxy)\n",
        "\n",
        "extra_galaxies = af.Collection(extra_galaxies_list)\n",
        "\n",
        "# Source:\n",
        "\n",
        "bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius,\n",
        "    total_gaussians=20,\n",
        "    gaussian_per_basis=1,\n",
        "    centre_prior_is_uniform=False,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=bulge)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(\n",
        "    galaxies=af.Collection(lens=lens, source=source), extra_galaxies=extra_galaxies\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can print the model to show the parameters that the model is composed of, which shows many of the MGE's fixed\n",
        "parameter values the API above hided the composition of."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__\n",
        "\n",
        "We now fit the data with the lens model using the non-linear fitting method and nested sampling algorithm Nautilus.\n",
        "\n",
        "This requires an `AnalysisImaging` object, which defines the `log_likelihood_function` used by Nautilus to fit\n",
        "the model to the imaigng data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"group\"),  # The path where results and output are stored.\n",
        "    name=\"start_here\",  # The name of the fit and folder results are output to.\n",
        "    unique_tag=dataset_name,  # A unique tag which also defines the folder.\n",
        "    n_live=150,  # The number of Nautilus \"live\" points, increase for more complex models.\n",
        "    n_batch=50,  # For fast GPU fitting lens model fits are batched and run simultaneously.\n",
        "    iterations_per_full_update=100000,  # Every N iterations the results are written to hard-disk for inspection.\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisImaging(dataset=dataset)\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Result__\n",
        "\n",
        "Now this is running you should checkout the `autolens_workspace/output` folder, where many results of the fit\n",
        "are written in a human readable format (e.g. .json files) and .fits and .png images of the fit are stored.\n",
        "\n",
        "When the fit is complex, we can print the results by printing `result.info`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(result.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result also contains the maximum likelihood lens model which can be used to plot the best-fit lensing information\n",
        "and fit to the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tracer_plotter = aplt.TracerPlotter(\n",
        "    tracer=result.max_log_likelihood_tracer, grid=result.grids.lp\n",
        ")\n",
        "tracer_plotter.subplot_tracer()\n",
        "\n",
        "fit_plotter = aplt.FitImagingPlotter(fit=result.max_log_likelihood_fit)\n",
        "fit_plotter.subplot_fit()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The result object contains pretty much everything you need to do science with your own strong lens, but details\n",
        "of all the information it contains are beyond the scope of this introductory script. The `guides` and `result` \n",
        "packages of the workspace contains all the information you need to analyze your results yourself.\n",
        "\n",
        "__Centre Input GUI__\n",
        "\n",
        "The centres of the extra galaxies above were loaded from a .json file, which was create using a GUI where one simply\n",
        "clicks the centres of the extra galaxies on the image. \n",
        "\n",
        "For your own group lens, if you do not know the centres of the extra galaxies already, you can use the GUI below\n",
        "to do this yourself. It will output a .json file in the dataset folder you can then load and use in the model above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search_box_size = (\n",
        "    3  # Size of the search box to find the brightest pixel around your click\n",
        ")\n",
        "\n",
        "try:\n",
        "    clicker = al.Clicker(\n",
        "        image=dataset.data,\n",
        "        pixel_scales=dataset.pixel_scales,\n",
        "        search_box_size=search_box_size,\n",
        "    )\n",
        "\n",
        "    extra_galaxies_centres = clicker.start(\n",
        "        data=dataset.data,\n",
        "        pixel_scales=dataset.pixel_scales,\n",
        "    )\n",
        "\n",
        "    al.output_to_json(\n",
        "        file_path=dataset_path / \"extra_galaxies_centres.json\",\n",
        "        obj=extra_galaxies_centres,\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(\n",
        "        \"\"\"\n",
        "        Problem loading GUI, probably an issue with TKinter or your matplotlib TKAgg backend.\n",
        "        \n",
        "        You will likely need to try and fix or reinstall various GUI / visualization libraries, or try\n",
        "        running this example not via a Jupyter notebook.\n",
        "        \n",
        "        There are also manual tools for performing this task in the workspace.\n",
        "        \"\"\"\n",
        "    )\n",
        "    print()\n",
        "    print(e)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Your Own Lens__\n",
        "\n",
        "If you have your own strong lens imaging data, you are now ready to model it yourself by adapting the code above\n",
        "and simply inputting the path to your own .fits files into the `Imaging.from_fits()` function.\n",
        "\n",
        "A few things to note, with full details on data preparation provided in the main workspace documentation:\n",
        "\n",
        "- Supply your own CCD image, PSF, and RMS noise-map.\n",
        "- Ensure the lens galaxy is roughly centered in the image.\n",
        "- Ensure you input the centres of the extra galaxies in the group correctly.\n",
        "- Double-check `pixel_scales` for your telescope/detector.\n",
        "- Adjust the mask radius to include all relevant light.\n",
        "- Start with the default model \u2014 it works very well for pretty much all group with < 5 extra galaxies!\n",
        "\n",
        "__Scaling Relations__\n",
        "\n",
        "This example above models the mass of each galaxy individually, which means the number of dimensions of the model \n",
        "increases as we model group scale lenses with more galaxies. This can lead to a model that is slow to fit and poorly \n",
        "constrained. There may also not be enough information in the data to constrain every galaxy's mass.\n",
        "\n",
        "A common approach to overcome this is to put many of the extra galaxies a scaling relation, where the mass of the \n",
        "galaxies are related to their light via a observationally motivated scaling relation. This means that as more \n",
        "galaxies are included in the lens model, the dimensionality of the model does not increase. Furthermore, their \n",
        "luminosities act as priors on their masses, which helps ensure the model is well constrained.\n",
        "\n",
        "We now perform a fit using this scaling relation approach. Instead of the SIE model used for extra galaxies above,\n",
        "we instead model the mass of ech extra galaxy using the dual Pseudo-Isothermal Elliptical (dPIE)\n",
        "mass distribution introduced in Eliasdottir 2007: https://arxiv.org/abs/0710.5636.\n",
        "\n",
        "It relates the luminosity of every galaxy to a cut radius (r_cut), a core radius (r_core) and a mass normaliaton b0:\n",
        "\n",
        "$r_cut = r_cut^* (L/L^*)^{0.5}$\n",
        "\n",
        "$r_core = r_core^* (L/L^*)^{0.5}$\n",
        "\n",
        "$b0 = b0^* (L/L^*)^{0.25}$\n",
        "\n",
        "The free parameters are therefore L^*, r_cut^*, r_core^* and b0^*.\n",
        "\n",
        "We use this model because it is commonly used in studies of lensing groups and clusters to put member galaxies on a\n",
        "scaling relation, thus it is more consistent with previous literature!\n",
        "\n",
        "To perform scaling relation lens modeling, the luminosity of every member galaxy must have been measured and is input\n",
        "below. If you want to put your own lens into this example, you'll need to have the luminosities measured yourself\n",
        "already. Note also that the code below could easily be adapted to use stellar masses or velocity dispersions,\n",
        "if you have those measurements instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "extra_galaxies_luminosity_list = [1e9, 1e9]\n",
        "\n",
        "ra_star = af.LogUniformPrior(lower_limit=1e8, upper_limit=1e11)\n",
        "rs_star = af.UniformPrior(lower_limit=-1.0, upper_limit=1.0)\n",
        "b0_star = af.LogUniformPrior(lower_limit=1e5, upper_limit=1e7)\n",
        "luminosity_star = 1e9\n",
        "\n",
        "extra_galaxies_list = []\n",
        "\n",
        "for extra_galaxy_centre, extra_galaxy_luminosity in zip(\n",
        "    extra_galaxies_centres.in_list, extra_galaxies_luminosity_list\n",
        "):\n",
        "\n",
        "    mass = af.Model(al.mp.dPIEMassSph)\n",
        "\n",
        "    mass.centre = extra_galaxy_centre\n",
        "\n",
        "    mass.ra = ra_star * (extra_galaxy_luminosity / luminosity_star) ** 0.5\n",
        "    mass.rs = rs_star * (extra_galaxy_luminosity / luminosity_star) ** 0.5\n",
        "    mass.b0 = b0_star * (extra_galaxy_luminosity / luminosity_star) ** 0.25\n",
        "\n",
        "    extra_galaxy = af.Model(al.Galaxy, redshift=0.5, mass=mass)\n",
        "\n",
        "    extra_galaxies_list.append(extra_galaxy)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Model Fit__\n",
        "\n",
        "We now compose the model using the same API as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Main Lens:\n",
        "\n",
        "bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius, total_gaussians=20, centre_prior_is_uniform=True\n",
        ")\n",
        "\n",
        "mass = af.Model(al.mp.Isothermal)\n",
        "\n",
        "shear = af.Model(al.mp.ExternalShear)\n",
        "\n",
        "lens = af.Model(al.Galaxy, redshift=0.5, bulge=bulge, mass=mass, shear=shear)\n",
        "\n",
        "# Source:\n",
        "\n",
        "bulge = al.model_util.mge_model_from(\n",
        "    mask_radius=mask_radius,\n",
        "    total_gaussians=20,\n",
        "    gaussian_per_basis=1,\n",
        "    centre_prior_is_uniform=False,\n",
        ")\n",
        "\n",
        "source = af.Model(al.Galaxy, redshift=1.0, bulge=bulge)\n",
        "\n",
        "# Overall Lens Model:\n",
        "\n",
        "model = af.Collection(\n",
        "    galaxies=af.Collection(lens=lens, source=source), extra_galaxies=extra_galaxies\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "the `model.info` shows that this scaling relation has been used to setup the galaxy parameters.\n",
        "\n",
        "Note how, although there are only 2 extra galaxies, adding extra galaxies now *no longer adds any free parameters** to\n",
        "the model complexity!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(model.info)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now fit the model using the scaling relation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "search = af.Nautilus(\n",
        "    path_prefix=Path(\"group\"),  # The path where results and output are stored.\n",
        "    name=\"start_here_scaling_relation\",  # The name of the fit and folder results are output to.\n",
        "    unique_tag=dataset_name,  # A unique tag which also defines the folder.\n",
        "    n_live=100,  # The number of Nautilus \"live\" points, increase for more complex models.\n",
        "    n_batch=50,  # For fast GPU fitting lens model fits are batched and run simultaneously.\n",
        "    iterations_per_full_update=100000,  # Every N iterations the results are written to hard-disk for inspection.\n",
        ")\n",
        "\n",
        "analysis = al.AnalysisImaging(dataset=dataset)\n",
        "\n",
        "result = search.fit(model=model, analysis=analysis)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__Simulator__\n",
        "\n",
        "In the galaxy-scale examples (`start_here_imaging.ipynb`, `start_here_interferometer.ipynb`, `start_here_point_source.ipynb`)\n",
        "we illustrate how to simulate strong lens images. \n",
        "\n",
        "For group scale lenses, we omit this, as it is quite techinical and long. The `autolens_workspace/*/group/simulator` \n",
        "package has examples of how to simulate group scale lenses if you are interested.\n",
        "\n",
        "__Wrap Up__\n",
        "\n",
        "This script has shown how to model CCD imaging data of group-scale strong lenses.\n",
        "\n",
        "Details of the **PyAutoLens** API and how lens modeling works were omitted for simplicity, but everything you need to \n",
        "know is described throughout the main workspace documentation. You should check it out, but maybe you want to try and \n",
        "model your own lens first!\n",
        "\n",
        "The following locations of the workspace are good places to checkout next:\n",
        "\n",
        "- `autolens_workspace/*/modeling/group`: A full description of the lens modeling API and how to customize your model-fits.\n",
        "- `autolens_workspace/*/simulators/group`: A full description of the lens simulation API and how to customize your simulations.\n",
        "- `autolens_workspace/*/data_preparation/group`: How to load and prepare your own imaging data for lens modeling.\n",
        "- `autolens_workspace/results`: How to load and analyze the results of your lens model fits, including tools for large samples.\n",
        "- `autolens_workspace/guides`: A complete description of the API and information on lensing calculations and units.\n",
        "- `autolens_workspace/feature`: A description of advanced features for lens modeling, for example pixelized source reconstructions, read this once you're confident with the basics!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}