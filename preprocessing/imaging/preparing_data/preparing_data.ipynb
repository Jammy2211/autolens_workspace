{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading and Preparing Data__\n",
    "\n",
    "To model data with PyAutoLens you first need to ensure it is in a format suitable for lens modeling. This tutorial takes you through data preparation, introducing PyAutoLens's built in tools that convert data to a suitable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autofit as af\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import autolens as al\n",
    "import autolens.plot as aplt\n",
    "\n",
    "from tools.loading_and_preparing_data import simulate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets setup the path to our current working directory. I recommend you use the 'autolens_workspace' directory and place data in the 'autolens_workspace/data' directory.\n",
    "\n",
    "For this tutorial, we'll use the 'autolens_workspace/tools/loading_and_preparing_data/data' directory. The folder 'data' contains example data we'll use in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (\n",
    "    \"path/to/AutoLens/autolens_workspace/tools/loading_and_preparing_data/\"\n",
    ")  # <----- You must include this slash on the end\n",
    "path = \"/home/jammy/PycharmProjects/PyAuto/autolens_workspace/tools/loading_and_preparing_data/\"\n",
    "\n",
    "dataset_path = af.path_util.make_and_return_path_from_path_and_folder_names(\n",
    "    path=path, folder_names=[\"data\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This populates the 'data' path with example simulated imaging data-sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_data.simulate_all_imaging(\n",
    "    dataset_path=dataset_path\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading Data From Individual Fits Files__\n",
    "\n",
    "First, lets load a data-set using the 'load_imaging_from_fits' function of the imaging module. This data-set represents a good data-reduction that conforms to the formatting standards I describe in this tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_path = af.path_util.make_and_return_path_from_path_and_folder_names(\n",
    "    path=dataset_path, folder_names=[\"imaging\"]\n",
    ")\n",
    "\n",
    "imaging = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"image.fits\",\n",
    "    noise_map_path=imaging_path + \"noise_map.fits\",\n",
    "    psf_path=imaging_path + \"psf.fits\",\n",
    "    pixel_scales=0.1,\n",
    ")\n",
    "\n",
    "aplt.imaging.subplot_imaging(imaging=imaging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading Data From Multiple HDUs__\n",
    "\n",
    "If your data comes in one .fits file spread across multiple hdus you can specify the hdus of each image instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"multiple_hdus.fits\",\n",
    "    image_hdu=0,\n",
    "    noise_map_path=imaging_path + \"multiple_hdus.fits\",\n",
    "    noise_map_hdu=1,\n",
    "    psf_path=imaging_path + \"multiple_hdus.fits\",\n",
    "    psf_hdu=2,\n",
    "    pixel_scales=0.1,\n",
    ")\n",
    "\n",
    "aplt.imaging.subplot_imaging(imaging=imaging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Converting Data To Electrons Per Second__\n",
    "\n",
    "Lets think about the format of our data. There are numerous reasons why the image we just looked at is a good data-set  for lens modeling. I strongly recommend you reduce your data to conform to the standards discussed below - it'll make  your time using PyAutoLens a lot simpler.\n",
    "\n",
    "However, you may not have access to the data-reduction tools that made the data, so we've included a number of in-built functions in PyAutoLens to convert the data to a good format for you. However, your life will be much easier if you can just reduce it this way in the first place!\n",
    "\n",
    "1) Brightness unit_label - the image's flux and noise-map values are in unit_label of electrons per second (not electrons, counts, ADU's etc.). Although PyAutoLens can technically perform an analysis using other unit_label, the default setup assume the image is in electrons per second (e.g. the priors on light profile image and regularization coefficient). Thus, images not in electrons per second should be converted!\n",
    "\n",
    "Lets look at an image that is in unit_label of counts - its easy to tell because the peak values are in the 1000's or 10000's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_path = af.path_util.make_and_return_path_from_path_and_folder_names(\n",
    "    path=dataset_path, folder_names=[\"imaging_in_counts\"]\n",
    ")\n",
    "\n",
    "imaging_in_counts = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"image.fits\",\n",
    "    pixel_scales=0.1,\n",
    "    noise_map_path=imaging_path + \"noise_map.fits\",\n",
    "    psf_path=imaging_path + \"psf.fits\",\n",
    ")\n",
    "\n",
    "aplt.imaging.subplot_imaging(imaging=imaging_in_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The effective exposure time in each pixel may vary. This occurs when data is reduced using 'dithering' and 'drizzling'. If you have access to an effective exposure-time map, you can use this to convert the image to electrons per second instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_converted_to_eps = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"image.fits\",\n",
    "    pixel_scales=0.1,\n",
    "    noise_map_path=imaging_path + \"noise_map.fits\",\n",
    "    psf_path=imaging_path + \"psf.fits\",\n",
    "    exposure_time_map_path=imaging_path + \"exposure_time_map.fits\",\n",
    "    convert_from_electrons=True,\n",
    ")\n",
    "aplt.imaging.subplot_imaging(imaging=imaging_converted_to_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Trimming Data__\n",
    "\n",
    "Postage stamp size - The bigger the postage stamp cut-out of the image the more memory it requires to store it. Why keep the edges surrounding the lens if they are masked out anyway?\n",
    "\n",
    "Lets look at an example of a very large postage stamp - we can barely even see the lens and source galaxies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_path = af.path_util.make_and_return_path_from_path_and_folder_names(\n",
    "    path=dataset_path, folder_names=[\"imaging_with_large_stamp\"]\n",
    ")\n",
    "\n",
    "imaging_large_stamp = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"image.fits\",\n",
    "    pixel_scales=0.1,\n",
    "    noise_map_path=imaging_path + \"noise_map.fits\",\n",
    "    psf_path=imaging_path + \"psf.fits\",\n",
    ")\n",
    "\n",
    "aplt.imaging.subplot_imaging(imaging=imaging_large_stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a large postage stamp you can trim it when you load the data by specifying a new image size in pixels. This will also trim the noise-map, exposoure time map and other arrays which are the same dimensions as the image. This trimming is centred on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_large_stamp_trimmed = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"image.fits\",\n",
    "    pixel_scales=0.1,\n",
    "    noise_map_path=imaging_path + \"noise_map.fits\",\n",
    "    psf_path=imaging_path + \"psf.fits\",\n",
    "    resized_imaging_shape=(101, 101),\n",
    ")\n",
    "\n",
    "aplt.imaging.subplot_imaging(imaging=imaging_large_stamp_trimmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Padding Data__\n",
    "\n",
    "Postage stamp size (again). The stamp may also be too small - for example it must have enough padding in the border that our mask includes all pixels with signal. In fact, this padding must also include the a 'blurring region', corresponding to all unmasked image pixels where light blurs into the masks after PSF convolution. Thus, we may need to pad an image to include this region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_path = af.path_util.make_and_return_path_from_path_and_folder_names(\n",
    "    path=dataset_path, folder_names=[\"imaging_with_small_stamp\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image is an example of a stamp which is big enough to contain the lens and source galaxies, but when we apply a sensible masks we get an error, because the masks's blurring region goes into the edge of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_small_stamp = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"image.fits\",\n",
    "    pixel_scales=0.1,\n",
    "    noise_map_path=imaging_path + \"noise_map.fits\",\n",
    "    psf_path=imaging_path + \"psf.fits\",\n",
    ")\n",
    "\n",
    "aplt.imaging.subplot_imaging(imaging=imaging_small_stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply a masks to this image we get an error when we try to use it to set up a lensing image because its blurring region hits the image edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = al.mask.circular(\n",
    "    shape_2d=imaging_small_stamp.shape,\n",
    "    pixel_scales=imaging_small_stamp.pixel_scales,\n",
    "    radius=2.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives an error because the mask's blurring region hits an edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_imaging = al.masked.imaging(imaging=imaging_small_stamp, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We overcome this using the same input as before. However, now, the resized image shape is bigger than the image, thus a padding of zeros is introduced to the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_small_stamp_padded = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"image.fits\",\n",
    "    pixel_scales=0.1,\n",
    "    noise_map_path=imaging_path + \"noise_map.fits\",\n",
    "    psf_path=imaging_path + \"psf.fits\",\n",
    "    resized_imaging_shape=(140, 140),\n",
    ")\n",
    "\n",
    "mask = al.mask.circular(\n",
    "    shape_2d=imaging_small_stamp_padded.shape,\n",
    "    pixel_scales=imaging_small_stamp_padded.pixel_scales,\n",
    "    radius=2.0,\n",
    ")\n",
    "\n",
    "aplt.imaging.subplot_imaging(imaging=imaging_small_stamp_padded, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This no longer gives an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_imaging = al.masked.imaging(\n",
    "    imaging=imaging_small_stamp_padded, mask=mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __Centering__\n",
    "\n",
    "########## IVE INCLUDED THE TEXT FOR 5 BELOW SO YOU CAN BE AWARE OF CENTERING, BUT THE BUILT IN FUNCTIONALITY FOR #####\n",
    "########## RECENTERING CURRENTLY DOES NOT WORK :( ###########\n",
    "\n",
    "# 5) Lens Galaxy Centering - The lens galaxy should be in the centre of the image as opposed to a corner. This ensures\n",
    "#    the origin of the lens galaxy's light and mass profiles are near the origin (0.0\", 0.0\") of the grid used to perform\n",
    "#    ray-tracing. The defaults priors on light and mass profiles assume a origin of (0.0\", 0.0\").\n",
    "\n",
    "# Lets look at an off-center image - clearly both the lens galaxy and Einstein ring are offset in the positive y and x d\n",
    "# directions.\n",
    "\n",
    "# imaging_path = af.path_util.make_and_return_path_from_path_and_folder_names(path=dataset_path,\n",
    "#                                                                           folder_names=['imaging_offset_centre'])\n",
    "\n",
    "# imaging_offset_centre = al.imaging.from_fits(image_path=path+'image.fits', pixel_scales=0.1,\n",
    "#                                   noise_map_path=path+'noise_map.fits',\n",
    "#                                   psf_path=path+'psf.fits')\n",
    "# aplt.imaging.subplot(imaging=imaging_offset_centre)\n",
    "\n",
    "# We can address this by using supplying a new centre for the image, in pixels. We also supply the resized shape, to\n",
    "# instruct the code whether it should trim the image or pad the edges that now arise due to recentering.\n",
    "\n",
    "# imaging_recentred_pixels = al.imaging.from_fits(image_path=path+'image.fits', pixel_scales=0.1,\n",
    "#                                             noise_map_path=path+'noise_map.fits',\n",
    "#                                             psf_path=path+'psf.fits',\n",
    "#                                             resized_imaging_shape=(100, 100),\n",
    "#                                             resized_imaging_centre_pixels=(0, 0))\n",
    "# #                                            resized_imaging_centre_arc_seconds=(1.0, 1.0))\n",
    "# print(imaging_recentred_pixels.shape)\n",
    "# aplt.imaging.subplot(imaging=imaging_recentred_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Noise Rescaling__\n",
    "\n",
    "The noise-map values are the RMS standard deviation in every pixel (and not the variances, HST WHT-map values, etc.). You MUST be 100% certain that the noise_map map is the RMS standard deviations or else your analysis will be incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways the noise-map can be reduced. We are aiming to include conversion functions for all common data-reductions. Currently, we have a function to convert an image from a HST WHT map, where RMS SD = 1.0/ sqrt(WHT). This can be called using the 'convert_noise_map_from_weight_map' flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_path = af.path_util.make_and_return_path_from_path_and_folder_names(\n",
    "    path=dataset_path, folder_names=[\"imaging_with_large_stamp\"]\n",
    ")\n",
    "\n",
    "imaging_noise_from_wht = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"image.fits\",\n",
    "    pixel_scales=0.1,\n",
    "    noise_map_path=imaging_path + \"noise_map.fits\",\n",
    "    psf_path=imaging_path + \"psf.fits\",\n",
    "    convert_noise_map_from_weight_map=True,\n",
    ")\n",
    "\n",
    "aplt.imaging.subplot_imaging(imaging=imaging_noise_from_wht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I don't currently have an example image in WHT for this tutorial, but the function above will work. Above, it actually converts an accurate noise-map to an inverse WHT map!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PSF Size__\n",
    "\n",
    "The PSF zooms around its central core, which is the most important region for strong lens modeling. By default, the size of the PSF image is used to perform convolution. The larger this stamp, the longer this convolution will take to run. In general, we would recommend the PSF size is 21 x 21.\n",
    "\n",
    "Lets look at an image where a large PSF kernel is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_path = af.path_util.make_and_return_path_from_path_and_folder_names(\n",
    "    path=dataset_path, folder_names=[\"imaging_with_large_psf\"]\n",
    ")\n",
    "\n",
    "imaging_with_large_psf = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"image.fits\",\n",
    "    pixel_scales=0.1,\n",
    "    noise_map_path=imaging_path + \"noise_map.fits\",\n",
    "    psf_path=imaging_path + \"psf.fits\",\n",
    ")\n",
    "\n",
    "aplt.imaging.subplot_imaging(imaging=imaging_with_large_psf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can resize a psf the same way that we resize an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_with_trimmed_psf = al.imaging.from_fits(\n",
    "    image_path=imaging_path + \"image.fits\",\n",
    "    pixel_scales=0.1,\n",
    "    noise_map_path=imaging_path + \"noise_map.fits\",\n",
    "    psf_path=imaging_path + \"psf.fits\",\n",
    "    resized_psf_shape=(21, 21),\n",
    ")\n",
    "\n",
    "aplt.imaging.subplot_imaging(imaging=imaging_with_trimmed_psf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PSF Dimensions__\n",
    "\n",
    "The PSF dimensions are odd x odd (21 x 21). It is important that the PSF dimensions are odd, because even-sized PSF kernels introduce a half-pixel offset in the convolution routine which can lead to systematics in the lens analysis.\n",
    "\n",
    "We do not currently have built-in functionality to address this issue. Therefore, if your PSF has an even dimension you must manually trim and recentre it. If you need help on doing this, contact me on the PyAutoLens SLACK channel, as I'll have already written the routine to do this by the time you read this tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
